<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Untitled Post - 1</title>
    <url>/2013/11/04/3781/</url>
    <content><![CDATA[<p>kernel 3.12 released!</p>
<p>发自 WordPress for Android</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 2</title>
    <url>/2013/11/07/3975/</url>
    <content><![CDATA[<p>全角空格的unciode码为\u3000,因此可以这样在vim中过滤全角空格<br>:%s/\%u3000//g</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 3</title>
    <url>/2013/11/08/4010/</url>
    <content><![CDATA[<p>BASH的命令替换有两种方式，传统的方式为使用后置引用`command`,但这种方式不能嵌套，还有一种方式是$(command),这种方式可以嵌套。命令替换会产生一个子shell进程。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 4</title>
    <url>/2013/11/09/4012/</url>
    <content><![CDATA[<p>游标(Cursor)不就是个结果集迭代器 (Iterator)嘛</p>
<p>发自 WordPress for Android</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 5</title>
    <url>/2013/11/09/4014/</url>
    <content><![CDATA[<p>Less is more.</p>
<p>发自 WordPress for Android</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 6</title>
    <url>/2013/11/09/4017/</url>
    <content><![CDATA[<p>HTML5中,script标签的type属性不是必须的，<a href="http://www.w3.org/html/wg/drafts/html/master/scripting-1.html#script">默认为text/javascript</a>,如果拼错了反而会出现问题，因此不要为script标签写type属性。引入样式表的<a href="http://www.w3.org/html/wg/drafts/html/master/document-metadata.html#the-link-element">link标签</a>，也就是其rel为”stylesheet”的link标签，其type属性也是可以省略的。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 7</title>
    <url>/2013/11/10/4025/</url>
    <content><![CDATA[<p>HTML5需要一个文件包含标签，比如这样，<include src="sidebar.html">,为了这点事儿预处理值得吗？忍忍吧！</p>
<p>发自 WordPress for Android</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 8</title>
    <url>/2013/11/11/4059/</url>
    <content><![CDATA[<p>media queries本质就是通过质询(获取文档的)设备的不同特性，应用不同的样式。这也是responsive design的基石。</p>
<p>发自 WordPress for Android</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 9</title>
    <url>/2013/11/14/4101/</url>
    <content><![CDATA[<p>python特别是3真是个好东西。</p>
<p>发自 WordPress for Android</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 10</title>
    <url>/2013/11/16/4114/</url>
    <content><![CDATA[<p>JavaScript 中局部变量只可能通过两种方式声明，一个是作为函数参数，另一个是通过 var 关键字声明。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 11</title>
    <url>/2013/11/19/4240/</url>
    <content><![CDATA[<p>Java EE Kepler Service Release 1版自带的EGIT仍然不支持符号链接，将符号连接视为脏文件，用.gitignore忽略掉符号链接都没用，只能从EGIT team-&gt;advanced里将符号连接设置为”Assume Anchanged”。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 12</title>
    <url>/2013/11/23/4263/</url>
    <content><![CDATA[<p>JAVA boolean类型变量最好不要以is开头，否则可能会出现很多意想不到的问题。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 13</title>
    <url>/2013/11/23/4272/</url>
    <content><![CDATA[<p>PostgreSQL重设serial类型主键从1开始。PostgreSQL为serial类型字段默认生成的序列sequence的名字为<table>_<cloumn><em>seq,可以用这个命令重设：ALTER SEQUENCE <table></em><cloumn>_seq RESTART WITH 1;</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 14</title>
    <url>/2013/11/23/4285/</url>
    <content><![CDATA[<p>PostgeSQL有serial字段的表插入记录时，要么不提供serial字段，要么为serial字段提供DEFAULT这个值。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 15</title>
    <url>/2013/11/24/4288/</url>
    <content><![CDATA[<p>没有最佳的设计，只有最合适的设计。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 16</title>
    <url>/2013/11/24/4302/</url>
    <content><![CDATA[<p>from spring:</p>
<blockquote>
<p>Typically one does not configure fine-grained domain objects in the container, because it is usually the responsibility of DAOs and business logic to create and load domain objects.</p>
</blockquote>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 17</title>
    <url>/2013/11/24/4316/</url>
    <content><![CDATA[<p>批量查找文件内的字符串，并输出结果的行号，可以这样find . -name “*.foo” xargs grep -n -s ‘bar’或者grep -n -s ‘bar’ `find . -name “*.foo”`</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 18</title>
    <url>/2013/11/25/4353/</url>
    <content><![CDATA[<p>jQuery对象(实际是jQuery.fn.init对象)并不会继承jQuery.xxx这些jQuery名字空间下的函数，但可以调用这些函数，因为所有人都可以调用。jQuery.xxx函数只是使用了jQuery作为名字空间，避免了全局名字空间污染而已。当用普通方式调用jQuery.xxx函数时,this指针指向jQuery函数对象自身。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 19</title>
    <url>/2013/11/27/4358/</url>
    <content><![CDATA[<p>过早优化是万恶之源(premature optimization is the root of all evil)</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 20</title>
    <url>/2013/12/11/4469/</url>
    <content><![CDATA[<p>发现一个python跨平台RAD框架<a href="http://kivy.org/">Kivy</a>,支持各种touch输入设备,支持GPU加速,可以用来开发各种革新性的现代用户界面。MIT授权，可以运行在Linux, Windows,Mac OS X,Android和iOS平台，只是还不支持python3。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 21</title>
    <url>/2013/12/11/4472/</url>
    <content><![CDATA[<p><a href="https://github.com/alejandroautalan/pygubu">pygubu</a>,python tkinter的可视化界面设计器，看样子还不是太成熟,tkinter好像就没有成熟好用的可视化GUI编辑器。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 22</title>
    <url>/2013/12/12/4477/</url>
    <content><![CDATA[<p><a href="http://www.bitflipper.ca/rapyd/">Rapyd-Tk</a>( Rapid python development with Tkinter) 也不支持python3,看来只能用<a href="https://wiki.python.org/moin/TkInter">Tkinter</a>了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 23</title>
    <url>/2013/12/14/4488/</url>
    <content><![CDATA[<p><a href="http://florence.sourceforge.net/english.html">Florence</a>是一款不错的GNOME屏幕虚拟键盘，如果不使用GNOME,可以使用另一款屏幕虚拟键盘<a href="http://homepage3.nifty.com/tsato/xvkbd/">xvkbd</a>,xvkbd只依赖于X11。有了屏幕虚拟键盘，触摸本用起来更爽了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 24</title>
    <url>/2013/12/15/4492/</url>
    <content><![CDATA[<p><a href="http://tomcat.apache.org/tomcat-8.0-doc/changelog.html">Tomcat 8.0.0</a> 已经RC5了，应该很快就可以正式发布了吧！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 25</title>
    <url>/2013/12/16/4494/</url>
    <content><![CDATA[<p>Internet标准时间<a href="http://www.ietf.org/rfc/rfc3339.txt">RFC3339</a>标准</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 27</title>
    <url>/2013/12/19/4506/</url>
    <content><![CDATA[<p>linux kernel 3.13 将会用<a href="http://netfilter.org/projects/nftables/">nftables</a>替代<a href="http://www.netfilter.org/projects/iptables/index.html">iptables</a>。<a href="http://lwn.net/Articles/564095/">The return of nftables</a>,<a href="http://en.wikipedia.org/wiki/Nftables">nftables(wiki)</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 28</title>
    <url>/2013/12/23/4532/</url>
    <content><![CDATA[<p>iptables是IPv4包过滤和NAT工具,ip6tables是IPv6包过滤工具。IPv6虽然理论上不需要NAT,但目前看来NAT还是必不可少的,特别是IPv4向IPv6过渡的时候。NAT这玩意儿说实话比较讨厌。iproute2中的ip命令则是路由,网络设备,策略路由和隧道等的配置工具,同时支持IPv4和IPv6。iptables/ip6tables与iproute2可以配合来管理网络的方方面面，比如，二者配合可以实现强大的策略路由。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 29</title>
    <url>/2013/12/31/4608/</url>
    <content><![CDATA[<p>MyBatis Generator自身已经提供了分页代码生成<a href="http://mybatis.org/generator/reference/plugins.html">插件</a>org.mybatis.generator.plugins.RowBoundsPlugin,还有一个网友实现的oracle方言的<a href="http://ufopw.iteye.com/blog/1289274">分页插件</a>。JDBC的游标分页和拦截Sql做分页都不如直接在数据库级别作分页靠谱,也就是直接生成查询数据库分页SQL代码。当然不同的数据库分页代码不尽相同。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 30</title>
    <url>/2013/12/31/4611/</url>
    <content><![CDATA[<p>抽时间写个MyBatis Generator plugin,生成selectBySampleSelective接口和相应的xml select元素。selectBySampleSelective方法使用一个样本实体记录,通过对sample样本存在的字段与表相应字段做相等比较来检索表记录。虽然selectByExample方法完全可以满足要求,但selectByExample实在太重量级了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 31</title>
    <url>/2014/01/10/4745/</url>
    <content><![CDATA[<p>debian installer提供了四个tty(TeleTYpe)控制台,tty1就是安装界面,tty2和tty3提供了一个busybox命令行,tty4用于安装日志输出。通过tty4可以看到全部的安装和错误信息,很是方便。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 32</title>
    <url>/2014/01/14/4807/</url>
    <content><![CDATA[<p>git pull本质上就先git fetch,然后git merge</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 33</title>
    <url>/2014/01/16/4829/</url>
    <content><![CDATA[<p>OpenID是Authentication,OAuth是Authorization。OpenID只是认证,而OAuth包含了认证和授权。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 34</title>
    <url>/2014/01/18/4853/</url>
    <content><![CDATA[<p>Lambda表达式本质就是一个匿名函数,其理论基础来自于λ演算。不过Lambda表达式是受到很多限制的匿名函数,比如有些语言只允许有一条表达式。闭包是持有自由变量从而具有状态的函数,闭包通常使用匿名函数来实现。闭包拥有的自由变量类似于对象拥有的成员变量。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 35</title>
    <url>/2014/01/22/4903/</url>
    <content><![CDATA[<p>公钥经CA签名后才成为数字证书。数字证书用来保证公钥是可信任的,这是一个始自CA根证书(root certificate)的信任链。CA根证书内置CA的公钥和身份信息,CA的根证书都是自签的。CA使用其私钥签发数字证书,也就是将申请人的公钥和身份信息按X.509标准进行数字签名。比如使用浏览器浏览https站点时,就可以使用内置的CA根证书来验证服务器端的数字证书是不是有效。当然使用数字证书的领域包含但不限于web,任何需要身份鉴别的地方都可以使用数字证书。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 36</title>
    <url>/2014/01/24/4986/</url>
    <content><![CDATA[<p>完全正向加密(PFS,<a href="https://en.wikipedia.org/wiki/Forward_secrecy">Perfect Forward Secrecy</a>)可以防止追溯攻击。<a href="http://imrman.com/?q=node/7">这里</a>讲述了一种实现方式。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 37</title>
    <url>/2014/01/26/4998/</url>
    <content><![CDATA[<p>想编辑已经存在的PDF文件？如果你使用Libreoffice的话,那么很简单,安装libreoffice-pdfimport包就可以导入PDF进行编辑了,完成后还可以导出PDF。这其实就是安装了libreoffice扩展pdf import。#Debian#</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 38</title>
    <url>/2014/02/27/5124/</url>
    <content><![CDATA[<p>JQuery有一个输入格式控制插件<a href="http://plugins.jquery.com/maskedinput/">jQuery Masked Input</a>,可以限制用户只能输入固定格式的数据。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 39</title>
    <url>/2014/02/27/5127/</url>
    <content><![CDATA[<p>将调用函数的实际参数转换为数组可以使用语句var args = [].slice.call(arguments);或语句var args = Array.prototype.slice.call(arguments); [].slice.call(arguments)怎么理解?其实就是将arguments对象绑定到数组的slice函数,从而第一个参数arguments成为slice函数的this,而后续的参数成为slice函数的常规参数,形如:[].slice.call(arguments,begin[, end]);比如这样调用:var args = [].slice.call(arguments,1);args变量里存储的是从第二个参数到最后一个参数的数组。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 40</title>
    <url>/2014/03/01/5137/</url>
    <content><![CDATA[<p><a href="http://kivy.org/">Kivy</a>从1.8.0(Jan 30, 2014)开始支持python3了。<a href="http://kivy.org/docs/faq.html#does-kivy-support-python-3-x">Does Kivy support Python 3.x?</a><br>Yes! As of version 1.8.0 Kivy supports both Python 2 and Python 3 with the same codebase</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 41</title>
    <url>/2014/03/05/5172/</url>
    <content><![CDATA[<p>HTML标签dl指defination list,dt指defination term,dd指defination description,可以组合这三个标签来展示数据。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 42</title>
    <url>/2014/03/06/5179/</url>
    <content><![CDATA[<p>CSS伪类(Pseudo-classes)和伪元素(Pseudo-elements )的区别及应用有两篇好文,<a href="http://swordair.com/origin-and-difference-between-css-pseudo-classes-and-pseudo-elements/">CSS伪类与CSS伪元素的区别及由来</a> 和 <a href="http://swordair.com/typical-and-atypical-usage-of-css-pseudo-classes-and-pseudo-elements/">CSS伪类与CSS伪元素的典型与非典型应用</a>,写的很好,自己就偷懒不用写了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 43</title>
    <url>/2014/03/10/5207/</url>
    <content><![CDATA[<p>xdpyinfo(X display information)用于输出X显示相关的信息,可以使用xdpyinfo grep resolution来获取显示器的DPI,我的是resolution: 96x96 dots per inch。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 44</title>
    <url>/2014/03/10/5210/</url>
    <content><![CDATA[<p>A4纸的尺寸是210mm<em>297mm，也就是21.0cm</em>29.7cm，而1英寸=2.54cm，如果屏幕DPI分辨率为96像素/英寸,则A4纸在屏幕上占据的像素大小约为:794×1123 (96/2.54<em>21≈794,96/2.54</em>29.7≈1123),在HTML中对应的就是像素单位px。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 45</title>
    <url>/2014/03/10/5212/</url>
    <content><![CDATA[<p>规范的编写网页的方法是在最合适的地方用最合语义的代码/标签构建网页HTML结构骨架，以CSS形式定制其外观样式，以Javascript描述其行为动作。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 46</title>
    <url>/2014/03/17/5263/</url>
    <content><![CDATA[<p>挂载NTFS分区一定要用ntfs-3g而不要用ntfs,传统的ntfs驱动读取还可以,不过也有问题,写会存在很多问题。 #linux#</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 47</title>
    <url>/2014/03/28/5367/</url>
    <content><![CDATA[<p>mac os x咋这样尼,想让用户登录时执行一个脚本,写到 <del>/.profile里竟然不执行,你默认的shell是bash啊,亲！然后需要各种方法执行一个用户登录脚本,麻烦死了,最后将登录脚本丢到login items里面,也勾选了hide选项,登录时竟然还有一个shell窗口一闪而过。<br>还有啊,打开非登录交互式终端竟然也不执行</del>/.bashrc,你这是bash吗???幸好~/.bash_profile还会被执行,完全不如linux好用啊！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 48</title>
    <url>/2014/03/29/5372/</url>
    <content><![CDATA[<p>macbook air上没有右CRTL键,vim里面使用CTRL+F翻页简直没法用了。而在mac上vim里重新映射option键(ALT)却无法工作,参数winaltkeys没用的,因为根本就不使用vim的菜单,都是光秃秃的窗口,linux上重新映射ALT键没问题的。只好在mba上全局性的修改键盘映射,<code>System Preferences -&gt; Keyboard -&gt; Modifier Keys</code>将Control和Option互换,勉强凑合用吧。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 49</title>
    <url>/2014/04/19/5403/</url>
    <content><![CDATA[<p>Mac OS X系统上有些组和用户的帐号是下划线开头的,一般用于系统服务帐号，这只是一个命名习惯,没有什么特别之处。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 50</title>
    <url>/2014/05/01/5467/</url>
    <content><![CDATA[<p>firefox在linux下窗口最大化时,tabs bar并不会与title bar合并,所以会比较浪费屏幕空间。如果想最大化的节省屏幕空间可以使用<a href="http://5digits.org/pentadactyl/">pentadactyl</a>,适合vim控,连地址栏都不会显示。还有一个插件叫<a href="https://github.com/seleznev/firefox-extension-htitle">HTitle</a>,也可以隐藏掉标题栏。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 51</title>
    <url>/2014/05/02/5470/</url>
    <content><![CDATA[<p>Mac OS X更改主机名 <code>sudo scutil --set HostName new_hostname</code></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 52</title>
    <url>/2014/05/05/5493/</url>
    <content><![CDATA[<p>变量附加到对象上才叫属性，函数附加到对象上才叫方法。属性是可以删除的，而变量不可以。方法也是属性的一种。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 53</title>
    <url>/2014/05/12/5515/</url>
    <content><![CDATA[<p>使用vim将代码风格(code style)由蛇形(snake_case)改为驼峰(Camel Case)：<br>:%s/_\([a-z]\)/\u\1/g</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 54</title>
    <url>/2014/05/13/5518/</url>
    <content><![CDATA[<p>yoga 13入手快一年半了，都快换新本的节奏了，RTL8723AU wifi驱动终于要进3.15内核了，@瑞昱 @Realtek 你动作真快啊！ <a href="http://www.phoronix.com/scan.php?page=news_item&px=MTY1OTQ">Realtek RTL8723AU Support Added To Linux 3.15</a>。而且貌似Bluetooth仍然用不了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 55</title>
    <url>/2014/05/14/5523/</url>
    <content><![CDATA[<p>instanceof运算符可以用来判断某个构造函数的prototype属性是否存在于另外一个要检测对象的原型链(__proto__属性指向的隐式原型链,真正的继承链)上。语法形式为:<br>object instanceof constructor</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 56</title>
    <url>/2014/05/21/5555/</url>
    <content><![CDATA[<p>Shadow DOM越来越近了,Chrome 35 已经去掉了Shadow DOM API的供应商前缀。下一个支持Shadow DOM的就是firefox 30了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 57</title>
    <url>/2014/05/27/5582/</url>
    <content><![CDATA[<p>[是一个shell内建命令函数,而不是一个关键字。也就是说[是一个函数,其最后一个参数为],[的参数之间必须严格的使用空白分隔。if [ “$str” == “a” ]; then实际上是调用[函数,其参数分别为”$str”,==,”a”和]，这与if test “$str”==”a”; then是等价的,test函数对空白没有特殊要求。[与test是基本等价的。而[[则是shell关键字,有更多的扩展特性，比如支持规则表达式匹配运算符。逻辑运算时,[使用-a和-o,而[[使用&amp;&amp;和。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 58</title>
    <url>/2014/05/28/5590/</url>
    <content><![CDATA[<p>当为设置块元素的height属性(attribute)为百分比数值时,其父元素必须显式的设置了height属性,否则子元素的height属性不起作用。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 59</title>
    <url>/2014/06/11/5595/</url>
    <content><![CDATA[<p>本站鸟枪换炮,从diahosting迁移到linode</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 60</title>
    <url>/2014/06/21/5624/</url>
    <content><![CDATA[<p>只有IE7及以下版本可以识别以非字母字符为前缀的CSS属性，而其它浏览器会忽略。所以有些代码在CSS样式属性名前面添加*号来hack低版本IE。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 61</title>
    <url>/2014/07/02/5639/</url>
    <content><![CDATA[<p>在CSS namespace尚未标准化之前，可以使用css的层次选择器来简单的模拟命名空间,而且可以模拟多层次的名字空间。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 62</title>
    <url>/2014/07/08/5643/</url>
    <content><![CDATA[<p>vim不需要NERDTree,因为有原生的netrw. <a href="https://medium.com/@mozhuuuuu/vimmers-you-dont-need-nerdtree-18f627b561c3">Vimmers, You Don’t Need NerdTree</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 63</title>
    <url>/2014/07/19/5689/</url>
    <content><![CDATA[<p>nginx fastcgi程序执行带有sudo命令的脚本时,前台报错”502 Bad Gateway”,后台日志中有错误记录”sudo: no tty present and no askpass program specified”,是因为nginx是以用户www-data来执行脚本的,而www-data用户默认是不在sudoers中的,并且执行脚本时没有tty,sudo也无法执行请求用户密码的程序，故有此提示。因此若要nginx可以执行使用sudo命令的CGI脚本,则必须将www-data加入sudoers,并且不能提示输入密码,也就是不用验证密码即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 64</title>
    <url>/2014/07/29/5700/</url>
    <content><![CDATA[<p>各大浏览器，除了fireofx,对select控件option子元素的样式支持都很差。为option设置padding,margin和text-indent只有firefox会正确的展现，其他浏览器，包括chrome,safari,opera和ie,根本没有任何效果。所以对于option的层次缩进只能使用空白填充大法了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 65</title>
    <url>/2014/07/31/5702/</url>
    <content><![CDATA[<p>tkinter(Tk interface)模块在python 3.x中的名字为”tkinter”,在python 2.x中的名字为”Tkinter”,好微妙！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 66</title>
    <url>/2014/07/31/5704/</url>
    <content><![CDATA[<p>python3m,python3mu是什么命令？是python3具有不同编译选项的二进制版本,<code>--with-pydebug</code>的标志为d,<code>--with-pymalloc</code>的标志为m,<code>--with-wide-unicode</code>的标志为u</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 67</title>
    <url>/2014/07/31/5706/</url>
    <content><![CDATA[<p>windows平台上,.py文件默认用python.exe打开,即使.py程序使用GUI,python.exe仍然会打开一个终端窗口。如果使用pythonw.exe打开则不会有额外的终端窗口，所以可以将脚本的扩展名更改为.pyw来自动的使用pythonw.exe。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 68</title>
    <url>/2014/08/04/5756/</url>
    <content><![CDATA[<p>tomcat8不知道什么时候已经进入debian testing源，开发机已升级到tomcat8.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 70</title>
    <url>/2014/08/06/5761/</url>
    <content><![CDATA[<p>debian 8.0 jessie已经决定基于kernel 3.16发行,虽然3.16并不是一个长期(longterm)分支,但3.16有很多新的特性,并且Ubuntu kernel team会支持此分支到2016年。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 69</title>
    <url>/2014/08/06/5758/</url>
    <content><![CDATA[<p>onpropertychange事件是IE专有的,而且从IE9开始这个事件被标记为Deprecated。</p>
<blockquote>
<p>The onpropertychange event is only supported in conjunction with the legacy attachEvent IE-only event registration model, which has deprecated since Windows Internet Explorer 9 in favor of the W3C standard “addEventListener” event model.</p>
</blockquote>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 71</title>
    <url>/2014/08/18/5816/</url>
    <content><![CDATA[<p>Python的条件表达式或叫三元操作符与其他语言有很大的不同，其格式为: result_while_condition_is_true if condition else result_while_condition_is_false,如果condition为True,整个条件表达式的值为result_while_condition_is_true,否则整个条件表达式的值为result_while_condition_is_false</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 72</title>
    <url>/2014/08/19/5818/</url>
    <content><![CDATA[<p>python里没有递增运算符<code>++</code>和递减运算符<code>--</code>，还好可以使用<code>+=</code>和<code>-=</code>运算符。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 73</title>
    <url>/2014/08/21/5829/</url>
    <content><![CDATA[<p>import module后,可以使用module.__file__查看模块源文件所在路径,dir(module)查看模块导出的符号 — Python</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 74</title>
    <url>/2014/08/30/5833/</url>
    <content><![CDATA[<p>openlayers 3 is released! ol3’s homesite change to <a href="http://openlayers.org/">http://openlayers.org/</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 75</title>
    <url>/2014/09/02/5835/</url>
    <content><![CDATA[<p>python经典的图像处理库叫<a href="http://www.pythonware.com/products/pil/">Python Imaging Library</a> (PIL),but当前并不支持python 3,并且已经几年没有更新了。不过有一个fork版本叫<a href="http://python-pillow.github.io/">Pillow</a>支持python 3,并且开发活跃。debian官方源里的python3-pil包即是Pillow。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 76</title>
    <url>/2014/09/06/5837/</url>
    <content><![CDATA[<p>文件名使用GBK编码的zip包在linux平台上解压时,如果系统locale是UTF-8,用unzip解码时文件名会出现乱码,unzip以前上有一个-O参数来指定解压时使用的编码,但现在这个参数已经无效了。可以使用<a href="http://lilydjwg.is-programmer.com/">依云</a>写的python3脚本<a href="http://lilydjwg.is-programmer.com/posts/16293">gbkunzip</a>来解压此类zip包。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 77</title>
    <url>/2014/09/11/5841/</url>
    <content><![CDATA[<p>jessie源里的rdesktop升级到1.8.2,参数-E不再适用,也就是不能禁止客户和服务器之间的连接加密,否则无法正常使用rdesktop.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 79</title>
    <url>/2014/09/23/5885/</url>
    <content><![CDATA[<p>因为sql语句中用了中文的”月”,而NLS_LANG设置为”AMERICAN_AMERICA.AL32UTF8”,所以oracle提示了错误”ORA-01843 not a valid month”,只需将NLS_LANG设置为”SIMPLIFIED CHINESE_CHINA.AL32UTF8”即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 80</title>
    <url>/2014/10/09/5904/</url>
    <content><![CDATA[<p>KVM客户机鼠标集成其实很简单，命令行里添加一个参数<code>-usbdevice tablet</code>就可以了，不过KVM运行带图形界面的客户机感觉还是不如virtualbox用起来更方面。KVM更适合服务器领域。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 78</title>
    <url>/2014/09/21/5869/</url>
    <content><![CDATA[<p>现代浏览器中的DOM对象有一个<a href="https://developer.mozilla.org/en-US/docs/Web/API/Element.classList">classList</a>属性,这是一个<a href="https://developer.mozilla.org/en-US/docs/Web/API/DOMTokenList">DOMTokenList</a>类型的对象。这个对象有add,remove,toggle,contains方法,可以用来操纵或测试DOM元素的class。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 81</title>
    <url>/2014/10/18/5941/</url>
    <content><![CDATA[<p>windows 2008 R2上安装oracle 10g 10.2.0.4时会提示”检查操作系统版本：必须是5.0，5.1，5.2 or 6.0。实际为6.1。未通过。”,修改安装目录下的文件install/oraparam.ini,其中Windows=5.0,5.1,5.2,6.0一行最后添加”,6.1”,安装过程中的其他依赖检查错误通过勾选都设置为”用户已验证”即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 82</title>
    <url>/2014/10/18/5947/</url>
    <content><![CDATA[<p>windows 2008 r2默认是开启网络防火墙的,因此oracle的服务默认端口1521也是被阻止的。费了好大劲连不上才发现这个问题，可以这样解决,用命令行：<code>C:\Users\Administrator&gt;netsh firewall set portopening TCP 1521 &quot;ORACLE&quot;</code>，或者图形化设置:<code>服务器管理器-&gt;配置-&gt;高级安全windows防火墙-&gt;入站规则-&gt;新建规则来配置TCP 1521端口</code>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 84</title>
    <url>/2014/10/24/5985/</url>
    <content><![CDATA[<p>debian配置默认文本编辑器<code>sudo update-alternatives --config editor</code></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 83</title>
    <url>/2014/10/22/5966/</url>
    <content><![CDATA[<p>gnome自带的菜单编辑工具包名字叫alacarte,这单词来自法语，意思是“照菜单点菜”。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 85</title>
    <url>/2014/11/18/6054/</url>
    <content><![CDATA[<p>如果执行chroot时遇到这个错误,<code>chroot: failed to run command `/bin/bash&#39;: Exec format error</code>,极有可能是因为两个环境的架构不一致，比如X86和AMD64。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 87</title>
    <url>/2014/12/06/6071/</url>
    <content><![CDATA[<p>uniq命令隔行重复是不认的，所以对于隔行重复的情况需要先用sort命令进行排序。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 86</title>
    <url>/2014/12/06/6063/</url>
    <content><![CDATA[<p>linux平台上virtualbox客户机如果需要访问主机的usb设备,则必须要将启动virtualbox主机的用户添加到vboxusers用户组。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 88</title>
    <url>/2014/12/31/6115/</url>
    <content><![CDATA[<p>macbook air外接显示器时，如果要合盖不休眠，必须外接电源，合盖后使用外接键盘或鼠标唤醒电脑。如果是蓝牙键盘和鼠标，需要设置相应的蓝牙设备可以唤醒电脑。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 89</title>
    <url>/2015/01/12/6134/</url>
    <content><![CDATA[<p>chrome提示”Uncaught SyntaxError: Unexpected token “ 后面跟一个字符，这个时候应该是解析JSON字符串出了问题,一般是传给JSON.parse函数了一个非法的JSON字符串。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 90</title>
    <url>/2015/01/20/6145/</url>
    <content><![CDATA[<p>web项目的一个组件在chrome浏览器里显示异常,其他浏览器没有问题。看网络请求有”Provisional headers are shown”字样的警告,关闭Adblock Pro后，显示正常，原来是Adblock Pro阻挡了浏览器对这个组件的网络请求,不过什么仇？什么怨呢？当服务器响应网络请求之后,”Provisional headers are shown”就会被真正的头部替代。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 91</title>
    <url>/2015/01/23/6155/</url>
    <content><![CDATA[<p>python3可以使用<a href="https://github.com/lincolnloop/python-qrcode">qrcode</a>库来生成二维码</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 92</title>
    <url>/2015/01/25/6157/</url>
    <content><![CDATA[<p>要浏览youtube视频，除了代理youtube.com之外,还要代理ytimg.com和googlevideo.com</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 93</title>
    <url>/2015/01/25/6159/</url>
    <content><![CDATA[<p>dl.google.com目前可用ip 203.208.49.162,速度尚可，IP在国内。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 94</title>
    <url>/2015/01/26/6161/</url>
    <content><![CDATA[<p>ECMAScript 6 promise已经被绝大多数主流浏览器原生支持,除了IE,包括最新的版本11都不支持，有一个polyfill可用，<a href="https://github.com/jakearchibald/es6-promise">es6-promise</a>。下一代IE浏览器Spartan毫无疑问的会支持promise,而且据说标准兼容性大大提高。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 95</title>
    <url>/2015/01/26/6163/</url>
    <content><![CDATA[<p>cql官方文档:”CQL for Cassandra 2.0 deprecated super columns.” 超列已死.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 96</title>
    <url>/2015/01/27/6165/</url>
    <content><![CDATA[<p>debian平台上,python3运行GUI程序时提示”ImportError: No module named ‘_tkinter’”,apt-get安装python3-tk包即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 97</title>
    <url>/2015/01/30/6167/</url>
    <content><![CDATA[<p><a href="https://letsencrypt.org/">Let’s Encrypt</a> is a new Certificate Authority: It’s free, automated, and open. Arriving Mid-2015</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 98</title>
    <url>/2015/02/04/6170/</url>
    <content><![CDATA[<p>QR二维码真复杂,虽然最终就是一些黑白点，但有着复杂的控制、数据、纠错编码，这篇文章说的很详细:<a href="http://coolshell.cn/articles/10590.html">二维码的生成细节和原理</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 99</title>
    <url>/2015/02/11/6172/</url>
    <content><![CDATA[<p>PostgreSQL还有一个外部表功能，很有趣，<a href="http://blog.osdba.net/521.html">PostgreSQL中使用外部表快速分析nginx日志</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 100</title>
    <url>/2015/03/16/6178/</url>
    <content><![CDATA[<p>dataguard中的standby在managed recovery模式下是无法export的,只有在readonly模式下才可以，但是这样主备库的数据又会不一致了，需要恢复redo logs,因此不要在standby上做exp,要在primary上做。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 101</title>
    <url>/2015/03/21/6187/</url>
    <content><![CDATA[<p>rman是非一致性的、块级别的备份，因此需要归档日志来保证数据的完整性。rman在备份开始和结束时都会对数据库进行归档。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 102</title>
    <url>/2015/03/28/6228/</url>
    <content><![CDATA[<p>访问控制列表ACL(Acess Control List)使用包过滤技术，在路由器、防火墙或交换机上读取第三层及第四层包头中的信息，如源地址、目的地址、源端口、目的端口等，根据预先定义好的规则对包进行过滤，从而达到访问控制的目的。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 103</title>
    <url>/2015/03/28/6230/</url>
    <content><![CDATA[<p>u盘自动挂装后挂载到了/media/usb0,而不是通常的挂载点/media/user_name/volume_name,而且是以root权限挂载的，普通用户无法读写u盘。原来是/etc/fstab在作怪，使用u盘安装系统时，会自动在/etc/fstab中添加item,将u盘设备的分区挂载到了/media/usb0以及/media/usb1等目录下(如果有多个分区的话)，而且是以root权限挂载的。删除相关的item后，重新插入U盘正常了。还有一个问题是，桌面环境下不要使用usbmount挂载U Disk。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 104</title>
    <url>/2015/03/30/6266/</url>
    <content><![CDATA[<p>Cassandra is a row-oriented database.</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 106</title>
    <url>/2015/04/08/6335/</url>
    <content><![CDATA[<p>发现一个不错的git托管开源程序<a href="http://gogs.io/">Gogs</a>，go语言开发的，据说比gitlab还好用，真的吗?</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 107</title>
    <url>/2015/04/08/6339/</url>
    <content><![CDATA[<p>egg之于python正如jar之于java</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 108</title>
    <url>/2015/04/09/6357/</url>
    <content><![CDATA[<p>测试ssl/tls连接：<code>js$ openssl s_client -connect host:port</code></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 109</title>
    <url>/2015/04/13/6362/</url>
    <content><![CDATA[<p>markdown的精髓是内容和表现形式的分离，让写作者更专注于内容而不受或少受展现格式的影响。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 110</title>
    <url>/2015/04/23/6368/</url>
    <content><![CDATA[<p>设计模式说到底就是迂回吧。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 111</title>
    <url>/2015/04/24/6371/</url>
    <content><![CDATA[<p>代码如其人</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 112</title>
    <url>/2015/04/30/6375/</url>
    <content><![CDATA[<p>上次dataguard主备切换时，将job_queue_processes设置为0,关闭了job背景进程。切换完毕后忘了重新设置此参数，导致所有job都停止了，今天才发现。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; alter system set job_queue_processes=<span class="number">20</span> scope=both;</span><br></pre></td></tr></table></figure>
<p>这样job就可以恢复正常运行了！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 113</title>
    <url>/2015/05/02/6378/</url>
    <content><![CDATA[<p>inline-block流式布局明显优于浮动布局，float可以休矣！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 114</title>
    <url>/2015/05/15/6419/</url>
    <content><![CDATA[<p>Cassandra集群对时间要求很严格,集群中所有节点必须时间严格同步，不然可能会出现各种奇怪的问题。因此最好架设ntp服务来保证各节点时间同步。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 115</title>
    <url>/2015/05/17/6434/</url>
    <content><![CDATA[<p>Cassandra集群中的所有节点都要使用相同的种子节点(seed nodes)。种子节点不是单点故障，只是用于当新节点加入集群时启动gossip。种子节点自身不会bootstrap,而其他节点启动时会向种子节点获取信息来bootstrap。对于多数据中心集群，每一个数据中心至少要有一个种子节点，为了容错，每个数据中心可以有多个种子节点，但不推荐将所有的节点都当作种子节点，因为这会降低gossip性能，大约每个数据中心三个种子节点就可以了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 116</title>
    <url>/2015/05/17/6439/</url>
    <content><![CDATA[<p>在cassandra集群上执行nodeltool status命令时,所有节点的Owns列都为问号?,并且最后有输出”Note: Non-system keyspaces don’t have the same replication settings, effective ownership information is meaningless”,这不是错误，是因为没有指定keyspace之故。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 117</title>
    <url>/2015/05/17/6442/</url>
    <content><![CDATA[<p>UTS namespaces (CLONE_NEWUTS, Linux 2.6.19) isolate two system identifiers—nodename and domainname—returned by the uname() system call; the names are set using the sethostname() and setdomainname() system calls. In the context of containers, the UTS namespaces feature allows each container to have its own hostname and NIS domain name. This can be useful for initialization and configuration scripts that tailor their actions based on these names. The term “UTS” derives from the name of the structure passed to the uname() system call: struct utsname. The name of that structure in turn derives from “UNIX Time-sharing System”.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 118</title>
    <url>/2015/05/19/6444/</url>
    <content><![CDATA[<p><a href="http://datatables.net/">datatables</a> columns count/sum,获取datatables组件的列数:table.columns()[0].length</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 119</title>
    <url>/2015/05/19/6446/</url>
    <content><![CDATA[<p>linux的cron守护程序, 其名字来源于希腊语的chronos,意思为时间。另一说为Command Run ON。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 120</title>
    <url>/2015/06/04/6468/</url>
    <content><![CDATA[<p>如果打开jenkins - Configure Global Security中的Prevent Cross Site Request Forgery exploits选项，则所有project的Build Now就会无效。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 121</title>
    <url>/2015/06/05/6474/</url>
    <content><![CDATA[<p>当form没有给定name时,Chrome会提示”An invalid form control with name=’’ is not focusable”，为form添加name属性即可，或者添加novalidate属性亦可，不过此时form将不校验其内部的所有输入元素。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 122</title>
    <url>/2015/07/02/6503/</url>
    <content><![CDATA[<p>画流程图,桌面工具有<a href="https://wiki.gnome.org/Apps/Dia">dia</a>,在线工具有<a href="https://www.processon.com/">ProcessOn</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 123</title>
    <url>/2015/07/12/6511/</url>
    <content><![CDATA[<p>标准化的web客户端存储,除了传统的cookie,现在还有Web Storage(LocalStorage, SessionStorage)和<a href="http://javascript.ruanyifeng.com/bom/indexeddb.html">IndexedDB</a>可用,而Web SQL已被废弃. 各大浏览器对Web Storage的支持度更高.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 124</title>
    <url>/2015/07/14/6515/</url>
    <content><![CDATA[<p>主要的浏览器平台都已经支持promise了，当然IE还不行，但是Edge支持。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 125</title>
    <url>/2015/07/22/6529/</url>
    <content><![CDATA[<p><a href="http://www.postgres-xl.org/">Postgres-XL</a>是一个通用的 ACID 、开源的、可方便进行水平扩展的、擅长OLTP 写频繁的业务、 SQL 数据库解决方案。衍生自PostgreSQL数据库。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 126</title>
    <url>/2015/07/22/6531/</url>
    <content><![CDATA[<p><a href="https://github.com/postgres-x2/postgres-x2">Postgres-XC</a> (eXtensible Cluster) is a multi-master write-scalable PostgreSQL cluster based on shared-nothing architecture。</p>
<p>Postgres-XC(eXtensible Cluster)是基于无共享架构的多主节点、写性能扩展PostgreSQL集群。主要的特性有：写性能扩展，多主节点同步，对应用程序透明，就像使用传统的PostgeSQL一样，等等。但其没有sharding机制，只是对称多主节点集群，提高写性能和可用性。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 127</title>
    <url>/2015/07/22/6534/</url>
    <content><![CDATA[<p><a href="https://wiki.postgresql.org/wiki/Pgpool-II">pgpool-II</a>是一个中间件，工作在PostgreSQL服务器和PostgreSQL数据库客户端之间，具有连接池，复制，负载均衡，并行查询和突破连接限制等功能。<br><a href="http://git.postgresql.org/gitweb/?p=pgpool2.git;a=summary">git代码库</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 128</title>
    <url>/2015/07/23/6536/</url>
    <content><![CDATA[<p>Postgres-X2试图融合Postgres-XC和Postgres-XL。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 129</title>
    <url>/2015/07/29/6563/</url>
    <content><![CDATA[<p>The keyword SNAPSHOT is supported in place of MATERIALIZED VIEW for backward compatibility.<br>也就是以前叫“快照”，现在叫“物化视图”了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 130</title>
    <url>/2015/08/01/6576/</url>
    <content><![CDATA[<p>查看oracle job的运行状态，可以查询这几张系统视图ALL_SCHEDULER_JOB_LOG/DBA_SCHEDULER_JOB_LOG和dba_scheduler_job_run_details</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 131</title>
    <url>/2015/08/02/6580/</url>
    <content><![CDATA[<p>几个意思相近又有区别的词语：<br>crew 全体船员； 全体乘务员；全体工作人员<br>staff 全体职员； 全体管理人员；<br>faculty 全体教员<br>crowd 一群,人群</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 132</title>
    <url>/2015/08/03/6585/</url>
    <content><![CDATA[<p>交换机简单了讲就是一个多端口网桥。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 133</title>
    <url>/2015/08/26/6598/</url>
    <content><![CDATA[<p>mac os x的bash切换到名字含有空格的目录时，可以使用单引号包围目录名，此时自动完成是正常的，也可以使用backslash反斜杠来转义空格，但此时无法自动完成，只能手工输入。#不如linux好用#</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 134</title>
    <url>/2015/08/29/6606/</url>
    <content><![CDATA[<p>PostgreSQL执行外部sql脚本有两种方式：<br>一种是在bash命令行上为psql命令用-f选项或重定向指定sql脚本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ psql -U username -d dbname -f /path/to/script.sql</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ psql -U username -d dbname &lt; <span class="regexp">/path/</span>to/script.sql</span><br></pre></td></tr></table></figure>
<p>另一种是在psql命令行上用\i命令执行sql脚本</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">=# \\i /path/to/script.sql</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 135</title>
    <url>/2015/09/03/6626/</url>
    <content><![CDATA[<p>“JAVA是第一个天生的网络应用平台，特别是J2EE发布以来，JAVA从一个编程语言，演变为网络应用架构，成为应用服务平台的事实标准。应用服务器中间件，成为中间件技术的集大成者，也成为事实上的中间件的核心。”</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 136</title>
    <url>/2015/09/03/6628/</url>
    <content><![CDATA[<p>中间件处于操作系统软件与用户的应用软件的中间。中间件在操作系统、网络和数据库之上，应用软件的下层，总的作用是为处于自己上层的应用软件提供运行与开发的环境，帮助用户灵活、高效地开发和集成复杂的应用软件。形象地说就是上下之间的中间。<br>　　此外，中间件主要为网络分布式计算环境提供通信服务、交换服务、语义互操作服务等系统之间的协同集成服务，解决系统之间的互连互通问题。形象地说就是所谓左右之间的中间。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 137</title>
    <url>/2015/09/20/6650/</url>
    <content><![CDATA[<p>系统内支持中文的字体列表<br><code>js$ fc-list :lang=zh</code></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 138</title>
    <url>/2015/09/20/6652/</url>
    <content><![CDATA[<p>安装google Noto 字体,Noto是No Tofu的缩写,google志在设计一款不缺失任何字型的超级字体，消灭可恶的<a href="http://tips.justfont.com/post/92067462307/%E8%B6%85%E7%B4%9A%E6%B2%92%E7%94%A8%E4%BD%86%E5%80%BC%E5%BE%97%E7%82%AB%E8%80%80%E7%9A%84%E8%B1%86%E7%9F%A5%E8%AD%98%E7%82%BA%E4%BB%80%E9%BA%BC%E6%80%9D%E6%BA%90%E9%BB%91%E9%AB%94-google-%E7%89%88%E5%8F%88%E5%8F%AB-noto-sans">Tofu</a></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install fonts-noto</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 139</title>
    <url>/2015/09/20/6654/</url>
    <content><![CDATA[<p>有了noto字体,文泉驿可以休矣。xterm终端下配置使用Noto字体,~/.Xresources文件中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">XTerm*faceNameDoublesize: Noto Sans CJK SC</span><br></pre></td></tr></table></figure>
<p>英文字体也可以设置为Noto等宽字体:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">XTerm*faceName: Noto Sans Mono</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 140</title>
    <url>/2015/09/20/6656/</url>
    <content><![CDATA[<p>信令网关（Signaling　Gateway）目前主要指七号信令网关设备。传统的七号信令系统是基于电路交换的，在软交换体系中需要由IP来作为核心传输网络，因此需要由信令网关转换。本质上信令网关是传统七号信令系统与IP网之间的转换设备。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 141</title>
    <url>/2015/09/24/6659/</url>
    <content><![CDATA[<p>短信网关结构图<br><img src="http://p.blog.csdn.net/images/p_blog_csdn_net/gnuhpc/598384/o_e847a81610192c244b90a71a_16b7bf09-1dba-4ac2-8b83-08b2356ad02a.jpg"></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 142</title>
    <url>/2015/09/24/6662/</url>
    <content><![CDATA[<p>短信点播MO业务流程图<br><img src="http://p.blog.csdn.net/images/p_blog_csdn_net/gnuhpc/598384/o_image_20_633951732428125000.png"></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 143</title>
    <url>/2015/09/25/6664/</url>
    <content><![CDATA[<p>pandoc转换中文markdown文档为pdf文档:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pandoc manual.mkd --latex-engine=xelatex -V mainfont=<span class="string">&quot;Noto Sans CJK SC&quot;</span> -o manual.pdf</span><br></pre></td></tr></table></figure>

<p>pdflatex是不支持中文的</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 144</title>
    <url>/2015/10/02/6670/</url>
    <content><![CDATA[<p>M$的LDAP实现叫Active Directory,Apple的LDAP实现叫Open Directory,Oracle的LDAP实现叫Virtual Directory,还有一个开源开放的LDAP实现叫OpenLDAP</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 145</title>
    <url>/2015/10/06/6674/</url>
    <content><![CDATA[<p>感觉proxychains比tsocks还好用，二者有一样的功能。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 146</title>
    <url>/2015/10/07/6676/</url>
    <content><![CDATA[<p>grub2中的几个变量名gfxmode,gfxterm,gfxpayload中的gfx前缀就是graphics的简写/缩写: graphics =&gt; g(ra)fx(phics)</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 147</title>
    <url>/2015/10/07/6679/</url>
    <content><![CDATA[<p>rEFInd is a boot manager, not a boot loader. GRUB is a boot manager, also a boot loader. The Linux kernel built in an EFI boot loader for itself from version 3.3.0, called “EFI Boot Stub”.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 148</title>
    <url>/2015/10/27/6782/</url>
    <content><![CDATA[<p>debian源安装gulp后,执行gulp -v提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/usr/bin/env: node: No such file or directory</span><br></pre></td></tr></table></figure>
<p>是因为/usr/local/bin/gulp.js第一行引用的是node,而node在debian系统中实际的可执行文件为nodejs,修正之后就正常了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 149</title>
    <url>/2015/10/27/6785/</url>
    <content><![CDATA[<p>unix上的模式匹配glob，其名字缩写来自于global或global command</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 150</title>
    <url>/2015/10/31/6809/</url>
    <content><![CDATA[<p>debian最小化安装时,debian Standard system utilities并不是必须的，可以选择不安装任何task,或者只选择安装ssh server,系统安装成功后安装需要的软件即可。相反，如果安装了用不到，反而增加了系统安全风险。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 151</title>
    <url>/2015/10/31/6812/</url>
    <content><![CDATA[<p>ACPI ERST stands for Error Record Serialization Table</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 152</title>
    <url>/2015/11/02/6818/</url>
    <content><![CDATA[<p>外部CSS文件中相对URL的相对起始路径是CSS文件的路径，也就是相对URL是相对于CSS文件路径的。而js文件中的相对路径则是以导入此js的网页文件所在的位置为基准的。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 153</title>
    <url>/2015/11/03/6823/</url>
    <content><![CDATA[<p>修改了/etc/fstab添加新的自动挂载设备后，可以使用</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount -a</span><br></pre></td></tr></table></figure>
<p>命令使其立即挂载，而不必重新启动机器。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 154</title>
    <url>/2015/11/06/6864/</url>
    <content><![CDATA[<p>使用cassandra最最重要的事情不要忘记，架设一台时间服务器，所有的节点都与这台时间服务器定时同步，切记！<br>时间一致性对cassandra至关重要。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 155</title>
    <url>/2015/11/15/6912/</url>
    <content><![CDATA[<p>默认情况下，git push 并不会把标签传送到远端服务器上，只有通过显式命令才能分享标签到远端仓库。其命令格式如同推送分支，运行 git push origin [tagname] 即可。如果要一次推送所有本地新增的标签上去，可以使用 - -tags 选项，运行git push origin - -tags</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 156</title>
    <url>/2015/11/16/6923/</url>
    <content><![CDATA[<p>When updating to a new minor release, the safest policy is to update the standby servers first — a new minor release is more likely to be able to read WAL files from a previous minor release than vice versa. — postgresql high availability</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 157</title>
    <url>/2015/11/19/6929/</url>
    <content><![CDATA[<p>Dumps created by pg_dump are internally consistent, meaning, the dump represents a snapshot of<br>the database at the time pg_dump began running. pg_dump does not block other operations on the<br>database while it is working. (Exceptions are those operations that need to operate with an exclusive<br>lock, such as most forms of ALTER TABLE .)</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 158</title>
    <url>/2015/12/01/6973/</url>
    <content><![CDATA[<p>KVM qcow2格式镜像文件转换为VirtualBox VDI格式镜像文件，转换完毕后，可以使用VirtualBox直接启动虚拟机：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ qemu-img convert -f qcow2 foo.qcow2 -O vdi foo.vdi</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 159</title>
    <url>/2015/12/12/7054/</url>
    <content><![CDATA[<p>cassandra的native_transport使用与rpc_address同样的绑定地址，默认情况下只绑定到localhost,所以从外部是无法访问到cassandra的9042端口的，使用native协议的驱动也就无法访问节点了。因此，可以在不启用rpc的情况下，修改rpc_address地址为外部可访问接口，从而可以从外部访问native transport。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 160</title>
    <url>/2015/12/18/7068/</url>
    <content><![CDATA[<p>linux自动化运维,saltstack + zabbix?</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 161</title>
    <url>/2015/12/23/7091/</url>
    <content><![CDATA[<p>JNA(Java Native Access) provides Java programs easy access to native shared libraries without writing anything but Java code - no JNI or native code is required. This functionality is comparable to Windows’ Platform/Invoke and Python’s ctypes.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 162</title>
    <url>/2016/06/03/7344/</url>
    <content><![CDATA[<p>一个小坑，windows计划任务执行的命令或脚本，以及嵌套调用的命令或脚本，其路径名中不能包含括号，不能包含括号，不能包含括号。不然只会告诉你执行失败，退出码0x1,别无其他可用信息。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 163</title>
    <url>/2016/06/16/7397/</url>
    <content><![CDATA[<p>vim可以通过scp来编辑远程文件，大约是这个样子:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vim scp:<span class="comment">//user@host/path/to/file </span></span><br><span class="line">$ vim scp:<span class="comment">//server_alias/path/to/file</span></span><br></pre></td></tr></table></figure>
<p>很神奇的样子。此功能依赖于netrw.vim，vim已经在发行中集成。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 164</title>
    <url>/2016/06/18/7409/</url>
    <content><![CDATA[<p>如果cqlsh执行COPY命令时出现错误”get_num_processes() takes no keyword arguments”,删除掉/usr/lib/pymodules/python2.7/cqlshlib/copyutil.so文件，如果有文件copyutil.c也删除掉就可以了。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 165</title>
    <url>/2016/07/24/7444/</url>
    <content><![CDATA[<p>V$ARCHIVED_LOG视图中的列DEST_ID指定的值N就是LOG_ARCHIVE_DEST_N参数中的那个N，也就是DEST_ID用来指定是哪一个归档目标的日志记录。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 166</title>
    <url>/2016/09/03/7540/</url>
    <content><![CDATA[<p>debian安装字体很简单，将字体丢到~/.fonts目录即可，要立即生效可以执行一下fc-cache命令。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 167</title>
    <url>/2016/09/29/7607/</url>
    <content><![CDATA[<p>nmap实现了一个功能更丰富的netcat，叫做<a href="https://nmap.org/ncat/">ncat</a>，随nmap一起发行，同样是跨平台的。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 168</title>
    <url>/2016/09/30/7610/</url>
    <content><![CDATA[<p>System Integrity Protection关闭打开的方法：启动mac时按住command+R，然后打开终端执行：csrutil disable enable，然后reboot即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 169</title>
    <url>/2016/10/07/7626/</url>
    <content><![CDATA[<p>cURL stands for “see URL” or “client for URLs”, the recursive version is “Curl URL Request Library”.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 170</title>
    <url>/2016/11/10/7687/</url>
    <content><![CDATA[<p>除了oracle_fdw，还可以通过其他fdw来访问oracle数据库，比如jdcb_fdw,可以参考“<a href="http://blog.osdba.net/522.html">在PostgreSQL中使用jdbc_fdw访问Oracle</a>”</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 171</title>
    <url>/2016/11/13/7701/</url>
    <content><![CDATA[<p>输入:h feature-list查看vim支持的特性,然后可以在脚本中通过if has(“feature-name”)来检测该特性.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 172</title>
    <url>/2016/11/13/7703/</url>
    <content><![CDATA[<p>Console Vim uses whatever font the console/terminal is using. Changing the font in your terminal is done differently depending on your system and the terminal in use.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 173</title>
    <url>/2016/11/13/7705/</url>
    <content><![CDATA[<p>sierra的terminal里,vim输入中文乱码了,百思不得其解,苦苦搜索后,发现一个线索,terminal的preferences- Profile - advanced - Input - Escape non-ASCII input with Control-V不要勾选,果然此选项被勾选了,去掉勾选汉字输入正常了. but,这选项不是我开启的啊~~~</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 174</title>
    <url>/2016/11/13/7708/</url>
    <content><![CDATA[<p>k8s就是指kubernetes,就像i18n是internationalization的缩写一样。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 175</title>
    <url>/2016/11/15/7713/</url>
    <content><![CDATA[<p>sed的s命令通常使用/作为分隔符，其实并不是只有/可以做分隔符，s命令紧邻其后的任意一个字符都可以作为分隔符，因此如果pattern或repacement中有/,所以可以这样<code>sed &#39;s,bin/bash,,&#39;</code> 也可以这样<code>sed &quot;s@bin/bash@@&quot;</code></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 176</title>
    <url>/2016/11/18/7720/</url>
    <content><![CDATA[<p>运行locate libodbc命令时，提示“locate: warning: database ‘/var/cache/locate/locatedb’ is more than 8 days old (actual age is 22.3 days)”，运行sudo updatedb更新一下数据库即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 177</title>
    <url>/2016/11/18/7723/</url>
    <content><![CDATA[<p><code>dpkg -s --status package_name</code>显示包的详细信息，或者执行<code>dpkg-query -s --status package_name</code></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 178</title>
    <url>/2016/11/20/7726/</url>
    <content><![CDATA[<p>utf-16(utf-16-be,utf-16-le)是ucs-2的超集，python3中支持的编码格式没有ucs-2，如需处理ucs-2，直接使用utf-16编码即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 179</title>
    <url>/2016/11/26/7773/</url>
    <content><![CDATA[<p>oracle参数OPEN_CURSORS设置值的范围为0~65535，设置比实际需要大的多的值并没有额外的负担。v$sessmetric视图可以查看每个会话的资源消耗状况。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 180</title>
    <url>/2016/12/03/7798/</url>
    <content><![CDATA[<p>postgesql查询序列当前值可以使用<code>SELECT last_value FROM sequence_name;</code>这个是跨session的。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 181</title>
    <url>/2016/12/12/7815/</url>
    <content><![CDATA[<p>重启服务并不能重置postgresql的统计计数器，比如pg_stat_database的deadlocks计数器，可以使用<code>select pg_stat_reset();</code>来重置各种统计计数器。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 182</title>
    <url>/2016/12/26/7823/</url>
    <content><![CDATA[<p>Mozilla推出免费的网站安全测试服务observatory, <a href="https://github.com/mozilla/http-observatory">https://github.com/mozilla/http-observatory</a> and <a href="https://observatory.mozilla.org/">https://observatory.mozilla.org/</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 183</title>
    <url>/2016/12/27/7826/</url>
    <content><![CDATA[<p><a href="https://github.com/gorhill/uBlock">uBlock Origin</a> - the next generation opensource blocker, it is a wide-spectrum blocker, not just for ad block.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 184</title>
    <url>/2016/12/27/7828/</url>
    <content><![CDATA[<p>haskell: <a href="http://blog.leichunfeng.com/blog/2015/11/08/functor-applicative-and-monad/">Functor、Applicative 和 Monad</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 185</title>
    <url>/2017/01/17/7831/</url>
    <content><![CDATA[<p>alter database datafile ‘/path/to/datafile’ autoextend on;<br>alter database datafile ‘/path/to/datafile’ resize 100KMG;</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 186</title>
    <url>/2017/10/31/7875/</url>
    <content><![CDATA[<p>docker官方仓库里有瘦身精简版的debian镜像叫做slim，当前稳定版为debian:stretch-slim，也可以使用stable-slim,testing-slim,unstable-slim,jessie-slim等标签，debian:stretch-slim大小大约为55.3MB，虽然还是比alpine大了不少，不过已经算很轻量了。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>Untitled Post - 187</title>
    <url>/2017/12/16/7891/</url>
    <content><![CDATA[<p>CPPFLAGS是<strong>C</strong>/C++ <strong>P</strong>re<strong>P</strong>rocessor预处理器选项，适用于C和C++语言。CFLAGS是适用于C语言的编译器选项，而CXXFLAGS是适用于C++的编译器选项。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>7z版本兼容性问题</title>
    <url>/2019/06/26/7z-compatibility-issue/</url>
    <content><![CDATA[<a id="more"></a>
<p>有一个7z格式分卷压缩的备份文件，使用7z解压缩时出现错误</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ 7z x db_2019_06_25.7z<span class="number">.001</span> </span><br><span class="line"></span><br><span class="line"><span class="number">7</span>-Zip \[<span class="number">64</span>\] <span class="number">16.02</span> : Copyright (c) <span class="number">1999</span>-<span class="number">2016</span> Igor Pavlov : <span class="number">2016</span>-<span class="number">05</span>-<span class="number">21</span></span><br><span class="line">p7zip Version <span class="number">16.02</span> (locale=en_US.UTF-<span class="number">8</span>,Utf16=on,HugeFiles=on,<span class="number">64</span> bits,<span class="number">4</span> CPUs Intel(R) Core(TM) i5-<span class="number">6400</span> CPU @ <span class="number">2.</span>70GHz (<span class="number">506E3</span>),ASM,AES-NI)</span><br><span class="line"></span><br><span class="line">Scanning the drive <span class="keyword">for</span> archives:</span><br><span class="line"><span class="number">1</span> file, <span class="number">4697620480</span> bytes (<span class="number">4480</span> MiB)</span><br><span class="line"></span><br><span class="line">Extracting archive: db_2019_06_25.7z<span class="number">.001</span></span><br><span class="line">ERROR: db_2019_06_25.7z<span class="number">.001</span></span><br><span class="line">db_2019_06_25.7z</span><br><span class="line">Open ERROR: Can not open the file <span class="keyword">as</span> \[7z\] archive</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">Can<span class="string">&#x27;t open as archive: 1</span></span><br><span class="line"><span class="string">Files: 0</span></span><br><span class="line"><span class="string">Size: 0</span></span><br><span class="line"><span class="string">Compressed: 0</span></span><br><span class="line"><span class="string">$ file db_2019_06_25.7z.001</span></span><br><span class="line"><span class="string">db_2019_06_25.7z.001: 7-zip archive data, version 0.3</span></span><br></pre></td></tr></table></figure>

<p>因为这个备份文件是在一个debian jessie服务器上使用7-Zip [64] 9.20分卷压缩的，7z archive 版本为0.3<br>而解压缩的机器使用的是7-Zip [64] 16.02，7z archive版本为0.4<br>使用7z 9.20解压缩此文档没有问题，这是7z的向后兼容性问题</p>
<p>备份服务器升级到debian stretch, 7z版本升级到了7-Zip [64] 16.02，这个问题就不存在了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>7zip与bzip2简单比较</title>
    <url>/2013/01/31/7zip-bzip2-simple-compare/</url>
    <content><![CDATA[<p>7zip与bizp2压缩率与消耗时间的简单比较</p>
<a id="more"></a>
<p>bzip2在GNU系统中使用广泛，一般与tar结合使用，bzip2负责压缩，tar(Tape ARchive)负责归档。<br>bzip2比gzip或者ZIP的压缩效率高，但是它的压缩速度较慢,某些情况下bzip2的压缩效率不如7zip。<br>一直使用tar和bzip2归档oracle导出备份文件,随着备份文件的增大，发现bzip2越来越力不从心。</p>
<p>遂将其<strong>与7zip做一简单比较</strong></p>
<p>原始文件为一15.3G大小的oracle导出dmp文件，先由bzip2出场</p>
<p><strong>bzip2</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ date &amp;&amp; bzip2 --best oracle.dmp &amp;&amp; date</span><br></pre></td></tr></table></figure>
<p>压缩时间为1小时33分，压缩后大小为4.7GB,best参数并不是最高压缩率，只是默认参数而已，参见man bzip2</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ date &amp;&amp; bunzip2 oracle.dmp.bz2 &amp;&amp; date</span><br></pre></td></tr></table></figure>
<p>解压缩时间为13分钟</p>
<p><strong>7zip</strong></p>
<p>快速压缩,压缩方法设置为x=3</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ date &amp;&amp; 7z a oracle.dmp.7z oracle.dmp -mx=<span class="number">3</span> &amp;&amp; date</span><br></pre></td></tr></table></figure>
<p>压缩时间为27分，压缩后大小为3.5G</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ date &amp;&amp; 7z e oracle.dmp.7z &amp;&amp; date</span><br></pre></td></tr></table></figure>
<p>解压缩时间为6分钟</p>
<p>正常压缩，压缩方法设置为x=5</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ date &amp;&amp; 7z a oracle.dmp.7z oracle.dmp -mx=<span class="number">5</span> &amp;&amp; date</span><br></pre></td></tr></table></figure>
<p>压缩时间为56分钟，压缩后大小为2.9G</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ date &amp;&amp; 7z e oracle.dmp.7z &amp;&amp; date</span><br></pre></td></tr></table></figure>
<p>解压缩时间为6分钟</p>
<p><strong>结论</strong></p>
<p>虽然这是很粗糙的测试，但是也可以看出端倪，7zip还是相当优秀的，压缩时间短，压缩后的文件小，压缩效率很高。</p>
<p><strong>7zip与tar结合使用</strong></p>
<p>debian源里关于7zip有如下几个包</p>
<figure class="highlight plain"><figcaption><span>apt-cache search 7zip</span></figcaption><table><tr><td class="code"><pre><span class="line">p7zip - 7z file archiver with high compression ratio</span><br><span class="line">p7zip-full - 7z and 7za file archivers with high compression ratio</span><br><span class="line">p7zip-rar - non-free rar module for p7zip</span><br></pre></td></tr></table></figure>
<p>包p7zip-full比p7zip处理更多的压缩格式，p7zip-rar提供对rar格式的支持，但这是个非自由的模块。</p>
<p>与tar的结合</p>
<p>归档压缩目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tar cf - directory 7za a -si directory.tar.7z</span><br></pre></td></tr></table></figure>
<p>解压缩还原目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ 7za x -so directory.tar.7z tar xf -</span><br></pre></td></tr></table></figure>

<p>参数说明<br>-si Read data from StdIn，从标准输入读取数据<br>-so Write data to StdOut，将数据写入标准输出</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian查看Acess MDB数据库文件</title>
    <url>/2013/10/31/access-mdb-viewer/</url>
    <content><![CDATA[<p>虽然ACESS MDB数据库是M$专有格式，有时候还是需要查看。</p>
<a id="more"></a>
<p># apt-get install mdbtools mdbtools-gmdb</p>
<p>mdbtools-gmdb是mdbtools的图形前端。安装完毕后运行MDB Viewer即可。</p>
<p><a href="http://mdbtools.sourceforge.net/">MDB Tools</a> 当前只能读取 Access 97 (Jet 3) 和 Access 2000/2002 (Jet 4) 格式，写支持还在开发中。<br>其实只要读功能就好了。</p>
<p><strong>拒绝使用专有格式，读取也是不得以而为之。</strong></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用acme.sh自动部署Let’s Encrypt证书</title>
    <url>/2019/01/19/acme-sh-deploy-lets-encrypt-certs/</url>
    <content><![CDATA[<a id="more"></a>
<p>TLS-SNI-01已经deprecated，但certbot尚不支持tls-alpn-01验证方法，因此可以使用dehydrated或者acme.sh通过https来获取Let’s Encrypt证书。</p>
<p>下面使用acme.sh，由于使用80，443端口的权限，拷贝证书文件的权限以及reload nginx的权限等问题，使用acme.sh正确的姿势应该是使用root账户来运行。</p>
<p><strong>安装</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># curl https://get.acme.sh sh</span><br><span class="line"># source ~/.bashrc # 使acme.sh alias生效</span><br></pre></td></tr></table></figure>

<p>如果使用acme.sh standalone方式来获取证书，还需要安装socat</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install socat</span><br></pre></td></tr></table></figure>

<p><strong>http方式获取证书</strong></p>
<p>http验证支持standalone、webroot或webserver(apache,nginx)方式获取证书，获取证书的过程不会破坏系统环境。</p>
<p>standalone方式,acme.sh会启动一个使用80端口的web server</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --issue -d mydomain.com --standalone</span><br></pre></td></tr></table></figure>
<p>80端口需要特权用户才能监听</p>
<p>webroot方式，指定正在运行的网站的root目录</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/wwwroot/mydomain.com/</span><br></pre></td></tr></table></figure>

<p>webserver方式，指定使用的web server，目前支持apache和nginx</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --issue -d mydomain.com --apache</span><br><span class="line"># acme.sh --issue -d mydomain.com --nginx</span><br></pre></td></tr></table></figure>

<p>默认申请的是RSA证书，acme.sh同样支持申请ECC证书，只要添加额外的<code>--keylength</code>参数即可，支持申请256和384位的ECC证书</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --issue -d mydomain.com --standalone --keylength ec-256</span><br></pre></td></tr></table></figure>

<p><strong>安装证书</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># acme.sh --installcert -d mydomain.com \\</span><br><span class="line"> --key-file /etc/nginx/ssl/mydomain.com.key \\</span><br><span class="line"> --fullchain-file /etc/nginx/ssl/fullchain.cer \\</span><br><span class="line"> --reloadcmd <span class="string">&quot;systemctl force-reload nginx&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>自动更新证书</strong></p>
<p>acme.sh自动安装了crontab入口，acme.sh会自动记录下申请证书和安装证书的命令，所以会在设定的周期内自动自行这些指令。</p>
<p><strong>手动更新证书</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --renew -d example.com --force</span><br></pre></td></tr></table></figure>

<p>或者ECC证书</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --renew -d example.com --force --ecc</span><br></pre></td></tr></table></figure>

<p><strong>acme.sh自动更新</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --upgrade --auto-upgrade</span><br></pre></td></tr></table></figure>

<p>关闭自动更新</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --upgrade --auto-upgrade 0</span><br></pre></td></tr></table></figure>

<p>手动更新</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --upgrade</span><br></pre></td></tr></table></figure>

<p><strong>卸载</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --uninstall</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://medium.com/@decrocksam/deploying-lets-encrypt-certificates-using-tls-alpn-01-https-18b9b1e05edf">Deploying Let’s Encrypt certificates using tls-alpn-01 (https)</a><br>[2]<a href="https://www.wuzhiyuan.com/2018/11/18/tls-alpn/">使用TLS-ALPN-01验证签发证书</a><br>[3]<a href="https://github.com/lukas2511/dehydrated">dehydrated</a><br>[4]<a href="https://github.com/Neilpang/acme.sh">acme.sh</a><br>[5]<a href="https://github.com/Neilpang/acme.sh/wiki/TLS-ALPN-without-downtime">TLS ALPN without downtime</a><br>[6]<a href="https://github.com/Neilpang/acme.sh/wiki/%E8%AF%B4%E6%98%8E">acme.sh中文说明</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>acme.sh使用DNS-01申请/自动更新Let&#39;s Encrypt ssl证书</title>
    <url>/2020/12/03/acme-sh-dns-01-issue-renew-lets-encrypt-ssl-cert/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>安装acme.sh</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ curl https:<span class="comment">//get.acme.sh sh</span></span><br><span class="line">$ source ~/.bashrc</span><br></pre></td></tr></table></figure>
<p>会自动添加cron任务</p>
<p><strong>创建api token</strong></p>
<p>acme.sh支持name.com，访问<a href="https://www.name.com/account/settings/api%EF%BC%8C%E9%9A%8F%E6%84%8F%E8%AE%BE%E7%BD%AEtoken%E6%98%B5%E7%A7%B0acme_sh_dns%EF%BC%8C%E7%94%9F%E6%88%90token">https://www.name.com/account/settings/api，随意设置token昵称acme_sh_dns，生成token</a><br>编辑~/.acme.sh/account.conf添加如下两行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> Namecom_Username=<span class="string">&quot;your_name_com_username&quot;</span></span><br><span class="line"><span class="keyword">export</span> Namecom_Token=<span class="string">&quot;*********&quot;</span></span><br></pre></td></tr></table></figure>
<p>Namecom_Username指定你在name.com的用户名而不是token name</p>
<p><strong>申请证书</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ acme.sh --issue --dns dns_namecom -d g.openwares.net</span><br></pre></td></tr></table></figure>
<p>可以会有提示</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">g.openwares.net:Verify error:DNS problem: SERVFAIL looking up CAA <span class="keyword">for</span> openwares.net - the domain<span class="string">&#x27;s nameservers may be malfunctioning</span></span><br></pre></td></tr></table></figure>
<p>忽略即可</p>
<p><strong>安装证书</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ acme.sh --install-cert -d g.openwares.net \\</span><br><span class="line">--cert-file /path/to/certfile/cert.pem \\</span><br><span class="line">--key-file /path/to/keyfile/key.pem \\</span><br><span class="line">--fullchain-file /path/to/fullchain/certfile/fullchain.pem</span><br></pre></td></tr></table></figure>

<p><strong>自动更新</strong><br>acme.sh自动安装了crontab入口，acme.sh会自动记录下申请证书和安装证书的命令，所以会在设定的周期内自动更新证书。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>acpi_pad导致高cpu占用</title>
    <url>/2019/04/06/acpi-pad-high-cpu-util/</url>
    <content><![CDATA[<a id="more"></a>
<p>服务器上突然出现很多acpi_pad/*进程,*为0,1,2,3,…，每个进程都占用100%CPU，导致系统极度缓慢</p>
<p>解决办法就是移除acpi_pad模块</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># rmmod acpi_pad</span><br></pre></td></tr></table></figure>
<p>并将其加入模块blacklist，/etc/modprobe.d/blacklist.conf文件中添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">blacklist acpi_pad</span><br></pre></td></tr></table></figure>

<p>或者<br>在 grub 的 kernel 配置后面，添加 acpi_pad.disable=1 重启机器之后，开机就不会自动加载 acpi_pad 模块</p>
<p>注：早上跑到机房一看，空调自己关闭了，环境温度40几度，服务器、机柜一片报警，赶快打开两个空调降温，acpi_pad的问题是不是与环境温度过高有关呢？</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>activemq debian 自启动配置</title>
    <url>/2016/07/04/activemq-debian-service/</url>
    <content><![CDATA[<a id="more"></a>
<p>activemq官方提供了init脚本</p>
<p>添加运行activemq的用户：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># useradd -m activemq -d /srv/activemq</span><br></pre></td></tr></table></figure>

<p>安装activemq</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ cd /srv/activemq</span><br><span class="line">$ sudo -u activemq tar zxvf apache-activemq-&lt;version&gt;-bin.tar.gz</span><br><span class="line"># ln -snf apache-activemq-&lt;version&gt; current</span><br><span class="line"># chown -R activemq:users apache-activemq-&lt;version&gt;</span><br></pre></td></tr></table></figure>

<p>修改activemq默认配置，使用activemq用户来运行activemq</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># cp apache-activemq-&lt;version&gt;/bin/env /etc/default/activemq</span><br><span class="line"># sed -i &#x27;~s/^ACTIVEMQ_USER=&quot;&quot;/ACTIVEMQ_USER=&quot;activemq&quot;/&#x27; /etc/default/activemq</span><br></pre></td></tr></table></figure>

<p>安装init脚本:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ln -snf /srv/activemq/current/bin/activemq /etc/init.d/activemq</span><br><span class="line"># update-rc.d activemq defaults</span><br></pre></td></tr></table></figure>

<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>activemq无法启动问题</title>
    <url>/2016/07/02/activemq-start-error/</url>
    <content><![CDATA[<a id="more"></a>
<p>安装完成后，首先要启用默认实例：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ln -sf /etc/activemq/instances-available/main /etc/activemq/instances-enabled/main</span><br></pre></td></tr></table></figure>

<p>然后以debug方式启动activemq的main实例：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># /etc/init.d/activemq console main</span><br></pre></td></tr></table></figure>
<p>会有错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR Temporary Store limit is <span class="number">50000</span> mb, whilst the temporary data directory: <span class="regexp">/var/</span>lib/activemq/main/data/localhost/tmp_storage only has <span class="number">3346</span> mb <span class="keyword">of</span> usable space</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>这是因为硬盘空间不够了，需要更改配置文件/etc/activemq/instances-enabled/main/activemq.xml，broker节内添加以下行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"> &lt;systemUsage&gt;</span><br><span class="line"> &lt;systemUsage&gt;</span><br><span class="line"> &lt;storeUsage&gt;</span><br><span class="line"> &lt;storeUsage limit=<span class="string">&quot;1 gb&quot;</span>/&gt;</span><br><span class="line"> &lt;/storeUsage&gt;</span><br><span class="line"> &lt;tempUsage&gt;</span><br><span class="line"> &lt;tempUsage limit=<span class="string">&quot;500 mb&quot;</span>/&gt;</span><br><span class="line"> &lt;/tempUsage&gt;</span><br><span class="line"> &lt;/systemUsage&gt;</span><br><span class="line">&lt;/systemUsage&gt;</span><br></pre></td></tr></table></figure>

<p>如果不配置storeUsage,会有这样的错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR Store limit is <span class="number">0</span> mb, whilst the max journal file size <span class="keyword">for</span> the store is: <span class="number">32</span> mb, the store will not accept any data when used.</span><br></pre></td></tr></table></figure>


<p>References:<br>[1]<a href="https://access.redhat.com/solutions/348353">Temporary Store Limit Error When Starting the Broker</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>为debian testing netinst镜像添加non-free firmware的addfirmare.sh脚本</title>
    <url>/2014/01/09/addfirmare-sh-script/</url>
    <content><![CDATA[<a id="more"></a>
<p>上一篇<a href="https://openwares.net/linux/debian_testing_netinst_iso_add_non_free_firmware.html">post</a>提到已经有集成firmware的netinst iso镜像文件可以下载了,但很不幸,服务器安装的时候仍然提示找不到ql2400_fw.bin,也就是installer仍然没有找到qlogic卡的firmware。</p>
<p> 无论使用原始的netinst还是添加firmware的netinst镜像,都不会提示需要额外的firmware。官方的<a href="https://wiki.debian.org/Firmware">wiki</a>也提到,安装程序有时候会提示用户完成安装所需要的firmware,有时候却不会提示。所以建议在安装之前,下载<a href="http://cdimage.debian.org/cdimage/unofficial/non-free/firmware/">non-free的firmware包</a>,将其解压到移动存储设备的/firmware目录下,安装程序如果需要会自动的去移动存储设备的/firmware目录下寻找相应的firmware。</p>
<p>另一个解决办法是为原始的netinst iso镜像添加firmware,脚本如下,只支持netinst testing iso镜像:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">set -ex</span><br><span class="line"></span><br><span class="line">if \[ $# != 2 \]; then</span><br><span class="line"> echo <span class="string">&quot;Usage: addfirmware.sh &lt;origin_iso_file&gt; &lt;new_iso_file&gt;&quot;</span></span><br><span class="line"> exit <span class="number">1</span></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">orign_iso_file=$<span class="number">1</span></span><br><span class="line">new_iso_file=$<span class="number">2</span></span><br><span class="line"></span><br><span class="line">#临时目录</span><br><span class="line">temp=$(mktemp -d)</span><br><span class="line">origin_iso=$&#123;temp&#125;/old</span><br><span class="line">new_iso=$&#123;temp&#125;/<span class="keyword">new</span></span><br><span class="line">firmware_file=$&#123;temp&#125;/firmware</span><br><span class="line">firmware_target=$&#123;firmware_file&#125;/target</span><br><span class="line">initrd=$&#123;temp&#125;/initrd</span><br><span class="line"></span><br><span class="line">#原始工作目录</span><br><span class="line">origin_pwd=$(pwd)</span><br><span class="line"></span><br><span class="line">mkdir $&#123;origin_iso&#125; $&#123;firmware_file&#125; $&#123;initrd&#125;</span><br><span class="line"></span><br><span class="line">#挂载原始镜像iso文件,挂载后是只读的,拷贝全部文件到./new目录</span><br><span class="line">sudo mount -o loop $&#123;orign_iso_file&#125; $&#123;origin_iso&#125;</span><br><span class="line">cp -a $&#123;origin_iso&#125; $&#123;new_iso&#125;</span><br><span class="line">sudo umount $&#123;origin_iso&#125;</span><br><span class="line"></span><br><span class="line">#将初始化内存盘压缩cpio文件解压到./initrd目录</span><br><span class="line">cd $&#123;initrd&#125; &amp;&amp; gunzip &lt; $&#123;new_iso&#125;/install.amd/initrd.gz sudo cpio --extract --preserve --verbose</span><br><span class="line"></span><br><span class="line">#下载testing的firmware包</span><br><span class="line">cd $&#123;firmware_file&#125; &amp;&amp; </span><br><span class="line">wget http:<span class="comment">//cdimage.debian.org/cdimage/unofficial/non-free/firmware/testing/current/firmware.tar.gz </span></span><br><span class="line">&amp;&amp; tar zxf firmware.tar.gz</span><br><span class="line"></span><br><span class="line">#将所有的firmware deb包提取到./firmware/target目录</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> *deb; <span class="keyword">do</span></span><br><span class="line"> dpkg-deb -x $&#123;file&#125; $&#123;firmware_target&#125;</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">#将target目录下所有的内容拷贝到./initrd目录</span><br><span class="line">sudo cp -ra $&#123;firmware_target&#125;/. $&#123;initrd&#125;</span><br><span class="line"></span><br><span class="line">#打包新的initrd文件并拷贝到./new目录下</span><br><span class="line">cd $&#123;initrd&#125; &amp;&amp; find . cpio --create --format=<span class="string">&#x27;newc&#x27;</span> gzip -<span class="number">9</span> &gt; ../initrd.gz.new</span><br><span class="line">sudo cp ../initrd.gz.new $&#123;new_iso&#125;/install.amd/initrd.gz</span><br><span class="line"></span><br><span class="line">#制作新的镜像文件</span><br><span class="line">cd $&#123;origin_pwd&#125; &amp;&amp;</span><br><span class="line">sudo genisoimage -o $&#123;new_iso_file&#125; -b isolinux/isolinux.bin \\</span><br><span class="line"> -c isolinux/boot.cat -no-emul-boot -boot-load-size <span class="number">4</span> -boot-info-table -J -R $&#123;new_iso&#125;</span><br><span class="line"></span><br><span class="line">sudo rm -rf $&#123;temp&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>USB stick引导</strong></p>
<p>上面制作的iso镜像刻录光盘安装系统是没有问题的。但如果要从USB引导就不可以了,因为从USB或硬盘启动时,PC-BIOS需要一个MBR,这样需要再为ISO镜像文件添加一个MBR,这与原来的El Torito引导记录并不冲突,二者可以共存。因此就可以创建一个MBR来启动El Torito引导记录,从而无论是从CDROM还是USB,HDD都可以正确引导。<br>这种MBR就叫做<a href="http://libburnia-project.org/wiki/FAQ#isohybrid">isohybrid</a>。</p>
<p>syslinux提供了这样的isohybrid MBR,还需要使用xorriso来制作镜像。因此先安装xorriso和syslinux</p>
<h1 id="apt-get-install-xorriso-syslinux"><a href="#apt-get-install-xorriso-syslinux" class="headerlink" title="apt-get install xorriso syslinux"></a>apt-get install xorriso syslinux</h1><p>然后将上面脚本最后制作iso的命令更改为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># -iso-level iso级别3允许文件大于4G</span><br><span class="line"># -partition_offset 分区表起始位置</span><br><span class="line"># -isohybrid-mbr 主引导记录文件</span><br><span class="line"># -b 为PC-BIOS指定El Torito引导记录文件(boot image)</span><br><span class="line"># -e 为EFI指定El Torito引导记录文件(boot image)</span><br><span class="line"># -c 指定El Torito Boot Catalog文件</span><br><span class="line"># -no-emul-boot 没有模拟启动,默认是软盘模拟启动</span><br><span class="line"># -boot-load-size BIOS要读取引导记录文件(boot image)的几个数据块,boot image由-b参数指定。</span><br><span class="line"># -boot-info-table 引导信息表写入boot image</span><br><span class="line"># -r或-R Rock Ridge扩展 </span><br><span class="line"># -J Joliet扩展,用于windows系统</span><br><span class="line"># -V 指定volume lable</span><br><span class="line"># -o 输出iso文件</span><br><span class="line">sudo xorriso -<span class="keyword">as</span> mkisofs -iso-level <span class="number">3</span> -partition_offset <span class="number">16</span> -isohybrid-mbr \\</span><br><span class="line">/usr/lib/syslinux/isohdpfx.bin -o $&#123;new_iso_file&#125; -b isolinux/isolinux.bin -c isolinux/boot.cat \\</span><br><span class="line">-no-emul-boot -boot-load-size <span class="number">4</span> -boot-info-table -r -V <span class="string">&quot;firmwared debian&quot;</span> $&#123;new_iso&#125;</span><br></pre></td></tr></table></figure>

<p>这里没有使用-J参数,如果添加了此参数会有警告:</p>
<p>libisofs: WARNING : Can’t add /debian to Joliet tree. Symlinks can<br> only be added to a Rock Ridget tree.<br>…</p>
<p>-J参数为iso生成Joliet目录树,当iso文件在windows系统下使用时才有用,Joliet不是标准的,只有windows和linux(为了和windows兼容)在使用。因此这个参数可以安全的去掉。</p>
<p>这里使用的isohybrid MBR为syslinux提供的/usr/lib/syslinux/isohdpfx.bin,这样生成的iso无论是刻盘还是写到usb stick都可以正常的引导安装了。</p>
<p><a href="/downloads/addfirmware.sh">脚本下载</a>。</p>
<p>参考:<br><a href="https://github.com/YunoHost/cd_build/blob/master/add-firmware-to">add-firmware-to</a><br><a href="http://lumux.co.uk/2012/08/09/rebuilding-debian-installer-iso-to-include-additional-drivers/">REBUILDING DEBIAN INSTALLER ISO TO INCLUDE ADDITIONAL DRIVERS</a><br><a href="http://wiki.osdev.org/Mkisofs">Mkisofs</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>adduser和useradd的区别</title>
    <url>/2015/08/29/adduser-vs-useradd/</url>
    <content><![CDATA[<a id="more"></a>
<p>man useradd里有一句话:</p>
<p>useradd is a low level utility for adding users. On Debian, administrators should usually use adduser(8) instead</p>
<p>也就是说useradd是一个低层次的用户添加工具，适合高阶用户使用，而在简单的场合适合使用adduser来添加用户，adduser添加用户时系统有step by step的用户提示来交互时的添加用户，使用比较简单，无需指定复杂的命令行选项。</p>
<p>那么说，<strong>useradd适用于非交互式场景</strong>，比如在脚本中创建用户，而<strong>adduser更适用于交互式场景</strong>。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>alacritty无法使用输入法问题</title>
    <url>/2020/01/14/alacritty-use-im/</url>
    <content><![CDATA[<a id="more"></a>
<p>alacritty在使用wayland的系统上无法切换出中文输入法，将alacritty菜单项执行的命令更改为：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">env WINIT_UNIX_BACKEND=x11 alacritty</span><br></pre></td></tr></table></figure>
<p>这样将渲染后端更改为x11</p>
<p>比如~/.local/share/applications/alacritty.desktop</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[Desktop Entry\]</span><br><span class="line">Type=Application</span><br><span class="line">TryExec=alacritty</span><br><span class="line">Exec=env WINIT_UNIX_BACKEND=x11 alacritty</span><br><span class="line">Icon=Alacritty</span><br><span class="line">Terminal=<span class="literal">false</span></span><br><span class="line">Categories=System;TerminalEmulator;</span><br><span class="line"></span><br><span class="line">Name=Alacritty</span><br><span class="line">GenericName=Terminal</span><br><span class="line">Comment=A cross-platform, GPU enhanced terminal emulator</span><br><span class="line">StartupWMClass=Alacritty</span><br><span class="line">Actions=New;</span><br><span class="line"></span><br><span class="line">\[Desktop Action New\]</span><br><span class="line">Name=New Terminal</span><br><span class="line">Exec=alacritty</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>misc</tag>
      </tags>
  </entry>
  <entry>
    <title>使用alsa驱动应用程序音量调节问题</title>
    <url>/2011/07/07/alsa-app-volume-tune/</url>
    <content><![CDATA[<p>现在ALSA(Advanced Linux Sound Architecture)已经彻底取代了OSS(Open Sound System)成了linux上的声卡驱动程序标准</p>
<a id="more"></a>
<p>ALSA也自带了mixer程序,已经十分好用了。刚装完系统的时候顺手也装上了pulseaudio这个声音服务器，pulseaudio是工作在alsa之上的，是应用程序和alsa之间抽象层，增加了linux声音系统的灵活性。但这个pulseadio在debian testing问题挺多的，最后只好卸载掉。</p>
<p>但是使用mplayer的时候发现，用0和9快捷键调节音量时，音量没有任何变化，无法调节，打开音量控制界面，再调节mplayer的音量，发现pcm音量在动，手动在系统音量调节界面调节一下headphone音量，mplayer的音量有变化了。原来电脑前面板的音频插口是独立的，是专门给耳机用的，是由headphone线控制的，而pcm与headphone是独立调节的，问题就出现在这里。</p>
<p>没找到mplayer怎样调节headphone音量，但是可以设置mplayer调节软音量，这样即可以调节音量又可以不影响其他应用程序的音量，这一点儿上pulseaudio有优势了，应用程序根本不用考虑太多，直接调节音量，pulseaudio会接管一切，应用程序之间不会相互影响。在mplayer的配置文件~/.mplayer/config中加如下行</p>
<p>softvol=1<br>softvol-max=100<br>这样以来mplayer快捷键0和9又可以调节音量了，而且不影响其他引用程序的音量。</p>
<p>audacious也存在这样的问题，调节音量失效，其实简单设置一下就可以了，而且audacious也支持软音量调节。打开preferencs -&gt; audio 界面 打钩选择”use softwares volume control”，然后点击进入 output plugin prefrences界面，mixer element:选择headphone。这样就可以独立调节音量了。如果不选择软音量控制，则调节的是headphone音量，会影响其他应用程序。</p>
<p>其实还是用pulseaudio更省事。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>更新keyspace的复制因子</title>
    <url>/2015/07/29/alter-keyspace-replication-factor/</url>
    <content><![CDATA[<a id="more"></a>
<p>keyspace创建以后，仍然可以更改其复制因子，也就是keyspace中数据的复制份数是可以动态修改的。</p>
<p>cassandra集群的系统keyspace system_auth默认的replication factor是1，也就是其实是没有冗余的。如果这唯一的节点挂掉，就无法再登录到集群了。<br>因此官方文档推荐将其复制因子设置为每个数据中心的每一个节点。也就是将其复制到集群中的每一个节点上。</p>
<p>查看system_auth的复制因子</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; DESC KEYSPACE system_auth</span><br><span class="line">CREATE KEYSPACE system_auth WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;SimpleStrategy&#x27;</span>, <span class="string">&#x27;replication_factor&#x27;</span>: <span class="string">&#x27;1&#x27;</span>&#125; AND durable_writes = <span class="literal">true</span>;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>果然replication factor只有1,修改之：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; ALTER KEYSPACE system_auth WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;NetworkTopologyStrategy&#x27;</span>, <span class="string">&#x27;dc1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;dc2&#x27;</span>:<span class="number">2</span>&#125;;</span><br></pre></td></tr></table></figure>

<p>durable_writes参数用于设置写数据时是否写入commit log,如果设置为false,则写请求不会写commit log，会有丢失数据的风险。<br>此参数默认为true,即要写commit log,生产系统应该将该参数设置为true。</p>
<p>References:<br>[1]<a href="http://docs.datastax.com/en/cql/3.1/cql/cql_reference/create_keyspace_r.html">CREATE KEYSPACE</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>amdgpu setup</title>
    <url>/2018/05/21/amdgpu-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p>ubuntu 16.04.4<br>amdgpu-pro 17.40-492261</p>
<p>before install amdgpu-pro<br>UEFI:<br>peg0 -&gt; gen2<br>peg1 -&gt; gen2<br>pci latency time -&gt; 96<br>above 4G memory -&gt; disable<br>hd audio controller -&gt; disable<br>intel serial i/o -&gt; disable<br>legacy usb support -&gt; enable<br>fastboot -&gt; disable<br>boot mode -&gt; legacy + uefi<br>comm port -&gt; disable<br>LPT port -&gt; disable</p>
<p>install <a href="https://support.amd.com/en-us/kb-articles/Pages/AMDGPU-PRO-Driver-for-Linux-Release-Notes.aspx">amdgpu-pro</a><br>$&gt; sudo update-pciids</p>
<p>reboot</p>
<p>UEFI:<br>above 4G memory -&gt; enable</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Android修改系统字体完美显示英文国际音标</title>
    <url>/2011/03/15/android-font-phonetic-display/</url>
    <content><![CDATA[<a id="more"></a>
<p>在推上fo了个toefl单词机器人,没想到很多单词的音标显示成了小方块,那就是android默认的英文字体对某些英语国际音标不支持了,当然我的Galaxy S刷了第三方ROM的，不过从网上的帖子来看，官方的字体存在一样的问题，总而言之是字体的问题了。</p>
<p>也搜了一些帖子，但没有很好的解决方案，默认的英文字体还是挺美观的，只是某些英语音标的编码位上缺失了相应的字符而已，Anroid使用Java作为默认开发环境,那默认的字体也应该是使用UNICODE UCS编码的，事实证明的却如此。那就很简单了，强大的字体编辑工具FontForge派上用场了。</p>
<p>Ubuntu仓库里面的版本太低了，可以使用GetDeb仓库来安装最新版本的FontForge。用FontForge打开Android默认的英文字体DroidSans.ttf，果然国际音标编码区域空空如也，英语音标显示不完全也就一点儿不奇怪了。从<a href="http://zh.wikipedia.org/zh-sg/%E5%9B%BD%E9%99%85%E9%9F%B3%E6%A0%87#Unicode.E7.B7.A8.E7.A2.BC">国际音标wiki</a>上查找到了这写符号的UNICODE编码，从DejaVuSerif.ttf和Gothic.ttf这两个字体里面提取了对应的字形(glyph)插入到DroidSans.ttf相应的BMP(Basic Multilingual Plane)编码位上。当然只补充了英语音标会用到的字符，包括ɑ,ɒ,ɔ,ə,ɛ,ɜ,ɪ,ɵ,ʃ,ʌ,ʒ,ʤ,ʦ,ʧ这几个常用音标字符。默认的字体竟然连重音(primary stress)和次重音(Secondary stress)这两个符号都没有，一并补齐了。</p>
<p>将制作好的字体覆盖Android默认英文字体/system/fonts/DroidSans.ttf，当然需要root权限，再看英语音标，显示的相当完美了，google dictionary里面的音标也完全没有问题。</p>
<p>修改后的字体请猛击<a href="/downloads/DroidSans.ttf.zip"><strong>此处</strong></a>下载。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>官方正式推出Android版Skype</title>
    <url>/2010/10/05/android-skype-release/</url>
    <content><![CDATA[<p>期待已久的Skype for android正式推出，不过不幸的是只支持Android 2.1及以后的版本.</p>
<a id="more"></a>
<p>已经可以从android market下载安装，或者用手机访问skype.com/m来下载安装.</p>
<p>可以进行免费的Skype-to-Skype通话，发送或接受短消息，也可以群组发送。支持通过wifi或3G以Skype’s great rates呼叫普通电话。如果曾经在电脑上使用Skype，那么当登陆Android Skype后，所有的联系人都会自动出现在联系人列表。</p>
<p>详细消息见<a href="http://blogs.skype.com/en/2010/10/android.html?cm_mmc=socialmtwitter-_-globalintlen-_-skype-_-androidannouncement">官方blog</a>.</p>
]]></content>
      <categories>
        <category>Mobile</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>use bridges to antibanned for tor on debian/ubuntu linux</title>
    <url>/2009/09/27/antibanned/</url>
    <content><![CDATA[<p>tor was banned recently by “some fucking reason”,all tor tcp connections stay at SYN_SENT state,that is,the packets is eated somewhere,so the connections can’t be established.oh fuck! </p>
<p>to reslove this fucking matter,following the steps list below.</p>
<p>step 1:<br>send a mail with subject and content all “get bridges” to <a href="mailto:&#98;&#114;&#x69;&#100;&#103;&#x65;&#115;&#x40;&#x74;&#x6f;&#x72;&#112;&#x72;&#x6f;&#x6a;&#101;&#99;&#116;&#x2e;&#111;&#114;&#103;">&#98;&#114;&#x69;&#100;&#103;&#x65;&#115;&#x40;&#x74;&#x6f;&#x72;&#112;&#x72;&#x6f;&#x6a;&#101;&#99;&#116;&#x2e;&#111;&#114;&#103;</a>,after a moment,the bridges list will be delivered to your mailbox.the bridges list looks like this</p>
<p>bridge ip:port</p>
<p>it can be more than one bridges.</p>
<p>step 2:<br>open the /etc/tor/torrc file,add tow lines with contents “UseBridges 1” and “UpdateBridgesFromAuthority 1” separately at the last.whereafter,add the bridges you received.finally looks like this<br>UseBridges 1<br>UpdateBridgesFromAuthority 1<br>bridge ip:port</p>
<p>step 3:<br>issue the command<br>sudo /etc/init.d/tor restart<br>on terminal to restart the tor and it will be ok</p>
<p>the great fucking wall is damn.</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>为apt-get设置代理服务器</title>
    <url>/2015/03/24/apt-get-setup-proxy/</url>
    <content><![CDATA[<a id="more"></a>
<ol>
<li> 使用配置文件<br>在全局配置文件中添加如下格式的代理：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Acquire::http::<span class="built_in">Proxy</span> <span class="string">&quot;http://proxy_ip:8080&quot;</span>;</span><br><span class="line">Acquire::ftp::proxy <span class="string">&quot;ftp://proxy_ip:8000/&quot;</span>;</span><br><span class="line">Acquire::https::proxy <span class="string">&quot;https://proxy_ip:8000/&quot;</span>;</span><br><span class="line">Acquire::socks::proxy <span class="string">&quot;socks://proxy_ip:proxy_port/&quot;</span>;</span><br><span class="line"># 如果ftp需要登陆</span><br><span class="line">Acquire::ftp</span><br><span class="line"> &#123;</span><br><span class="line"> <span class="built_in">Proxy</span> <span class="string">&quot;ftp://proxy_ip:2121/&quot;</span>;</span><br><span class="line"> ProxyLogin</span><br><span class="line"> &#123;</span><br><span class="line"> <span class="string">&quot;USER $(SITE_USER)@$(SITE)&quot;</span>;</span><br><span class="line"> <span class="string">&quot;PASS $(SITE_PASS)&quot;</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
或者在apt-get 命令行指定参数文件的位置：<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get -c ~/apt_proxy.conf update</span><br></pre></td></tr></table></figure></li>
<li> 命令行参数<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get -o Acquire::http::proxy=&quot;http://proxy_ip:proxy_port/&quot; update</span><br><span class="line"># apt-get -o Acquire::http::proxy=&quot;http://proxy_ip:proxy_port/&quot; upgrade</span><br></pre></td></tr></table></figure></li>
<li> 全局环境变量<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">export</span> http_proxy=http:<span class="comment">//proxy_ip:proxy_port</span></span><br></pre></td></tr></table></figure>
不过貌似apt-get不是用全局代理配置了？</li>
</ol>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>apt安装软件包指定版本</title>
    <url>/2018/12/06/apt-install-package-versioned/</url>
    <content><![CDATA[<a id="more"></a>
<p>当配置了多个源，特别是添加backports源之后，一个package可能有多个候选版本<br>源是有优先级的，apt会默认从优先级高的源安装package</p>
<p>可以通过apt-cache来查看package候选版本信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ apt-cache policy tmux</span><br><span class="line">tmux:</span><br><span class="line"> Installed: (none)</span><br><span class="line"> Candidate: <span class="number">2.3</span>-<span class="number">4</span></span><br><span class="line"> Version table:</span><br><span class="line"> <span class="number">2.8</span>-<span class="number">1</span>~bpo9+<span class="number">1</span> <span class="number">100</span></span><br><span class="line"> <span class="number">100</span> http:<span class="comment">//ftp.tw.debian.org/debian stretch-backports/main amd64 Packages</span></span><br><span class="line"> <span class="number">2.3</span>-<span class="number">4</span> <span class="number">500</span></span><br><span class="line"> <span class="number">500</span> http:<span class="comment">//ftp.tw.debian.org/debian stretch/main amd64 Packages</span></span><br></pre></td></tr></table></figure>
<p>可以看到backports源优先级比较低，所以默认安装并不会安装最新版本</p>
<p>可以通过指定版本来安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install tmux=<span class="number">2.8</span>-<span class="number">1</span>~bpo9+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>bpo就是backports的缩写，</p>
<p>或者指定从backports源里安装：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install tmux -t stretch-backports</span><br></pre></td></tr></table></figure>

<p>还可以查看源里多个版本的详细信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ apt-cache show tmux</span><br><span class="line">Package: tmux</span><br><span class="line">Version: <span class="number">2.8</span>-<span class="number">1</span>~bpo9+<span class="number">1</span></span><br><span class="line">Installed-Size: <span class="number">677</span></span><br><span class="line">...</span><br><span class="line">Package: tmux</span><br><span class="line">Version: <span class="number">2.3</span>-<span class="number">4</span></span><br><span class="line">Installed-Size: <span class="number">620</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用apt-mirror搭建debian源镜像</title>
    <url>/2015/12/23/apt-mirror-debian/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian官方提供了脚本<a href="https://openwares.net/linux/setup_debian_archive_mirror.html">ftpsync来搭建源镜像</a>，而apt-mirror是一个更简单便捷的源镜像搭建工具。</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install apt-mirror</span><br></pre></td></tr></table></figure>

<p><strong>配置</strong><br>配置文件/etc/apt/mirror.list只要修改很少的地方，大部分使用默认值即可。</p>
<p>这里使用中科大镜像ftp.cn.debian.org作为上游镜像,只镜像debian jessie amd64架构,不需要镜像源代码。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">############# config ##################</span><br><span class="line">#</span><br><span class="line"># set base_path /var/spool/apt-mirror</span><br><span class="line">#</span><br><span class="line"># set mirror_path $base_path/mirror</span><br><span class="line"># set skel_path $base_path/skel</span><br><span class="line"># set var_path $base_path/var</span><br><span class="line"># set cleanscript $var_path/clean.sh</span><br><span class="line"># set defaultarch &lt;running host architecture&gt;　# 默认架构与镜像主机的架构一致,这里是amd64</span><br><span class="line"># set postmirror_script $var_path/postmirror.sh</span><br><span class="line"># set run_postmirror 0</span><br><span class="line">set nthreads <span class="number">20</span></span><br><span class="line">set _tilde <span class="number">0</span></span><br><span class="line">#</span><br><span class="line">############# end config ##############</span><br><span class="line"></span><br><span class="line">deb http:<span class="comment">//ftp.cn.debian.org/debian jessie main contrib non-free</span></span><br><span class="line">deb http:<span class="comment">//ftp.cn.debian.org/debian/ jessie-backports main contrib non-free</span></span><br><span class="line">deb http:<span class="comment">//ftp.cn.debian.org/debian/ jessie-proposed-updates main contrib non-free</span></span><br><span class="line">deb http:<span class="comment">//ftp.cn.debian.org/debian/ jessie-updates main contrib non-free</span></span><br><span class="line">deb http:<span class="comment">//ftp.cn.debian.org/debian-security/ jessie/updates main contrib non-free</span></span><br><span class="line">#deb-src http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line"></span><br><span class="line"># mirror additional architectures</span><br><span class="line">#deb-alpha http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-amd64 http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-armel http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-hppa http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-i386 http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-ia64 http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-m68k http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-mips http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-mipsel http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-powerpc http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-s390 http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line">#deb-sparc http:<span class="comment">//ftp.us.debian.org/debian unstable main contrib non-free</span></span><br><span class="line"></span><br><span class="line">clean http:<span class="comment">//ftp.cn.debian.org/debian</span></span><br></pre></td></tr></table></figure>

<p><strong>自动同步</strong></p>
<p>只需root权限cron自动运行apt-mirror命令即可。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># crontab -e</span><br></pre></td></tr></table></figure>
<p>最后输入</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># m h dom mon dow command</span><br><span class="line"><span class="number">0</span> <span class="number">0</span> * * * apt-mirror</span><br></pre></td></tr></table></figure>
<p>即可</p>
<p><strong>发布</strong></p>
<p>使用nginx发布源镜像</p>
<p>将apt-mirror的镜像目录链接到/var/www/mirror</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ln -sf /var/spool/apt-mirror/mirror/ftp.cn.debian.org/ mirror</span><br></pre></td></tr></table></figure>

<p>然后将nginx默认主机default(或者单独虚拟主机)的根目录设置为/var/www/mirror,并开启目录列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">root /<span class="keyword">var</span>/www/mirror</span><br><span class="line">location / &#123;</span><br><span class="line"> autoindex on;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其他机器就可以正常使用新建的源镜像了。</p>
<p>References:<br>[1]<a href="http://apt-mirror.github.io/">apt-mirror</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用apt-spy自动查找最快的镜像源</title>
    <url>/2011/06/30/apt-spy-search-source-mirrior/</url>
    <content><![CDATA[<p>debian testing更新这么频繁,找个速度快的源是很有必要的，不然能郁闷死</p>
<a id="more"></a>
<p>apt-spy通过测试带宽来自动寻找速度最快的源，并自动添加list文件,是一个很不错的工具</p>
<p><strong>安装</strong></p>
<p>$sudo apt-get install apt-spy</p>
<p><strong>使用</strong></p>
<p>apt-spy的参数很多，具体看man，这里只介绍最常用的参数<br>-d distrabution 指定为那个分发版查找源,最直观的就是stable,testing和unstable，也可以指定具体的分发版名称，比如当前的squeezy<br>-a area 只测试指定区域area的镜像源列表，有效的值有Africa, Asia, Europe, North-America, Oceania和South-America.</p>
<p>通过一下命令来测试更新源,其他参数默认</p>
<p>$sudo apt-spy -d testing -a asia</p>
<p>apt-spy会测试区域内的源镜像,并将最快的源添加到/etc/apt/sources.lisd.d/apt-spy.list文件中,默认没有打开contrib和non-free。注释掉/etc/apt/sources.list中的源就可以开始使用新的镜像源了。</p>
<p>台湾的源ftp.tw.debian.org真的挺快,最快上到1MB/s了,比官方源快了好几倍。这是移动的线路,从联通线路访问就慢多了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ASPI,SPTI,SPTD简介</title>
    <url>/2010/04/03/aspi-spti-sptd-introduce/</url>
    <content><![CDATA[<p>这三个东西都是用来支持主机与外围SCSI或ATAPI接口存储设备通讯的编程接口。ASPI(Advanced SCSI Programming Interface)是由存储领域大名鼎鼎的Adaptec于1990年代初期开发的，最初是为了支持SCSI驱动器，后来加入了ATAPI驱动器的支持。MS获取授权在windows 9x系列使用这个开发接口。后来MS在NT系列开发了自己的接口，这就是SPTI(SCSI Pass Through Interface)用以取代ASPI。NT系统默认是没有安装ASPI驱动的，不过有些存储应用程序还在使用ASPI接口，可以从Adaptec下载<a href="http://www.adaptec.com/en-US/speed/software_pc/aspi/aspi_471a2_exe.htm">此驱动</a>安装。而SPTD则是由Duplex Secure Ltd.开发的同类接口。</p>
<p>此外，Nero也开发了自己的ASPI驱动。其他比较有名的还有ASAPI等。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>authbind设置</title>
    <url>/2014/01/13/authbind-setup/</url>
    <content><![CDATA[<p>tomcat 7突然无法启动了</p>
<a id="more"></a>
<p><strong>问题及解决</strong></p>
<p>catalina.out中有如下异常:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">SEVERE: Failed to initialize end point associated <span class="keyword">with</span> ProtocolHandler \[<span class="string">&quot;http-bio-80&quot;</span>\]</span><br><span class="line">java.net.SocketException: No such file or directory</span><br><span class="line">at java.net.PlainSocketImpl.socketBind(Native Method)</span><br><span class="line"> ...</span><br><span class="line">SEVERE: Failed to initialize connector \[Connector\[HTTP/<span class="number">1.1</span>-<span class="number">80</span>\]\]</span><br><span class="line">org.apache.catalina.LifecycleException: Failed to initialize component \[Connector\[HTTP/<span class="number">1.1</span>-<span class="number">80</span>\]\]</span><br><span class="line">at org.apache.catalina.util.LifecycleBase.init(LifecycleBase.java:<span class="number">106</span>)</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>

<p>百思不得其解,将tomcat默认端口改回8080,启动成功。看来是绑定到80端口出了问题,但这提示也实在是太模糊了。</p>
<p>查看/etc/authbind/byuid/110文件,110为tomcat7用户的uid:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span>:<span class="number">1</span>,<span class="number">1023</span></span><br></pre></td></tr></table></figure>
<p>这里的设置是允许绑定到ipv4地址的端口1-1023<br>文件的所有者和组都是tomcat7,权限设置也没有问题,不知道为啥就无法绑定80端口了。</p>
<p>/etc/authbind/byuid/110的内容更改为绑定ipv6地址和80端口:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">::/<span class="number">0</span>,<span class="number">80</span></span><br></pre></td></tr></table></figure>
<p>或者允许绑定到一个端口范围,端口1-1023:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">::/<span class="number">0</span>,<span class="number">1</span>-<span class="number">1023</span></span><br></pre></td></tr></table></figure>

<p>重新启动tomcat7,绑定到80端口成功。虽然绑定是ipv6通配地址,但在双协议栈主机上,是可以接受ipv4连接请求的。ipv4地址有对应的ipv6地址映射。<br>有一个系统参数/proc/sys/net/ipv6/bindv6only控制是否只绑定到ipv6地址,如果此值为非0(true),则只绑定到ipv6地址,此参数值默认为0(false),所以可以同时绑定到ipv4和ipv6。</p>
<p>ipv6和ipv4共享相同的端口空间。</p>
<p><strong>authbind的三种配置方式</strong></p>
<p>authbind会依次测试byport,byaddr,byuid直到查找到一个允许的配置才停止查找,否则会失败,无法绑定到请求的端口。</p>
<p><em>byuid</em></p>
<p>刚才使用的是authbind的byuid配置方式,在/etc/authbind/byuid目录下新建文件,以tomcat7的uid为文件名,文件内容为如下格式之一的一行内容,每行格式的具体含义参见man authbind</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">addrmin\[-addrmax\],portmin\[-portmax\]</span><br><span class="line">addr\[/length\],portmin\[-portmax\]</span><br><span class="line">addr4/length:portmin,portmax</span><br></pre></td></tr></table></figure>

<p><em>byport</em></p>
<p>在/etc/authbind/byport目录下新建80文件,使其可以被tomcat7用户读取,则表示可以允许tomcat绑定到80端口</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># touch 80</span><br><span class="line"># chown tomcat7:tomcat7 80</span><br><span class="line"># chmod 0700 80</span><br></pre></td></tr></table></figure>

<p><em>byaddr</em></p>
<p>byaddr有两种形式</p>
<p>/etc/authbind/byaddr/addr,port 或者 /etc/authbind/byaddr/addr:port,前者适用于ipv6和ipv4,后者只适用于ipv4</p>
<p>参考:<br>man authbind</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>authorized_keys的访问控制</title>
    <url>/2014/01/14/authorized-keys-access-control/</url>
    <content><![CDATA[<p>authorized_keys用于存放用户的公钥,另外它还有访问控制的功能。</p>
<a id="more"></a>
<p>authorized_keys文件可以在首部附加一个选项语句,这个选项语句可以用于限制主机访问,执行特定的命名,设置一些其他访问控制选项。</p>
<p>authorized_keys文件格式，每个公钥独占一行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">OPTIONS KEY_TYPE KEY COMMENT</span><br><span class="line">...</span><br><span class="line">OPTIONS KEY_TYPE KEY COMMENT</span><br></pre></td></tr></table></figure>

<p><strong>可访问主机列表</strong></p>
<p>from=”string”用于限制可以通过ssh访问服务器的主机,string可是客户机的规范域名(主机名)或者ip地址,多个值使用逗号分隔，ip地址可以使用address/masklen格式。主机名可以使用通配符,*匹配一个或多个字符,?匹配一个字符。</p>
<p>如果使用主机名,则对应主机必须要做反向DNS解析,也就是要为主机添加PTR记录。服务器通过客户IP地址查询DNS,然后与from语句进行匹配。</p>
<p>这个语句用于进一步增加安全性,因为默认情况下,公钥认证只信任用户的key,和网络/主机无关,如果用户的私钥泄漏,就可以从世界上的任何一个地方登录。通过from语句就可以限制登录的主机,即使私钥被盗,仍然可以保持相当程度的安全性,比如盗取私钥者不可能接触到服务器信任的网络。</p>
<p><strong>只能执行特定命令</strong></p>
<p>command=”command”指定登录客户可以执行的命令,客户无法执行任何其他的命令。客户通过环境变量SSH_ORIGINAL_COMMAND设定的命令将被忽略。<br>如果客户端请求一个伪终端pty(Pseudo TTY),那么这命令将在一个pty中运行,否则命令在没有tty的情况下运行。<br>比如只允许一个key执行备份任务。<br>客户端可以为命令传递参数，参见[4]<br>注意：执行特定命令时，pwd目录为用户的主目录。</p>
<p><strong>指定环境变量</strong></p>
<p>environment=”NAME=value”,当使用这个key登录系统时,会设置指定的环境变量,会覆盖的服务器上同名环境变量,也可以指定多个环境变量值。</p>
<p>不过,客户环境变量默认是被禁止的,由ssh选项PermitUserEnvironment控制。</p>
<p><strong>其他访问控制选项</strong></p>
<ul>
<li>  no-user-rc<br>不执行~/.ssh/rc</li>
<li>  no-X11-forwarding<br>禁止X11转发</li>
<li>  no-port-forwarding<br>禁止端口转发</li>
<li>  no-pty<br>不为客户分配伪终端</li>
<li>  no-agent-forwarding<br>禁止认证转发</li>
<li>  tunnel=”n”<br>指定tun隧道设备,而不是新分配一个</li>
<li>  permitopen=”host:port”<br>限制通过ssh -L命令端口转发只能连接到指定的主机:端口</li>
</ul>
<p><strong>authorized_keys样例</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line"># comments are ignored in authorized_keys files</span><br><span class="line">#</span><br><span class="line"><span class="keyword">from</span>=<span class="string">&quot;trusted.eng.cam.ac.uk&quot;</span>,no-port-forwarding,no-pty ssh-rsa AAAAB</span><br><span class="line">3NzaC1yc2EAAAABIwAAAQEAybmcqaU/Xos/GhYCzkV+kDsK8+A5OjaK5WgLMqmu38aPo</span><br><span class="line">...</span><br><span class="line">fMKMKg+ERAz9XHYH3608RL1RQ== This comment describes key #1</span><br></pre></td></tr></table></figure>

<p>参考:<br>[1]<a href="http://www-h.eng.cam.ac.uk/help/jpmg/ssh/authorized_keys_howto.html">ssh - authorized_keys HOWTO</a><br>[2]<a href="http://man.he.net/man5/authorized_keys">authorized_keys</a><br>[3]<a href="http://blog.pkufranky.com/2012/08/ssh-agent-forwarding-guide/">SSH Agent Forwarding原理</a><br>[4]<a href="https://research.kudelskisecurity.com/2013/05/14/restrict-ssh-logins-to-a-single-command/">RESTRICT SSH LOGINS TO A SINGLE COMMAND</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>自动隐藏gnome-shell窗口标题栏</title>
    <url>/2013/04/28/autohide-gnomeshell-titlebar/</url>
    <content><![CDATA[<p>有一个软件叫maximus可以最大化打开窗口，并隐藏标题栏，增大应用程序可视面积</p>
<a id="more"></a>
<p>#apt-get install maximus</p>
<p>每个新打开的窗口默认都是最大化并没有标题栏的，ALT+F5可以还原窗口,ALT+F4可以关闭窗口，ALT+SPACEBAR可以调出窗口上下文菜单，当然也可以滑动鼠标，在预览状态下关闭窗口。</p>
<p>这种状态下vim挺酷的，完全与桌面融为一体。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>awstats:纯真IP数据库查询脚本ip_geo_qqwry.pl</title>
    <url>/2009/06/14/awstats-ip-geo-qqwrypl/</url>
    <content><![CDATA[<p>这几天正好研究了一下纯真IP数据库的格式，看着qqwry.pl的代码实在是太乱，所以完全重写了一个perl查询脚本ip_geo_qqwry.pl，配合qqhostinfo插件来查询IP地理位置，看着顺眼多了 ：）</p>
<a id="more"></a>
<p>代码如下：<br> 20 #/*<br> 21 # *  Jun 14,2009<br> 22 # <em>/<br> 23<br> 24 use Encode;<br> 25<br> 26 sub ipwhere{<br> 27     my $ip      <strong>=</strong> shift;<br> 28     my @ip      <strong>=</strong> split(/\./, $ip);<br> 29     my $ip_num  <strong>=</strong> $ip[0]<em>256</em></em>3 + $ip[1]<em>256**2 + $ip[2]<em>256 + $ip[3];<br> 30<br> 31     #my $qqwry_dat</em></em>=<strong>“${DIR}/plugins/QQWry.Dat”;<br> 32     my $qqwry_dat **=</strong> “/usr/local/share/ip_geo/QQWry.Dat”;<br> 33     <strong>open</strong>(INFILE, “$qqwry_dat”);<br> 34     binmode(INFILE);<br> 35<br> 36     my $first_index_of_begin_ip, $last_index_of_begin_ip;<br> 37     sysread(INFILE, $first_index_of_begin_ip, 4);<br> 38     sysread(INFILE, $last_index_of_begin_ip, 4);<br> 39<br> 40     $first_index_of_begin_ip    <strong>=</strong> unpack(“L”,$first_index_of_begin_ip);<br> 41     $last_index_of_begin_ip     <strong>=</strong> unpack(“L”,$last_index_of_begin_ip);<br> 42     my $total_index_of_begin_ip <strong>=</strong> ($last_index_of_begin_ip - $first_index_of_begin_ip)/7 + 1;<br> 43<br> 44     #binary search the begin ip<br> 45     my $begin_index, $end_index <strong>=</strong> $total_index_of_begin_ip;<br> 46     my $middle_index, $middle_ip, $middle_ip_num;<br> 47<br> 48 #    while(1){<br> 49 #        if($begin_index <strong>&gt;=</strong> $end_index-1){<br> 50 #            last;<br> 51 #        }<br> 52 #        $middle_index <strong>=</strong> int(($end_index + $begin_index)/2); <br> 53 #        seek(INFILE, $first_index_of_begin_ip + $middle_index*7, 0);<br> 54 #        <strong>read</strong>(INFILE, $middle_ip, 4);<br> 55 #        $middle_ip_num <strong>=</strong> unpack(“L”, $middle_ip);<br> 56 #        if($ip_num <strong>&lt;** $middle_ip_num){<br> 57 #            $end_index **=** $middle_index ;<br> 58 #        } else {<br> 59 #            $begin_index **=** $middle_index ;<br> 60 #        }<br> 61 #    }<br> 62<br> 63     while($begin_index **&lt;** ($end_index -1) ){<br> 64<br> 65         $middle_index **=** int (($end_index + $begin_index)/2); <br> 66         seek(INFILE, $first_index_of_begin_ip + 7*$middle_index, 0);<br> 67         **read**(INFILE, $middle_ip, 4);<br> 68         $middle_ip_num **=** unpack(“L”, $middle_ip);<br> 69<br> 70         if($ip_num **==** $middle_ip_num){<br> 71             $begin_index **=** $middle_index;<br> 72             last;<br> 73         } elsif ($ip_num **&lt;** $middle_ip_num){<br> 74             $end_index **=** $middle_index;<br> 75         } else {<br> 76             $begin_index **=** $middle_index;<br> 77         }<br> 78     }<br> 79<br> 80     my $end_ip_index_offset, $end_ip, $end_ip_num, $end_ip_offset;<br> 81     $end_ip_index_offset **=** $first_index_of_begin_ip + 7*($begin_index) + 4;<br> 82     seek(INFILE, $end_ip_index_offset, 0);<br> 83     **read**(INFILE, $end_ip_offset, 3);<br> 84     <br> 85     $end_ip_offset **=** unpack(“L”, $end_ip_offset.”\0”);<br> 86     seek(INFILE, $end_ip_offset, 0);<br> 87     **read**(INFILE, $end_ip, 4);<br> 88     $end_ip_num **=** unpack(“L”, $end_ip);<br> 89<br> 90     if($ip_num &lt;= $end_ip_num){<br> 91         my $offset, $position_mode, $geo_country_mode_2_pos**=**0;<br> 92<br> 93         $/**=**”\0”;<br> 94         **read**(INFILE,$position_mode,1);<br> 95<br> 96         #position mode 1  <br> 97         if ($position_mode eq “\1”) {<br> 98             **read**(INFILE,$offset,3);<br> 99             $offset **=** unpack(“L”,$offset.”\0”);<br>100             seek(INFILE,$offset,0);<br>101             **read**(INFILE,$position_mode,1);<br>102         }<br>103         #position mode 2<br>104         if ($position_mode eq “\2”) {<br>105             **read**(INFILE,$offset,3);<br>106             $geo_country_mode_2_pos **=** tell(INFILE);<br>107             $offset **=** unpack(“L”,$offset.”\0”);<br>108             seek(INFILE,$offset,0);<br>109         } else {<br>110             seek(INFILE,-1,1);<br>111         }<br>112         $ip_geo_country**=&lt;**INFILE**&gt;</strong>;<br>113<br>114         if($geo_country_mode_2_pos !<strong>=</strong> 0){<br>115             seek(INFILE, $geo_country_mode_2_pos, 0);<br>116         }<br>117<br>118         #geo local, geo local only position mode 2<br>119         <strong>read</strong>(INFILE,$position_mode,1);<br>120         if($position_mode eq “\2”) {<br>121             <strong>read</strong>(INFILE,$offset,3);<br>122             $offset <strong>=</strong> unpack(“L”,$offset.”\0”);<br>123             seek(INFILE,$offset,0);<br>124         } else {<br>125             seek(INFILE,-1,1);<br>126         }<br>127         $ip_geo_local<strong>=&lt;**INFILE**&gt;</strong>;<br>128     } else{<br>129         $ip_geo_country <strong>=</strong> “未知数据”;<br>130     }<br>131<br>132     chomp($ip_geo_country, $ip_geo_local);<br>133     $/<strong>=</strong>“\n”;<br>134     <strong>close</strong>(INFILE);<br>135     <br>136     my $ip_geo_addr<strong>=</strong>“$ip_geo_country $ip_geo_local”;<br>137     $ip_geo_addr <strong>=</strong>~ s/CZ88\.NET//isg;<br>138     $ip_geo_addr**=**decode(“gbk”,$ip_geo_addr);<br>139<br>140     return $ip_geo_addr;<br>141 }<br>142<br>143 1;  </p>
<p>将下载的QQWry.Dat拷贝到/usr/local/share/ip_geo/目录下，然后将qqhostinfo.pm需要的IP地址位置查询程序修改为ip_geo_qqwry.pl,我的是这下面这句：<br>require “/usr/share/awstats/plugins/ip_geo_qqwry.pl”<br>根据你的具体情况修改一下就可以了。</p>
<p><a href="/downloads/ip_geo_qqwry.zip">代码下载</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Perl</tag>
      </tags>
  </entry>
  <entry>
    <title>awstats:utf8编码页面使用纯真IP数据库显示地理位置问题的解决办法</title>
    <url>/2009/06/14/awstats-utf8-qqwry/</url>
    <content><![CDATA[<p>utf8是目前最好的多字节编码方案，支持世界上的绝多大多数语言，也是我最喜欢的字符集。debian lenny 上的awstats安装完毕后，默认输出iso-8859-1字符集，对中文支持不友好。打开/usr/lib/cgi-bin/awstats.pl<br>，定位到大约第80、81行将$PageCode变量的内容更改为’UTF-8’,这样awstats就可以吐出utf8编码格式的页面了。修改成utf8字符集还有一个好处，不用加载decodeutfkeys插件就可以正确的显示来自google的中文搜索关键字了。至于百度让它自生自灭去吧！</p>
<p>awstats通过插件qqhostinfo插件和qqwry.pl库使用纯真IP数据库可以显示来访者的地理位置，是一个不错的解决方案。具体的使用方法网上转载很多，可以google之。纯真IP数据库使用的是gbk/gb2312/gb18030系列编码，而我的awstats使用utf8编码，所以显示出来的物理地址全部是乱码。解决方法也很简单，打开qqwry.pl，在文件前面加上一句”use Encode;”,然后找到”return $ipaddr;”这一行，在其前面加上一句”$ipaddr=decode(“gbk”,$ipaddr);” 就ok了，因为perl 5内部使用的就是utf8编码，所以就不用再encode成utf8了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>bash shell脚本访问PostgreSQL的三种方式</title>
    <url>/2013/11/07/bash-access-postgresql/</url>
    <content><![CDATA[<p>bash脚本里有三种方式访问PostgreSQL数据库</p>
<a id="more"></a>
<p>但前提是要设置密码文件。当然对于有系统对应账户的数据库角色可以绕过密码登录环节，如</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql</span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo su - postgres</span><br><span class="line">$ psql</span><br></pre></td></tr></table></figure>

<p>但是对于没有系统账户对应的数据库角色，如要使用脚本登录则必须使用<a href="https://openwares.net/database/postgresql_passwd_file.html">PostgreSQL密码文件</a></p>
<ul>
<li>  heredoc方式<br><a href="http://en.wikipedia.org/wiki/Here_document">heredoc</a>是一种很常用的方式，在bash环境下还可以使用变量替换，用法示例<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">psql -U $&#123;role&#125; -h $&#123;host&#125; -d mydb &lt;&lt; EOF</span><br><span class="line"> CREATE SCHEMA $&#123;role&#125;;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
也可以在循环语句中，向数据库批量插入数据，类似<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> ...</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">psql -U $&#123;role&#125; -h $&#123;host&#125; -d mydb &lt;&lt; EOF</span><br><span class="line"> INSERT INTO $&#123;table&#125; VALUES($&#123;value1&#125;,$&#123;value2&#125;,...);</span><br><span class="line">EOF</span><br><span class="line">done </span><br></pre></td></tr></table></figure>
但这种方式，每次插入一条语句都重新登录一次数据库，效率肯定不咋地。</li>
<li>*UPDATE(05/05/2014):既然可以使用变量替换,可以将所有插入语句组合到一个变量中，然后就可以在一次登录中批量插入数据了。**</li>
</ul>
<p>还可以用以下方式来获取查询结果</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">result=\<span class="string">`psql -U role -h localhost -d mydb &lt;&lt; EOF</span></span><br><span class="line"><span class="string"> SELECT * FROM products;</span></span><br><span class="line"><span class="string">EOF\`</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">echo <span class="subst">$&#123;result&#125;</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li>  使用psql命令行选项-f执行sql脚本文件<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">psql -U $&#123;role&#125; -h $&#123;host&#125; -d mydb -f $&#123;scriptname&#125; </span><br></pre></td></tr></table></figure></li>
<li>  使用psql命令行选项-c执行SQL语句或psql命令</li>
</ul>
<p>psql的-c选项可以指定SQL语句或者psql命令，但二者不能混合，除非使用管道。如果命令参数中有多条SQL语句，则它们在一个事务里执行，除非使用BEGIN/COMMIT明确的指定事务。这与交互式使用psql终端不同，如果不明确指定事务，则每条SQL属于一个单独的事务并自动提交。只有最后一条SQL语句的结果被返回。<br>详见psql(1)。</p>
<p>可以看出，虽然有三种方式，但其实都是利用了PostgreSQL提供的外部命令psql,所以更复杂的数据库操作可以考虑使用Python</p>
<p>P.S.<br>事实证明用bash脚本插入大量数据，其效率相当低下，3510行的两个简单字段的数据竟然用了4分多种。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>bash alias for wine apps</title>
    <url>/2019/07/15/bash-alias-for-wine-apps/</url>
    <content><![CDATA[<a id="more"></a>
<p>terminal下运行wine apps比较繁琐，可以在.bashrc中添加alias</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias ssmc=<span class="string">&quot;(cd $HOME/.wine/drive_c/Program\\ Files/StorageManager/client/ &amp;&amp; WINEPREFIX=$HOME/.wine wine start SANtricity\\ Storage\\ Manager\\ Client.exe &gt;/dev/null 2&gt;&amp;1)&quot;</span></span><br></pre></td></tr></table></figure>

<p>这样终端下只要执行ssmc就可以了，不会破坏当前的工作目录和stdout</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>bash alias in scripts</title>
    <url>/2019/10/20/bash-alias-in-scripts/</url>
    <content><![CDATA[<a id="more"></a>
<p>bash在非交互式模式下是不扩展alias定义的，除非明确指定shell选项expand_aliases</p>
<p>因此要在脚本中使用alias定义，可以这样：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">shopt -s expand_aliases</span><br><span class="line">source ~/.bash_aliases</span><br><span class="line">alias ll=<span class="string">&#x27;ls -lht&#x27;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://www.thegeekdiary.com/how-to-make-alias-command-work-in-bash-script-or-bashrc-file/">How to make alias command work in bash script or bashrc file</a><br>[2]<a href="https://unix.stackexchange.com/questions/1496/why-doesnt-my-bash-script-recognize-aliases">Why doesn’t my Bash script recognize aliases?</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>bash中一串命令的执行()与{}</title>
    <url>/2018/11/24/bash-bunch-of-command/</url>
    <content><![CDATA[<a id="more"></a>
<p>bash中一串命令执行用()和{}区别</p>
<ul>
<li>  ()只是对一串命令重新开一个子shell进行执行</li>
<li>  {}对一串命令在当前shell执行</li>
<li>  ()和{}都是把一串的命令放在括号里面，并且命令之间用;号隔开</li>
<li>  ()最后一个命令可以不用分号</li>
<li>  {}最后一个命令要用分号</li>
<li>  {}的第一个命令和左括号之间必须要有一个空格</li>
<li>  ()里的各命令不必和括号有空格</li>
<li>  ()和{}中括号里面的某个命令的重定向只影响该命令，但括号外的重定向则影响到括号里的所有命令</li>
</ul>
<p>References:<br>[1]<a href="https://www.cnblogs.com/HKUI/p/6423918.html">shell中的(),{}几种语法用法</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash中调用其他脚本的三种方式</title>
    <url>/2013/11/07/bash-call-other-scripts/</url>
    <content><![CDATA[<p>有三种方式可以调用其他脚本</p>
<a id="more"></a>
<ul>
<li>  fork<br>这是最常用的调用方式，直接指定要调用的脚本的名字，也可以指定要使用的shell,比如<br>sh ${scriptname}<br>bash ${scriptname}<br>如果不指定使用的shell名称，则根据脚本的shebang来确定使用的脚本解释器。</li>
</ul>
<p>这种方式，shell会为调用脚本fork一个子进程来执行被调用的脚本。子进程继承父进程的环境变量，子进程结束时会有退出状态给父进程。</p>
<ul>
<li>  source(.)<br>source或.是bash的内建命令，在命令行上执行的时候,将会直接执行被调用脚本。<br>在脚本内source另一个脚本时，会将被调用脚本插入到调用脚本，并执行这些脚本。因此调用脚本和被调用脚本可以相互访问彼此的变量。<br>类似C/C++语言的include语句</li>
<li>  exec<br>这是 shell 的内建命令，将使用被调用脚本来取代当前进程，当被调用脚本执行完毕后,调用脚本也随之结束。</li>
</ul>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash $-变量</title>
    <url>/2018/11/15/bash-dollar-var/</url>
    <content><![CDATA[<a id="more"></a>
<p>$-是bash内置变量，其值为bash shell打开的选项的一个集合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ echo <span class="string">&quot;$-&quot;</span></span><br><span class="line">himBH</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">H - histexpand</span><br><span class="line">m - monitor</span><br><span class="line">h - hashall</span><br><span class="line">B - braceexpand</span><br><span class="line">i - interactive</span><br></pre></td></tr></table></figure>

<p>可以使用set -/+ options来打开或者关闭这些shell选项</p>
<p>[1]<a href="http://www.cnblogs.com/ziyunfei/p/4913758.html">Bash 为何要发明 shopt 命令</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>bash fastcgi输出内容类型</title>
    <url>/2014/07/19/bash-fastcgi-content-type/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用bash写fastcgi程序时,一定要先输出Content-type和一个空行,不然nginx会报错502 Bad Gateway,后台访问日志中会有”upstream prematurely closed FastCGI stdout while reading response header from upstream”错误。</p>
<p>下面两种写法皆可:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash </span><br><span class="line"></span><br><span class="line">echo -e <span class="string">&quot;Content-type: text/html\\n&quot;</span></span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash </span><br><span class="line"></span><br><span class="line">echo <span class="string">&quot;Content-type: text/html&quot;</span></span><br><span class="line">echo <span class="string">&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>之后可以继续输出text或者html文本</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>Bash heredoc界定终止符缩进</title>
    <url>/2014/04/22/bash-here-doc-indent/</url>
    <content><![CDATA[<a id="more"></a>
<p>即时文档(heredoc)的界定符是可以自定义的,但一般习惯上使用EOF。<br>界定符的终止符有一个限制,终止符必须放到行首,后面也不能有任何空白,有时候不缩进会很不美观。</p>
<p>这时候可以这样来使终止符EOF可以使用TAB缩进:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">echo</span><br><span class="line"> cat &lt;&lt;-EOF</span><br><span class="line"> test</span><br><span class="line"> EOF</span><br></pre></td></tr></table></figure>

<p>在设定终止符时加一个横线,也就是使用<code>&lt;&lt;-</code><br>但这里还有一个坑,即使是这样写,EOF缩进时也只能使用TAB字符而不能使用任何其他空白字符。<br>我的vim配置里使用了expandtab来将tab自动替换为空格,因此踩上了这个大坑,无论如何都提示错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">warning: here-<span class="built_in">document</span> at line xxx delimited by end-<span class="keyword">of</span>-file (wanted \<span class="string">`EOF&#x27;)</span></span><br><span class="line"><span class="string">syntax error: unexpected end of file</span></span><br></pre></td></tr></table></figure>

<p>这时候只要输入真正的TAB字符就可以了,<code>Ctrl+V+TAB</code>,windows下要用<code>Ctrl+Q+TAB</code></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash内建字符串处理</title>
    <url>/2013/11/07/bash-inside-string-handler/</url>
    <content><![CDATA[<p>bash 内建字符串处理</p>
<a id="more"></a>
<p>bash中有多种方式可以处理字符串，有内建的处理方式，也可以使用很多内部或外部命令来处理,比如使用命令expr，awk,grep/egrep,ed/sed等，还有两个个专门针对路径名处理的外部命令basename和dirname。</p>
<p>这里只讨论bash内建的字符串处理功能，不涉及内部或外部命令。应该优先使用bash内建功能，因为外部命令系统中不一定会存在，一般内部命令总是随bash而存在的。</p>
<p><strong>获取字符串长度</strong></p>
<p>length=${ #string}</p>
<p><strong>截取子串</strong></p>
<p>${string:position}</p>
<p>在 string 中从位置$position 开始提取子串.<br>如果$string 为”*”或”@”,那么将提取从位置$position 开始的位置参数</p>
<p>${string:position:length}</p>
<p>在 string 中从位置$position 开始提取$length 长度的子串.</p>
<p><strong>替换子串</strong></p>
<p>${string/substring/replacement}<br>使用$replacement 来替换第一个匹配的$substring.</p>
<p>${string//substring/replacement}<br>使用$replacement 来替换所有匹配的$substring.</p>
<p>${string/#substring/replacement}<br>如果$substring 匹配$string 的开头部分,那么就用$replacement 来替换$substring.</p>
<p>${string/%substring/replacement}<br>如果$substring 匹配$string 的结尾部分,那么就用$replacement 来替换$substring.</p>
<p><strong>删除子串</strong></p>
<p>删除字串有两种方式，替换字符串的时候如果不提供replacement部分，那么会删除掉查找到的子串，这是替换的一种特例。</p>
<p>另一种方式如下：</p>
<p>${string#substring}<br>从$string 的左边截掉第一个匹配的$substring<br>${string##substring}<br>从$string 的左边截掉最后一个匹配的$substring</p>
<p>${string%substring}<br>从$string 的右边截掉第一个匹配的$substring<br>${string%%substring}<br>从$string 的右边截掉最后一个匹配的$substring</p>
<p><strong>注意：</strong></p>
<p>bash内建的字符处理功能不支持正则表达式，但支持基于通配符 (wildcard) 的globbing</p>
<p><strong>tips</strong></p>
<p>#表示从左边开始，%表示从右边开始，从键盘上的位置看，#也是在左边，%在右边</p>
<p>References:<br>[1]<a href="https://segmentfault.com/a/1190000002539169">玩转Bash变量</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash noop command</title>
    <url>/2019/01/20/bash-noop-command/</url>
    <content><![CDATA[<a id="more"></a>
<p>bash的内建命令<code>&quot;:&quot;</code>，类似于x86的nop机器指令，或者python的pass语句，其返回值为0</p>
<p>References:<br>[1]<a href="https://www.gnu.org/software/bash/manual/html_node/Bourne-Shell-Builtins.html#Bourne-Shell-Builtins">4.1 Bourne Shell Builtins</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash位置参数</title>
    <url>/2013/11/07/bash-positional-parameters/</url>
    <content><![CDATA[<p>位置参数属于bash内置变量。</p>
<a id="more"></a>
<ul>
<li>  $0, $1, $2, 等<br>位置参数，从命令行传递给脚本，传递给函数，或者赋值到变量。$0总是命令行上调用脚本名字，有可能包含相对路径，如果调用脚本的时候指定了路径前缀。如果位置参数大于10，则必须这样引用”${10}”<br>引用变量时推荐一直使用大括号”${variable}”，这样更安全。</li>
<li>  $#<br>命令行或位置参数的个数</li>
<li>  $*<br>所有的位置参数被组合成一个单词，注意”$*”必须要被引用才能正常工作。</li>
<li>  $@<br>和$*一样，但是每一个参数都是一个引用的字符串，也就是，参数被完整的传递，没有解释或者扩展。参数列表中的每一个参数被视为一个单独的单词。”$@”一样需要被引用才能正常工作。</li>
</ul>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash按行读取文本文件</title>
    <url>/2013/11/08/bash-read-text-file/</url>
    <content><![CDATA[<p>bash有多种方式读取文本文件</p>
<a id="more"></a>
<p>列举几个常见的方式：</p>
<ul>
<li>  使用cat等外部命令<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">OLDIFS=$IFS</span><br><span class="line">IFS=<span class="string">&#x27;&#x27;</span></span><br><span class="line"># for in 按IFS设置分割单词，而IFS默认为为空白(空格,tab,和新行),</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> \<span class="string">`cat <span class="subst">$&#123;file&#125;</span>\`</span></span><br><span class="line"><span class="string">do</span></span><br><span class="line"><span class="string"> echo $line</span></span><br><span class="line"><span class="string">done</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">IFS=$OLDIFS</span></span><br></pre></td></tr></table></figure>
Bash使用内部域分隔符IFS(Internal Field Separator)来识别域或单词边界，$IFS 默认为空白(空格,tab,和新行),所以如果行内有空格，则会被断开单独读取。但可以修改$IFS,比如在分析逗号分隔的数据文件时</li>
<li>  使用内建命令read方式一<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> read line</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"> echo $line</span><br><span class="line">done &lt; $&#123;file&#125;</span><br></pre></td></tr></table></figure>
这种方式不会生成subshell</li>
<li>  使用内建命令read方式二<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cat $&#123;file&#125; <span class="keyword">while</span> read line</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"> echo $line</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
这种方式会生成新的subshell,do循环是在subshell中执行的,因为要注意变量的作用域范围。subshell中对变量的操作不会影响到parent shell。</li>
</ul>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>BASH脚本中使用正则表达式检查IP地址和端口号</title>
    <url>/2009/05/23/bash-regex-ip-port/</url>
    <content><![CDATA[<p>新版本bash(可能从3.0以后)内置了运算符 =~ 来支持正则表达式匹配。请注意此运算符只能用在[[…]]表达式中，而不能用在[…] 中。bash内置支持的好处在于使用方便和效率提升，不需要fork一个process即可以进行正则表达式匹配。但是似乎bash对正则表达式的支持不很完善，比如用 转义符\d无法匹配单个数字，必须用 [0-9]来匹配才行，比较罗嗦。</p>
<a id="more"></a>
<p>下面是在bash脚本中用正则表达式对IP地址和端口号进行检查的代码:<br>33 #check arguments<br>34<br>35 #check ip<br>36 pattern_ip=<strong>“**^(([0-9][1-9][0-9]1[0-9]{2}2([0-4][0-9]5[0-5]))\.){3}([0-9][1-9][0-9]1[0-9]{2}2([0-4][0-9]5[0-5]))$</strong>“**<br>37 #pattern_ip=”^((1?[0-9]?[0-9]2([0-4][0-9]5[0-5]))\.){3}(1?[0-9]?[0-9]2([0-4][0-9]5[0-5]))$”<br>38<br>39 <strong>if</strong> [[ <strong>!</strong>(($1 <strong>=</strong>~ $pattern_ip) <strong>&amp;&amp;</strong> ($3 <strong>=</strong>~ $pattern_ip)) ]] <strong>;</strong> <strong>then</strong><br>40     <strong>echo</strong> <strong>“**from_ip or to_ip has errors!</strong>“**<br>41     <strong>exit</strong> 0<br>42 <strong>fi</strong><br>43<br>44 #check port<br>45 pattern_port=<strong>“**^([0-9]{1,4}[1-5][0-9]{4}6[0-5]{2}[0-3][0-5])$</strong>“**<br>46 <strong>if</strong> [[ <strong>!</strong>($2 <strong>=</strong>~ $pattern_port) ]]<strong>;</strong> <strong>then</strong><br>47     <strong>echo</strong> <strong>“**port has erros!</strong>“**<br>48     <strong>exit</strong> 0**;**<br>49 <strong>fi</strong>  </p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash脚本中捕捉信号</title>
    <url>/2016/08/10/bash-script-trap-signals/</url>
    <content><![CDATA[<a id="more"></a>
<p>当脚本遇到错误或被用户终止时,有些清理动作需要执行,这时候可以通过捕捉signal来完成这项工作.</p>
<p>trap格式为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">trap commands signals</span><br></pre></td></tr></table></figure>

<p>commands可以是任何内建命令,外部命令或者脚本中的函数等.<br>signals是要捕捉的信号,可以一次扑捉多个信号,只要提供信号列表即可.</p>
<p>系统支持的信号列表:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ kill -l</span><br></pre></td></tr></table></figure>

<p>trap不只可以捕获各种信号，还可以捕获EXIT和ERR。<br>trap func EXIT允许在脚本结束时调用注册的函数。由于无论正常退出抑或异常退出，因此是写脚本清理函数绝佳所在。<br>trap func ERR允许在运行出错时调用注册的函数。不过要记住，程序异常退出时，既会调用EXIT注册的函数，也会调用ERR注册的函数。</p>
<p>如果脚本中设置了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">set -e</span><br></pre></td></tr></table></figure>

<p>当脚本中任何命令退出码非0时,立即退出脚本,这时候可以扑捉ERR,并设置处理程序:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">trap <span class="string">&#x27;err_handler $&#123;LINENO&#125; $?&#x27;</span> ERR </span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">err_handler</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"> # some clean works</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>通过捕捉ERR,可以捕捉到程序非正常退出包括SIGINT(Ctrl+C)</p>
<p>${LINENO}为出错的行号,$?为最后执行命令的退出码</p>
<p>References:<br>[1]<a href="https://blog.robotshell.org/2012/necessary-details-about-signal-trap-in-shell/">关于Linux Shell的信号trap功能你必须知道的细节</a><br>[2]<a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_12_02.html">12.2. Traps</a><br>[3]<a href="https://segmentfault.com/a/1190000006900083">编写可靠shell脚本的八个建议</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Bash启动文件(startup files)</title>
    <url>/2009/11/07/bash-startup-files/</url>
    <content><![CDATA[<p>如果任何一个启动文件存在，但不能读取，Bash会报告一个错误。</p>
<a id="more"></a>
<ul>
<li>  <strong>做为一个交互式登录shell被调用，或者带有<code>--login</code>选项</strong><br>当Bash做为一个交互式登录shell被调用，或者做为一个非交互式登录shell被调用但带有- -login选项，如果/etc/profile文件存在，Bash首先读取这个文件来执行命令。读完这个文件后，Bash按顺序查找<del>/.bash_profile,</del>/.bash_login和<del>/.profile文件，并从第一个存在且可读的文件读取执行命令。当shell启动时可以使用参数- -noprofile来禁止这种行为。<br>当一个登录Shell退出,如果文件</del>/.bash_logout存在，Bash读取并执行其中的命令。</li>
<li>  <strong>做为一个交互式非登录shell被调用</strong><br>如果~/.bashrc文件存在，Bash读取该文件并执行其中的命令。通过使用<code>--norc</code>选项可以禁止读取该文件。</li>
</ul>
<ul>
<li>-rcfile选项则可以强制Bash读取指定的文件而不是<del>/.bashrc。<br>因此，典型地，你的</del>/.bash_profile在任何登录相关的初始化之前或之后会包含下面的行<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> \[ -f ~/.bashrc \]; then </span><br><span class="line"> . ~/.bashrc; </span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>  <strong>做为非交互式shell被调用</strong><br>当Bash做为一个非交互式shell被调用，比如执行一个shell脚本,它查找环境变量BASH_ENV,如果该变量存在，Bash使用变量扩展后的值做为文件名来读取并执行其中的命令。Bash的行为类似于执行以下命令<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> \[ -n <span class="string">&quot;$BASH_ENV&quot;</span> \]; then </span><br><span class="line"> . <span class="string">&quot;$BASH_ENV&quot;</span>;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
但是Bash并不使用环境变量PATH的值来搜索这个文件。</li>
<li>  <strong>做为sh被调用</strong><br>如果Bash以sh的名字被调用，在遵循POSIX标准的同时，它尝试尽可能接近的模仿sh历史版本的启动行为。<br>当做为交互式登录shell或带<code>--login</code>选项的非交互式登录shell被调用时，它首先尝试按顺序读取/etc/profile和~/.profile文件并执行命令。<br><code>--noprofile</code>选项可以用来禁止这种行为。当Bash以sh的名字做为交互式登录shell被调用时，Bash查找ENV环境变量，如果变量被定义，就扩展变量，并以扩展后的值做为文件名来读取执行命令。因为以名字sh调用的shell不再尝试任何其他的启动文件，因此<code>--rcfile</code>是无效的。以名字sh调用的非交互式登录shell不再读取其他任何启动文件。<br>当做为sh被调用时，启动文件读取完毕后,Bash进入POSIX模式。</li>
<li>  <strong>以POSIX模式被调用</strong><br>当Bash带有<code>--posix</code>命令行选项，以posix模式启动时，Bash遵循POSIX启动文件标准。在这种模式下，交互式shell扩展ENV环境变量，并以扩展后的变量值为文件名做为启动文件读取并执行命令。不再读取其他文件。</li>
<li>  <strong>被远程shell守护程序调用</strong><br>Bash尝试去侦测当被调用时它的标准输入是否绑定到一个网络连接，比如通过远程shell守护进程(remote shell daemon)rshd，或者安全shell守护进程(secure shell daemon)sshd。如果正是通过这种方式被调用，那么Bash从<del>/.bashrc读取并执行命令，只要</del>/.bashrc文件是存在并且是可读的。如果被当作sh调用则不会这样做。<code>--norc</code>选项参数可以用来禁止这种行为，<code>--rcfile</code>选项可以强制使用另一个启动文件，但是rshd不支持这两个选项。</li>
<li>  <strong>在有效uid/gid不等于实际uid/gid的情况下被调用</strong></li>
</ul>
<p>如果Bash在有效uid(gid)不等于实际uid(gid)的情形下启动，并且没有指定-p选项，那么Bash不会读取启动文件，不从环境继承shell功能，忽略SHELLOPTS环境变量,有效uid设置为实际uid。如果调用时指定了-p选项，启动行为是相同的，除了不会重设有效uid。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>bash特殊内部参数</title>
    <url>/2013/11/07/bash%E7%89%B9%E6%AE%8A%E5%86%85%E9%83%A8%E5%8F%82%E6%95%B0/</url>
    <content><![CDATA[<p>bash部分特殊参数介绍</p>
<a id="more"></a>
<ul>
<li>  $-<br>传递给脚本的标志(flags)</li>
<li>  $!<br>最后一个后台作业(job)的进程PID(Process ID)</li>
<li>  $_<br>保存上一个执行命令的最后一个参数</li>
<li>  $?<br>命令，函数或者脚本自身的退出状态。0表示成功，非0表示失败。</li>
<li>  $$<br>脚本自身的进程PID(Process ID)。通常用于脚本构建独一无二的临时文件名字。这比通常比调用mktemp更简单。</li>
<li>  $n<br>通过命令行传递给脚本的第n个参数,n取自然数，比如$0,$1,$2,…,其实$0为脚本自身的名字。</li>
<li>  $@<br>通过命令行传递给脚本的全部参数</li>
<li>  $#<br>通过命令行传给脚本的所有参数的个数</li>
</ul>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>linux一条命令批量压缩jpg图像</title>
    <url>/2012/03/16/batch-image-size/</url>
    <content><![CDATA[<p>想把很多图片保存到dropbox,这样保存更安全一些,但是好多年的图片了,容量实在太大了</p>
<a id="more"></a>
<p>jpg本来就是高度压缩的图像格式,要想继续压缩图片文件大小,只能是降低分辨率或者降低图片质量,保存的图片本来就分辨率过高,降低一半的分辨率会大大减少图片占用的空间</p>
<p>安装imagemagick</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install imagemagick</span><br></pre></td></tr></table></figure>

<p>imagemagick的命令convert可以完成此任务,其参数-resize用来改变图片尺寸,可以直接指定像素值,也可以指定缩放百分比。而如果想降低图片的质量,可以用convert的-quality参数,质量值为0-100之间的数值,数字越大,质量越好,一般指定70-80,基本上看不出前后的差别。</p>
<p>用下面的命令批量修改图片分辨率为原来的1/4大小,同时保持原图片比例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find ./ -regex <span class="string">&#x27;.*\\(jpg\\JPG\\)&#x27;</span> -exec convert -resize <span class="number">50</span>%x50% &#123;&#125; &#123;&#125; \\;</span><br></pre></td></tr></table></figure>

<p>用规则表达式把jpg和JPG后缀图片一网打尽,{}代表查找到的文件,这里没有改变convert前后的文件名,最后是转义的分号表示一个迭代的处理完成。<br>也可以用以下命令</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find ./ -name <span class="string">&#x27;*jpg&#x27;</span> -o -name <span class="string">&#x27;*JPG&#x27;</span> -exec convert -resize <span class="number">50</span>%x50% &#123;&#125; &#123;&#125; \\;</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>一款漂亮开放自由的编程、终端字体</title>
    <url>/2018/11/27/beautiful-font-for-terminal-and-dev/</url>
    <content><![CDATA[<a id="more"></a>
<p>偶然发现一款漂亮的编程字体inconsolata，而且是自由、开放字体，值得推荐</p>
<p>debian官方源里就有:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install fonts-inconsolata</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>贝奥武夫高性能计算集群(Beowulf Cluster)</title>
    <url>/2011/04/22/beowulf-cluster/</url>
    <content><![CDATA[<p>Beowulf cluster概念介绍</p>
<a id="more"></a>
<p>Beowulf是一种高性能并行计算集群，其原始的含义是指建造于1994年的一台特殊的计算机，类似于最初的NASA系统的一种计算机集群，起源于NASA。现在Beowulf在全世界范围内部署，主要用来进行科学计算，它们是由廉价的PC组成的高性能并行计算集群。Beowulf的名字来源于古英语诗歌Beowulf里面的主要人物,诗里面描述Beowulf可以用一只手轻而易举的举起30个人。</p>
<p>Beowulf集群通常有统一架构的、商用的计算机组成，这些计算机运行自由开源的软件(FOSS，Free and open source software),类UNIX操作系统，比如BSD,GNU/Linux或者Solaris。它们由TCP/IP网络连接到一起。</p>
<p>并没有一个特殊的软件来定义一个集群是Beowulf集群,通常是使用并行计算规范包括MPI(Message Passing Interface)和PVM(Parallel Virtual Machine),这两个并行计算规范都允许程序开发者在一组网络计算机间分解任务，并且将任务的计算结果再集成起来。MPI的实现包括OpenMPI和MPICH,都为开源软件,还有一些其他的MPI实现。</p>
<p>Beowulf不是一个特殊的软件包，也不是一种新的网络拓扑技术，Beowulf是集成廉价计算机组成并行虚拟超级计算机的一种技术，可以使用标准的GNU/Linux发行版来构建Beowulf集群。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>不基于GAE构建birdnest twitter api proxy</title>
    <url>/2010/07/29/birdnest-twitter-api-proxy/</url>
    <content><![CDATA[<p>其实只要空间支持python都可以<a href="http://yegle.net/2009/07/29/setup-a-birdnest-twitter-api-proxy-on-your-own-host/">使用birdnest搭建twitter api proxy</a>。</p>
<p>曾经尝试用twip来搭建，但是因为主机用的是nginx，尝试N久未成功，遂放弃改用birdnest，原来是如此简单，记叙如下：</p>
<p>1.安装python及支持模块。我的VPS已经自带了python。下载<a href="http://pypi.python.org/pypi/simplejson/">simplejson</a>,解压后进去目录执行python setup.py build和sudo python setup.py install即可</p>
<p>2.下载birdnest。在某个目录下执行</p>
<p>svn checkout <a href="http://birdnest.googlecode.com/svn/branches/stable">http://birdnest.googlecode.com/svn/branches/stable</a> birdnest-read-only</p>
<p>或者如果你用git的话</p>
<p>git-svn clone <a href="http://birdnest.googlecode.com/svn/branches/stable">http://birdnest.googlecode.com/svn/branches/stable</a> birdnest-read-only</p>
<p>3. 进入birnest目录执行</p>
<p>python code.py 空间ip:随便指定的port</p>
<p>测试一下如果正常，则可以在/etc/init.d下面加入脚本birdnest，并在/etc/rc3.d/目录下建立其目录链接,注意你自己的运行级，让其开机自动运行，脚本内容如下</p>
<p>#!/bin/sh</p>
<p>cd /你的birdnest路径</p>
<p>python code.py 空间ip:指定的port &gt; /dev/null 2&gt;&amp;1 &amp;</p>
<p>4.在twitter客户端设置api地址为http://空间ip:指定的port/api即可.birdnest提供了4种api，/api、/optimized、/image、/text，具体介绍请翻墙去<a href="http://nest.onedd.net/">官网</a>。我只用了/api，看起来还不错</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Twitter</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP使用隐含字段防止重复提交表单</title>
    <url>/2012/07/04/block-refresh-submit/</url>
    <content><![CDATA[<p>PHP表单提交以后,如果用户刷新当前页面,则上次提交的历史信息会重新提交一次,信息重复很容易处理,但如果刷新提交的数据中有过期的信息则需要谨慎处理。</p>
<a id="more"></a>
<p>防止重复提交的方法多种多样,这里介绍一个通过隐含字段防止重复提交的方法,如果发现是重复提交,则简单的不处理该提交。此处的form提交到本页面处理。</p>
<p>表单里面增加一个隐含字段submitid</p>
<form>
....
<input type='hidden' name='submitid' value='<? php echo $_SESSION\["submitid"\] ?>' >
</form>

<p>PHP代码</p>
<?php

if(!isset($_SESSION\["submitid"\])){
$_SESSION\["submitid"\] = 0;
}

if(($_SERVER\['REQUEST_METHOD'\] == 'POST') && isset($_POST\['btn_submit'\])){  //post submit
if($_SESSION\["submitid"\] == $submitid){  //normal submit,not refresh
$_SESSION\["submitid"\] += 1;

}

?>

<p> </p>
<p>将PHP代码置于form之前,每次正常提交时SESSION变量submitid会加1,如果是刷新提交,则sumbitid的值仍然是浏览器缓存的旧值,与SESSION变量submitid的值不同,从而判断出是刷新提交,直接忽略掉即可。</p>
]]></content>
      <categories>
        <category>lang</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>博客重新上线</title>
    <url>/2009/12/21/blog-reload/</url>
    <content><![CDATA[<p>　　世界是普遍联系的。<br>　　上个月，CCAV曝光了手机色情，本来这种事情和我们这些安分守己的P民是没有什么牵扯的。做梦也不会梦到和我们有什么瓜葛。但就在上个月末的某一天，美梦中醒来发现博客无法访问了，其他几个站点也都无法访问了。心中暗自惴惴，不知道这次又错在哪里了。traceroute发现到ip的路由出现了问题，也就是ip被封了，闷。记得前几日那备案核查的打过电话，核实的信息都是无误的，而且对方也说没问题，怎么这就又给下线了呢。电话打到接入商那里才明白，原来也是拜手机色情所赐，先强制下线再说，给我的理由是“网页语言为英文，无法进行核实。” 诸位，这也能算是理由吗？是的，那个ip上面是有英文站，难道你们看不懂反要来怪我吗？是不是色情难道还需要看懂英文吗？这种作风实在太彪悍了，无语。这种环境下和谁去讲理呢。我们是鱼肉，人家是刀俎，哪天想切就切呗。<br>　　没几天，这cn域名也开始整治了，据说就算你跑到国外注册域名也逃不过censorship，生猛啊。幸亏原来的com域名都转移到name.com了，看来这cn域名也用不了几天了，先有心理准备吧。<br>　　如果互联网、IT是先进生产力的话，是不是这先进的生产力和落后的生产关系之间很矛盾呢？不然怎么理解呢，让我们拭目以待吧。<br>　　这几天购买了<a href="http://www.diahosting.com/client/aff.php?aff=190">diahosting</a>的Xen VPS，开始折腾nginx了，apache实在太占用资源了。<br> 　　实在是受够了这些烦心事，从备案开始就没消停过，从此以后就在国外流浪吧，天知道哪天那些阴魂不散的东西会搞出什么新花样来。<br>　　不过，就算你跑到国外，说不定也要被墙的，随它去吧。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>关于C和C++的布尔类型,_Bool和bool</title>
    <url>/2009/06/04/bool-and-bool/</url>
    <content><![CDATA[<p>C++内置对布尔类型的支持，其关键字是bool，C语言直到C99标准才增加了对布尔类型的支持，关键字为_Bool，因为bool已经被C++ 用了，所以选了这个十分奇怪的关键字。在这之前C程序员对布尔类型的模拟是相当混乱的。为了在C和C++程序中以统一的方式使用布尔类型，同时提高可移植性，可以采用下面的方式:</p>
<a id="more"></a>
<p>构造一个stdbool.h头文件定义相关的宏，内容如下：<br> 1 /*<br> 2  * stdbool.h<br> 3  * boolean macros for C<br> 4 */<br> 5<br> 6 #ifndef <strong>STDBOOL_H__<br> 7 #define __STDBOOL_H</strong><br> 8<br> 9 #ifndef __cplusplus<br>10<br>11 #undef <strong>bool</strong><br>12 #undef true<br>13 #undef false<br>14<br>15 #define true 1<br>16 #define false 0<br>17<br>18 #if __STDC_VERSION__ &lt; 199901L<br>19 <strong>typedef</strong> <strong>int</strong> <em>Bool<br>20 #endif //__STDC_VERSION_</em><br>21 #define <strong>bool</strong> <em>Bool<br>22<br>23 #define __bool_true_false_are_defined 1<br>24<br>25 #endif //__cplusplus<br>26<br>27 #endif //__STDBOOL_H_</em>  </p>
<p>然后在要使用布尔类型的文件里包含这个头文件，</p>
<p> #include “stdbool.h”</p>
<p>就可以统一按bool来表达布尔类型了。</p>
<p>P.S. 目前仍然有很多编译器并不支持C99的新特性，特别是比较老的编译器，如CB6和VC6都不支持_Bool关键字</p>
<hr>
<p>PS:<a href="http://blog.csdn.net/mopyman/archive/2006/03/09/619564.aspx">此文</a>最早发表于CSDN.</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Visual C++ 2008 Express编译boost 1.39 regex库遇到的问题及解决办法</title>
    <url>/2009/06/01/boost-1-39-regex-solutions/</url>
    <content><![CDATA[<p>最近在玩boost,用vc++ 2008 express编译最新版本1.39时遇到一点小问题，记录于此。<br>分别下载了zlib,bzip2和icu，python暂时不玩，没接触过。我喜欢静态链接程序，根据官方文档的提示，在console输入如下指令，为了输入方便，最好写个bat脚本：</p>
<p>bootstrap<br>bjam -sBZIP2_SOURCE=D:/libs/bzip2-1.0.5 -sZLIB_SOURCE=D:/libs/zlib-1.2.3 -sHAVE_ICU=1 -sICU_PATH=D:/libs/icu link=static runtime-link=static threading=multi –without-python</p>
<p>console窗口一阵晃动后吐出了这么三行error:</p>
<p>error: link=shared together with runtime-link=static is not allowed<br>error: such property combination is either impossible<br>error: or too dangerious to be of any use</p>
<p>百思不得其解，明明我的link选项只有static，哪来的shared啊，郁闷啊郁闷，反复折腾后，发现，如果没有ICU选项，则不会出现此错误提示。</p>
<p>用vim打开boost_1_39_0\libs\regex\build\jamfile.v2,搜索一下/\&lt;shared\&gt;，果然在文件底部，218,223和229行链接选项被写死为shared。那就去掉这该死的shared，重新来过，bjam终于开始正常工作了。</p>
<p>编译带ICU选项的regex还会遇到一点儿小问题。boost.regex期望的icui18n.lib和icudata.lib与编译后的ICU库的名字并不相同，简单修改一下就可以了,如下：<br>libs\icu\lib\icuin.lib -&gt; icui18n.lib<br>libs\icu\lib\icudt.lib -&gt; icudata.lib</p>
<p>测试了boost 1.39官方文档的regex测试程序，静态链接，一切OK。</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>源码编译Spring Framework</title>
    <url>/2013/10/10/build-spring-framework/</url>
    <content><![CDATA[<p>最新的Spring Framework没有jar包提供下载了，推荐用maven或gradle来引用Spring Framework,找了好久没找到下载的地方。</p>
<a id="more"></a>
<p><strong>前置条件</strong></p>
<p>JDK是必须的，安装openjdk7即可。<br>Spring Framework已经迁移到Gtihub,并且使用gradle建构系统,所以需要安装git。<br>gradle可装可不装，如果不安装，spring framework的构建脚本会自动下载特定版本的gradle</p>
<p><strong>下载</strong></p>
<p>使用git克隆Spring Framework的源代码库<br>$ git clone git://github.com/SpringSource/spring-framework.git</p>
<p>克隆完成后，代码库处于最新的master分支，最好检出稳定的版本进行编译,所以检出最新的稳定版本3.2.4 GA release, 其tag为v3.2.4.RELEASE</p>
<p>$ cd spring-framework<br>$ git checkout v3.2.4.RELEASE<br>这样代码库就是最新的稳定版本3.2.4了</p>
<p><strong>编译</strong><br>Spring Framework已经切换到了gradle构建系统，编译也比较简单，不过要从网络上下载很多依赖的东西，时间会比较久</p>
<p>$ ./gradlew build</p>
<p>构建时间依网络速度会有所不同，最后输出<br>BUILD SUCCESSFUL<br>Total time: 1 hrs 27 mins 12.286 secs<br>算是构建完成了</p>
<p>build/distributions/目录下会生成完整的发布包spring-framework-3.2.4.RELEASE-dist.zip,里面包含拆分开的各个jar包，现在已经没有一个完整的spring.jar单包了，根据项目需要选用拆分开的jar包即可。</p>
<p>参考：<a href="https://github.com/spring-projects/spring-framework/tree/3.2.x">spring-projects/spring-framework</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>button与input type=\&quot;button\&quot;</title>
    <url>/2014/06/25/button%E4%B8%8Einput-typebutton/</url>
    <content><![CDATA[<a id="more"></a>
<p>button元素有更强的表现力,在button元素内部可以放置样式化的其他元素,这是比input(type=”button”)强大的地方。如果button元素放在form内部,点击button会导致form的提交,虽然这个button并没有显式的指定其为submit类型。这是因为”Internet Explorer 的默认类型是 “button”，而其他浏览器中（包括 W3C 规范）的默认值是 “submit””,所以应该始终为button指定明确的类型，button或者submit。</p>
<p>对于二者更详细的区别见参考[1]</p>
<p>Rreferences:<br>[1]<a href="http://www.cnblogs.com/purediy/archive/2012/06/10/2544184.html">button和input type=”button” 的区别</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>locale问题：Cannot set LC_CTYPE to default locale</title>
    <url>/2009/12/22/cannot-set-lc-ctype/</url>
    <content><![CDATA[<p>刚购买的<a href="http://www.diahosting.com/client/aff.php?aff=190">VPS</a>默认安装的系统是CentOS，没想到CentOS现在这么火，很多VPS默认安装这个。但是我只用Debian或FreeBSD，重新安装了一下Debian lenny AMD64，几分钟就完成了。sudo apt-get upgrade时出现错误提示：</p>
<p>locale: Cannot set LC_CTYPE to default locale: No such file or directory<br>locale: Cannot set LC_MESSAGES to default locale: No such file or directory<br>locale: Cannot set LC_ALL to default locale: No such file or directory</p>
<p>原来是默认没有设置locale<br>用这个命令dpkg-reconfigure locales配置一下，选个lcoale就好了，我用en_US.UTF-8。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ora-04031 无法分配共享内存</title>
    <url>/2011/02/23/cant-alloc-share-memory/</url>
    <content><![CDATA[<p>错误”ora-04031 无法分配XXX字节的共享内存(XXX)”的解决办法：</p>
<a id="more"></a>
<p><strong>oracle 9i:</strong><br>sys用户以sysdba身份登录<br>先查看当前shared_pool_size值<br>sql&gt;show parameter shared_pool_size;<br>然后<br>sql&gt;alter system set shared_pool_size=’比原先值适当增加’ scope=spfile;<br>然后<br>sql&gt;shutdown immediate<br>sql&gt;startup</p>
<p><strong>oracle 10g:</strong><br>oracle 10g shared_pool_size默认值为0，也就是系统自动管理shared pool内存，这时可以适当增加shared_pool_reserved_size的值,仍然让系统自动管理这部分内存</p>
<p>sql&gt;alter system set shared_pool_reserved_size=’比原先值适当增加’ scope=spfile;<br>sql&gt;shutdown immediate<br>sql&gt;startup</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra集群添加新的数据中心</title>
    <url>/2015/11/06/cassandra-add-new-datacenter/</url>
    <content><![CDATA[<a id="more"></a>
<p>可以为现有集群添加一个新的数据中心，要求新添加数据中心的所有节点，要安装与原集群节点相同的cassandra版本。</p>
<p>操作步骤:</p>
<ol>
<li> 使用NetworkTopologyStrategy<br>系统keyspace并没有使用NetworkTopologyStrategy策略，用户的keyspace如果要使用多数据中心就要使用NetworkTopologyStrategy策略。</li>
<li> 停止节点<br>debian包系统安装的cassandra,安装完成后处于运行状态，而且有默认的集群Test Cluster，因为需要逐一停止新数据中心节点，并清除默认安装的信息：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra stop</span><br><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/cassandra<span class="comment">/*</span></span><br></pre></td></tr></table></figure></li>
<li> 配置cassandra.yaml<br>新数据中心节点cassandra.yaml文件中添加<code>auto_bootstrap: false</code>。auto_bootstrap默认是true，并且没有在cassandra.yaml文件中列出来。设置其他参数，比如seeds和endpoint_snitch，匹配原有集群的配置。num_tokens参数可以设置与原集群一致，但不要设置initial_token参数。</li>
<li> 编辑相关配置文件<br>GossipingPropertyFileSnitch使用的配置文件cassandra-rackdc.properties中添加新数据中心和机架。</li>
<li> 客户端配置<br>如果使用DataStax驱动,负载均衡策略设置为DCAwareRoundRobinPolicy,其他驱动做相应修改，以使客户端与新的集群相适应。<br>如果原来使用一致性级别QUORUM，那么现在重新审视一下，是否LOCAL_QUORUM或者EACH_QUORUM一致性级别更适合现在的多数据中心集群。</li>
<li> 新节点启动cassandra</li>
<li> 新节点数据同步<br>当集群中的所有节点都正常运行之后，修改keyspace的属性以便将数据分布到新的数据中心，比如:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; ALTER KEYSPACE system_auth WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;NetworkTopologyStrategy&#x27;</span>, <span class="string">&#x27;DC1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;DC2&#x27;</span>:<span class="number">1</span>&#125;;</span><br><span class="line">cqlsh&gt; ALTER KEYSPACE system_traces WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;NetworkTopologyStrategy&#x27;</span>, <span class="string">&#x27;DC1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;DC2&#x27;</span>:<span class="number">1</span>&#125;;</span><br><span class="line">cqlsh&gt; ALTER KEYSPACE system_distributed WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;NetworkTopologyStrategy&#x27;</span>, <span class="string">&#x27;DC1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;DC2&#x27;</span>:<span class="number">1</span>&#125;;</span><br></pre></td></tr></table></figure>
在原数据中心或新数中心的任意节点上执行皆可。</li>
</ol>
<p>然后新添加数据中心的每一个节点上运行nodetool rebuild,并指定原数据中心的名字:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool rebuild -- name_of_existing_data_center</span><br></pre></td></tr></table></figure>
<p>多个节点可以同时运行此命令。</p>
<ol start="9">
<li> 还原auto_bootstrap参数<br>新添数据中心节点的配置文件cassandra.yaml去掉auto_bootstrap参数或者将其值设置为true。如果新添加的节点是种子节点，则此参数应设置为false,种子节点不需要bootstrap。</li>
</ol>
<p>References:<br>[1]<a href="http://docs.datastax.com/en/cassandra/2.2/cassandra/operations/opsAddDCToCluster.html">Adding a data center to a cluster</a><br>[2]<a href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/configuration/configMultiNetworks.html">Using multiple network interfaces</a><br>[3]<a href="https://www.instaclustr.com/apache-cassandra-deployed-on-private-and-public-networks/">Apache Cassandra Deployed on Private and Public Networks</a><br>[4]<a href="https://docs.datastax.com/en/cassandra-oss/2.2/cassandra/operations/opsAddNodeToCluster.html">Adding nodes to an existing cluster</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>更改cassandra集群数据中心和机架(rack)名</title>
    <url>/2016/06/18/cassandra-change-dc-rack-name/</url>
    <content><![CDATA[<a id="more"></a>
<p>为了防止意外，cassandra不允许更改节点的数据中心和机架名字。会有类似错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[main\] <span class="number">2016</span>-<span class="number">06</span>-<span class="number">18</span> <span class="number">11</span>:<span class="number">01</span>:<span class="number">40</span>,<span class="number">730</span> CassandraDaemon.java:<span class="number">638</span> - Cannot start node <span class="keyword">if</span> snitch<span class="string">&#x27;s </span></span><br><span class="line"><span class="string">data center (DC1) differs from previous data center (datacenter1). Please fix the snitch configuration, </span></span><br><span class="line"><span class="string">decommission and rebootstrap this node or use the flag -Dcassandra. ignore_dc=true.</span></span><br></pre></td></tr></table></figure>

<p>如果你知道你在做什么，可以添加两个JVM参数cassandra.ignore_rack和cassandra.ignore_dc来更改数据中心和机架的名字。</p>
<p>编辑/etc/cassandra/cassandra-env.sh文件,添加JVM参数:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">JVM_OPTS=<span class="string">&quot;$JVM_OPTS -Dcassandra.ignore_dc=true -Dcassandra.ignore_rack=true&quot;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://stackoverflow.com/questions/35056986/failed-to-start-dse-solr-node">failed to start dse solr node</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra集群更名</title>
    <url>/2015/11/06/cassandra-change-name/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian从官方源安装cassandra后，集群其实已经建立起来了，默认的集群名字为Test Cluster<br>直接更改/etc/cassandra/cassandra.yaml文件中的cluster_name,然后重新启动cassandra是行不通的。<br>有如下类似错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[main\] <span class="number">2015</span>-<span class="number">11</span>-<span class="number">06</span> <span class="number">22</span>:<span class="number">44</span>:<span class="number">41</span>,<span class="number">853</span> CassandraDaemon.java:<span class="number">635</span> - Fatal exception during initialization</span><br><span class="line">org.apache.cassandra.exceptions.ConfigurationException: Saved cluster name Test Cluster != configured name imageCluster</span><br></pre></td></tr></table></figure>

<p>这是因为集群的名字存储在系统表中，当与配置文件中的集群名字不同时，就会出现以上错误。<strong>二者必须要一致才可以</strong>。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; UPDATE system.local SET cluster_name = <span class="string">&#x27;test&#x27;</span> where key=<span class="string">&#x27;local&#x27;</span>;</span><br><span class="line"># flush the sstables to persist the update.</span><br><span class="line">bash $ ./nodetool flush</span><br></pre></td></tr></table></figure>

<p>修改完后还要flush一下节点。如果更改集群的名字，集群中所有的节点要逐一这样改过才行。</p>
<p>最好在集群初始化之初规划好集群的名字，不要随意更改集群名字。</p>
<p>References:<br>[1]<a href="http://stackoverflow.com/questions/22006887/cassandra-saved-cluster-name-test-cluster-configured-name">Saved cluster name Test Cluster != configured name</a><br>[2]<a href="https://wiki.apache.org/cassandra/FAQ#clustername_mismatch">Cassandra says “ClusterName mismatch: oldClusterName != newClusterName” and refuses to start</a><br>[3]<a href="http://www.tomas.cat/blog/en/troubleshooting-cassandra-saved-cluster-name-xxxx-configured-name-yyyy-en">Troubleshooting cassandra: Saved cluster name XXXX != configured name YYYY</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra compaction strategy</title>
    <url>/2019/06/22/cassandra-compaction-strategy/</url>
    <content><![CDATA[<a id="more"></a>
<p>cassandra更新或删除rows时并不会真正的更新或删除原先的rows，只是添加新的rows并将原rows打上tombstone标记，所以cassandra需要周期性的运行compaction来整理数据库。</p>
<p>compaction有三种策略，SizeTieredCompactionStrategy (STCS)、LeveledCompactionStrategy (LCS)和DateTieredCompactionStrategy (DTCS)，默认的compaction策略是STCS。</p>
<p>当前使用的集群在compaction时出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[CompactionExecutor:<span class="number">41367</span>\] <span class="number">2019</span>-<span class="number">06</span>-<span class="number">22</span> <span class="number">11</span>:<span class="number">22</span>:<span class="number">02</span>,<span class="number">063</span> CassandraDaemon.java:<span class="number">185</span> - Exception <span class="keyword">in</span> thread Thread\[CompactionExecutor:<span class="number">41367</span>,<span class="number">1</span>,main\]</span><br><span class="line">java.lang.RuntimeException: Not enough space <span class="keyword">for</span> compaction, estimated sstables = <span class="number">1</span>, expected write size = <span class="number">678107716200</span></span><br><span class="line"> at org.apache.cassandra.db.compaction.CompactionTask.checkAvailableDiskSpace(CompactionTask.java:<span class="number">275</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.6</span>.jar:<span class="number">2.2</span><span class="number">.6</span>\]</span><br><span class="line"> at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:<span class="number">118</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.6</span>.jar:<span class="number">2.2</span><span class="number">.6</span>\]</span><br><span class="line"> at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:<span class="number">28</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.6</span>.jar:<span class="number">2.2</span><span class="number">.6</span>\]</span><br><span class="line"> at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:<span class="number">74</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.6</span>.jar:<span class="number">2.2</span><span class="number">.6</span>\]</span><br><span class="line"> at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:<span class="number">59</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.6</span>.jar:<span class="number">2.2</span><span class="number">.6</span>\]</span><br><span class="line"> at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:<span class="number">256</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.6</span>.jar:<span class="number">2.2</span><span class="number">.6</span>\]</span><br><span class="line"> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">511</span>) ~\[na:<span class="number">1.8</span><span class="number">.0_66</span>\]</span><br><span class="line"> at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">266</span>) ~\[na:<span class="number">1.8</span><span class="number">.0_66</span>\]</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1142</span>) ~\[na:<span class="number">1.8</span><span class="number">.0_66</span>\]</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">617</span>) \[na:<span class="number">1.8</span><span class="number">.0_66</span>\]</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>) \[na:<span class="number">1.8</span><span class="number">.0_66</span>\]</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>需要600多G的空间来compaction，昏！</p>
<p>是的，有一个数据文件达到了600多G，默认的SizeTieredCompactionStrategy压缩策略需要比数据文件大一些的空闲空间来执行compaction，但是磁盘剩余空间只有不到400G了，so.</p>
<p>“SizeTieredCompactionStrategy Compaction requires a lot of temporary space: In worst case, we need to merge all existing SSTables into one, so we need half the disk to be empty to write the output file and only later can delete the old SSTables”</p>
<p>使用STCS compaction策略，cassandra节点一般要保持50%以上的剩余空间，对于大数据集来讲，太可怕了，几个T的数据，需要额外几个T的剩余空间才能正常运行, WTF!</p>
<p>STCS策略会在达到min_threshold(默认为4)时，将这几个SSTABLE合并为一个大的SSTABLE，这个SSTABLE并不会有上限大小的限制，初期数据少的时候并不会有什么问题。但是目前2T的节点，已经有3个600G的SSTABLE了，下一步compaction要生成单个2T以上的SSTABLE了，看来默认的STCS策略并不太适合大数据集。</p>
<p>LeveledCompactionStrategy压缩策略只使用很少的空间来执行压缩，只要10 * sstable_size_in_mb的空间，目前默认的sstable_size_in_mb为160MB，10倍的话差不多2个G的样子，不过官方也讲最好保持10G以上的剩余空间。</p>
<p>sstable_size_in_mb是LeveledCompactionStrategy bean的一个RW attribute来控制compaction后生成的sstable的大小，一般使用当前默认的160M或设置为200M都是适合的。对于大数据集LCS会生成数量很多的sstables。</p>
<p><strong>当前表的compaction</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; desc TABLE image;</span><br><span class="line">CREATE TABLE reis.image (</span><br><span class="line"> id text PRIMARY KEY,</span><br><span class="line"> content blob,</span><br><span class="line"> name text</span><br><span class="line">) WITH bloom_filter_fp_chance = <span class="number">0.01</span></span><br><span class="line"> AND caching = <span class="string">&#x27;&#123;&quot;keys&quot;:&quot;ALL&quot;, &quot;rows_per_partition&quot;:&quot;NONE&quot;&#125;&#x27;</span></span><br><span class="line"> AND comment = <span class="string">&#x27;&#x27;</span></span><br><span class="line"> AND compaction = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy&#x27;</span>&#125;</span><br><span class="line"> AND compression = &#123;<span class="string">&#x27;sstable_compression&#x27;</span>: <span class="string">&#x27;org.apache.cassandra.io.compress.LZ4Compressor&#x27;</span>&#125;</span><br><span class="line"> AND dclocal_read_repair_chance = <span class="number">0.1</span></span><br><span class="line"> AND default_time_to_live = <span class="number">0</span></span><br><span class="line"> AND gc_grace_seconds = <span class="number">864000</span></span><br><span class="line"> AND max_index_interval = <span class="number">2048</span></span><br><span class="line"> AND memtable_flush_period_in_ms = <span class="number">0</span></span><br><span class="line"> AND min_index_interval = <span class="number">128</span></span><br><span class="line"> AND read_repair_chance = <span class="number">0.0</span></span><br><span class="line"> AND speculative_retry = <span class="string">&#x27;99.0PERCENTILE&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>果然是SizeTieredCompactionStrategy</p>
<p><strong>修改compaction策略</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt;ALTER TABLE image WITH compaction = &#123; <span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;org.apache.cassandra.db.compaction.LeveledCompactionStrategy&#x27;</span>,<span class="string">&#x27;sstable_size_in_mb&#x27;</span>:<span class="string">&#x27;200&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>这里虽然将compaction策略由STCS修改成了LCS，但是要完成一次完整的转换仍然需要巨大的剩余磁盘空间，因为在完整的转换为LCS之前，那些大的sstable,当前有3个600G以上的，会一直保留在磁盘上，完整转换完毕后才能删除，只剩下数量众多的小sstabel，之后的compaction就不会需要这么多的剩余磁盘空间了。</p>
<p>official documnet: “While a merge of several SSTables is ongoing, the request path continues to read the old SSTables. Ideally, the old SSTables would be deleted as soon as the merge is done, but we must not delete an SSTable that still has in-progress reads.”</p>
<p>还有一个问题，直接alter table修改compaction策略，会使所有的集群节点开始转换到LCS的compaction动作，集群的负载会高居不下，所以也可以使用jmx来逐个节点的迁移到LCS策略。</p>
<p>当然也可以关闭节点的自动compaction</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool disableautocompation -- keyspacename tablename </span><br></pre></td></tr></table></figure>

<p>修改完table的compaction策略后，手动逐个执行compaction</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool compact -- keyspacename tablename</span><br></pre></td></tr></table></figure>

<p>最后再打开autocompaction</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool enableautocompaction</span><br></pre></td></tr></table></figure>

<p><strong>创建新表时</strong><br>可以直接指定compaction策略</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CREATE TABLE reis.image (</span><br><span class="line"> id text PRIMARY KEY,</span><br><span class="line"> content blob,</span><br><span class="line"> name text</span><br><span class="line">) WITH compaction = &#123; <span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;org.apache.cassandra.db.compaction.LeveledCompactionStrategy&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://docs.datastax.com/en/archived/cassandra/2.2/cassandra/dml/dmlHowDataMaintain.html">How is data maintained?</a><br>[2]<a href="https://www.datastax.com/dev/blog/leveled-compaction-in-apache-cassandra">Leveled Compaction in Apache Cassandra</a><br>[3]<a href="https://www.datastax.com/dev/blog/when-to-use-leveled-compaction">When to Use Leveled Compaction</a><br>[4]<a href="https://www.cnblogs.com/didda/p/4728588.html">Cassandra 的压缩策略STCS，LCS 和 DTCS</a><br>[5]<a href="https://www.cnblogs.com/gpcuster/archive/2010/05/27/1745859.html">介绍CASSANDRA中的压缩</a><br>[6]<a href="https://stackoverflow.com/questions/45419041/cancelling-ongoing-compaction-jobs-in-cassandra">Cancelling ongoing compaction jobs in Cassandra</a><br>[7]<a href="https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/tools/toolsSetCompactionThreshold.html">nodetool setcompactionthreshold</a><br>[8]<a href="https://www.cnblogs.com/sing1ee/archive/2012/05/24/2765042.html">被忽视的Compaction策略-有关NoSQL Compaction策略的一点思考</a><br>[9]<a href="https://stackoverflow.com/questions/29392153/cassandra-control-sstable-size">Cassandra control SSTable size</a><br>[10]<a href="https://github.com/scylladb/scylla/wiki/SSTable-compaction-and-compaction-strategies">SSTable compaction and compaction strategies</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra copy导入数据时batch too large错误</title>
    <url>/2016/07/15/cassandra-copy-batch-too-large%E9%94%99%E8%AF%AF/</url>
    <content><![CDATA[<a id="more"></a>
<p>执行COPY命令时,出现Batch too large错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh:reis&gt; COPY image FROM <span class="string">&#x27;image.csv&#x27;</span>;</span><br><span class="line">Using <span class="number">7</span> child processes</span><br><span class="line"></span><br><span class="line">Starting copy <span class="keyword">of</span> reis.image <span class="keyword">with</span> columns \[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;content&#x27;</span>, <span class="string">&#x27;name&#x27;</span>\].</span><br><span class="line">Failed to <span class="keyword">import</span> <span class="number">11</span> rows: InvalidRequest - code=<span class="number">2200</span> \[Invalid query\] message=<span class="string">&quot;Batch too large&quot;</span>, will retry later, attempt <span class="number">1</span> <span class="keyword">of</span> <span class="number">5</span></span><br><span class="line">Failed to <span class="keyword">import</span> <span class="number">16</span> rows: InvalidRequest - code=<span class="number">2200</span> \[Invalid query\] message=<span class="string">&quot;Batch too large&quot;</span>, will retry later, attempt <span class="number">1</span> <span class="keyword">of</span> <span class="number">5</span></span><br><span class="line">Failed to <span class="keyword">import</span> <span class="number">18</span> rows: InvalidRequest - code=<span class="number">2200</span> \[Invalid query\] message=<span class="string">&quot;Batch too large&quot;</span>, will retry later, attempt <span class="number">1</span> <span class="keyword">of</span> <span class="number">5</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>/var/log/cassandra/system.log文件中可见:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[SharedPool-Worker-<span class="number">1</span>\] <span class="number">2016</span>-<span class="number">07</span>-<span class="number">15</span> <span class="number">15</span>:<span class="number">07</span>:<span class="number">20</span>,<span class="number">725</span> BatchStatement.java:<span class="number">267</span> - Batch <span class="keyword">of</span> prepared statements <span class="keyword">for</span> \[reis.image\] is <span class="keyword">of</span> size <span class="number">2732525</span>, exceeding specified threshold <span class="keyword">of</span> <span class="number">614400</span> by <span class="number">2118125.</span> (see batch_size_fail_threshold_in_kb)</span><br></pre></td></tr></table></figure>

<p>batch就是批量执行DML语句. 因为我的image表中有大字段,用于存储图片,每个图片不超过500K,所以遭遇了batch too large错误.</p>
<p>/etc/cassandra/cassandra.yaml文件中,参数batch_size_fail_threshold_in_kb的默认值只有50,一条DML语句就超过了这个阈值.<br>所以将此参数设置为600</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">batch_size_fail_threshold_in_kb: <span class="number">600</span></span><br></pre></td></tr></table></figure>
<p>然后将COPY命令的批操作限制为1:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh:reis&gt; COPY image FROM <span class="string">&#x27;image.csv&#x27;</span> WITH MAXBATCHSIZE = <span class="number">1</span> and MINBATCHSIZE = <span class="number">1</span>;</span><br><span class="line">Using <span class="number">7</span> child processes</span><br><span class="line"></span><br><span class="line">Starting copy <span class="keyword">of</span> reis.image <span class="keyword">with</span> columns \[<span class="string">&#x27;id&#x27;</span>, <span class="string">&#x27;content&#x27;</span>, <span class="string">&#x27;name&#x27;</span>\].</span><br><span class="line">Processed: <span class="number">826</span> rows; Rate: <span class="number">30</span> rows/s; Avg. rate: <span class="number">60</span> rows/s</span><br><span class="line"><span class="number">826</span> rows imported <span class="keyword">from</span> <span class="number">1</span> files <span class="keyword">in</span> <span class="number">13.682</span> seconds (<span class="number">0</span> skipped).</span><br></pre></td></tr></table></figure>

<p>顺利的导入了所有数据.</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra导出和导入数据</title>
    <url>/2015/11/24/cassandra-export-import/</url>
    <content><![CDATA[<a id="more"></a>
<p>cassandra像其他RDBMS一样提供了export/import工具：</p>
<ul>
<li>  cqlsh命令COPY TO/FROM<br>注意这不是cql命令。使用这组命令可以在cassandra与其他RDBMS或cassandra之间迁移数据。COPY TO/FROM支持CSV文件格式以及标准输出和输入。<br>COPY TO/FROM命令同样支持集合数据类型。</li>
<li>  sstable2json/json2sstable<br>这组工具已经过时，在3.0版本中已被删除。所以不应该再使用这组工具。</li>
<li>  sstableloader<br>Cassandra bulk loader,可以装载外部数据到cassandra,也可以恢复snapshot,装载sstable到不同配置的cassandra集群。<br>如果数据量很大，应该使用sstableloader，如果数据量比较小的话，使用COPY TO/FROM更省时省力。</li>
<li>  Snapshots<br>snapshots是cassandra正牌的备份恢复工具，而不是用于与其他数据库系统进行数据迁移的工具。所以严格来说它不应该算作export/import工具。</li>
<li>  ETL工具<br>很多第三方的ETL(Extract-Transform-Load)工具支持从其他数据库向cassandra数据库迁移数据。</li>
</ul>
<p><strong>COPY TO/FROM</strong></p>
<p>这里只讲一下COPY TO/FROM命令。</p>
<p>命令格式:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">COPY table_name ( column, ...)</span><br><span class="line">FROM ( <span class="string">&#x27;file_name&#x27;</span> STDIN )</span><br><span class="line">WITH option = <span class="string">&#x27;value&#x27;</span> AND ...</span><br><span class="line"></span><br><span class="line">COPY table_name ( column , ... )</span><br><span class="line">TO ( <span class="string">&#x27;file_name&#x27;</span> STDOUT )</span><br><span class="line">WITH option = <span class="string">&#x27;value&#x27;</span> AND ...</span><br></pre></td></tr></table></figure>

<p>COPY FROM 用于从csv文件或标准输入import数据到表，而COPY TO用于将表数据export到csv文件或标准输出。</p>
<p>WITH option=’value’ 用于指定csv文件的格式,分隔符，引用，转移字符，文件编码，时间格式等等，详见官方文档。</p>
<p>如果不指定列名，会按表元数据中记载的列顺序输出所有的列。同样，如果csv也是按相同的顺序组织数据，COPY FROM时也可以忽略所有的列名。</p>
<p>COPY TO/FROM时，可以只指定部分列进行部分数据的导出和导入，而且可以以任意顺序指定列名。</p>
<p>如果表中已经存在数据，COPY FROM不会truncate已有的数据。</p>
<p>导出数据的示例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; use test ;</span><br><span class="line">cqlsh&gt; COPY airplanes (name, mach, year, manufacturer) TO <span class="string">&#x27;export.csv&#x27;</span> ;</span><br></pre></td></tr></table></figure>

<p>导入数据的示例:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; COPY airplanes (name, mach, year, manufacturer) FROM <span class="string">&#x27;import.csv&#x27;</span> ;</span><br></pre></td></tr></table></figure>

<p>如果使用标准输入导入数据，要使用只包含 <code>\.</code> 字符的单独一行来结束数据输入。</p>
<p>如果导入数据时出现如下错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Error</span> starting <span class="keyword">import</span> process:</span><br><span class="line"></span><br><span class="line">field larger than field limit (<span class="number">131072</span>)</span><br><span class="line">%d format: a number is required, not NoneType</span><br></pre></td></tr></table></figure>
<p>这是因为csv文件包含大容量字段，python的csv模块需要设置更大的字段尺寸限制。</p>
<p>修改/usr/bin/cqlsh.py文件,在导入csv模块之后，添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">csv.field_size_limit(sys.maxsize)</span><br></pre></td></tr></table></figure>

<p><strong>注意：含有counter列的表无法使用COPY TO/FROM来导出和导入数据。</strong></p>
<p>References:<br>[1]<a href="http://www.datastax.com/dev/blog/ways-to-move-data-tofrom-datastax-enterprise-and-cassandra">Ways to Move Data To/From DataStax Enterprise and Cassandra</a><br>[2]<a href="https://issues.apache.org/jira/browse/CASSANDRA-9618">Consider deprecating sstable2json/json2sstable in 2.2</a><br>[3]<a href="http://stackoverflow.com/questions/15063936/csv-error-field-larger-than-field-limit-131072">_csv.Error: field larger than field limit (131072)</a><br>[4]<a href="http://alongwith.me/cassandra/cassandra%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB">cassandra数据迁移</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra修复损坏的sstables</title>
    <url>/2019/07/15/cassandra-fix-corrupt-sstables/</url>
    <content><![CDATA[<a id="more"></a>
<p>由于磁盘阵列Unreadable Sectors错误，强制修复后导致cassandra的一个sstable损坏，cassandra启动时报错:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[CompactionExecutor:<span class="number">2</span>\] <span class="number">2019</span>-<span class="number">07</span>-<span class="number">15</span> <span class="number">15</span>:<span class="number">03</span>:<span class="number">27</span>,<span class="number">161</span> DefaultFSErrorHandler.java:<span class="number">92</span> - Exiting forcefully due to file system exception on startup, disk failure policy <span class="string">&quot;stop&quot;</span></span><br><span class="line">org.apache.cassandra.io.FSReadError: org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: <span class="regexp">/mnt/</span>data/cassandra/reis/image-6a85c44086a711e5aef4b53617129a2a/lb-<span class="number">47344</span>-big-Data.db</span><br><span class="line">at org.apache.cassandra.io.util.RandomAccessReader.readBytes(RandomAccessReader.java:<span class="number">365</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.utils.ByteBufferUtil.read(ByteBufferUtil.java:<span class="number">361</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.utils.ByteBufferUtil.readWithLength(ByteBufferUtil.java:<span class="number">324</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.ColumnSerializer.deserializeColumnBody(ColumnSerializer.java:<span class="number">132</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:<span class="number">92</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:<span class="number">52</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br></pre></td></tr></table></figure>
<p>lb-47344-big-Data.db这个sstable被破坏了。<br>因为节点已经无法启动了，所以下面的尝试无可避免的失败了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool scrub</span><br><span class="line">nodetool: Failed to connect to <span class="string">&#x27;127.0.0.1:7199&#x27;</span> - ConnectException: <span class="string">&#x27;Connection refused (Connection refused)&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>尝试离线修复，如果数据量很大，记得开启screen会话</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u cassandra sstablescrub reis image</span><br></pre></td></tr></table></figure>
<p>注意cassandra数据目录的权限，这里使用cassandra用户来执行scrub<br>执行结束后，删除掉已经损坏的sstable，scrub时cassandra会将损坏的sstable保持原样</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mv lb-<span class="number">47344</span>* backups/</span><br></pre></td></tr></table></figure>

<p>启动cassandra</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl start cassandra</span><br></pre></td></tr></table></figure>

<p>确认系统运行正常</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool status </span><br></pre></td></tr></table></figure>

<p>之后可以删除sstablescrub自动创建的快照，释放掉已经无用的sstables</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool clearsnapshot</span><br><span class="line">Requested clearing snapshot(s) <span class="keyword">for</span> \[all keyspaces\]</span><br></pre></td></tr></table></figure>

<p>最后需要repair本节点，修复节点数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool repair -local -- reis image</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://docs.datastax.com/en/dse/5.1/dse-admin/datastax_enterprise/tools/toolsSStables/toolsSSTableScrub.html">sstablescrub</a><br>[2]<a href="https://engineering.gosquared.com/dealing-corrupt-sstable-cassandra">Dealing with a corrupt SSTable in Cassandra</a><br>[3]<a href="https://blog.pythian.com/so-you-have-a-broken-cassandra-sstable-file/">So You Have A Broken Cassandra SSTable File?</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra跨数据中心、多网络接口部署</title>
    <url>/2020/06/14/cassandra-mutidatacenter-multinetworking-deploy/</url>
    <content><![CDATA[<a id="more"></a>
<p>cassandra集群以前运行于本地机房，现在需要扩展到云端，云主机添加为集群的新数据中心。因为并不是公有云，所有没有启动SSL认证和加密。</p>
<p>本地机房与云机房通过专线连接，并且本地只有两个互联ip地址可用。本地机房原集群内节点只使用私有网络地址，无法被云端访问。云端主机使用私有地址，云平台将私有地址映射到专线可以访问的“公有地址”，这里并不是真正的“公有地址”，仍然是一个大的私有网络，不过本地机房和云机房通过这些地址可以互访，所有这里也叫做“公有地址”</p>
<p>因此集群的本地机房节点通过NAT映射，将私有地址的7000和9042端口映射到公有地址，从而可以被云主机访问，同时做了端口回流，保证本地机房其他机器也可以通过公有地址访问节点。<br>如果不做或不能做端口回流，应该也可以使用iptables/nftables在集群内节点以及需要访问集群的客户机器上添加nat转换规则,从公有ip转换到对应的私有ip，这个没试。</p>
<p>这样本地机房和云机房的节点都有私有地址和映射后的公有地址，cassandra集群节点需要使用公有地址进行互访，但cassandra都无法直接监听公有地址。这需要配置cassandra.yaml,设置listen_address和rpc_address为私有地址，设置broadcast_address和broadcast_rpc_address为公有ip地址，但是listen_on_broadcast_address设置为false，因为各个节点并不能在公有ip上监听。这样当跨数据中心时使用公有ip通讯，但在本地网络内部可以使用私有网络。</p>
<p>cassandra-rackdc.properties配置文件可以打开prefer_local选项，这样可以优先使用本地网络，降低网络延迟。</p>
<p>配置实例：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">listen_address: <span class="number">192.168</span><span class="number">.136</span><span class="number">.250</span></span><br><span class="line">broadcast_address: <span class="number">59.206</span><span class="number">.31</span><span class="number">.152</span></span><br><span class="line">rpc_address: <span class="number">192.168</span><span class="number">.136</span><span class="number">.250</span></span><br><span class="line">broadcast_rpc_address: <span class="number">59.206</span><span class="number">.31</span><span class="number">.152</span></span><br><span class="line"></span><br><span class="line">seed_provider:</span><br><span class="line"> # Addresses of hosts that are deemed contact points. </span><br><span class="line"> # Cassandra nodes use this list of hosts to find each other and learn</span><br><span class="line"> # the topology of the ring. You must change this if you are running</span><br><span class="line"> # multiple nodes!</span><br><span class="line"> - class_name: org.apache.cassandra.locator.SimpleSeedProvider</span><br><span class="line"> parameters:</span><br><span class="line"> # seeds is actually a comma-delimited list of addresses.</span><br><span class="line"> # Ex: &quot;&lt;ip1&gt;,&lt;ip2&gt;,&lt;ip3&gt;&quot;</span><br><span class="line"> - seeds: <span class="string">&quot;59.206.31.152,10.160.4.196,10.160.4.197&quot;</span></span><br></pre></td></tr></table></figure>

<p>这样本地数据中心和云数据中心就可以通过公有ip相互通讯了。<br><strong>备注：</strong>rpc并不是必须的，只使用cql是可行的。</p>
<p>References:<br>[1]<a href="https://docs.datastax.com/en/cassandra-oss/3.0/cassandra/configuration/configMultiNetworks.html">Using multiple network interfaces</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>Cassandra竟然歧视OpenJDK</title>
    <url>/2014/12/25/cassandra-openjdk-issues/</url>
    <content><![CDATA[<a id="more"></a>
<p>cassandra 2.1.2的启动日志中出现如下字样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">WARN \[main\] <span class="number">2013</span>-<span class="number">11</span>-<span class="number">24</span> <span class="number">10</span>:<span class="number">54</span>:<span class="number">30</span>,<span class="number">423</span> CassandraDaemon.java (line <span class="number">155</span>) OpenJDK is not recommended. Please upgrade to the newest Oracle Java release</span><br></pre></td></tr></table></figure>

<p>查看CassandraDaemon.java源代码,有如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"> <span class="built_in">String</span> javaVmName = System.getProperty(<span class="string">&quot;java.vm.name&quot;</span>);</span><br><span class="line">logger.info(<span class="string">&quot;JVM vendor/version: &#123;&#125;/&#123;&#125;&quot;</span>, javaVmName, javaVersion);</span><br><span class="line"><span class="keyword">if</span> (javaVmName.contains(<span class="string">&quot;OpenJDK&quot;</span>))</span><br><span class="line">&#123;</span><br><span class="line"> <span class="comment">// There is essentially no QA done on OpenJDK builds, and</span></span><br><span class="line"> <span class="comment">// clusters running OpenJDK have seen many heap and load issues.</span></span><br><span class="line"> logger.warn(<span class="string">&quot;OpenJDK is not recommended. Please upgrade to the newest Oracle Java release&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (!javaVmName.contains(<span class="string">&quot;HotSpot&quot;</span>))</span><br><span class="line">&#123;</span><br><span class="line"> logger.warn(<span class="string">&quot;Non-Oracle JVM detected. Some features, such as immediate unmap of compacted SSTables, may not work as intended&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>OpenJDK没这么差吧！</p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>文件系统权限不足导致cassandra无法启动一例</title>
    <url>/2015/03/24/cassandra-permission-deny/</url>
    <content><![CDATA[<a id="more"></a>
<p>集群中的某一node无法启动,nodetool status输出如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">error: No nodes present <span class="keyword">in</span> the cluster. Has <span class="built_in">this</span> node finished starting up?</span><br><span class="line">-- StackTrace --</span><br><span class="line">java.lang.RuntimeException: No nodes present <span class="keyword">in</span> the cluster. Has <span class="built_in">this</span> node finished starting up?</span><br><span class="line"> at org.apache.cassandra.dht.Murmur3Partitioner.describeOwnership(Murmur3Partitioner.java:<span class="number">129</span>)</span><br><span class="line"> at org.apache.cassandra.service.StorageService.getOwnership(StorageService.java:<span class="number">3856</span>)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">62</span>)</span><br><span class="line"> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"> at java.lang.reflect.Method.invoke(Method.java:<span class="number">497</span>)</span><br><span class="line"> at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:<span class="number">71</span>)</span><br><span class="line"> at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)</span><br><span class="line"> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"> at java.lang.reflect.Method.invoke(Method.java:<span class="number">497</span>)</span><br><span class="line"> at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:<span class="number">275</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:<span class="number">112</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:<span class="number">46</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:<span class="number">237</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:<span class="number">83</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:<span class="number">206</span>)</span><br><span class="line"> at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:<span class="number">647</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:<span class="number">678</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:<span class="number">1443</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:<span class="number">76</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:<span class="number">1307</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:<span class="number">1399</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:<span class="number">637</span>)</span><br><span class="line"> at sun.reflect.GeneratedMethodAccessor9.invoke(Unknown Source)</span><br><span class="line"> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"> at java.lang.reflect.Method.invoke(Method.java:<span class="number">497</span>)</span><br><span class="line"> at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:<span class="number">323</span>)</span><br><span class="line"> at sun.rmi.transport.Transport$1.run(Transport.java:<span class="number">200</span>)</span><br><span class="line"> at sun.rmi.transport.Transport$1.run(Transport.java:<span class="number">197</span>)</span><br><span class="line"> at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line"> at sun.rmi.transport.Transport.serviceCall(Transport.java:<span class="number">196</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:<span class="number">568</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:<span class="number">826</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$78(TCPTransport.java:<span class="number">683</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$$Lambda$1/<span class="number">294183905.</span>run(Unknown Source)</span><br><span class="line"> at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:<span class="number">682</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1142</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">617</span>)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br></pre></td></tr></table></figure>

<p>/var/log/cassandra/system.log有如下错误信息:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[MemtableFlushWriter:<span class="number">3</span>\] <span class="number">2015</span>-<span class="number">03</span>-<span class="number">23</span> <span class="number">18</span>:<span class="number">26</span>:<span class="number">37</span>,<span class="number">996</span> CassandraDaemon.java:<span class="number">153</span> - Exception <span class="keyword">in</span> thread Thread\[MemtableFlushWriter:<span class="number">3</span>,<span class="number">5</span>,main\]</span><br><span class="line">java.lang.RuntimeException: java.io.FileNotFoundException: <span class="regexp">/var/</span>lib/cassandra/data/image/image-2a19ce908f1f11e481c2a9fac1d00bce/image-image-tmp-ka--&gt; <span class="number">2</span>-Index.db (Permission denied)</span><br><span class="line"> at org.apache.cassandra.io.util.SequentialWriter.&lt;init&gt;(SequentialWriter.java:<span class="number">75</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.io.util.SequentialWriter.open(SequentialWriter.java:<span class="number">104</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.io.util.SequentialWriter.open(SequentialWriter.java:<span class="number">99</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.io.sstable.SSTableWriter$IndexWriter.&lt;init&gt;(SSTableWriter.java:<span class="number">552</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.io.sstable.SSTableWriter.&lt;init&gt;(SSTableWriter.java:<span class="number">134</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.db.Memtable$FlushRunnable.createFlushWriter(Memtable.java:<span class="number">390</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.db.Memtable$FlushRunnable.writeSortedContents(Memtable.java:<span class="number">329</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.db.Memtable$FlushRunnable.runWith(Memtable.java:<span class="number">313</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.io.util.DiskAwareRunnable.runMayThrow(DiskAwareRunnable.java:<span class="number">48</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:<span class="number">28</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:<span class="number">297</span>) ~\[guava-<span class="number">16.0</span>.jar:na\]</span><br><span class="line"> at org.apache.cassandra.db.ColumnFamilyStore$Flush.run(ColumnFamilyStore.java:<span class="number">1037</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>) ~\[na:<span class="number">1.7</span><span class="number">.0_65</span>\]</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>) ~\[na:<span class="number">1.7</span><span class="number">.0_65</span>\]</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>) ~\[na:<span class="number">1.7</span><span class="number">.0_65</span>\]</span><br><span class="line">Caused by: java.io.FileNotFoundException: <span class="regexp">/var/</span>lib/cassandra/data/image/image-2a19ce908f1f11e481c2a9fac1d00bce/image-image-tmp-ka-<span class="number">2</span>-Index.db -&gt; (Permission denied)</span><br><span class="line"> at java.io.RandomAccessFile.open(Native Method) ~\[na:<span class="number">1.7</span><span class="number">.0_65</span>\]</span><br><span class="line"> at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:<span class="number">241</span>) ~\[na:<span class="number">1.7</span><span class="number">.0_65</span>\]</span><br><span class="line"> at org.apache.cassandra.io.util.SequentialWriter.&lt;init&gt;(SequentialWriter.java:<span class="number">71</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.2</span>.jar:<span class="number">2.1</span><span class="number">.2</span>\]</span><br><span class="line"> ... <span class="number">14</span> common frames omitted</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>看错误信息为文件系统访问权限问题所致，查看/var/lib/cassandra/data/image,果然此目录的属主和组都成了root</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># chown -R cassandra:cassandra /var/lib/cassandra/data/image</span><br></pre></td></tr></table></figure>

<p>重新启动cassandra成功。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra rebuild 种子节点</title>
    <url>/2018/12/02/cassandra-rebuild-seed-node/</url>
    <content><![CDATA[<a id="more"></a>
<p>cassandra 2.2.6环境，有一台种子节点硬件故障，半年以后才修复重新上线。<br>其数据已经落后太多，而cassandra并不会在其重新上线后自动进行数据同步。<br>nodetool repair应该可以使其数据重新同步，但是那速度是无法忍受的，因此使用nodetool rebuild来重建其数据。</p>
<p>首先停止cassandra服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop cassandra</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra stop</span><br></pre></td></tr></table></figure>

<p>然后删除掉数据目录下system和用户keyspace的所有数据<br> $ sudo rm -rf /var/lib/cassandra/data/system/*<br>$ sudo rm -rf /var/lib/cassandra/data/your_keyspaces/* </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/cassandra<span class="comment">/*</span></span><br></pre></td></tr></table></figure>

<p>如果不清除用户的keyspace，rebuild的时候并不会自动清除，而且rebuild是全量而不是增量，所以那些数据会成为垃圾数据，如果数据量很大，应该提前清除掉。</p>
<p>对于种子节点，还应该确认auto_bootstrap参数已经设置为false。</p>
<p>启动cassandra服务，执行rebuild</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra start</span><br><span class="line">$ nodetool rebuild -- name_of_existing_data_center</span><br></pre></td></tr></table></figure>

<p>指定源数据中心时，要指定与当前节点所在数据中心不同的数据中心。</p>
<p>查看rebuild进度</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ watch -n <span class="number">10</span> <span class="string">&#x27;nodetool netstats grep &quot;Receiving\\Sending&quot; gawk &#123;&#x27;</span><span class="string">&quot;&#x27;&quot;</span><span class="string">&#x27; print $1&quot; - &quot;$11/$4*100&quot;% Complete, &quot;($4-$11)/1024/1024/1024&quot; GB remaining&quot; &#x27;</span><span class="string">&quot;&#x27;&quot;</span><span class="string">&#x27;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>等nodetool rebuild结束重建就算完成了，其实这与添加新的节点差别不大,不过就是原来的环境，所有的配置都不用动罢了。</p>
<p>同步完成后可以看看用户表的统计信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool tablestats keyspace_name.table_name</span><br></pre></td></tr></table></figure>

<p><strong>updated:06/22/2019</strong></p>
<p>这次种子节点下线重做RAID，系统重新安装，cassandra版本为2.2.14</p>
<p>rebuild的时候提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$nodetool rebuild -- DC2</span><br><span class="line"></span><br><span class="line">nodetool: Unable to find sufficient sources <span class="keyword">for</span> streaming range (<span class="number">2952258499581076301</span>,<span class="number">2996932853512195336</span>\] <span class="keyword">in</span> keyspace system_traces</span><br><span class="line">See <span class="string">&#x27;nodetool help&#x27;</span> or <span class="string">&#x27;nodetool help &lt;command&gt;&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>需要将keyspace system_traces的replication strategy设置为NetworkTopologyStrategy并将其分布到所有的数据中心，其默认设置为SimpleStrategy</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; ALTER KEYSPACE system_traces WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;NetworkTopologyStrategy&#x27;</span>, <span class="string">&#x27;DC1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;DC2&#x27;</span>:<span class="number">1</span>&#125;;</span><br></pre></td></tr></table></figure>

<p>keyspace system_distributed的replication strategy也应该设置为NetworkTopologyStrategy并将其分布到所有的数据中心</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh&gt; ALTER KEYSPACE system_distributed WITH replication = &#123;<span class="string">&#x27;class&#x27;</span>: <span class="string">&#x27;NetworkTopologyStrategy&#x27;</span>, <span class="string">&#x27;DC1&#x27;</span>:<span class="number">2</span>,<span class="string">&#x27;DC2&#x27;</span>:<span class="number">1</span>&#125;;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://support.datastax.com/hc/en-us/articles/213145066-Unable-to-find-sufficient-sources-for-streaming-range-token-a-token-b-in-keyspace-some-keyspace-">Unable to find sufficient sources for streaming range (,] in keyspace</a><br>[2]<a href="https://stackoverflow.com/questions/46723429/unable-to-find-sufficient-sources-for-streaming-range-in-keyspace">Unable to find sufficient sources for streaming range in keyspace</a><br>[3]<a href="https://issues.apache.org/jira/browse/CASSANDRA-11098">system_distributed and system_traces keyspaces use hard-coded replication factors</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra替换当掉的种子节点</title>
    <url>/2019/08/30/cassandra-replace-dead-seed-node/</url>
    <content><![CDATA[<a id="more"></a>
<p>分为两个步骤，首先用新的节点替换宕机的节点，其次把新节点提升为种子节点。</p>
<p><strong>替换故障节点</strong></p>
<p>1、<code>nodetool status</code>命令找到DN节点的ip地址比如192.168.0.82，后面会用到这个ip地址。</p>
<p>2、新节点安装与集群其他节点一样版本的cassandra，然后停止cassandra服务，并清除节点全部数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop cassandra</span><br><span class="line"><span class="comment">//$ sudo kill -sigterm &lt;pid_of_cassandra&gt;</span></span><br><span class="line"><span class="comment">//$ sudo kill -15 &lt;pid_of_cassandra&gt;</span></span><br><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/cassandra<span class="comment">/*</span></span><br></pre></td></tr></table></figure>

<p>3、设置参数文件cassandra.yaml和cassandra-rackdc.properties或者 cassandra-topology.properties</p>
<p>auto_bootstrap要设置为true，因为新节点要从种子节点获取数据。<br>cluster_name设置为要加入的集群的名字<br>linsten_address和rpc_address设置为本机ip<br>endpoint_snitch 要与集群其他节点一致，然后修改对应的属性文件<br>seed_provider只要要提供一个集群中现有的种子节点，但不要将新添加节点的地址加入，因为种子节点并不会bootstrap，等新节点bootstrap完成后再将新节点提升为种子节点。</p>
<p>可以提取集群中其他节点的配置文件，只对应修改新节点独有的参数即可。</p>
<p>4、使用 replace_address 选项启动新节点</p>
<p>修改/etc/cassandra/cassandra-env.sh 文件，添加选项：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">JVM_OPTS=<span class="string">&quot;$JVM_OPTS -Dcassandra.replace_address=192.168.0.82&quot;</span></span><br></pre></td></tr></table></figure>
<p>这里的ip地址就是上面找到的要被替换的节点ip地址</p>
<p>5、启动新节点</p>
<p>等新节点bootstrap完成后再执行以下步骤，并且需要去掉replace_address选项</p>
<p>6、cassandra-rackdc.properties或cassandra-topology.properties文件中去掉被替换的节点</p>
<p>7、从集群中移除当掉的节点</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool removenode &lt;hostid&gt;</span><br></pre></td></tr></table></figure>

<p>nodetool status命令可以获取到节点的hostid</p>
<p><strong>提升为种子节点</strong></p>
<p>新添加节点bootstrap完成之后，可以提升为种子节点。</p>
<p>1、因为种子节点不能bootstrap，所以需要将其cassandra.yaml文件中的auto_bootstrap参数设置为false<br>2、在集群所有节点执行以下操作:<br> 将cassandra.yaml配置文件中的种子列表中去掉被替换的节点，将新添加节点的地址加入种子列表，然后重启节点。<br>注意不要并行操作，最好一个节点接一个节点的逐一操作。</p>
<p>References:<br>[1]<a href="https://docs.datastax.com/en/archived/cassandra/2.2/cassandra/operations/opsReplaceNode.html">Replacing a dead node or dead seed node</a><br>[2]<a href="https://docs.scylladb.com/operating-scylla/procedures/cluster-management/replace_dead_node/">Replace a Dead Node in a Scylla Cluster</a><br>[3]<a href="https://docs.scylladb.com/operating-scylla/procedures/cluster-management/replace_seed_node/">Replacing a dead seed node</a><br>[4]<a href="https://docs.datastax.com/en/archived/cassandra/2.2/cassandra/tools/toolsRemoveNode.html">nodetool removenode</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>Cassandra快照</title>
    <url>/2015/12/23/cassandra-snapshot/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>概念</strong></p>
<p>cassandra通过为数据目录下所有的SSTable磁盘文件制作快照来备份数据。当系统在线时，可以为所有的keyspace、单独的keyspace或者单独的表制作快照。如果使用并行ssh工具，比如pssh,可以为整个集群制作快照。</p>
<p>虽然制作快照时并不能保证节点与其复制节点保持一致，但当快照恢复后，依靠cassandra的一致性机制，最终还是会达到一致状态。</p>
<p>快照支持增量备份机制。</p>
<p>Cassandra通过硬链接(需要JNA,当前版本默认打开JNA)来制作快照，因此成本还是比较低的。</p>
<p><strong>查看快照</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool listsnapshots</span><br><span class="line"></span><br><span class="line">Snapshot Details: </span><br><span class="line">Snapshot name Keyspace name Column family name True size Size on disk </span><br><span class="line"><span class="number">1541832995400</span> reis image_increment <span class="number">0</span> bytes <span class="number">13</span> bytes </span><br><span class="line"><span class="number">1541832995400</span> reis image <span class="number">1.23</span> GB <span class="number">1.73</span> TB </span><br><span class="line"></span><br><span class="line">Total TrueDiskSpaceUsed: <span class="number">1.23</span> GB</span><br></pre></td></tr></table></figure>

<p><strong>制作快照</strong></p>
<p>制作快照时会先将内存数据刷写到硬盘，然后硬链接SSTable文件到备份目录。快照会创建到data_directory_location/keyspace_name/table_name-UUID/<br>snapshots/snapshot_name/目录下,里面有许多的.db文件记录了快照制作时的数据。<br>快照制作完成后，一般应将其拷贝到另外的存储空间单独存放。</p>
<p>使用以下命令来制作快照:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool snapshot foo</span><br><span class="line">Requested creating snapshot(s) <span class="keyword">for</span> \[foo\] <span class="keyword">with</span> snapshot name \[<span class="number">1450876735125</span>\]</span><br><span class="line">Snapshot directory: <span class="number">1450876735125</span></span><br></pre></td></tr></table></figure>

<p>foo这里是keyspace的名字，如果不指定keyspace则默认制作所有keyspaces的快照。</p>
<p>应为只是创建硬链接，因此快照速度飞快，无论节点有多大的容量，但是拷贝快照到另外的机器另当别论。</p>
<p>可以看到table_name-UUID/snapshots目录下多了一个以快照名命名的目录1450876735125，其内容即为方才制作的快照。</p>
<p>之后将快照归档，然后删除掉快照目录即可。</p>
<p><strong>删除快照</strong></p>
<p>快照会阻止删除已经无用的数据文件，因此保留快照会占用额外的存储空间。</p>
<p>删除所有的快照：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool clearsnapshot</span><br><span class="line">Requested clearing snapshot(s) <span class="keyword">for</span> \[all keyspaces\]</span><br></pre></td></tr></table></figure>
<p>或者单独删除某个keyspace的所有快照:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool clearsnapshot foo</span><br><span class="line">Requested clearing snapshot(s) <span class="keyword">for</span> \[foo\]</span><br></pre></td></tr></table></figure>

<p><strong>增量备份</strong></p>
<p>Cassandra支持增量备份，但默认配置没有打开。需要在cassanda.yaml文件中将incremental_backups设置为true以打开增量备份。<br>打开增量备份后，Cassandra会将每一个写入磁盘的SSTable制作一个硬链接写入data_directory_location/keyspace_name/table_name-UUID/backups目录下。</p>
<p>这样快照加上增量备份就可以提供一个可靠活的备份机制。</p>
<p>但是有一点儿需要注意，增量备份目录/backups下的文件Cassandra并不会自动删除，移除这些硬链接是用户的责任。因此应该在制作快照之前删除掉backups目录下的所有文件。</p>
<p><strong>其实,增量备份并不依赖于快照。</strong></p>
<p><strong>快照恢复</strong></p>
<p>恢复快照，需要表的所有快照文件以及可能有的增量备份文件。<br>在恢复快照之前应该先truncate表。如果在删除某些数据前制作快照，然后在删除后没有truncate表的情况下恢复数据，那些删除的数据并不会恢复回来。因为cassandra删除数据时并不会真正删除原始的数据，而是生成一个带有墓碑标志的一样的行来标记删除了某行，原始行和标记删除行存在于不同的SSTable中。因此恢复原始的数据，并不能去掉数据的删除标记，从来数据看起来仍然是被删除掉的。</p>
<p>快照恢复时需要表的schema已经存在，因此快照恢复之前需要重建表的schema。</p>
<p>快照恢复有多种方法：</p>
<ul>
<li>  使用sstableloader</li>
<li>  拷贝所有的快照文件及增量备份文件到data_directory_location/keyspace/table_name-UUID目录下，然后通过JConsole调用column family MBean 中的JMX方法loadNewSSTables()，或者调用nodetool refresh命令。</li>
<li>  重启节点的方式<br>如果恢复一个节点，需要关闭该节点，如果要恢复整个集群，则需要关闭集群内所有的节点。</li>
</ul>
<ol>
<li> 关闭节点</li>
<li> 删除commitlog目录下的所有文件<br>debian包安装方式，commitlog所在目录为<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/<span class="keyword">var</span>/lib/cassandra/commitlog</span><br></pre></td></tr></table></figure></li>
<li> 删除*.db文件<br>删除data_directory_location/keyspace_name/table_name-UUID目录下的所有*.db文件</li>
<li> 拷贝最新快照及增量备份文件<br>将需要恢复的快照文件拷贝到data_directory/keyspace_name/table_name-UUID目录</li>
<li> 拷贝增量备份文件<br>如果有增量备份文件，同样拷贝到data_directory/keyspace_name/table_name-UUID目录</li>
<li> 重启节点</li>
<li> 运行nodetool repair</li>
</ol>
<p><strong>快照恢复到新集群</strong></p>
<p>假设需要从三个节点的集群(256 tokens)拷贝SSTable快照数据文件，然后将其恢复到一个新创建的三节点集群(256 tokens)上，新集群节点的token范围必须手动指定以与原始集群相匹配。</p>
<p>恢复过程：</p>
<ol>
<li> 获取节点tokens<br>从原始集群中的每个节点上执行如下命令，获取其负责的tokens<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool ring grep ip_address_of_node awk <span class="string">&#x27;&#123;print $NF &quot;,&quot;&#125;&#x27;</span> xargs</span><br></pre></td></tr></table></figure></li>
<li> 配置新集群节点<br>新集群每个节点的cassandra.ymal文件中，initial_token参数分别设置为上一步获取的tokens。新集群节点要使用与旧集群节点相同的num_tokens参数，同时新旧集群节点的其他参数也要相匹配。</li>
<li> 清除新集群节点的system数据<br>新集群每个节点执行:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/cassandra/data/system<span class="comment">/*</span></span><br></pre></td></tr></table></figure></li>
<li> 拷贝节点数据<br>将旧集群节点的快照数据拷贝到新集群节点的相同的数据目录下,三个节点分别一一对应进行。</li>
<li> 启动新集群<br>依次分别启动新集群的节点。</li>
</ol>
<p>References:<br>[1]<a href="https://docs.datastax.com/en/archived/cassandra/2.2/cassandra/tools/toolsSnapShot.html">cassandra 2.2 document</a><br>[2]<a href="https://docs.datastax.com/en/ddac/doc/datastax_enterprise/operations/opsSnapshotRestoreNewCluster.html">Restoring a snapshot into a new cluster</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>cassandra数据结构</title>
    <url>/2015/09/04/cassandra-structure/</url>
    <content><![CDATA[<a id="more"></a>
<p>cassandra是键值对NoSQL数据库，其数据表结构是这样组织的:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">keyspace:&#123;</span><br><span class="line"> column_family:&#123;</span><br><span class="line"> column_family_key:&#123;<span class="attr">column_key</span>:column_value, <span class="attr">column_key</span>:column_value, ...&#125;,</span><br><span class="line"> column_family_key:&#123;<span class="attr">column_key</span>:column_value, <span class="attr">column_key</span>:column_value, ...&#125;,</span><br><span class="line"> ...</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以这样来访问列：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">keyspace.column_family\[column_family_key\]\[column_key\] = column_value;</span><br></pre></td></tr></table></figure>

<p>可以将其结构理解为map:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Map</span>&lt;RowKey, SortedMap&lt;ColumnKey, ColumnValue&gt;&gt;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://yikebocai.com/2014/06/cassandra-principle/">Cassandra原理介绍</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Cassandra上传大文件失败</title>
    <url>/2015/06/05/cassandra-uplaod-large-file-failure/</url>
    <content><![CDATA[<a id="more"></a>
<p>上传大文件到Cassandra时失败，/var/log/cassandra/system.log中有如下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">WARN \[SharedPool-Worker-<span class="number">2</span>\] <span class="number">2015</span>-<span class="number">05</span>-<span class="number">26</span> <span class="number">10</span>:<span class="number">29</span>:<span class="number">56</span>,<span class="number">900</span> AbstractTracingAwareExecutorService.java:<span class="number">169</span> - Uncaught exception on thread Thread\[SharedPool-Worker-<span class="number">2</span>,<span class="number">5</span>,main\]: &#123;&#125;</span><br><span class="line">java.lang.RuntimeException: java.lang.IllegalArgumentException: Mutation <span class="keyword">of</span> <span class="number">25802415</span> bytes is too large <span class="keyword">for</span> the maxiumum size <span class="keyword">of</span> <span class="number">16777216</span></span><br><span class="line"> at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:<span class="number">2219</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">471</span>) ~\[na:<span class="number">1.7</span><span class="number">.0_79</span>\]</span><br><span class="line"> at org.apache.cassandra.concurrent.AbstractTracingAwareExecutorService$FutureTask.run(AbstractTracingAwareExecutorService.java:<span class="number">164</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:<span class="number">105</span>) \[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>) \[na:<span class="number">1.7</span><span class="number">.0_79</span>\]</span><br><span class="line">Caused by: java.lang.IllegalArgumentException: Mutation <span class="keyword">of</span> <span class="number">25802415</span> bytes is too large <span class="keyword">for</span> the maxiumum size <span class="keyword">of</span> <span class="number">16777216</span></span><br><span class="line"> at org.apache.cassandra.db.commitlog.CommitLog.add(CommitLog.java:<span class="number">221</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:<span class="number">368</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at org.apache.cassandra.db.Keyspace.apply(Keyspace.java:<span class="number">348</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at org.apache.cassandra.db.Mutation.apply(Mutation.java:<span class="number">214</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at org.apache.cassandra.service.StorageProxy$7.runMayThrow(StorageProxy.java:<span class="number">1036</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> at org.apache.cassandra.service.StorageProxy$LocalMutationRunnable.run(StorageProxy.java:<span class="number">2215</span>) ~\[apache-cassandra-<span class="number">2.1</span><span class="number">.5</span>.jar:<span class="number">2.1</span><span class="number">.5</span>\]</span><br><span class="line"> ... <span class="number">4</span> common frames omitted</span><br></pre></td></tr></table></figure>

<p>这是因为cassandra.yaml配置文件中默认配置的单个提交日志文件的大小为32MB,而Cassandra允许的最大写尺寸是其一半，也就是16MB,亦即是上述错误中提示的16777216</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">commitlog_segment_size_in_mb: <span class="number">32</span></span><br></pre></td></tr></table></figure>

<p>Cassandra并不是为大文件设计的，所以最好适当的限制一下写尺寸，或者上传文件的大小，而不是调整系统参数。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>ceph cluster benchmark</title>
    <url>/2019/11/14/ceph-cluster-benchmark/</url>
    <content><![CDATA[<a id="more"></a>
<p>创建测试使用的pool</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd pool create testbench <span class="number">32</span> <span class="number">32</span></span><br></pre></td></tr></table></figure>

<p>写测试</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rados bench -p testbench <span class="number">10</span> write --no-cleanup</span><br><span class="line">hints = <span class="number">1</span></span><br><span class="line">Maintaining <span class="number">16</span> concurrent writes <span class="keyword">of</span> <span class="number">4194304</span> bytes to objects <span class="keyword">of</span> size <span class="number">4194304</span> <span class="keyword">for</span> up to <span class="number">10</span> seconds or <span class="number">0</span> objects</span><br><span class="line"><span class="built_in">Object</span> prefix: benchmark_data_work_17785</span><br><span class="line"> sec Cur ops started finished avg MB/s cur MB/s last lat(s) avg lat(s)</span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> - <span class="number">0</span></span><br><span class="line"> <span class="number">1</span> <span class="number">16</span> <span class="number">18</span> <span class="number">2</span> <span class="number">7.99976</span> <span class="number">8</span> <span class="number">0.743612</span> <span class="number">0.641529</span></span><br><span class="line"> <span class="number">2</span> <span class="number">16</span> <span class="number">30</span> <span class="number">14</span> <span class="number">27.9973</span> <span class="number">48</span> <span class="number">1.85864</span> <span class="number">1.29122</span></span><br><span class="line"> <span class="number">3</span> <span class="number">16</span> <span class="number">42</span> <span class="number">26</span> <span class="number">34.663</span> <span class="number">48</span> <span class="number">1.28555</span> <span class="number">1.39395</span></span><br><span class="line"> <span class="number">4</span> <span class="number">16</span> <span class="number">55</span> <span class="number">39</span> <span class="number">38.9956</span> <span class="number">52</span> <span class="number">1.32261</span> <span class="number">1.43965</span></span><br><span class="line"> <span class="number">5</span> <span class="number">16</span> <span class="number">58</span> <span class="number">42</span> <span class="number">33.5958</span> <span class="number">12</span> <span class="number">1.53666</span> <span class="number">1.44482</span></span><br><span class="line"> <span class="number">6</span> <span class="number">16</span> <span class="number">68</span> <span class="number">52</span> <span class="number">34.662</span> <span class="number">40</span> <span class="number">2.08014</span> <span class="number">1.50223</span></span><br><span class="line"> <span class="number">7</span> <span class="number">16</span> <span class="number">84</span> <span class="number">68</span> <span class="number">38.8516</span> <span class="number">64</span> <span class="number">0.823587</span> <span class="number">1.5045</span></span><br><span class="line"> <span class="number">8</span> <span class="number">16</span> <span class="number">96</span> <span class="number">80</span> <span class="number">39.9944</span> <span class="number">48</span> <span class="number">0.899492</span> <span class="number">1.44845</span></span><br><span class="line"> <span class="number">9</span> <span class="number">16</span> <span class="number">114</span> <span class="number">98</span> <span class="number">43.5496</span> <span class="number">72</span> <span class="number">0.633734</span> <span class="number">1.40136</span></span><br><span class="line"> <span class="number">10</span> <span class="number">16</span> <span class="number">123</span> <span class="number">107</span> <span class="number">42.7941</span> <span class="number">36</span> <span class="number">0.856593</span> <span class="number">1.3861</span></span><br><span class="line">Total time run: <span class="number">10.6523</span></span><br><span class="line">Total writes made: <span class="number">124</span></span><br><span class="line">Write size: <span class="number">4194304</span></span><br><span class="line"><span class="built_in">Object</span> size: <span class="number">4194304</span></span><br><span class="line">Bandwidth (MB/sec): <span class="number">46.5625</span></span><br><span class="line">Stddev Bandwidth: <span class="number">20.2254</span></span><br><span class="line">Max bandwidth (MB/sec): <span class="number">72</span></span><br><span class="line">Min bandwidth (MB/sec): <span class="number">8</span></span><br><span class="line">Average IOPS: <span class="number">11</span></span><br><span class="line">Stddev IOPS: <span class="number">5.05635</span></span><br><span class="line">Max IOPS: <span class="number">18</span></span><br><span class="line">Min IOPS: <span class="number">2</span></span><br><span class="line">Average Latency(s): <span class="number">1.3707</span></span><br><span class="line">Stddev Latency(s): <span class="number">0.472979</span></span><br><span class="line">Max latency(s): <span class="number">2.64427</span></span><br><span class="line">Min latency(s): <span class="number">0.539447</span></span><br></pre></td></tr></table></figure>

<p>顺序读测试</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rados bench -p testbench <span class="number">10</span> seq</span><br><span class="line">hints = <span class="number">1</span></span><br><span class="line"> sec Cur ops started finished avg MB/s cur MB/s last lat(s) avg lat(s)</span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> - <span class="number">0</span></span><br><span class="line"> <span class="number">1</span> <span class="number">16</span> <span class="number">42</span> <span class="number">26</span> <span class="number">103.976</span> <span class="number">104</span> <span class="number">0.588145</span> <span class="number">0.431675</span></span><br><span class="line"> <span class="number">2</span> <span class="number">16</span> <span class="number">69</span> <span class="number">53</span> <span class="number">105.983</span> <span class="number">108</span> <span class="number">0.593612</span> <span class="number">0.500811</span></span><br><span class="line"> <span class="number">3</span> <span class="number">16</span> <span class="number">98</span> <span class="number">82</span> <span class="number">109.319</span> <span class="number">116</span> <span class="number">0.555486</span> <span class="number">0.529656</span></span><br><span class="line"> <span class="number">4</span> <span class="number">15</span> <span class="number">124</span> <span class="number">109</span> <span class="number">108.986</span> <span class="number">108</span> <span class="number">0.408214</span> <span class="number">0.531251</span></span><br><span class="line">Total time run: <span class="number">4.45077</span></span><br><span class="line">Total reads made: <span class="number">124</span></span><br><span class="line">Read size: <span class="number">4194304</span></span><br><span class="line"><span class="built_in">Object</span> size: <span class="number">4194304</span></span><br><span class="line">Bandwidth (MB/sec): <span class="number">111.441</span></span><br><span class="line">Average IOPS: <span class="number">27</span></span><br><span class="line">Stddev IOPS: <span class="number">1.25831</span></span><br><span class="line">Max IOPS: <span class="number">29</span></span><br><span class="line">Min IOPS: <span class="number">26</span></span><br><span class="line">Average Latency(s): <span class="number">0.567093</span></span><br><span class="line">Max latency(s): <span class="number">1.16315</span></span><br><span class="line">Min latency(s): <span class="number">0.062019</span></span><br></pre></td></tr></table></figure>

<p>随机读测试</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rados bench -p testbench <span class="number">10</span> rand</span><br><span class="line">hints = <span class="number">1</span></span><br><span class="line"> sec Cur ops started finished avg MB/s cur MB/s last lat(s) avg lat(s)</span><br><span class="line"> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span> - <span class="number">0</span></span><br><span class="line"> <span class="number">1</span> <span class="number">16</span> <span class="number">43</span> <span class="number">27</span> <span class="number">107.978</span> <span class="number">108</span> <span class="number">0.548233</span> <span class="number">0.400351</span></span><br><span class="line"> <span class="number">2</span> <span class="number">16</span> <span class="number">70</span> <span class="number">54</span> <span class="number">107.985</span> <span class="number">108</span> <span class="number">0.507102</span> <span class="number">0.467039</span></span><br><span class="line"> <span class="number">3</span> <span class="number">16</span> <span class="number">99</span> <span class="number">83</span> <span class="number">110.653</span> <span class="number">116</span> <span class="number">0.66861</span> <span class="number">0.518288</span></span><br><span class="line"> <span class="number">4</span> <span class="number">16</span> <span class="number">128</span> <span class="number">112</span> <span class="number">111.987</span> <span class="number">116</span> <span class="number">0.821184</span> <span class="number">0.518217</span></span><br><span class="line"> <span class="number">5</span> <span class="number">16</span> <span class="number">155</span> <span class="number">139</span> <span class="number">111.187</span> <span class="number">108</span> <span class="number">0.71247</span> <span class="number">0.532804</span></span><br><span class="line"> <span class="number">6</span> <span class="number">16</span> <span class="number">183</span> <span class="number">167</span> <span class="number">111.32</span> <span class="number">112</span> <span class="number">0.698042</span> <span class="number">0.541571</span></span><br><span class="line"> <span class="number">7</span> <span class="number">16</span> <span class="number">211</span> <span class="number">195</span> <span class="number">111.416</span> <span class="number">112</span> <span class="number">0.137</span> <span class="number">0.545219</span></span><br><span class="line"> <span class="number">8</span> <span class="number">16</span> <span class="number">239</span> <span class="number">223</span> <span class="number">111.488</span> <span class="number">112</span> <span class="number">0.797219</span> <span class="number">0.549091</span></span><br><span class="line"> <span class="number">9</span> <span class="number">16</span> <span class="number">267</span> <span class="number">251</span> <span class="number">111.543</span> <span class="number">112</span> <span class="number">0.249707</span> <span class="number">0.547871</span></span><br><span class="line"> <span class="number">10</span> <span class="number">16</span> <span class="number">296</span> <span class="number">280</span> <span class="number">111.988</span> <span class="number">116</span> <span class="number">0.577749</span> <span class="number">0.555318</span></span><br><span class="line">Total time run: <span class="number">10.5902</span></span><br><span class="line">Total reads made: <span class="number">297</span></span><br><span class="line">Read size: <span class="number">4194304</span></span><br><span class="line"><span class="built_in">Object</span> size: <span class="number">4194304</span></span><br><span class="line">Bandwidth (MB/sec): <span class="number">112.179</span></span><br><span class="line">Average IOPS: <span class="number">28</span></span><br><span class="line">Stddev IOPS: <span class="number">0.816497</span></span><br><span class="line">Max IOPS: <span class="number">29</span></span><br><span class="line">Min IOPS: <span class="number">27</span></span><br><span class="line">Average Latency(s): <span class="number">0.565831</span></span><br><span class="line">Max latency(s): <span class="number">1.20987</span></span><br><span class="line">Min latency(s): <span class="number">0.0559923</span></span><br></pre></td></tr></table></figure>

<p>清除测试数据</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rados -p testbench cleanup</span><br><span class="line">Removed <span class="number">124</span> objects</span><br></pre></td></tr></table></figure>


<p>References:<br>[1]<a href="https://access.redhat.com/documentation/en-us/red_hat_ceph_storage/1.3/html/administration_guide/benchmarking_performance">CHAPTER 9. BENCHMARKING PERFORMANCE</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph集群部署-monitors配置</title>
    <url>/2019/10/16/ceph-cluster-deploy-monitors/</url>
    <content><![CDATA[<a id="more"></a>
<p>ceph官方仓库尚未提供debian 10 buster版本的ceph nautilus，而debian官方仓库里也只有ceph 12版本，可以使用三方仓库在debian buster上安装ceph nautilus</p>
<p>proxmox仓库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ echo <span class="string">&#x27;deb \[arch=amd64\] http://download.proxmox.com/debian/ceph-nautilus buster main&#x27;</span> sudo tee /etc/apt/sources.list.d/proxmox-ceph.list</span><br><span class="line">$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 7BF2812E8A6E88E0</span><br><span class="line">$ sudo apt update &amp;&amp; sudo apt install ceph</span><br></pre></td></tr></table></figure>

<p>croit.io仓库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ curl https:<span class="comment">//mirror.croit.io/keys/release.asc sudo apt-key add -</span></span><br><span class="line">$ echo <span class="string">&#x27;deb https://mirror.croit.io/debian-nautilus/ buster main&#x27;</span> sudo tee /etc/apt/sources.list.d/croit-ceph.list</span><br><span class="line">$ sudo apt update &amp;&amp; sudo apt install ceph</span><br></pre></td></tr></table></figure>

<p><strong>Updated(2020/02/01):</strong> 现在可以使用buster-backports仓库来安装ceph nautilus</p>
<p>ceph集群安装的第一步是monitor自举</p>
<p><strong>一、monitor bootstrapping</strong><br>1、添加配置文件/etc/ceph/ceph.conf<br>这里集群的名字使用默认的ceph,ceph.conf文件名中的基本名ceph也是集群名。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[<span class="built_in">global</span>\]</span><br><span class="line"># 使用uuidgen生成,debian请安装uuid-runtime包</span><br><span class="line">fsid = 0238426D-78D6-48CD-AF64-B6A8407996C6</span><br><span class="line"># 使用主机名,可以用hostname -s命令获取</span><br><span class="line">mon initial members = node8</span><br><span class="line"># ip地址,支持messenger v1和v2</span><br><span class="line">mon_host = <span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span></span><br><span class="line">#mon_host = v2:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">3300</span>/<span class="number">0</span>,<span class="attr">v1</span>:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">6789</span>/<span class="number">0</span></span><br><span class="line"># public network可以指定逗号分割的多个子网</span><br><span class="line">public network = <span class="number">192.168</span><span class="number">.3</span><span class="number">.0</span>/<span class="number">24</span></span><br><span class="line"># 使用cephx认证</span><br><span class="line">auth cluster required = cephx</span><br><span class="line">auth service required = cephx</span><br><span class="line">auth client required = cephx</span><br><span class="line">osd journal size = <span class="number">1024</span></span><br><span class="line"># 副本策略,副本数量</span><br><span class="line">osd pool <span class="keyword">default</span> size = <span class="number">3</span></span><br><span class="line"># 降级状态最小副本数量,低于此数量会失败</span><br><span class="line">osd pool <span class="keyword">default</span> min size = <span class="number">2</span></span><br><span class="line"># 默认placement group数量</span><br><span class="line">osd pool <span class="keyword">default</span> pg num = <span class="number">333</span></span><br><span class="line"># 默认placement groups for placement数量</span><br><span class="line">osd pool <span class="keyword">default</span> pgp num = <span class="number">333</span></span><br><span class="line">osd crush chooseleaf type = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>2、创建集群keyring,生成monitor密钥</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon <span class="string">&#x27;allow *&#x27;</span></span><br></pre></td></tr></table></figure>

<p>3、创建管理keyring,生成client.admin用户并加入keyring</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --cap mon <span class="string">&#x27;allow *&#x27;</span> --cap osd <span class="string">&#x27;allow *&#x27;</span> --cap mds <span class="string">&#x27;allow *&#x27;</span> --cap mgr <span class="string">&#x27;allow *&#x27;</span></span><br></pre></td></tr></table></figure>

<p>4、创建bootstrap-osd keyring,生成client.bootstrap-osd用户并加入keyring</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-authtool --create-keyring /<span class="keyword">var</span>/lib/ceph/bootstrap-osd/ceph.keyring --gen-key -n client.bootstrap-osd --cap mon <span class="string">&#x27;profile bootstrap-osd&#x27;</span> --cap mgr <span class="string">&#x27;allow r&#x27;</span></span><br></pre></td></tr></table></figure>

<p>5、将生成的key添加到ceph.mon.keyring</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-authtool /tmp/ceph.mon.keyring --<span class="keyword">import</span>-keyring /etc/ceph/ceph.client.admin.keyring</span><br><span class="line">$ sudo ceph-authtool /tmp/ceph.mon.keyring --<span class="keyword">import</span>-keyring /<span class="keyword">var</span>/lib/ceph/bootstrap-osd/ceph.keyring</span><br></pre></td></tr></table></figure>

<p>6、生成monitor map</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ monmaptool --create --add node8 <span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span> --fsid 0238426D-78D6-48CD-AF64-B6A8407996C6 /tmp/monmap</span><br></pre></td></tr></table></figure>
<p>注意此处指定的节点名称、ip地址和fsid要与/etc/ceph/ceph.conf中指定的一致,ip地址还可以使用新的格式指定v2:192.168.3.8:3300/0,v1:192.168.3.8:6789/0</p>
<p>map文件是二进制格式的，可以这样查看生成的map内容</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ monmaptool --print /tmp/monmap</span><br><span class="line">monmaptool: monmap file /tmp/monmap</span><br><span class="line">epoch <span class="number">0</span></span><br><span class="line">fsid 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line">last_changed <span class="number">2019</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">20</span>:<span class="number">24</span>:<span class="number">58.156493</span></span><br><span class="line">created <span class="number">2019</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">20</span>:<span class="number">24</span>:<span class="number">58.156493</span></span><br><span class="line">min_mon_release <span class="number">0</span> (unknown)</span><br><span class="line"><span class="number">0</span>: v1:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">6789</span>/<span class="number">0</span> mon.node8</span><br></pre></td></tr></table></figure>

<p>7、创建monitor数据目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo -u ceph mkdir /<span class="keyword">var</span>/lib/ceph/mon/ceph-node8</span><br></pre></td></tr></table></figure>
<p>目录名字格式为{cluster-name}-{hostname}</p>
<p>8、修改ceph.mon.keyring访问权限</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ chmod o+r /tmp/ceph.mon.keyring</span><br></pre></td></tr></table></figure>
<p>不然会因为ceph用户无法读取/tmp/ceph.mon.keyring而抛出如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">2019</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">19</span>:<span class="number">43</span>:<span class="number">54.149</span> 7eff2ff1f440 -<span class="number">1</span> mon.node8@-<span class="number">1</span>(???) e0 unable to find a keyring file on /tmp/ceph.mon.keyring: (<span class="number">13</span>) Permission denied</span><br><span class="line"><span class="number">2019</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">19</span>:<span class="number">43</span>:<span class="number">54.149</span> 7eff2ff1f440 -<span class="number">1</span> ceph-mon: error creating monfs: (<span class="number">2</span>) No such file or directory</span><br></pre></td></tr></table></figure>

<p>9、初始化monitor数据结构</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo -u ceph ceph-mon --mkfs -i node8 --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring</span><br></pre></td></tr></table></figure>

<p>10、启动ceph monitor</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//$ sudo ln -sf /lib/systemd/system/ceph-mon@.service /etc/systemd/system/multi-user.target.wants/ceph-mon@node8.service</span></span><br><span class="line"><span class="comment">//$ sudo systemctl daemon-reload</span></span><br><span class="line">$ sudo systemctl enable ceph-mon@node8.service</span><br><span class="line">$ sudo systemctl start ceph-mon@node8.service</span><br></pre></td></tr></table></figure>
<p>生成monitor实例自启动systemd服务文件并开启服务</p>
<p>11、查看集群状态</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph -s</span><br><span class="line"> cluster:</span><br><span class="line"> id: 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line"> health: HEALTH_WARN</span><br><span class="line"> <span class="number">1</span> monitors have not enabled msgr2</span><br><span class="line"> </span><br><span class="line"> services:</span><br><span class="line"> mon: <span class="number">1</span> daemons, quorum node8 (age 12m)</span><br><span class="line"> mgr: no daemons active</span><br><span class="line"> osd: <span class="number">0</span> osds: <span class="number">0</span> up, <span class="number">0</span> <span class="keyword">in</span></span><br><span class="line"> </span><br><span class="line"> data:</span><br><span class="line"> pools: <span class="number">0</span> pools, <span class="number">0</span> pgs</span><br><span class="line"> objects: <span class="number">0</span> objects, <span class="number">0</span> B</span><br><span class="line"> usage: <span class="number">0</span> B used, <span class="number">0</span> B / <span class="number">0</span> B avail</span><br><span class="line"> pgs: </span><br></pre></td></tr></table></figure>

<p>12、启用messenger v2协议</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph mon enable-msgr2</span><br><span class="line">$ sudo ceph -s</span><br><span class="line"> cluster:</span><br><span class="line"> id: 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line"> health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line"> services:</span><br><span class="line"> mon: <span class="number">1</span> daemons, quorum node8 (age 67m)</span><br><span class="line"> mgr: no daemons active</span><br><span class="line"> osd: <span class="number">0</span> osds: <span class="number">0</span> up, <span class="number">0</span> <span class="keyword">in</span></span><br><span class="line"> </span><br><span class="line"> data:</span><br><span class="line"> pools: <span class="number">0</span> pools, <span class="number">0</span> pgs</span><br><span class="line"> objects: <span class="number">0</span> objects, <span class="number">0</span> B</span><br><span class="line"> usage: <span class="number">0</span> B used, <span class="number">0</span> B / <span class="number">0</span> B avail</span><br><span class="line"> pgs: </span><br></pre></td></tr></table></figure>
<p>集群健康状态成为HEALTH_OK<br>dump集群配置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph mon dump</span><br><span class="line">dumped monmap epoch <span class="number">2</span></span><br><span class="line">epoch <span class="number">2</span></span><br><span class="line">fsid 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line">last_changed <span class="number">2019</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">20</span>:<span class="number">15</span>:<span class="number">02</span><span class="number">.687549</span></span><br><span class="line">created <span class="number">2019</span>-<span class="number">10</span>-<span class="number">28</span> <span class="number">19</span>:<span class="number">51</span>:<span class="number">04</span><span class="number">.486571</span></span><br><span class="line">min_mon_release <span class="number">14</span> (nautilus)</span><br><span class="line"><span class="number">0</span>: \[v2:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">3300</span>/<span class="number">0</span>,<span class="attr">v1</span>:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">6789</span>/<span class="number">0</span>\] mon.node8</span><br></pre></td></tr></table></figure>

<p><strong>二、添加其他monitor</strong></p>
<p>一个monitor可以运行ceph集群，但是在生产环境推荐至少要运行三个monitor实例或以上，而且数量最好是奇数，这是因为容错时需要大多数实例达成一致的原因。monitor可以与OSD实例运行在一台物理机器上，但推荐是分开部署。</p>
<p>以下操作皆是在将要添加的monitor机器上执行</p>
<p>1、拷贝初始monitor配置文件</p>
<p>将集群第一个monitor的配置文件目录/etc/ceph整个拷贝到新monitor相同路径，注意保持文件属性不变。之后，新monitor节点虽然尚未初始化，但已经可以访问ceph集群。</p>
<p>2、创建目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u ceph mkdir /<span class="keyword">var</span>/lib/ceph/mon/ceph-node6</span><br></pre></td></tr></table></figure>

<p>3、获取monitor keyring</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph auth get mon. -o /tmp/ceph.mon.keyring</span><br><span class="line">exported keyring <span class="keyword">for</span> mon.</span><br></pre></td></tr></table></figure>
<p>注意检查/tmp/ceph.mon.keyring文件的访问权限，确保ceph用户可以读取。</p>
<p>4、获取集群monitor map</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph mon getmap -o /tmp/ceph.mon.map</span><br><span class="line">got monmap epoch <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>5、初始化新monitor</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u ceph ceph-mon --mkfs -i node6 --monmap /tmp/ceph.mon.map --keyring /tmp/ceph.mon.keyring</span><br><span class="line">$ sudo systemctl enable ceph-mon@node6.service</span><br><span class="line">$ sudo systemctl start ceph-mon@node6.service</span><br><span class="line">$ sudo ceph -s</span><br><span class="line"> cluster:</span><br><span class="line"> id: 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line"> health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line"> services:</span><br><span class="line"> mon: <span class="number">2</span> daemons, quorum node8,node6 (age <span class="number">0.</span>16939s)</span><br><span class="line"> mgr: no daemons active</span><br><span class="line"> osd: <span class="number">0</span> osds: <span class="number">0</span> up, <span class="number">0</span> <span class="keyword">in</span></span><br><span class="line"> </span><br><span class="line"> data:</span><br><span class="line"> pools: <span class="number">0</span> pools, <span class="number">0</span> pgs</span><br><span class="line"> objects: <span class="number">0</span> objects, <span class="number">0</span> B</span><br><span class="line"> usage: <span class="number">0</span> B used, <span class="number">0</span> B / <span class="number">0</span> B avail</span><br><span class="line"> pgs: </span><br></pre></td></tr></table></figure>

<p>可以看到集群已经有了两个monitor<br>查看集群monitor状态信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph mon stat</span><br><span class="line">e3: <span class="number">2</span> mons at &#123;node6=\[v2:<span class="number">192.168</span><span class="number">.3</span><span class="number">.6</span>:<span class="number">3300</span>/<span class="number">0</span>,<span class="attr">v1</span>:<span class="number">192.168</span><span class="number">.3</span><span class="number">.6</span>:<span class="number">6789</span>/<span class="number">0</span>\],node8=\[v2:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">3300</span>/<span class="number">0</span>,<span class="attr">v1</span>:<span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="number">6789</span>/<span class="number">0</span>\]&#125;, election epoch <span class="number">26</span>, leader <span class="number">0</span> node8, quorum <span class="number">0</span>,<span class="number">1</span> node8,node6</span><br></pre></td></tr></table></figure>

<p>添加其他新monitor重复以上步骤。</p>
<p>References:<br>[1]<a href="https://docs.ceph.com/docs/master/">Ceph Docs</a><br>[2]<a href="https://croit.io/2019/07/07/2019-07-07-debian-mirror">Debian stable and Ceph are great</a><br>[3]<a href="https://docs.ceph.com/docs/master/install/manual-deployment/">MANUAL DEPLOYMENT</a><br>[4]<a href="https://www.cnblogs.com/netant-cg/p/10696205.html">ceph nautilus版本手动安装</a><br>[5]<a href="https://docs.ceph.com/docs/master/mgr/administrator/#mgr-administrator-guide">CEPH-MGR ADMINISTRATOR’S GUIDE</a><br>[6]<a href="https://docs.ceph.com/docs/mimic/rados/configuration/network-config-ref/">NETWORK CONFIGURATION REFERENCE</a><br>[7]<a href="https://docs.ceph.com/docs/master/rados/operations/add-or-rm-mons/">ADDING/REMOVING MONITORS</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Ceph集群部署-mgr-osd-mds配置</title>
    <url>/2019/10/31/ceph-deploy-mgr-osd-mds/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>一、添加manager</strong></p>
<p>通常每一个运行monitor的机器上同时运行一个manager,以获取同样的可用性，但是manager不涉及到选举，运行于primary/standby模式。</p>
<p>1、创建mgr认证keyring</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph auth get-or-create mgr.node6 mon <span class="string">&#x27;allow profile mgr&#x27;</span> osd <span class="string">&#x27;allow *&#x27;</span> mds <span class="string">&#x27;allow *&#x27;</span></span><br><span class="line">\[mgr.node6\]</span><br><span class="line">key = AQDAzLpdq7HzDRAAkRLSSkRO/1aLZU+87FcN5g==</span><br></pre></td></tr></table></figure>
<p>这里mgr的名字仍然选用主机名,也就是mgr.$(hostname -s)</p>
<p>2、创建mgr实例的目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo -u ceph mkdir /<span class="keyword">var</span>/lib/ceph/mgr/ceph-node6/</span><br></pre></td></tr></table></figure>

<p>3、导出mgr keyring到ngr实例目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph auth get mgr.node6 -o /<span class="keyword">var</span>/lib/ceph/mgr/ceph-node6/keyring</span><br><span class="line">exported keyring <span class="keyword">for</span> mgr.node6</span><br></pre></td></tr></table></figure>

<p>4、运行mgr实例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl enable ceph-mgr@node6.service</span><br><span class="line">$ sudo systemctl start ceph-mgr@node6.service</span><br><span class="line">$ sudo ceph -s</span><br><span class="line">cluster:</span><br><span class="line"> id: 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line"> health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line"> services:</span><br><span class="line"> mon: <span class="number">3</span> daemons, quorum node8,node6,node7 (age 11m)</span><br><span class="line"> mgr: node6(active, starting, since <span class="number">0.</span>109568s)</span><br><span class="line"> osd: <span class="number">0</span> osds: <span class="number">0</span> up, <span class="number">0</span> <span class="keyword">in</span></span><br><span class="line"> </span><br><span class="line"> data:</span><br><span class="line"> pools: <span class="number">0</span> pools, <span class="number">0</span> pgs</span><br><span class="line"> objects: <span class="number">0</span> objects, <span class="number">0</span> B</span><br><span class="line"> usage: <span class="number">0</span> B used, <span class="number">0</span> B / <span class="number">0</span> B avail</span><br><span class="line"> pgs: </span><br></pre></td></tr></table></figure>
<p>可以看到mgr活动实例启动了，重复以上步骤添加其他mgr实例。</p>
<p><strong>二、添加OSD</strong></p>
<p>OSD(Object Storage Device)是真正存储数据的组件，一般生产环境至少要部署3个OSD,参数文件/etc/ceph/ceph.conf中<code>osd pool default size = 3</code>设定为3，至少需要3个osd进程，集群才能达到active + clean状态。</p>
<p>OSD有几种后端存储，建议使用bluestore提高系统稳定性和效率，bluestore只能使用逻辑卷、磁盘或分区，注意初始化OSD时指定的逻辑卷、磁盘或者分区上的数据会全部被抹掉。一般建议OSD使用单独的机器部署，并且与OS分别使用不同的驱动器。</p>
<p>1、导出client.bootstrap-osd keyring<br>如果本地机器上没有此keyring,则需要先从集群导出到本地</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph auth get client.bootstrap-osd -o /<span class="keyword">var</span>/lib/ceph/bootstrap-osd/ceph.keyring</span><br></pre></td></tr></table></figure>

<p>2、创建OSD</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-volume lvm create --data /dev/sdb</span><br></pre></td></tr></table></figure>
<p>注意要使用正确的底层设备,lsblk可以查看系统块存储设备。<br>如果提示错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ceph-volume lvm create: error: GPT headers found, they must be removed on: <span class="regexp">/dev/</span>sdb</span><br><span class="line">...</span><br><span class="line">stderr: Device /dev/sdc excluded by a filter.</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>需要先清除掉分区表:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo partprobe -s /dev/sdb</span><br><span class="line">$ sudo dd <span class="keyword">if</span>=<span class="regexp">/dev/</span>zero <span class="keyword">of</span>=<span class="regexp">/dev/</span>sdb bs=<span class="number">512</span> count=<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><strong>注意：</strong>这些操作是破坏性的，一定要确认是在正确的块设备上进行操作。</p>
<p>3、运行OSD</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-volume lvm list</span><br><span class="line"></span><br><span class="line">====== osd<span class="number">.0</span> =======</span><br><span class="line"></span><br><span class="line"> \[block\] /dev/ceph-f67dd26c-f5d8-44ca-a9da-fe6b6fccec65/osd-block-bf952b83-7ffe-<span class="number">49e2</span>-bdd7-d2fd3faacafb</span><br><span class="line"></span><br><span class="line"> block device /dev/ceph-f67dd26c-f5d8-44ca-a9da-fe6b6fccec65/osd-block-bf952b83-7ffe-<span class="number">49e2</span>-bdd7-d2fd3faacafb</span><br><span class="line"> block uuid jYMJc5-jjUe-hgPk-Wlhk-yo9y-t6JF-r8SqNa</span><br><span class="line"> cephx lockbox secret </span><br><span class="line"> cluster fsid 0238426D-78D6-48CD-AF64-B6A8407996C6</span><br><span class="line"> cluster name ceph</span><br><span class="line"> crush device <span class="class"><span class="keyword">class</span> <span class="title">None</span></span></span><br><span class="line"><span class="class"> <span class="title">encrypted</span> 0</span></span><br><span class="line"><span class="class"> <span class="title">osd</span> <span class="title">fsid</span> <span class="title">bf952b83</span>-7<span class="title">ffe</span>-49<span class="title">e2</span>-<span class="title">bdd7</span>-<span class="title">d2fd3faacafb</span></span></span><br><span class="line"><span class="class"> <span class="title">osd</span> <span class="title">id</span> 0</span></span><br><span class="line"><span class="class"> <span class="title">type</span> <span class="title">block</span></span></span><br><span class="line"><span class="class"> <span class="title">vdo</span> 0</span></span><br><span class="line"><span class="class"> <span class="title">devices</span> /<span class="title">dev</span>/<span class="title">sdb</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">//<span class="title">sudo</span> <span class="title">systemctl</span> <span class="title">enable</span> <span class="title">ceph</span>-<span class="title">osd</span>@0.<span class="title">service</span></span></span><br><span class="line"><span class="class">//<span class="title">sudo</span> <span class="title">systemctl</span> <span class="title">start</span> <span class="title">ceph</span>-<span class="title">osd</span>@0.<span class="title">service</span></span></span><br></pre></td></tr></table></figure>
<p>先查找osd实例的名称，然后启用相应的实例服务,ceph-volume会自动创建相应的服务并启动它们。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph -s</span><br><span class="line"> cluster:</span><br><span class="line"> id: 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line"> health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line"> services:</span><br><span class="line"> mon: <span class="number">3</span> daemons, quorum node8,node6,node7 (age 37m)</span><br><span class="line"> mgr: node6(active, since 25m), <span class="attr">standbys</span>: node7, node8</span><br><span class="line"> osd: <span class="number">1</span> osds: <span class="number">1</span> up (since 85s), <span class="number">1</span> <span class="keyword">in</span> (since 85s)</span><br><span class="line"> </span><br><span class="line"> data:</span><br><span class="line"> pools: <span class="number">0</span> pools, <span class="number">0</span> pgs</span><br><span class="line"> objects: <span class="number">0</span> objects, <span class="number">0</span> B</span><br><span class="line"> usage: <span class="number">1.0</span> GiB used, <span class="number">6.0</span> GiB / <span class="number">7</span> GiB avail</span><br><span class="line"> pgs: </span><br></pre></td></tr></table></figure>
<p>可以看到运行了一个osd实例，重复以上步骤添加其他OSD实例。</p>
<p><strong>三、添加mds</strong><br>如果要使用CephFS文件系统才需要设置mds实例，对象存储和块设备存储无需mds实例。</p>
<p>1、创建mds实例目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u ceph mkdir -p /<span class="keyword">var</span>/lib/ceph/mds/ceph-node6</span><br></pre></td></tr></table></figure>
<p>目录格式为{cluster-name}-{id}，按照惯例这里id仍然取主机名$(hostname -s)</p>
<p>2、创建mds实例keyring</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u ceph ceph-authtool --create-keyring /<span class="keyword">var</span>/lib/ceph/mds/ceph-node6/keyring --gen-key -n mds.node6</span><br></pre></td></tr></table></figure>

<p>3、将mds实例keyring导入集群并设置caps权限</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph auth add mds.node6 osd <span class="string">&quot;allow rwx&quot;</span> mds <span class="string">&quot;allow&quot;</span> mon <span class="string">&quot;allow profile mds&quot;</span> -i /<span class="keyword">var</span>/lib/ceph/mds/ceph-node6/keyring</span><br><span class="line">added key <span class="keyword">for</span> mds.node6</span><br></pre></td></tr></table></figure>
<p>或者2,3步合并为一步：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph auth get-or-create mds.node6 mon <span class="string">&#x27;allow profile mds&#x27;</span> mgr <span class="string">&#x27;allow profile mds&#x27;</span> mds <span class="string">&#x27;allow *&#x27;</span> osd <span class="string">&#x27;allow *&#x27;</span> sudo -u ceph tee /<span class="keyword">var</span>/lib/ceph/mds/ceph-node6/keyring</span><br></pre></td></tr></table></figure>

<p>4、编辑/etc/ceph/ceph.conf添加mds实例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[mds.node6\]</span><br><span class="line">host = node6</span><br></pre></td></tr></table></figure>

<p>5、启动mds实例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl enable ceph-mds@node6</span><br><span class="line">$ sudo systemctl start ceph-mds@node6</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://docs.ceph.com/docs/master/mgr/administrator/#mgr-administrator-guide">CEPH-MGR ADMINISTRATOR’S GUIDE</a><br>[2]<a href="https://docs.ceph.com/docs/master//cephfs/add-remove-mds/">DEPLOYING METADATA SERVERS</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ceph集群移除osd,mon,mdr,mds节点</title>
    <url>/2019/11/14/ceph-remove-osds/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>移除osd节点</strong></p>
<p>查看当前osd状态</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd tree</span><br><span class="line">ID CLASS WEIGHT TYPE NAME STATUS REWEIGHT PRI-AFF </span><br><span class="line">-<span class="number">1</span> <span class="number">9.74405</span> root <span class="keyword">default</span> </span><br><span class="line">-<span class="number">9</span> <span class="number">0.95409</span> host bank1 </span><br><span class="line"> <span class="number">3</span> hdd <span class="number">0.95409</span> osd<span class="number">.3</span> up <span class="number">1.00000</span> <span class="number">1.00000</span> </span><br><span class="line">-<span class="number">3</span> <span class="number">5.99799</span> host vm01 </span><br><span class="line"> <span class="number">0</span> hdd <span class="number">5.99799</span> osd<span class="number">.0</span> up <span class="number">1.00000</span> <span class="number">1.00000</span> </span><br><span class="line">-<span class="number">5</span> <span class="number">1.81929</span> host vm02 </span><br><span class="line"> <span class="number">1</span> hdd <span class="number">1.81929</span> osd<span class="number">.1</span> up <span class="number">1.00000</span> <span class="number">1.00000</span> </span><br><span class="line">-<span class="number">7</span> <span class="number">0.97269</span> host web </span><br><span class="line"> <span class="number">2</span> hdd <span class="number">0.97269</span> osd<span class="number">.2</span> up <span class="number">1.00000</span> <span class="number">1.00000</span> </span><br></pre></td></tr></table></figure>

<p>将osd标记为out，准备踢出集群，{osd-num}为osd编号,比如osd.2</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd out &#123;osd-num&#125;</span><br></pre></td></tr></table></figure>

<p>集群会进行重新平衡和数据迁移，查看 </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph -w</span><br></pre></td></tr></table></figure>
<p><code>ceps -s</code>也可以查看进度，当完成时集群状态会重新回归到actice+clean状态<br>如果卡在active+clean+remapped或者active+remapped状态,先将osd回归集群</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd <span class="keyword">in</span> &#123;osd-num&#125;</span><br></pre></td></tr></table></figure>
<p>等集群恢复到active+clean状态后，执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd crush reweight osd.&#123;osd-num&#125; <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>等集群状态再次变成active+clean状态后，将osd标记为out,并停止ceph-osd服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd out &#123;osd-num&#125;</span><br><span class="line">$ sudo systemctl stop ceph-osd@<span class="number">2.</span>service</span><br></pre></td></tr></table></figure>

<p>移除osd</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph osd purge osd.&#123;osd-num&#125; --yes-i-really-mean-it</span><br><span class="line">purged osd<span class="number">.2</span></span><br></pre></td></tr></table></figure>

<p><strong>移除mon节点</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ceph mon remove &#123;mon-name&#125;</span><br></pre></td></tr></table></figure>

<p><strong>移除mgr节点</strong><br>在将要被移除的mgr节点上执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop ceph-mgr@&#123;mgr-name&#125;</span><br><span class="line">$ sudo systemctl disable ceph-mgr@&#123;mgr-name&#125;</span><br><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/ceph/mgr/ceph-&#123;mgr-name&#125;</span><br></pre></td></tr></table></figure>

<p><strong>移除mds节点</strong><br>在将要被移除的mds节点上执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop ceph-mds@&#123;mds-name&#125;</span><br><span class="line">$ sudo systemctl disable ceph-mds@&#123;mds-name&#125;</span><br><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/ceph/mds/ceph-&#123;mds-name&#125;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://docs.ceph.com/docs/master/rados/operations/add-or-rm-osds/">ADDING/REMOVING OSDS</a><br>[2]<a href="https://docs.ceph.com/docs/master/cephfs/add-remove-mds/">DEPLOYING METADATA SERVERS</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>CephFS文件系统NFS导出和挂载</title>
    <url>/2019/11/05/cephfs-nfs-export-mount/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>一、使用nfs-ganesha</strong></p>
<p>需要先创建cephfs,参考<a href="https://openwares.net/2019/10/31/cephfs-using/">使用CephFS文件系统</a></p>
<p><strong>安装</strong><br>在ceph集群的某个节点上安装nfs-ganesha-ceph</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install nfs-ganesha-ceph</span><br></pre></td></tr></table></figure>
<p>如果启动服务时出错:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Failed to restart nfs-ganesha.service: The name org.freedesktop.PolicyKit1 was not provided by any .service files</span><br></pre></td></tr></table></figure>
<p>安装policykit-1包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo apt install policykit-<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p><strong>配置</strong><br>/etc/ganesha/ganesha.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">NFS_CORE_PARAM</span><br><span class="line">&#123;</span><br><span class="line">Enable_NLM = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">Enable_RQUOTA = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">Protocols = <span class="number">4</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">NFSv4</span><br><span class="line">&#123;</span><br><span class="line">Delegations = active;;</span><br><span class="line"></span><br><span class="line">Minor_Versions = <span class="number">1</span>,<span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">CACHEINODE &#123;</span><br><span class="line">Dir_Chunk = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">NParts = <span class="number">1</span>;</span><br><span class="line">Cache_Size = <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">EXPORT</span><br><span class="line">&#123;</span><br><span class="line"># Unique export ID number for this export</span><br><span class="line">Export_ID=<span class="number">100</span>;</span><br><span class="line"></span><br><span class="line"># We&#x27;re only interested in NFSv4 in this configuration</span><br><span class="line">Protocols = <span class="number">4</span>;</span><br><span class="line"></span><br><span class="line"># NFSv4 does not allow UDP transport</span><br><span class="line">Transports = TCP;</span><br><span class="line"></span><br><span class="line">Path = /;</span><br><span class="line"> Pseudo = <span class="regexp">/cephfs/</span>;</span><br><span class="line"></span><br><span class="line"># We want to be able to read and write</span><br><span class="line">Access_Type = RW;</span><br><span class="line"></span><br><span class="line"># Time out attribute cache entries immediately</span><br><span class="line">Attr_Expiration_Time = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">Delegations = RW;</span><br><span class="line"></span><br><span class="line">Squash = no_root_squash;</span><br><span class="line"></span><br><span class="line">FSAL &#123;</span><br><span class="line"># FSAL_CEPH export</span><br><span class="line">Name = CEPH;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># Config block for FSAL_CEPH</span><br><span class="line">CEPH</span><br><span class="line">&#123;</span><br><span class="line"># Path to a ceph.conf file for this cluster.</span><br><span class="line"># Ceph_Conf = /etc/ceph/ceph.conf;</span><br><span class="line"></span><br><span class="line"># User file-creation mask. These bits will be masked off from the unix</span><br><span class="line"># permissions on newly-created inodes.</span><br><span class="line"># umask = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重启nfs-ganesha服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl restart nfs-ganesha</span><br></pre></td></tr></table></figure>

<p><strong>客户端挂载</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mount -t nfs4 -o nfsvers=<span class="number">4.2</span>,rw <span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="regexp">/ /m</span>nt/mycephfs</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mount -t nfs4 -o nfsvers=<span class="number">4.2</span>,rw <span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="regexp">/cephfs /m</span>nt/mycephfs</span><br></pre></td></tr></table></figure>
<p>/etc/fstab挂载项:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="regexp">/ /m</span>nt/mycephfs nfs4 nfsvers=<span class="number">4.2</span> <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p><strong>二、使用kernel driver/ceph-fuse和nfsd</strong></p>
<p>Ceph 提供了 kernel driver/ceph-fuse 来挂载和访问 CephFS。在 NFS 服务器上通过 kernel driver/ceph-fuse 挂载 CephFS 后，我们可以通过 nfsd 将其发布出去。</p>
<p>References:<br>[1]<a href="https://docs.ceph.com/docs/mimic/cephfs/nfs/">NFS</a><br>[2]<a href="https://amito.me/2019/Mount-CephFS-over-NFS/">将 Ceph 文件系统 CephFS 挂载为 NFS</a><br>[3]<a href="https://github.com/phdeniel/nfs-ganesha/wiki/nfsidmap">nfsidmap</a><br>[4]<a href="https://jtlayton.wordpress.com/2018/12/10/deploying-an-active-active-nfs-cluster-over-cephfs/">Deploying an Active/Active NFS Cluster over CephFS</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用CephFS文件系统</title>
    <url>/2019/10/31/cephfs-using/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>创建池</strong><br>ceph文件系统需要驻留在pool上，至少需要创建一个data和一个metadata pool</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph osd pool create cephfs_data <span class="number">128</span></span><br><span class="line">pool <span class="string">&#x27;cephfs_data&#x27;</span> created</span><br><span class="line"></span><br><span class="line">$ sudo ceph osd pool create cephfs_metadata <span class="number">128</span></span><br><span class="line"><span class="built_in">Error</span> ERANGE: pg_num <span class="number">128</span> size <span class="number">3</span> would mean <span class="number">768</span> total pgs, which exceeds max <span class="number">750</span> (mon_max_pg_per_osd <span class="number">250</span> * num_in_osds <span class="number">3</span>)</span><br><span class="line">john@node6:~$ sudo ceph osd pool create cephfs_metadata <span class="number">24</span></span><br><span class="line">pool <span class="string">&#x27;cephfs_metadata&#x27;</span> created</span><br></pre></td></tr></table></figure>

<p><strong>创建文件系统</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph fs <span class="keyword">new</span> cephfs cephfs_metadata cephfs_data</span><br><span class="line"><span class="keyword">new</span> fs <span class="keyword">with</span> metadata pool <span class="number">2</span> and data pool <span class="number">1</span></span><br><span class="line">$ sudo ceph fs ls</span><br><span class="line">name: cephfs, metadata pool: cephfs_metadata, data pools: \[cephfs_data \]</span><br></pre></td></tr></table></figure>
<p>查看mds状态</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph mds stat</span><br><span class="line">cephfs:<span class="number">1</span> &#123;<span class="number">0</span>=node6=up:active&#125; <span class="number">2</span> up:standby</span><br></pre></td></tr></table></figure>
<p>没有创建文件系统之前，所有的mds实例都为standby状态<br>集群状态</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph -s</span><br><span class="line"> cluster:</span><br><span class="line"> id: 0238426d-78d6-48cd-af64-b6a8407996c6</span><br><span class="line"> health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line"> services:</span><br><span class="line"> mon: <span class="number">3</span> daemons, quorum node8,node6,node7 (age 11m)</span><br><span class="line"> mgr: node6(active, since 11m), <span class="attr">standbys</span>: node7, node8</span><br><span class="line"> mds: cephfs:<span class="number">1</span> &#123;<span class="number">0</span>=node6=up:active&#125; <span class="number">2</span> up:standby</span><br><span class="line"> osd: <span class="number">3</span> osds: <span class="number">3</span> up (since 11m), <span class="number">3</span> <span class="keyword">in</span> (since 3d)</span><br><span class="line"> </span><br><span class="line"> data:</span><br><span class="line"> pools: <span class="number">2</span> pools, <span class="number">152</span> pgs</span><br><span class="line"> objects: <span class="number">22</span> objects, <span class="number">2.2</span> KiB</span><br><span class="line"> usage: <span class="number">3.0</span> GiB used, <span class="number">18</span> GiB / <span class="number">21</span> GiB avail</span><br><span class="line"> pgs: <span class="number">152</span> active+clean</span><br></pre></td></tr></table></figure>

<p><strong>fuse挂载cephfs</strong><br>安装客户端和fuse</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install ceph-common ceph-fuse</span><br></pre></td></tr></table></figure>
<p>将集群配置/etc/ceph/*拷贝到客户机相同位置<br>挂载</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-fuse /path/to/mount</span><br></pre></td></tr></table></figure>
<p>或者指定monitor地址</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph-fuse -m ip_of_monitor /path/to/mount</span><br></pre></td></tr></table></figure>
<p>/etc/fstab:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">none /mnt/mycephfs fuse.ceph ceph.id=admin,_netdev,defaults <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>这里指定使用admin用户，使用其他用户需要提前建立用户keyring</p>
<p><strong>内核驱动挂载cephfs</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ sudo mount.ceph <span class="number">192.168</span><span class="number">.3</span><span class="number">.8</span>:<span class="regexp">/ /m</span>nt/mycephfs -o name=admin,secret=AQBHybZdKRryLRAAY9jTUkPpNcXmeykzFPNTTw==</span><br><span class="line">###or: sudo mount -t ceph 192.168.3.8:6789:/ /mnt/mycephfs -o name=admin,secret=AQBHybZdKRryLRAAY9jTUkPpNcXmeykzFPNTTw==</span><br></pre></td></tr></table></figure>
<p>如果不指定name选项，默认使用guest用户<br>当前内核驱动使用msgr v1协议与ceph集群通讯，因此应该使用6789端口，指定3300端口无法连接。</p>
<p><strong>后记：</strong><br>只要/etc/ceph目录下的文件普通用户可以读取，特别是keyring文件，那么普通用户就可以连接到集群使用所有的ceph命令。</p>
<p>References:<br>[1]<a href="https://docs.ceph.com/docs/mimic/cephfs/createfs/">CREATE A CEPH FILESYSTEM</a><br>[2]<a href="https://docs.ceph.com/docs/master/cephfs/kernel/">MOUNT CEPHFS WITH THE KERNEL DRIVER</a><br>[3]<a href="https://docs.ceph.com/docs/master/cephfs/administration/">CEPHFS ADMINISTRATIVE COMMANDS</a><br>[4]<a href="https://runsisi.com/2019-02-14/cephx">cephx</a><br>[5]<a href="https://int32bit.me/2016/05/19/Ceph-Pool%E6%93%8D%E4%BD%9C%E6%80%BB%E7%BB%93/">Ceph Pool操作总结</a><br>[6]<a href="https://docs.ceph.com/docs/jewel/rados/operations/pools/">POOLS</a><br>[7]<a href="https://blog.programster.org/ubuntu-14-04-mount-ceph-filesystem">Mount Ceph Filesystem</a><br>[8]<a href="https://docs.ceph.com/docs/master/man/8/mount.fuse.ceph/">MOUNT CEPHFS IN YOUR FILE SYSTEMS TABLE</a><br>[9]<a href="https://amito.me/2018/CephFS-Introduction-Installation-and-Configuration/">Ceph 文件系统 CephFS 的介绍与配置</a><br>[10]<a href="https://docs.ceph.com/docs/master/cephfs/cephfs-shell/">CEPHFS SHELL</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>数字证书基础概念</title>
    <url>/2014/01/22/cert-conceptions/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>X.509</strong></p>
<p><a href="http://www.itu.int/rec/T-REC-X.509">X.509</a>是国际电联ITU-T的标准,用于规范基于公钥密码体系PKI(public key infrastructure)体系的数字证书管理。其标准主要由RFC5280[1]描述,现在常用的数字证书正是基于X.509标准的。</p>
<p><strong>证书结构</strong></p>
<p>X.509 v3数字证书的结构如下:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">Certificate</span><br><span class="line"> Version #版本号,区分不同的X.509版本 </span><br><span class="line"> Serial Number #序列号,CA分配给证书的唯一编号</span><br><span class="line"> #签名算法,CA签发证书时使用的公开密钥算法和摘要算法,比如PKCS #1 SHA-1 With RSA Encryption</span><br><span class="line"> Certificate Signature Algorithm </span><br><span class="line"> Issuer #证书签发机构</span><br><span class="line"> Validity #有效期限</span><br><span class="line"> Not Before #起始日期</span><br><span class="line"> Not After #终止日期</span><br><span class="line"> Subject #证书主体信息,证书主体即证书的持有人</span><br><span class="line"> Subject Public Key Info #证书主体的公钥信息</span><br><span class="line"> Public Key Algorithm #证书主体使用的公钥算法</span><br><span class="line"> Subject Public Key #证书主体的公钥</span><br><span class="line"> Issuer Unique Identifier (optional) #证书签发者唯一标识符</span><br><span class="line"> Subject Unique Identifier (optional) #证书主体唯一标识符</span><br><span class="line"> Extensions (optional) #扩展</span><br><span class="line"> ...</span><br><span class="line">Certificate Signature Algorithm #证书签名算法,比如PKCS #1 SHA-1 With RSA Encryption</span><br><span class="line">Certificate Signature #证书的数字签名</span><br><span class="line">Fingerprints #指纹</span><br><span class="line"> SHA-256 Fingerprint #</span><br><span class="line"> SHA-1 Fingerprint #</span><br></pre></td></tr></table></figure>
<p><strong>数字证书编码和扩展名</strong></p>
<p>数字证书使用文件作为载体,目前有两种编码方法,多种文件扩展名。</p>
<p><em>编码格式(同时可以作为对应编码格式的扩展名)</em></p>
<ul>
<li><p>  DER(Distinguished Encoding Rules)<br>DER[4]是一种二进制编码格式。可以使用.der作为DER格式编码的数字证书的文件扩展名。通常应该这样说,”我有一个DER编码格式的数字证书”,而不是,”我有一个DER数字证书”。</p>
</li>
<li><p>  PEM(Privacy-Enhanced Mail)<br>PEM采用BASE64文本编码格式,用于不同类型的X.509 v3数字证书。PEM一般以BEGIN XXX开头,以END XXX结束。</p>
</li>
</ul>
<p>比如:</p>
<p>使用PEM格式存储的数字证书:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">...</span><br><span class="line">-----END CERTIFICATE-----</span><br></pre></td></tr></table></figure>
<p>使用PEM格式存储的私钥</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-----BEGIN PRIVATE KEY-----</span><br><span class="line">...</span><br><span class="line">-----END PRIVATE KEY-----</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-----BEGIN RSA PRIVATE KEY-----</span><br><span class="line">...</span><br><span class="line">-----END RSA PRIVATE KEY-----</span><br></pre></td></tr></table></figure>
<p>使用PEM格式存储的证书请求文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-----BEGIN CERTIFICATE REQUEST-----</span><br><span class="line">...</span><br><span class="line">-----END CERTIFICATE REQUEST-----</span><br></pre></td></tr></table></figure>

<p><em>证书文件扩展名</em></p>
<ul>
<li><p>.crt<br>CeRTificate的缩写,用于证书文件,可以是DER或者PEM编码格式。</p>
</li>
<li><p>.cer<br>CERtificate的缩写,用于证书文件,可以是DER或者PEM编码格式。</p>
</li>
<li><p>.key<br>用于存储私钥或者公钥,可以使DER或者PEM编码格式。</p>
</li>
</ul>
<p>CRT文件和CER文件只有在使用相同编码的时候才可以安全地相互替代。</p>
<p><strong>查看数字证书</strong><br>PEM编码格式证书</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl x509 -<span class="keyword">in</span> cert.(pem cer crt) -text -noout</span><br></pre></td></tr></table></figure>
<p>DER编码格式证书</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl x509 -<span class="keyword">in</span> cert.(der cer crt) -inform der -text -noout</span><br></pre></td></tr></table></figure>

<p><strong>数字证书编码格式转换</strong></p>
<p>PEM to DER</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl x509 -<span class="keyword">in</span> cert.crt -outform der -out cert.der</span><br></pre></td></tr></table></figure>
<p>DER to PEM</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">openssl x509 -<span class="keyword">in</span> cert.crt -inform der -outform pem -out cert.pem</span><br></pre></td></tr></table></figure>

<p><strong>其他名词</strong></p>
<ul>
<li>  CSR<br>证书请求文件(Certificate Signing Request),生成 X509 数字证书前,一般先由用户提交证书申请文件CSR,然后由 CA 来签发证书。<br>大致流程是,用户自行生成公私密钥对,然后生成证书请求文件CSR,主要包含用户的身份信息,公钥以及一些其他信息,用户使用私钥对上述信息进行签名。CSR文件递交给CA机构后,CA会审核用户的真实身份,通过之后,CA使用自己的私钥为用户签发数字证书。CA的签名可以使用CA公开的根证书来验证。</li>
<li>  CRL<br>证书撤销列表 (Certification Revocation List) 是一种包含撤销的证书列表的签名数据结构。用于公布某些数字证书不再有效。CRL文件同样需要数字签名。</li>
<li>  OCSP<br>在线证书状态协议(OCSP,Online Certificate Status Protocol,rfc2560)用于实时表明证书状态。OCSP通过在线方式来查询证书的有效性,避免了CRL的缺陷。</li>
<li>  PKCS<br>公钥加密标准(Public Key Cryptography Standards)包含一系列的标准,从PKCS#1到PKCS#15,分别定义了PKCS的不同方面。</li>
</ul>
<p>PKCS#11是目前最常用的标准之一。</p>
<p>PKCS#11为加密令牌定义了一组平台无关的API ，如硬件安全模块和智能卡。PKCS#11称为Cyptoki，定义了一套独立于技术的程序设计接口，USBKey安全应用需要实现的接口。由于没有一个真正的标准加密令牌，这个API已经发展成为一个通用的加密令牌的抽象层。 PKCS#11 API定义最常用的加密对象类型（RSA密钥，X.509证书，DES /三重DES密钥等）和所有需要使用的功能，创建/生成，修改和删除这些对象。pkcs#11只提供了接口的定义， 不包括接口的实现，一般接口的实现是由设备提供商提供的，如usbkey的生产厂商会提供 符合PKCS#11接口标准的API的实现。这样你只要通过接口调用API函数即可实现其功能。</p>
<p>References:<br>[1]<a href="http://www.ietf.org/rfc/rfc5280.txt">rfc5280</a><br>[2]<a href="http://en.wikipedia.org/wiki/X.509">X.509</a><br>[3]<a href="https://support.ssl.com/index.php?/Knowledgebase/Article/View/19/0/der-vs-crt-vs-cer-vs-pem-certificates-and-how-to-convert-them">DER vs. CRT vs. CER vs. PEM Certificates and How To Convert Them</a><br>[4]<a href="http://www.planetlarg.net/encyclopedia/ssl-secure-sockets-layer/der-distinguished-encoding-rules-certificate-encoding">DER (Distinguished Encoding Rules) certificate encoding</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>certbot验证方法TLS-SNI-01即将过时</title>
    <url>/2018/12/29/certbot-tls-sni-01-deprecated/</url>
    <content><![CDATA[<p>Let’s Encrypt因为安全性问题已经将TLS-SNI-01验证方法标记为过时，而且很快就不能使用了。</p>
<a id="more"></a>
<p>今天renew站点的证书时，突然提示开始使用http-01验证方式，然鹅80端口并没有配置，所以毫无悬念的更新失败了。</p>
<p>临时更改了renew的配置文件/etc/letsencrypt/renewal/xxx.com.conf，在renewalparams节添加参数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">pref_challs=tls-sni-<span class="number">01</span></span><br></pre></td></tr></table></figure>
<p>或者也可以在命令行添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">--preferred-challenges tls-sni-<span class="number">01</span></span><br></pre></td></tr></table></figure>
<p>然后renew证书成功，但出现deprecated提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">TLS-SNI-<span class="number">01</span> is deprecated, and will stop working soon.</span><br></pre></td></tr></table></figure>
<p>下次renew证书就要改用http-01或者dns-01了。</p>
<p>References:<br>[1]<a href="https://community.letsencrypt.org/t/upcoming-tls-sni-deprecation-in-certbot/76383">Upcoming TLS-SNI Deprecation in Certbot</a><br>[2]<a href="https://www.vultr.com/docs/let-s-encrypt-migrating-from-tls-sni-01">Let’s Encrypt: Migrating From TLS-SNI-01</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>更改cassandra数据存储目录</title>
    <url>/2015/11/06/change-cassandra-data-dir/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian使用apache源安装完成的cassandra节点，默认数据存储在/var/lib/cassandra/data目录下。</p>
<p>为了优化性能，可能将data与commitlog分别存储到不同的磁盘上。</p>
<p>比如，更改数据目录到/mnt/data/cassandra目录下，这是挂装的一个不同的磁盘驱动器。</p>
<p>首先停掉cassandra</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra stop</span><br></pre></td></tr></table></figure>

<p>然后修改/etc/cassandra/cassandra.yaml</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">data_file_directories:</span><br><span class="line"> - <span class="regexp">/mnt/</span>data/cassandra</span><br></pre></td></tr></table></figure>

<p>将/var/lib/cassandra/data目录下的所有东西全部拷贝或移动到/mnt/data/cassandra目录下</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u cassandra cp -r /<span class="keyword">var</span>/lib/cassandra/data<span class="comment">/* /mnt/data/cassandra</span></span><br></pre></td></tr></table></figure>
<p>或</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u cassandra mv /<span class="keyword">var</span>/lib/cassandra/data /mnt/data/cassandra</span><br></pre></td></tr></table></figure>

<p>最后重新启动cassandra</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra start</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>多clang环境设置默认clang版本</title>
    <url>/2018/11/26/clang-set-default-version/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian当前源内的clang版本为3.8，backport源里的版本为6.0</p>
<p>设置默认版本为6.0:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo update-alternatives --install \\</span><br><span class="line">/usr/bin/clang++ clang++ <span class="regexp">/usr/</span>lib/llvm-<span class="number">6.0</span>/bin/clang++ <span class="number">100</span></span><br><span class="line">$ sudo update-alternatives --install \\</span><br><span class="line"> /usr/bin/clang clang /usr/lib/llvm-<span class="number">6.0</span>/bin/clang <span class="number">100</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>磁盘类,端口,小端口驱动(Class,Port,Miniport Drivers)</title>
    <url>/2010/04/08/class-port-miniport-drivers/</url>
    <content><![CDATA[<p>During initialization, the Windows I/O manager starts the disk storage drivers. Storage drivers in Windows follow a class/port/miniport architecture, in which Microsoft supplies a storage class driver that implements functionality common to all storage devices and a storage port driver that implements functionality common to a particular bus—such as a Small Computer System Interface (SCSI) bus or an Integrated Device Electronics (IDE) system—and OEMs supply miniport drivers that plug into the port driver to interface Windows to a particular controller implementation.</p>
<p>系统初始化期间,windows I/O管理器开始装载磁盘存储驱动.windows中的存储驱动遵循类/端口/小端口(class/port/miniport)架构,MS提供一个存储类驱动实现与具体设备无关的、所有存储设备共同的功能特性和一个存储端口驱动实现一类特殊总线共同的功能—比如SCSI(Small Computer System Interface)总线或者IDE(Integrated Device Electronics)总线—然后OEM(Original Equipment Manufacturer)制造商提供挂接到端口驱动的小端口驱动来为windows提供到一个特殊控制器实现的访问接口。</p>
<p>-–译自《windows internals》(5th)</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>VirtualBox主机(host)I/O负载过重导致客户机数据破坏(corruption)</title>
    <url>/2009/11/16/client-data-corrupt/</url>
    <content><![CDATA[<p>先说一下主机和客户机配置<br>主机：4颗双核AMD 8218HE CPU,16G内存,windows 2003 R2 server x86<br>客户机：单颗CPU,1500MB内存,debian lenny amd64</p>
<p>最近经常能遇到客户机运行迟缓(lag)，无法正常提供服务的情况，客户机的控制台一般有这样的提示：<br>end_request: I/O error,dev hda,sector xxxxxxxx(扇区号)<br>Buffer I/O error on device hda6,logical block xxx(块号)<br>…<br>日志文件/var/log/messages中有这样的消息：<br>Nov 16 10:54:06 debian kernel: [255938.816139] hda: dma_timer_expiry: dma status == 0x21<br>Nov 16 10:54:16 debian kernel: [255948.816121] hda: DMA timeout error<br>Nov 16 10:54:16 debian kernel: [255948.816174] hda: dma timeout error: status=0x48 { DriveReady DataRequest }<br>Nov 16 10:54:16 debian kernel: [255948.816183] ide: failed opcode was: unknown<br>Nov 16 10:54:16 debian kernel: [255948.816199] hda: DMA disabled<br>Nov 16 10:54:16 debian kernel: [255948.965023] ide0: reset: master: error (0x00?)</p>
<a id="more"></a>
<p>最早出现这个问题的时候客户机使用的是SATA硬盘，本来以为是这个接口还不成熟，就又换回了最原始的IDE(PIIX4)，但是问题依旧。隔一段时间客户机仍然会崩溃，而且错误提示基本一样，可以排除是硬盘接口层的问题。<br>每次出现这种问题基本上都是在主机进行大文件拷贝的时候，host有一个脚本，定期拷贝大约120G的数据,每个文件大约30G。<br>经过搜索，发现virtualbox官方打开了一个<a href="http://www.virtualbox.org/ticket/2524">ticket(#2524)</a>就是描述的这个问题，看来这是virtualbox的一个bug无疑了。<br>这个bug在最新的virtualbox 3.0.10上仍然存在，看来只有祈祷了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title>关闭OpenSSH UseDNS选项加速SSH登录</title>
    <url>/2011/03/16/close-openssh-usedns-option/</url>
    <content><![CDATA[<p>ssh登录服务器时总是要停顿等待一下才能连接上,这是因为OpenSSH服务器有一个DNS查找选项UseDNS默认是打开的。</p>
<a id="more"></a>
<p>UseDNS选项打开状态下,当客户端试图登录OpenSSH服务器时,服务器端先根据客户端的IP地址进行DNS PTR反向查询,查询出客户端的host name，然后根据查询出的客户端host name进行DNS 正向A记录查询，验证与其原始IP地址是否一致，这是防止客户端欺骗的一种手段,但一般我们的IP是动态的，不会有PTR记录的，打开这个选项不过是在白白浪费时间而已。<br>1 $sudo vim /etc/ssh/sshd_config   </p>
<p>在文件最后增加UseDNS no,:wq退出,<br>1 $sudo /etc/init.d/ssh restart  </p>
<p>就可以加快ssh登录的速度了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用JMX逐节点迁移集群的compaction策略</title>
    <url>/2019/06/23/compaction-strategy-migration-one-node-by-one-use-jmx/</url>
    <content><![CDATA[<a id="more"></a>
<p>这里使用交互式jmx命令行客户端<a href="https://docs.cyclopsgroup.org/jmxterm">jmxterm</a>来与mbeans交互。</p>
<p>下载uber依赖自包含版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//github.com/jiaqi/jmxterm/releases/download/v1.0.1/jmxterm-1.0.1-uber.jar</span></span><br></pre></td></tr></table></figure>

<p>使用很简单</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ java -jar jmxterm-<span class="number">1.0</span><span class="number">.1</span>-uber.jar -h</span><br><span class="line">\[USAGE\]</span><br><span class="line"> jmxterm &lt;OPTIONS&gt;</span><br><span class="line">\[DESCRIPTION\]</span><br><span class="line"> Main executable <span class="keyword">of</span> JMX terminal CLI tool</span><br><span class="line">\[OPTIONS\]</span><br><span class="line"> -a --appendtooutput With <span class="built_in">this</span> flag, the outputfile is preserved and content is appended to it</span><br><span class="line"> -e --exitonfailure With <span class="built_in">this</span> flag, terminal exits <span class="keyword">for</span> any Exception</span><br><span class="line"> -h --help Show usage <span class="keyword">of</span> <span class="built_in">this</span> command line</span><br><span class="line"> -i --input &lt;value&gt; Input script file. There can only be one input file. <span class="string">&quot;stdin&quot;</span> is the <span class="keyword">default</span> value which means <span class="built_in">console</span> input</span><br><span class="line"> -n --noninteract Non interactive mode. Use <span class="built_in">this</span> mode <span class="keyword">if</span> input doesn<span class="string">&#x27;t come from human or jmxterm is embedded</span></span><br><span class="line"><span class="string"> -o --output &lt;value&gt; Output file, stdout or stderr. Default value is stdout</span></span><br><span class="line"><span class="string"> -p --password &lt;value&gt; Password for user/password authentication</span></span><br><span class="line"><span class="string"> -s --sslrmiregistry Whether the server&#x27;</span>s RMI registry is protected <span class="keyword">with</span> SSL/TLS</span><br><span class="line"> -l --url &lt;value&gt; Location <span class="keyword">of</span> MBean service. It can be &lt;host&gt;:&lt;port&gt; or full service URL.</span><br><span class="line"> -u --user &lt;value&gt; User name <span class="keyword">for</span> user/password authentication</span><br><span class="line"> -v --verbose &lt;value&gt; Verbose level, could be silentbriefverbose. Default value is brief</span><br><span class="line">\[NOTE\]</span><br><span class="line"> Without any option, <span class="built_in">this</span> command opens an interactive command line based <span class="built_in">console</span>. With a given input file, commands <span class="keyword">in</span> file will be executed and process ends after file is processed</span><br><span class="line"></span><br><span class="line">$ java -jar jmxterm-<span class="number">1.0</span><span class="number">.1</span>-uber.jar</span><br><span class="line">Welcome to JMX terminal. Type <span class="string">&quot;help&quot;</span> <span class="keyword">for</span> available commands.</span><br><span class="line">$&gt;help</span><br><span class="line">#following commands are available to use:</span><br><span class="line">about - Display about page</span><br><span class="line">bean - Display or set current selected MBean. </span><br><span class="line">beans - List available beans under a domain or all domains</span><br><span class="line">bye - Terminate <span class="built_in">console</span> and exit</span><br><span class="line">close - Close current JMX connection</span><br><span class="line">domain - Display or set current selected domain. </span><br><span class="line">domains - List all available domain names</span><br><span class="line">exit - Terminate <span class="built_in">console</span> and exit</span><br><span class="line">get - Get value <span class="keyword">of</span> MBean attribute(s)</span><br><span class="line">help - Display available commands or usage <span class="keyword">of</span> a command</span><br><span class="line">info - Display detail information about an MBean</span><br><span class="line">jvms - List all running local JVM processes</span><br><span class="line">open - Open JMX session or display current connection</span><br><span class="line">option - <span class="built_in">Set</span> options <span class="keyword">for</span> command session</span><br><span class="line">quit - Terminate <span class="built_in">console</span> and exit</span><br><span class="line">run - Invoke an MBean operation</span><br><span class="line">set - <span class="built_in">Set</span> value <span class="keyword">of</span> an MBean attribute</span><br><span class="line">subscribe - Subscribe to the notifications <span class="keyword">of</span> a bean</span><br><span class="line">unsubscribe - Unsubscribe the notifications <span class="keyword">of</span> an earlier subscribed bean</span><br><span class="line">watch - Watch the value <span class="keyword">of</span> one MBean attribute constantly</span><br><span class="line">$&gt;help get</span><br><span class="line">\[USAGE\]</span><br><span class="line"> get &lt;OPTIONS&gt; &lt;ARGS&gt;</span><br><span class="line">\[DESCRIPTION\]</span><br><span class="line"> Get value <span class="keyword">of</span> MBean attribute(s)</span><br><span class="line">\[OPTIONS\]</span><br><span class="line"> -b --bean &lt;value&gt; MBean name where the attribute is. Optional <span class="keyword">if</span> bean has been set</span><br><span class="line"> -l --delimiter &lt;value&gt; Sets an optional delimiter to be printed after the value</span><br><span class="line"> -d --domain &lt;value&gt; Domain <span class="keyword">of</span> bean, optional</span><br><span class="line"> -h --help Display usage</span><br><span class="line"> -i --info Show detail information <span class="keyword">of</span> each attribute</span><br><span class="line"> -q --quots Quotation marks around value</span><br><span class="line"> -s --simple Print simple expression <span class="keyword">of</span> value without full expression</span><br><span class="line"> -n --singleLine Prints result without a newline - <span class="keyword">default</span> is <span class="literal">false</span></span><br><span class="line">\[ARGS\]</span><br><span class="line"> &lt;attr&gt;... Name <span class="keyword">of</span> attributes to select</span><br><span class="line">\[NOTE\]</span><br><span class="line"> * stands <span class="keyword">for</span> all attributes. eg. get Attribute1 Attribute2 or get *</span><br></pre></td></tr></table></figure>

<p>设置compaction策略为LCS</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ java -jar jmxterm-<span class="number">1.0</span><span class="number">.1</span>-uber.jar --url localhost:<span class="number">7199</span></span><br><span class="line">Welcome to JMX terminal. Type <span class="string">&quot;help&quot;</span> <span class="keyword">for</span> available commands.</span><br><span class="line">$&gt;domain org.apache.cassandra.db #设置当前domain</span><br><span class="line">#domain is set to org.apache.cassandra.db</span><br><span class="line">$&gt;bean org.apache.cassandra.db:columnfamily=image,keyspace=reis,type=ColumnFamilies #设置当前mbean</span><br><span class="line">#bean is set to org.apache.cassandra.db:columnfamily=image,keyspace=reis,type=ColumnFamilies</span><br><span class="line">$&gt;info #显示当前mbean的信息</span><br><span class="line">#mbean = org.apache.cassandra.db:columnfamily=image,keyspace=reis,type=ColumnFamilies</span><br><span class="line">#<span class="class"><span class="keyword">class</span> <span class="title">name</span> </span>= org.apache.cassandra.db.ColumnFamilyStore</span><br><span class="line"># attributes</span><br><span class="line"> %<span class="number">0</span> - AutoCompactionDisabled (boolean, r)</span><br><span class="line"> %<span class="number">1</span> - BuiltIndexes (java.util.List, r)</span><br><span class="line"> %<span class="number">2</span> - ColumnFamilyName (java.lang.String, r)</span><br><span class="line"> %<span class="number">3</span> - CompactionParameters (java.util.Map, rw)</span><br><span class="line"> %<span class="number">4</span> - CompactionParametersJson (java.lang.String, rw)</span><br><span class="line"> %<span class="number">5</span> - CompactionStrategyClass (java.lang.String, rw)</span><br><span class="line"> %<span class="number">6</span> - CompressionParameters (java.util.Map, rw)</span><br><span class="line"> %<span class="number">7</span> - CrcCheckChance (double, w)</span><br><span class="line"> %<span class="number">8</span> - DroppableTombstoneRatio (double, r)</span><br><span class="line"> %<span class="number">9</span> - MaximumCompactionThreshold (int, rw)</span><br><span class="line"> %<span class="number">10</span> - MinimumCompactionThreshold (int, rw)</span><br><span class="line"> %<span class="number">11</span> - SSTableCountPerLevel (\[I, r)</span><br><span class="line"> %<span class="number">12</span> - UnleveledSSTables (int, r)</span><br><span class="line"># operations</span><br><span class="line"> %<span class="number">0</span> - <span class="keyword">void</span> beginLocalSampling(java.lang.String p1,int p2)</span><br><span class="line"> %<span class="number">1</span> - long estimateKeys()</span><br><span class="line"> %<span class="number">2</span> - javax.management.openmbean.CompositeData finishLocalSampling(java.lang.String p1,int p2)</span><br><span class="line"> %<span class="number">3</span> - <span class="keyword">void</span> forceMajorCompaction(boolean p1)</span><br><span class="line"> %<span class="number">4</span> - java.util.List getSSTablesForKey(java.lang.String p1)</span><br><span class="line"> %<span class="number">5</span> - <span class="keyword">void</span> loadNewSSTables()</span><br><span class="line"> %<span class="number">6</span> - <span class="keyword">void</span> setCompactionThresholds(int p1,int p2)</span><br><span class="line"> %<span class="number">7</span> - long trueSnapshotsSize()</span><br><span class="line">#there<span class="string">&#x27;s no notifications</span></span><br><span class="line"><span class="string">$&gt;get CompactionStrategyClass # 查询compaction当前策略类</span></span><br><span class="line"><span class="string">#mbean = org.apache.cassandra.db:columnfamily=mytable,keyspace=mykeyspace,type=ColumnFamilies:</span></span><br><span class="line"><span class="string">CompactionStrategyClass = org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy;</span></span><br><span class="line"><span class="string">$&gt;set CompactionStrategyClass &quot;org.apache.cassandra.db.compaction.LeveledCompactionStrategy&quot; #设置compaction策略类为LCS</span></span><br><span class="line"><span class="string">#Value of attribute CompactionStrategyClass is set to &quot;org.apache.cassandra.db.compaction.LeveledCompactionStrategy&quot;</span></span><br><span class="line"><span class="string">$&gt;get CompactionParametersJson #查询LCS的CompactionParametersJson参数</span></span><br><span class="line"><span class="string">#mbean = org.apache.cassandra.db:columnfamily=image,keyspace=reis,type=ColumnFamilies:</span></span><br><span class="line"><span class="string">CompactionParametersJson = &#123;&quot;class&quot;:&quot;LeveledCompactionStrategy&quot;,&quot;sstable_size_in_mb&quot;:&quot;160&quot;&#125;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$&gt;set CompactionParametersJson #设置LCS的CompactionParametersJson参数 \\&#123;&quot;class&quot;:&quot;LeveledCompactionStrategy&quot;,&quot;sstable_size_in_mb&quot;:&quot;200&quot;\\&#125;</span></span><br><span class="line"><span class="string">#Value of attribute CompactionParametersJson is set to &#123;&quot;class&quot;:&quot;LeveledCompactionStrategy&quot;,&quot;sstable_size_in_mb&quot;:&quot;200&quot;&#125; </span></span><br></pre></td></tr></table></figure>

<p>在逐节点compaction策略转换过程中不要alter table，alter table会将jmx对节点的设置扩散到所有的其他节点。</p>
<p>所有节点转换完成后,使用alter table永久的改变compaction策略，否则节点重启后会用table的schema定义覆盖掉jmx对table的修改。</p>
<p>References:<br>[1]<a href="https://support.datastax.com/hc/en-us/articles/213370546-Change-CompactionStrategy-and-sub-properties-via-JMX">Change CompactionStrategy and sub-properties via JMX</a><br>[2]<a href="https://blog.alteroot.org/articles/2015-04-20/change-cassandra-compaction-strategy-on-production-cluster.html">How to change Cassandra compaction strategy on a production cluster</a><br>[3]<a href="https://docs.cyclopsgroup.org/jmxterm">JMXTERM</a><br>[4]<a href="https://docs.cyclopsgroup.org/jmxterm/user-manual">LAUNCH JMXTERM</a><br>[5]<a href="https://github.com/jiaqi/jmxterm">Interactive command line JMX client</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>编译qemu</title>
    <url>/2019/06/11/compile-qemu/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>安装编译环境和必要的附加组件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install dkms build-essential pkg-config libglib2<span class="number">.0</span>-dev libpixman-<span class="number">1</span>-dev libusb-dev libusbredirparser-dev libfdt-dev libbz2-dev flex bison</span><br></pre></td></tr></table></figure>

<p><strong>下载解压源代码</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//download.qemu.org/qemu-4.0.0.tar.xz</span></span><br><span class="line">$ tar xvJf qemu-<span class="number">4.0</span><span class="number">.0</span>.tar.xz</span><br></pre></td></tr></table></figure>

<p><strong>配置并编译</strong></p>
<p>只编译x86_64架构</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd qemu-<span class="number">4.0</span><span class="number">.0</span></span><br><span class="line">$ mkdir build</span><br><span class="line">$ cd build</span><br><span class="line">$ ../configure --target-list=x86_64-softmmu --enable-debug</span><br><span class="line">$ make -j8</span><br></pre></td></tr></table></figure>

<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure>

<p>目标程序安装在/usr/local/</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 26</title>
    <url>/2013/12/17/complete-finish-distinct/</url>
    <content><![CDATA[<p>complete和finish的区别: When you marry the right girl, you are completed. When you marry the wrong girl, you are finished. When the right girl catches you with the wrong girl, you are completely finished. 太经典了！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>CPL vs. DPL vs. RPL</title>
    <url>/2019/02/09/cpl-vs-dpl-vs-rpl/</url>
    <content><![CDATA[<a id="more"></a>
<h1 id="CPL-vs-DPL-vs-RPL"><a href="#CPL-vs-DPL-vs-RPL" class="headerlink" title="CPL vs. DPL vs. RPL"></a>CPL vs. DPL vs. RPL</h1><p>To make this simpler, let’s first just consider CPL and DPL:</p>
<ul>
<li>  The CPL is your current privilege level.</li>
<li>  The DPL is the privilege level of a segment. It defines the minimum1 privilege level required to access the segment.</li>
<li>  Privilege levels range from 0-3; lower numbers are <em>more</em> privileged</li>
<li>  So: To access a segment, CPL must be less than or equal to the DPL of the segment</li>
</ul>
<p>RPL is a privilege level associated with a <em>segment selector</em>. A segment selector is just a 16-bit value that references a segment. Every memory access (implicitly2 or otherwise) uses a segment selector as part of the access.</p>
<p>When accessing a segment, there are actually two checks that must be performed. Access to the segment is only allowed if <em>both</em> of the following are true:</p>
<ul>
<li>  CPL &lt;= DPL</li>
<li>  RPL &lt;= DPL</li>
</ul>
<p>So even if CPL is sufficiently privileged to access a segment, the access will still be denied if the segment selector that references that segment is not sufficiently privileged.</p>
<h1 id="The-motivation-behind-RPL"><a href="#The-motivation-behind-RPL" class="headerlink" title="The motivation behind RPL"></a>The motivation behind RPL</h1><p><em>What’s the purpose of this?</em> Well, the reasoning is a bit dated now, but the Intel documentation offers a scenario that goes something like this:</p>
<ul>
<li>  Suppose the operating system provides a system call that accepts a logical address (segment selector + offset) from the caller and writes to that address</li>
<li>  Normal applications run with a CPL of 3; system calls run with a CPL of 0</li>
<li>  Let’s say some segment (we’ll call it X) has a DPL of 0</li>
</ul>
<p>An application would ordinarily not be able to access the memory in segment X (because CPL &gt; DPL). But depending on how the system call was implemented, an application might be able to invoke the system call with a parameter of an address within segment X. Then, because the system call is privileged, it would be able to write to segment X on behalf of the application. This could introduce a <a href="https://en.wikipedia.org/wiki/Privilege_escalation">privilege escalation vulnerability</a> into the operating system.</p>
<p>To mitigate this, the official recommendation is that when a privileged routine accepts a segment selector provided by unprivileged code, it should first set the RPL of the segment selector to match that of the unprivileged code3. This way, the operating system would not be able to make any accesses to that segment that the unprivileged caller would not already be able to make. This helps enforce the boundary between the operating system and applications.</p>
<h1 id="Then-and-now"><a href="#Then-and-now" class="headerlink" title="Then and now"></a>Then and now</h1><p>Segment protection was introduced with the 286, before paging existed in the x86 family of processors. Back then, segmentation was the only way to restrict access to kernel memory from a user-mode context. RPL provided a convenient way to enforce this restriction when passing pointers across different privilege levels.</p>
<p>Modern operating systems use paging to restrict access to memory, which removes the need for segmentation. Since we don’t need segmentation, we can use a <a href="https://en.wikipedia.org/wiki/Flat_memory_model">flat memory model</a>, which means segment registers <code>CS</code>, <code>DS</code>, <code>SS</code>, and <code>ES</code> all have a base of zero and extend through the entire address space. In fact, in 64-bit “long mode”, a flat memory model is <em>enforced</em>, regardless of the contents of those four segment registers. Segments are still used sometimes (for example, Windows uses <code>FS</code> and <code>GS</code> to point to the <a href="https://en.wikipedia.org/wiki/Win32_Thread_Information_Block">Thread Information Block</a> and 0x23 and 0x33 to <a href="http://www.malwaretech.com/2014/02/the-0x33-segment-selector-heavens-gate.html">switch between 32- and 64-bit code</a>, and Linux is similar), but you just don’t go passing segments around anymore. So RPL is mostly an unused leftover from older times.</p>
<h1 id="RPL-Was-it-ever-necessary"><a href="#RPL-Was-it-ever-necessary" class="headerlink" title="RPL: Was it ever necessary?"></a>RPL: Was it ever <em>necessary</em>?</h1><p>You asked why it was a necessity to have both DPL and RPL. Even in the context of the 286, it wasn’t actually a <em>necessity</em> to have RPL. Considering the above scenario, a privileged procedure could always just retrieve the DPL of the provided segment via the LAR instruction, compare this to the privilege of the caller, and preemptively bail out if the caller’s privilege is insufficient to access the segment. However, setting the RPL, in my opinion, is a more elegant and simpler way of managing segment accesses across different privilege levels.</p>
<p>To learn more about privilege levels, check out Volume 3 of <a href="http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html">Intel’s software developer manuals</a>, particularly the sections titled “Privilege Levels” and “Checking Caller Access Privileges”.</p>
<p>1 Technically, the DPL can have different meanings depending on what type of segment or gate is being accessed. For the sake of simplicity, everything I describe applies to <em>data segments</em> specifically. Check the Intel docs for more information<br>2 For example, the instruction pointer implicitly uses the segment selector stored in CS when fetching instructions; most types of data accesses implicitly use the segment selector stored in DS, etc.<br>3 See the ARPL instruction (16-bit/32-bit protected mode only)</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>奇怪的CPP编译错误</title>
    <url>/2017/12/02/cpp-compile-error/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果编译CPP程序时出现类似如下的错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/usr/bin/locale:<span class="number">111</span>:<span class="number">128</span>: error: stray ‘\\<span class="number">21</span>’ <span class="keyword">in</span> program </span><br><span class="line">/usr/bin/locale:<span class="number">111</span>:<span class="number">130</span>: error: stray ‘\\<span class="number">3</span>’ <span class="keyword">in</span> program </span><br><span class="line">/usr/bin/locale:<span class="number">111</span>:<span class="number">136</span>: error: stray ‘\\<span class="number">376</span>’ <span class="keyword">in</span> program </span><br></pre></td></tr></table></figure>

<p>那是因为有代码包含了locale头文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#include &lt;locale&gt;</span><br></pre></td></tr></table></figure>

<p>而编译时include搜索路径包含了/usr/bin，导致编译器找到了/usr/bin/locale这个二进制程序当做了locale头文件，所以有时候就是这么莫名其妙，include路径为什么要包含/usr/bin呢，这是错误的。</p>
<p>仔细的检查你的<br>CPATH<br>C_INCLUDE_PATH<br>CPLUS_INCLUDE_PATH<br>等环境变量，还有编译指令的-I参数吧</p>
<p>我就是因为包含CPATH时写成了PATH，真无语了。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>C++项目目录组织结构</title>
    <url>/2010/05/16/cpp-project-directories/</url>
    <content><![CDATA[<p>项目目录结构的问题基本上是个仁者见仁，智者见智的问题，只要自己用着顺手，使用什么样的目录组织结构是没有什么大碍的。当然如果项目很大，参与的人员很多，那么合理的组织一下目录结构还是会有很大的益处的。不同类型的项目也会有不同的目录结构,这里简单的展示一下我所使用的C++项目的基本目录结构。</p>
<p>project —+—build—+—debug<br>　　　　　　　　　　—release<br>　　　　　—dist<br>　　　　　—doc<br>　　　　　—include—+—module1<br>　　　　　　　　　　　—module2<br>　　　　　—lib<br>　　　　　—module1<br>　　　　　—module2<br>　　　　　—res<br>　　　　　—samples—+—sample1<br>　　　　　　　　　　　—sample2<br>　　　　　—tools<br>　　　　　—copyleft<br>　　　　　—Makefile<br>　　　　　—README<br>　　　　　— …</p>
<a id="more"></a>
<p>下面分别介绍一下各目录和文件的用途</p>
<p>build/:项目编译目录，各种编译的临时文件和最终的目标文件皆存于此，分为debug/和release/子目录</p>
<p>dist/:分发目录，最终发布的可执行程序和各种运行支持文件存放在此目录，打包此目录即可完成项目分发</p>
<p>doc/:保存项目各种文档</p>
<p>include/:公共头文件目录，可以按模块划分组织目录来保存模块相关头文件</p>
<p>lib/:外部依赖库目录</p>
<p>res/:资源目录</p>
<p>samples/:样例程序目录</p>
<p>tools/:项目支撑工具目录</p>
<p>copyleft:版权声明文件，当然也可以叫做copyright :-)</p>
<p>Makefile:项目构建配置文件，当然也有可能是其他类型的构建配置文件,比如bjam</p>
<p>README:项目的总体说明文件</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>cqlsh操作超时</title>
    <url>/2016/07/09/cqlsh-operation-timeput/</url>
    <content><![CDATA[<a id="more"></a>
<p>执行cqlsh查询：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cqlsh:xxx&gt; select count(*) <span class="keyword">from</span> image;</span><br></pre></td></tr></table></figure>

<p>时出现错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">OperationTimedOut: errors=&#123;&#125;, last_host=x.x.x.x</span><br></pre></td></tr></table></figure>

<p>在~/.cassandra/cqlshrc中设置客户端超时时间即可：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">\[connection\]</span><br><span class="line">request_timeout = 120 # seconds</span><br></pre></td></tr></table></figure>

<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>手工创建oracle 10g数据库</title>
    <url>/2012/04/01/create-database-manual/</url>
    <content><![CDATA[<p>操作系统为Debian Wheezy(当前仍为testing) AMD64,数据库为oracle 10g 10.2.0.4</p>
<a id="more"></a>
<p>安装oracle 10g 10.2.0.4时,因为要先安装10.2.0.1,然后再升级到10.2.0.4,所以没有建库,省却升级数据库的麻烦。</p>
<p>新建oracle数据库可以使用图形化的工具DBCA(Database Configuration Assistant),也可以使用CREATE DATABASE语句手工创建数据库。这里采用后者手工建库。</p>
<p><strong>手工新建oracle数据库</strong></p>
<p><strong>1、确定数据库实例标识符并设置相关环境变量,建立相关路径</strong></p>
<p>为数据库确定一个SID,并设置操作系统环境变量ORACLE_SID,此处新建数据库拟定的SID为catlogdb</p>
<p>设定环境变量</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> ORACLE_SID=catlogdb</span><br><span class="line"><span class="keyword">export</span> ORACLE_BASE=<span class="regexp">/u01/</span>app/oracle</span><br><span class="line"><span class="keyword">export</span> ORACLE_HOME=$ORACLE_BASE/product/<span class="number">10.2</span><span class="number">.0</span>/db_1</span><br><span class="line"><span class="keyword">export</span> PATH=$ORACLE_HOME/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>创建需要的路径,相关路径设置参照<a href="http://docs.oracle.com/cd/B19306_01/install.102/b15660/app_ofa.htm">Optimal Flexible Architecture for 10.2</a></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mkdir -p $ORACLE_BASE/admin/$ORACLE_SID/&#123;a,b,c,u&#125;dump</span><br><span class="line"><span class="comment">//$ mkdir -p $ORACLE_BASE/admin/$ORACLE_SID/pfile</span></span><br><span class="line"><span class="comment">//$ mkdir -p $ORACLE_BASE/admin/$ORACLE_SID/create</span></span><br><span class="line"><span class="comment">//$ mkdir -p $ORACLE_BASE/admin/$ORACLE_SID/arch</span></span><br><span class="line">$ mkdir -p /u01/oradata/$ORACLE_SID</span><br><span class="line">$ mkdir -p $ORACLE_BASE/flash_recovery_area/$ORACLE_SID</span><br></pre></td></tr></table></figure>
<p><strong>2、创建密码文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID password=passwd_for_sys force=y</span><br></pre></td></tr></table></figure>
<p>在目录$ORACLE_HOME/dbs目录下生成<a href="https://openwares.net/database/oracle_passwd_file.html">密码文件</a>orapwcatlogdb,sys用户的密码为passwd_for_sys</p>
<p><strong>3、创建初始化参数文件</strong></p>
<p>oracle提供了一个样例<a href="https://openwares.net/database/pfile_and_spfile.html">参数文件</a>$ORACLE_HOME/dbs/init.ora,可以根据需要增删修改初始化参数。</p>
<p>初始化参数命名为initcatlogdb.ora,其内容如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">db_name=catlogdb</span><br><span class="line">compatible=<span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span></span><br><span class="line"></span><br><span class="line">nls_language=american</span><br><span class="line">nls_territory=america</span><br><span class="line"></span><br><span class="line">control_files=(<span class="regexp">/u01/</span>oradata/catlogdb/control01.ctl,</span><br><span class="line"> /u01/oradata/catlogdb/control02.ctl,</span><br><span class="line"> /u01/oradata/catlogdb/control03.ctl)</span><br><span class="line"></span><br><span class="line">db_block_size=<span class="number">8192</span></span><br><span class="line">sga_target=960M</span><br><span class="line">pga_aggregate_target=270M</span><br><span class="line"></span><br><span class="line">processes=<span class="number">150</span></span><br><span class="line">sessions=<span class="number">150</span></span><br><span class="line">open_cursors=<span class="number">150</span></span><br><span class="line"></span><br><span class="line">undo_management=auto</span><br><span class="line">undo_tablespace=undotbs1</span><br><span class="line"></span><br><span class="line">audit_file_dest=<span class="regexp">/u01/</span>app/oracle/admin/catlogdb/adump</span><br><span class="line">background_dump_dest=<span class="regexp">/u01/</span>app/oracle/admin/catlogdb/bdump</span><br><span class="line">core_dump_dest=<span class="regexp">/u01/</span>app/oracle/admin/catlogdb/cdump</span><br><span class="line">user_dump_dest=<span class="regexp">/u01/</span>app/oracle/admin/catlogdb/udump</span><br><span class="line"></span><br><span class="line">db_recovery_file_dest=<span class="regexp">/u01/</span>app/oracle/flash_recovery_area/catlogdb</span><br><span class="line">db_recovery_file_dest_size=1G</span><br></pre></td></tr></table></figure>

<p>三个控制文件control01.ctl,control02.ctl和control03.ctl内容是完全一样的,最好将其分散到不同的驱动器上以提高控制文件的安全性,这叫做多路镜像multiplexing</p>
<p><strong>4、创建spfile并启动实例</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sqlplus / <span class="keyword">as</span> sysdba;</span><br><span class="line">SQL&gt; create spfile <span class="keyword">from</span> pfile;</span><br></pre></td></tr></table></figure>
<p>这会在$ORACLE_HOME/dbs/目录下生成spfile参数文件spfilecatlogdb.ora,这是服务器端的参数文件,关于参数文件详见”<a href="https://openwares.net/database/pfile_and_spfile.html">oracle初始化参数文件pfile和spfile</a>“</p>
<p>启动实例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; startup nomount</span><br></pre></td></tr></table></figure>
<p><strong>5、创建数据库</strong></p>
<p>建库脚本createdb.sql如下：<br>[sql]<br>CREATE DATABASE catlogdb<br> USER SYS IDENTIFIED BY oracle<br> USER SYSTEM IDENTIFIED BY oracle<br> LOGFILE GROUP 1 (‘/u01/oradata/catlogdb/redo01.log’) SIZE 100M,<br> GROUP 2 (‘/u01/oradata/catlogdb/redo02.log’) SIZE 100M,<br> GROUP 3 (‘/u01/oradata/catlogdb/redo03.log’) SIZE 100M<br> MAXLOGFILES 5<br> MAXLOGMEMBERS 5<br> MAXLOGHISTORY 1<br> MAXDATAFILES 100<br> MAXINSTANCES 1<br> CHARACTER SET AL32UTF8<br> NATIONAL CHARACTER SET UTF8<br> EXTENT MANAGEMENT LOCAL<br> DATAFILE ‘/u01/oradata/catlogdb/system01.dbf’ SIZE 325M REUSE<br> SYSAUX DATAFILE ‘/u01/oradata/catlogdb/sysaux01.dbf’ SIZE 325M REUSE<br> DEFAULT TABLESPACE users<br> DATAFILE ‘/u01/oradata/catlogdb/users01.dbf’<br> SIZE 500M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED<br> DEFAULT TEMPORARY TABLESPACE tempts1<br> TEMPFILE ‘/u01/oradata/catlogdb/temp01.dbf’<br> SIZE 20M REUSE<br> UNDO TABLESPACE undotbs1<br> DATAFILE ‘/u01/oradata/catlogdb/undo01.dbf’<br> SIZE 200M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED;<br>[/sql]</p>
<p>执行建库脚本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; @createdb.sql;</span><br><span class="line">Database created.</span><br><span class="line">Tablespace created.</span><br><span class="line">Database altered.</span><br></pre></td></tr></table></figure>
<p><strong>6、运行系统脚本建立数据字典视图</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; @?<span class="regexp">/rdbms/</span>admin/catalog.sql;</span><br><span class="line">SQL&gt; @?<span class="regexp">/rdbms/</span>admin/catproc.sql;</span><br></pre></td></tr></table></figure>
<p><strong>7、编辑对外监听配置文件</strong></p>
<p>监听文件$ORACLE_HOME/network/admin/listener.ora内容：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SID_LIST_LISTENER =</span><br><span class="line"> (SID_LIST =</span><br><span class="line"> (SID_DESC =</span><br><span class="line"> (GLOBAL_DBNAME = catlogdb)</span><br><span class="line"> (ORACLE_HOME = <span class="regexp">/u01/</span>app/oracle/product/<span class="number">10.2</span><span class="number">.0</span>/db_1)</span><br><span class="line"> (SID_NAME = catlogdb)</span><br><span class="line"> )</span><br><span class="line"> )</span><br><span class="line"> </span><br><span class="line"> LISTENER =</span><br><span class="line"> (DESCRIPTION_LIST =</span><br><span class="line"> (DESCRIPTION =</span><br><span class="line"> (ADDRESS = (PROTOCOL = TCP)(HOST = hostname.domain)(PORT = <span class="number">1521</span>))</span><br><span class="line"> )</span><br><span class="line"> )</span><br></pre></td></tr></table></figure>
<p>其中hostname为主机名,domain为主机域名,也可以用ip地址来代替hostname.domain字段。</p>
<p><strong>建库完毕。</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>crontab环境变量问题</title>
    <url>/2016/05/10/crontab-environ-vars/</url>
    <content><![CDATA[<a id="more"></a>
<p>python脚本在shell下运行的好好的，作为crontab任务运行就出错，import cx_Oracle的时候出错：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ImportError: libclntsh.so<span class="number">.12</span><span class="number">.1</span>: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>

<p>明显是库路径的问题。</p>
<p>crontab运行程序时，其环境变量与用户的环境变量是不同的，有自己的变量环境，因此需要为crontab设置正确的环境变量，脚本才能正确运行。</p>
<p>python脚本中使用os.environ或者os.putenv来设置环境变量是没用的，反正在py脚本中正确设置了LD_LIBRARY_PATH变量，仍然无法解决问题。</p>
<p>有这么几个方法来设置crontab的环境变量：</p>
<p><strong>第一种</strong></p>
<p>可以在crontab配置文件中添加环境变量，但是不能用变量，类似$PATH这种，只能照实写。<br>类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORACLE_HOME=<span class="regexp">/opt/</span>oracle/instantclient_12_1</span><br><span class="line">LD_LIBRARY_PATH=<span class="regexp">/opt/</span>oracle/instantclient_12_1</span><br><span class="line">PATH=<span class="regexp">/opt/</span>oracle/instantclient_12_1</span><br><span class="line">TNS_ADMIN=<span class="regexp">/opt/</span>oracle/instantclient_12_1</span><br><span class="line">SQLPATH=<span class="regexp">/opt/</span>oracle/instantclient_12_1</span><br><span class="line">NLS_LANG=AMERICAN_AMERICA.AL32UTF8</span><br></pre></td></tr></table></figure>
<p><strong>第二种</strong></p>
<p>写一个bash脚本来中转一下，bash脚本中再调用py脚本，类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"><span class="keyword">export</span> ORACLE_HOME=<span class="regexp">/opt/</span>oracle/instantclient_12_1</span><br><span class="line">source /home/xxx/.mybashrc</span><br><span class="line">/home/xxx/py/business_notify.py <span class="string">&quot;$@&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>第三种</strong></p>
<p>直接在crontab配置任务要执行的命令行上添加环境变量，类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">*<span class="regexp">/10 * * * * LD_LIBRARY_PATH=/</span>opt/oracle/instantclient_12_1 TNS_ADMIN=<span class="regexp">/opt/</span>oracle/instantclient_12_1 /home/xxx/py/business_notify.py</span><br></pre></td></tr></table></figure>

<p>推荐第一种</p>
<p>一般crontab运行的脚本中尽量不要依赖环境变量，使用绝对路径为佳。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS背景图片定位属性background-position</title>
    <url>/2013/06/17/css-background-position/</url>
    <content><![CDATA[<p>background-position用来指定背景图片左上角相对于容器元素左上角的位置</p>
<a id="more"></a>
<p>有三种方式来指定background-position的值：<br>1、可以用top,left,center,right,bottom等值，比如background-position: top left;<br>2、使用百分比,比如background-position: 0% 0%;<br>3、使用像素值，比如background-position: 0px 0px;</p>
<p>以指定像素值来说，将容器元素的左上角作为原点(0,0),用背景图片的左上角相对于原点来指定x和y方向的像素值，x坐标向右为正，y坐标向下为正，与浏览器的视口坐标方向一致。</p>
<p>比如background-position: -10px -10px; 背景图片与容器元素的相对位置如下图所示<br>[javascript]<br>(-10,-10)<br> +———–+———-</p>
<p> background </p>
<p> ———–+———-&gt; X<br> (0,0)<br> container</p>
<p> V<br> Y<br>[/javascript]</p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS垂直外边距合并</title>
    <url>/2014/03/11/css-margin-collapse/</url>
    <content><![CDATA[<a id="more"></a>
<p>这几天写CSS的时候发现一个奇怪的现象,子元素的margin-top会影响父元素的margin-top。本来父元素只是一个简单的容器,没有设置样式,第一个子元素设置了margin-top后,父元素也具有了一样的margin-top,原来是边距合并(Margin Collapse)在作怪。</p>
<p>普通文档流中相邻的块框,还有父元素与第一个子元素的上边距,父元素与最后一个子元素的下边距都有可能会发生外边距合并,这其中有些复杂的规则存在,与BFC(Block formatting contexts)密切相关,在同一个BFC(块格式化上下文)中，相邻的块级框之间的垂直外边距会出现折叠。详细的描述见参考文档[1]和[2],文档[1]描述的十分详细,这里就没必要再重复了。</p>
<p>防止父子元素外边据合并的常用方法有:</p>
<ul>
<li>  父元素设置overflow:visible之外的其他值</li>
<li>  父元素设置border<br>比如设置一个1px透明的border<br>[css]<br>border: 1px solid transparent;/<em>透明边框,防止父子元素垂直边距合并</em>/<br>[/css]</li>
<li>  父元素或子元素设置float属性</li>
<li>  父元素设置padding-top(padding-top:1px)</li>
<li>  设置父元素或者自身display:inline-block</li>
<li>  父元素或子元素绝对定位(absolute或fix)</li>
<li>  设置父元素非空，填充一定的内容</li>
</ul>
<p><strong>注意：只有普通文档流中块框的垂直外边距才会发生外边距合并。行内框、浮动框或绝对定位之间的外边距不会合并。</strong></p>
<p>References:<br>[1]<a href="http://www.w3cplus.com/css/understanding-bfc-and-margin-collapse.html">深入理解BFC和Margin Collapse</a><br>[2]<a href="http://www.w3school.com.cn/css/css_margin_collapsing.asp">CSS 外边距合并</a><br>[3]<a href="http://www.planabc.net/2007/03/18/css_attribute_margin/">由浅入深漫谈margin属性</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS打印分页的坑</title>
    <url>/2015/05/08/css-page-break-bitch/</url>
    <content><![CDATA[<p>CSS有几个控制分页的属性page-break-before,page-break-after和page-break-inside,要注意使用这些属性时一定要使用在块级元素上。只有firefox对inline元素也有效,而chrome和safari则只在block元素上生效,大坑啊，那就用div好了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>CSS print 样式</title>
    <url>/2014/03/13/css-print-style/</url>
    <content><![CDATA[<a id="more"></a>
<p>显示器(screen)和打印机(printer)是两种差别很大的设备,所以从浏览器里看到的页面,打印出来也许和你看到的样子有很大的差距。screen一般使用逻辑单位比如px,而打印机则应该使用物理单位比如cm或in。我们常见的A4纸张大小在不同DPI的显示器上显示的大小是不同的。因此如果要精确的控制打印效果就应该使用print css，这是跨平台兼容的标准。不推荐使用浏览器插件方式实现打印。</p>
<p>web打印还有一种解决方式是生成pdf格式文件,客户端下载来打印,这也是不错的一种打印方式,因为pdf本身就是一种打印标准,可以做到精确控制。可以使用<a href="http://parall.ax/products/jspdf">jsPDF</a>在客户端动态生成pdf,也可以在服务器端使用一些组件生成pdf后传送给客户端。当然首选还是使用print css来实现打印。</p>
<p><strong>引入print css</strong></p>
<ul>
<li>  使用link标签<br>就像通常在html页面中引入样式表一样,不过附加一个额外的media属性,如下面这样:<br>[html]<link rel="stylesheet" href="print.css" media="print" />
\[/html\]
表明print.css样式表是用于打印的</li>
<li>使用@media规则<br>可以在通用的样式表中,使用@media规则指定样式用于打印,比如这样:<br>[html]<br>@media print selector {<br>…<br>}<br>[/html]<br>或者<br>[html]<br>@media print {<br>selector {<br>…<br>}<br>}<br>[/html]</li>
<li>  使用@import规则<br>使用@import规则在通用的样式表中导入打印样式表,有两种形式,其本质是一样的。<br>css文件中:<br>[html]<br>@import url(print-style.css) print;<br>[/html]</li>
</ul>
<p>html文件中:<br>[html]</p>
<style type="text/css">
@import url(print-style.css) print;
</style>
<p>[/html]</p>
<p>使用link标签要比使用@import规则性能更好。</p>
<p><strong>度量单位</strong></p>
<p>显示时一般使用px,em或pt等逻辑单位,但在打印时要使用物理单位,比如cm或in(英寸)。对于常见的DPI(Dot Per Inch)为96的screen,px与cm的换算关系如下：</p>
<p>1 inch = 2.54 cm<br>1cm = 96/2.54 ≈ 37.80 px<br>1px = 2.54/96 ≈ 0.0265 cm<br>100px = 2.65 cm</p>
<p>A4纸的标准尺寸为:<br>21.0cm * 29.7 cm</p>
<p>在96DPI分辨率下,其对应的像素尺寸大约为:<br>794px * 1123px</p>
<p>因为不同的DPI下,其对应的像素尺寸是不同的,所以才要使用print css,使用物理单位来描述要打印的页面,这样打印效果就会一致了。</p>
<p><strong>@page规则(at-rule)</strong></p>
<p>@page 规则用于指定打印页面的一些属性,包括纸张尺寸,方向,页边距,分页等特性。其语法如下:</p>
<p>[html]<br>@page :pseudo-class {<br> size: A4 landscape;<br> margin:2cm;<br>}<br>[/html]<br>其中伪类可以指定:</p>
<ul>
<li>  :first<br>指定第一页</li>
<li>  :left<br>指定左侧页面</li>
<li>  :right<br>指定右侧页面</li>
</ul>
<p><strong>分页(paginate)</strong></p>
<p>有几个用于控制打印分页的属性可以用于常规的标签元素:</p>
<ul>
<li><p>  page-break-before<br>用于设置元素前面的分页行为,可取值:</p>
</li>
<li><p>  auto<br>默认值。如果必要则在元素前插入分页符。</p>
</li>
<li><p>  always<br>在元素前插入分页符。</p>
</li>
<li><p>  avoid<br>避免在元素前插入分页符。</p>
</li>
<li><p>  left<br>在元素之前足够的分页符，一直到一张空白的左页为止。</p>
</li>
<li><p>  right<br>在元素之前足够的分页符，一直到一张空白的右页为止。</p>
</li>
<li><p>  inherit<br>规定应该从父元素继承 page-break-before 属性的设置。</p>
</li>
<li><p>  page-break-after<br>设置元素后的分页行为。取值与page-break-before一样。</p>
</li>
<li><p>  page-break-inside<br>设置元素内部的分页行为。取值如下:</p>
</li>
<li><p>  auto<br>默认。如果必要则在元素内部插入分页符。</p>
</li>
<li><p>  avoid<br>避免在元素内部插入分页符。</p>
</li>
<li><p>  inherit<br>规定应该从父元素继承 page-break-inside 属性的设置。</p>
</li>
</ul>
<p>比如:<br>[html]<br>@media print {<br> section {page-break-before: always;}<br> h1 {page-break-after: always;}<br> p {page-break-inside: avoid;}<br>}<br>[/html]</p>
<ul>
<li>  orphans<br>设置当元素内部发生分页时必须在页面底部保留的最少行数。</li>
<li>widows<br>设置当元素内部发生分页时必须在页面顶部保留的最少行数。比如:<br>[html]<br>@media print {<br>p {orphans:3; widows:2;}<br>}<br>[/html]</li>
</ul>
<p><strong>其他</strong><br>对于页面上有显示而不想打印的内容,可以将其display设置为none来避免打印。需要打印的内容尽量避免float,有些浏览器不会正确的打印浮动的内容。</p>
<p>可以调用window.print()函数来打印当前页面。</p>
<p>References:<br>[1]<a href="http://edutechwiki.unige.ch/en/CSS_for_print_tutorial">CSS for print tutorial</a><br>[2]<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@page">@page</a><br>[3]<a href="http://www.w3school.com.cn/cssref/#print">CSS 打印属性（Print）</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS替换元素(Replaced element)</title>
    <url>/2014/03/14/css-replaced-element/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>替换元素</strong></p>
<p>其内容不受<a href="https://openwares.net/internet/css_visual_formatting_model.html">CSS视觉格式化模型</a>控制的元素,比如image,嵌入的文档(iframe之类)或者applet,叫做替换元素。比如,img元素的内容通常会被其src属性指定的图像替换掉。替换元素通常有其固有的尺寸:一个固有的宽度,一个固有的高度和一个固有的比率。比如一幅位图有固有用绝对单位指定的宽度和高度,从而也有固有的宽高比率。另一方面,其他文档也可能没有固有的尺寸,比如一个空白的html文档。</p>
<p>CSS渲染模型不考虑替换元素内容的渲染。这些替换元素的展现独立于CSS。object,video,textarea,input也是替换元素,audio和canvas在某些特定情形下为替换元素。使用CSS的content属性插入的对象是匿名替换元素。</p>
<p><strong>固有尺寸</strong></p>
<p>宽度和高度是有元素自身定义的,不受周围元素的影响。CSS没有定义如何去寻找替换元素的固有尺寸。在CSS 2.1中,只有替换元素可以有固有的尺寸。对于没有可靠的解析度信息的光栅图像,必须假定一个图像源像素为一个px单位。</p>
<p>一些CSS属性比如vertical-align可能会用到替换元素的固有尺寸或基线。</p>
<p><strong>非替换元素</strong></p>
<p>替换元素之外的所有其他元素都是非替换元素,由CSS的视觉格式化模型负责非替换元素的渲染。</p>
<p><strong>混乱的术语</strong></p>
<p>看到有些文章中将这两种元素称作可替换元素和不可替换元素,这种叫法很明显是错误的。<br>首先，从w3c标准的原始定义中替换元素使用了Replaced而不是Replaceable。<br>其次,替换元素和非替换元素是已经被替换(CSS不负责其展示渲染,由其固有属性接管渲染)和不会被替换(由CSS负责展示渲染)，而不是可不可以被替换的概念。</p>
<p>References:<br>[1]<a href="http://www.w3.org/TR/CSS21/conform.html#w3.org:replaced-element">Replaced element</a><br>[2]<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Replaced_element">MDN:Replaced element</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS视觉格式化模型(Visual Formatting Model)</title>
    <url>/2014/03/16/css-visual-formatting-model/</url>
    <content><![CDATA[<p>CSS视觉格式化模型用于计算如何布置和渲染各种元素,是HTML页面呈现的核心模型。</p>
<a id="more"></a>
<p>视觉格式化模型是CSS核心的,基础的概念。要完全掌控页面的展示效果,了解视觉格式化模型是有必要的。</p>
<p>视觉格式化模型比较复杂,要完整的描述需要很多笔墨,这里只讲核心的概念,更详细的描述见参考[1],[2],[3]和[4]。</p>
<p><strong>核心概念</strong></p>
<p>对于CSS的box,有些人翻译为”框”,有些人翻译为”盒”,无论框还是盒都还是指的那一个box,这一点需要明确一下。</p>
<ul>
<li>  <strong>块级元素,块级框,块框,块容器框,匿名块框和块格式化上下文</strong></li>
</ul>
<p><strong>块级(block-level)元素</strong>在页面上表现为一个块,单独占有一行,与<strong>块格式化上下文</strong>(Block Formatting Context)中的其他块按顺序垂直排列。浮动是一种特殊情况。当元素的CSS属性display为 block, list-item 或 table 时,它是块级(block-level)元素。</p>
<p>每个块级元素生成一个主要的<strong>块级框</strong>(Block-level box)来包含其子框和生成的内容，同时任何定位方案都会与这个主要的框有关。某些块级元素还会在主要框之外产生额外的框：例如“list-item”元素。这些额外的框会相对于主要框来放置。</p>
<p>除了table框和替换元素块级框,一个块级框可能也是一个<strong>块容器框</strong>(block container box)。块容器框只包含其他块级框,或者创建一个行内格式化上下文(inline formatting context)从而只包含行内框。</p>
<p>同时是块容器框的块级框称为<strong>块框</strong>(block boxes)。并非所有的块容器框都是块级框：非替换的行内块和非替换的table cell也是块容器但不是块级框。</p>
<p>有时需要添加补充性盒，这些盒称为<strong>匿名块框</strong>(anonymous box), 它们没有名字，不能被 CSS 选择符选中。不能被 CSS 选择符选中意味着不能用样式表添加样式。这意味着所有继承的 CSS 属性值为 inherit ，所有非继承的 CSS 属性值为 initial 。比如下面一段HTML会生成两个匿名块框,在div内部但在p外部的文本会被匿名块框包裹。<br>[html]</p>
<div>Some inline text <p>followed by a paragraph</p> followed by more inline text.</div>
\[/html\]

<p>块格式化上下文BFC包含一组相关的块框,这些块框在同一个BFC内按预定规则进行排列。</p>
<ul>
<li>  <strong>行内级元素,行内级框,行内框,行框,匿名行级框和行格式化上下文</strong></li>
</ul>
<p>当元素的CSS属性display的计算值为 inline, inline-block 或 inline-table 时，称它为<strong>行内级(inline-level)元素</strong>。行内级元素与其他行内级元素共享行。行内级元素生成<strong>行内级框</strong>(inline-level box),同时参与生成<strong>行内格式化上下文</strong>(inline formatting context)的行内级框称为<strong>行内框</strong>(Inline boxes)，因此，行内框是行内级框的一种。那些不是行内框的行内级框(例如替换的行级元素、行内块元素、行内表格元素)被称为<strong>原子行内级框</strong>(atomic inline-level box),因为它们是以单一不透明框的形式来参与其行格式化上下文,原子行内级框在行内格式化上下文IFC里不能分成多行。</p>
<p><strong>匿名行内框</strong>(Anonymous inline boxes)类似于块盒，CSS引擎有时自动生成行内框。这些框也是匿名的，因为它们没有对应的选择器名字。它们继承所有可继承的属性，非继承的属性取 initial。 匿名行内框最常见的例子是块框直接包含文本，文本将包含在匿名行内框中。</p>
<p><strong>行框</strong>(Line boxes)由行内格式化上下文(inline formatting context)产生的框，用于表示一行。在包含块里面，行框从包含快一边排版到另一边。 当有浮动时, 行框从左浮动的最右边排版到右浮动的最左边。行框是行内框的容器,类似于块容器框是块框的容器。</p>
<p>行内格式化上下文IFC包含一组相关的行内框,这些行内框在同一个IFC内按预定规则进行排列。</p>
<ul>
<li>  <strong>堆叠上下文</strong></li>
</ul>
<p>单纯的z-index并不能最终决定元素在Z轴上的排列顺序,还要关系到<strong>堆叠上下文</strong>(stacking context)。堆叠上下文的优先级要高于z-index。也就是z-index值很大也不一定能排列到Z轴的前面,还要先看所处的堆叠上下文。参考[4]对此问题描述的比较详细清楚。</p>
<p><strong>块格式化上下文(BFC),行格式化上下文(IFC)和堆叠上下文(SC)都有不同的产生条件和时机</strong>,具体请参考其他文档。</p>
<p>[1]MDN:<a href="https://developer.mozilla.org/zh-CN/docs/CSS/Visual_formatting_model">视觉格式化模型</a><br>[2]w3.org:<a href="http://www.w3.org/html/ig/zh/wiki/CSS2/visuren">视觉格式化模型</a><br>[3]MDN:<a href="https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Understanding_z_index/The_stacking_context">The stacking context</a><br>[4]<a href="http://www.html5kit.com/article/777.html">关于z-index的那些事儿</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>linux下cups打印奇偶页</title>
    <url>/2014/12/24/cups-even-odd/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian系统提供的打印对话框，竟然没有打印奇偶页的选项,一下命令可以满足要求：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lp -o page-set=odd filename <span class="comment">//只打印奇数页</span></span><br><span class="line">$ lp -o page-set=even filename <span class="comment">//只打印偶数页</span></span><br></pre></td></tr></table></figure>


<p>References:<br>[1] <a href="http://www.xgezhang.com/linux_cups.html">Linux下通用打印系统CUPS使用教程</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用cwrap调用WebAssembly模块方法</title>
    <url>/2018/11/27/cwrap-call-webassembly-method/</url>
    <content><![CDATA[<a id="more"></a>
<p>Emscripten提供了很多库的webassembly实现，甚至为了文件系统存取还提供了虚拟文件系统，这可以让很多C/C++代码做很少的修改就可以移植到web上来运行。</p>
<p>目前来讲js直接与wasm代码交互还不是那么方便，通过Emscripten提供的js glue代码可以使这个过程更简单一点。</p>
<p>胶水代码导出了一个名字空间Module，其中有两个方法ccall和cwarp作为桥接原生代码的桥梁，ccall适合一次性的调用C/C++函数，而cwrap则返回一个函数适配器，适合多次反复调用C/C++代码。</p>
<p>使用如下命令编译C/C++代码：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ emcc area.c triangle.c -Os -s WASM=<span class="number">1</span> -o area.js </span><br><span class="line">-s <span class="string">&quot;EXPORTED_FUNCTIONS=\[&#x27;_getArea&#x27;\]&quot;</span> </span><br><span class="line">-s EXTRA_EXPORTED_RUNTIME_METHODS=<span class="string">&#x27;\[&quot;ccall&quot;, &quot;cwrap&quot;\]&#x27;</span></span><br></pre></td></tr></table></figure>

<p>-Oz比-Os可以做更进一步的编译器优化，生成的代码更小。</p>
<p>除了要导出你自己的函数之外，还要导出这两个辅助方法ccall和cwrap<br>编译完后会生成area.wasm和胶水代码area.js</p>
<p>将area.js导入到html中，然后就可以写下面的代码来获取到导出的函数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> area = Module.cwrap(<span class="string">&#x27;getArea&#x27;</span>, <span class="string">&#x27;number&#x27;</span>, \[<span class="string">&#x27;number&#x27;</span>, <span class="string">&#x27;array&#x27;</span>\]);</span><br></pre></td></tr></table></figure>

<p>cwrap的第一个参数为导出的函数名，第二个参数为函数返回值，第三个参数为函数的参数。<br>目前数据类型支持的很少，有number, array, string, boolean, null等，而且array只接受Uint8Array类型。<br>对于C/C++的指针类型可以用array来传递数据。</p>
<p>对于ccall来讲，则除了cwrap的参数之外，还要将函数的实参传递进去，完成真正的函数调用，然后返回函数值。</p>
<p>References:<br>[1]<a href="http://kripken.github.io/emscripten-site/docs/porting/connecting_cpp_and_javascript/Interacting-with-code.html">Interacting with code</a></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
  </entry>
  <entry>
    <title>DAS,SAN和NAS</title>
    <url>/2011/03/17/das-san-nas/</url>
    <content><![CDATA[<p>对于服务器来讲，一般除了内置的本地存储设备外，由于容量、安全性、冗余、备份等等的需求，还需要外挂存储设备。外挂式存储设备一般包括磁盘阵列柜、磁盘柜(JBOD,Just a Bunch Of Disks)、磁带柜、光盘柜等。</p>
<a id="more"></a>
<p>外挂式存储设备接口方式一般分为DAS,SAN和NAS这三种。</p>
<p><strong>DAS</strong></p>
<p>直接附加存储DAS(Direct Attached Storage)是现在最常见的外挂存储模式，一般为服务器通过SCSI或者FC(Fibre Channel)通道连接外挂式存储设备。每一组服务器和DAS存储的组合都是完全独立的,形成一个个存储的孤岛。</p>
<p><strong>SAN</strong></p>
<p>存储区域网络SAN(Storage Area Network)则是以类似于局域网的方式将外挂存储设备和服务器通过特定的协议连接成一个存储网络，如使用比较常见的光纤通道协议(Fibre Channel Protocol)，外挂存储设备和服务器都通过FC接口连接到光纤通道交换机,实现外挂存储设备的集中式管理。如果使用其他连接协议，比如基于TCP/IP网络的iSCSI协议组成IP SAN,则可以大大的延伸存储网络可以跨域的地域范围。</p>
<p>SAN中,服务器与外挂式存储设备物理上不是直接相连的，服务器不用关心存储设备的地理位置。SAN将存储设备从服务器中分离出来，管理起来更加方便。</p>
<p>SAN网络中，服务器对存储设备的存取仍然是块级别的,从服务器的视角看，存储设备仍然是与其直接相连的,文件系统是由服务器管理，而不是存储设备自己管理的。</p>
<p>SAN网络中，服务器可以设置为从SAN网络中的存储设备启动,当服务器发生故障时，可以通过更换服务器从原来的SAN设备启动来迅速的恢复故障。SAN可以通过多种方式实现存储冗余。</p>
<p>SAN中存储设备不能由多个服务器共享同时存取。</p>
<p><strong>NAS</strong></p>
<p>网络附加存储NAS(Network Attached Storage)是外挂式存储设备通过交换机连接入计算机网络(TCP/IP)，提供文件级别的存取访问功能，比如使用NFS或SMB/CIFS等通信协议。也就是说NAS设备提供一个基于计算机网络的远程文件系统,这个文件系统是由NAS自己管理的，这是与SAN的最大的区别。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>数据库高可用概念(database high availability)</title>
    <url>/2015/11/03/database-high-availability/</url>
    <content><![CDATA[<a id="more"></a>
<p>数据库高可用是为了降低停机时间，提高数据库服务器的持续服务能力，减少数据丢失，减少服务恢复时间。</p>
<p>大体可以有以下几个分类：</p>
<ul>
<li>  cold standby<br>最传统的备份/恢复模式属于此类。主库定期备份，备份数据可以存储到主库以外的其他存储介质上。当主库当机时，启动备机，从备份中恢复主库最近的一次备份，然后接替主库对外提供服务。这种模式数据丢失的风险极大，最后一次备份到当机之间的数据丢失的可能性很大。而且，当数据库很大时，备机的恢复时间可能会相当长，达几个小时甚至几十个小时。</li>
<li>  warm standby<br>主备库同时运行，主库数据以同步或异步方式复制到备库，主库崩溃时的恢复时间很短，但是备库在正常状态下是无法提供服务的。</li>
<li>  hot standby<br>主备库同时运行，主库数据以同步或异步方式复制到备库，主库崩溃时的恢复时间很短，备库可以提供只读查询服务。如果是流式复制方式，一般提交的事务都不会丢失。数据丢失的风险很低。</li>
<li>  active-active<br>这就是传说中的双活或多活，或叫master-master模式，多个数据库互为主备，一起对外提供服务，一个崩溃，不影响系统对外提供服务，只是服务的性能会有下降。这种模式又可以称作负载均衡load balance。</li>
</ul>
<p>postgresql对warm standby和hot standby的定义:</p>
<p>A standby server that cannot be connected to until it is promoted to a master server is called a warm standby server, and one that can accept connections and serves read-only queries is called a hot standby server.</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>danted + redsocks + iptables/nftables全局socks5代理配置</title>
    <url>/2020/06/28/danted-redsocks-iptables-nftables-global-socks5-proxy-config/</url>
    <content><![CDATA[<a id="more"></a>
<p>1、danted<br>安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install dante-server</span><br></pre></td></tr></table></figure>

<p>配置/etc/danted.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">logoutput: syslog /<span class="keyword">var</span>/log/sockd.log stdout</span><br><span class="line">internal: br0 port = <span class="number">1080</span></span><br><span class="line">external: <span class="number">10.100</span><span class="number">.0</span><span class="number">.32</span></span><br><span class="line">clientmethod: none</span><br><span class="line">socksmethod: none</span><br><span class="line">user.privileged: proxy</span><br><span class="line">user.unprivileged: nobody</span><br><span class="line">user.libwrap: nobody</span><br><span class="line">client pass &#123;</span><br><span class="line"> <span class="keyword">from</span>: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> port <span class="number">1</span>-<span class="number">65535</span> to: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">socks pass &#123;</span><br><span class="line"> <span class="keyword">from</span>: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">8</span> to: <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span></span><br><span class="line"> command: bind connect udpassociate</span><br><span class="line"> log: error</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库命名及设计简单规范</title>
    <url>/2013/11/01/database-naming-convention/</url>
    <content><![CDATA[<p>数据库命名及设计简单规范</p>
<a id="more"></a>
<h5 id="命名规范"><a href="#命名规范" class="headerlink" title="命名规范"></a>命名规范</h5><p>所有schema对象的命名使用其英语含义，杜绝使用汉语拼音以及汉语拼音首字母缩写。<br>sql脚本中sql标准关键字用大写,所有用户自定义对象名字用小写。<br>尽量不要用缩写词，如用缩写词一定要容易辨识，不要太简略。</p>
<p><em><strong>表</strong></em></p>
<p>tb_<br>表名以前缀tb_开头,后面跟表的实际名字,如果表名字需要几个单词来表单，单词之间用下划线_分隔,全部用小写字母。如：</p>
<p>tb_orders<br>tb_have_multi_words</p>
<p>如多个模块有名字重复的表，可以在表名字前添加模块名，并用下划线分隔。</p>
<p>用户维护字典表使用dic_格式，如有与用户维护字典表名字冲突的应用系统内部维护字典表使用dic__system。</p>
<p><strong><em>字段</em></strong></p>
<p>字段名字不要带表名字前缀，因为表名字本身就是字段的名字空间。如用多个单词，每个单词间用下划线_分隔。字段名全部使用小写字母。<br>主键命名有点儿例外，如果主键是没有业务含义的逻辑主键,名字可以直接用id，如果是业务主键则要用_id的格式</p>
<p>字段是顺序码可以用id命名，如果字段是按特定规范的固定编码可以用code命名。</p>
<p>如果字段是boolean类型，不要使用is前缀，实体生成工具产生getter/setter方法时可能会出现意想不到的结果。</p>
<p><em><strong>约束</strong></em></p>
<p>所有约束都要命名，而不要依赖数据库系统默认生成的名字。这里提及的表名不要带tb_前缀</p>
<ul>
<li>  检查约束Check Constraints<br>ck___，比如订单表的订单号只能大于零，可以这样命名如下：<br>ck_orders_orderid_gt_zero</li>
<li>  非空约束Not-Null Constraints<br>nn__<br>注：因为PostgreSQL在违反非空约束时，根本不提及非空约束的名字，所以非空约束在PostgreSQL中可以不命名。</li>
<li>  唯一约束Unique Constraints<br>uk__,如果是组合字段，则把所有的字段都添加到后面，用下划线分隔。</li>
<li>  主键约束Primary Keys<br>pk_，因为主键只有一个，可以不用指名主键字段名。一个表只能有一个单一字段主键，而且一定要把主键放在表的第一个字段。</li>
<li>  外键约束Foreign Keys<br>fk___</li>
</ul>
<p><em><strong>视图</strong></em><br>vw_</p>
<p><em><strong>存储过程</strong></em><br>sp_</p>
<p><em><strong>函数</strong></em><br>fn_</p>
<p><em><strong>触发器</strong></em><br>tr_</p>
<p><em><strong>表空间</strong></em><br>ts_</p>
<p><em><strong>数据文件</strong></em></p>
<h5 id="设计规范"><a href="#设计规范" class="headerlink" title="设计规范"></a>设计规范</h5><ul>
<li>  每个表都应该有主键,根据实际情况采用业务主键或逻辑主键皆可</li>
<li>  避免使用复合主键</li>
<li>  尽量使用各种约束来规范表数据</li>
<li>  尽量符合数据库设计范式，一般达到第三范式就可以了</li>
<li>  为可空字段设定默认值<br>因为NULL值是不确定的，程序中处理起来比较繁琐，应该为所有允许不提供值的字段设定默认值。</li>
<li>  避免使用触发器</li>
<li>  尽量少用存储过程，特别是业务逻辑不能写在存储过程中。数据统计时可以适当使用存储过程。</li>
<li>  根据建库sql脚本,自动生成数据库结构设计文档，而不是在多处维护文档<br>可以通过注释机制，自定义一些注释元字符，建库脚本中合理注释，然后通过程序或shell脚本处理sql脚本生成数据库结构设计文档</li>
<li>  版本化数据库<br>详见<a href="https://openwares.net/database/database_version_control.html">数据库版本控制</a></li>
<li>  关注数据库设计可移植性</li>
</ul>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库版本控制</title>
    <url>/2013/10/30/database-version-control/</url>
    <content><![CDATA[<p>代码的版本控制十分常见，数据库版本也有必要纳入版本控制。</p>
<a id="more"></a>
<p>开发和维护过程中，数据库的schema发生变化是难以避免的，而相关数据库脚本不做版本控制，很容易造成开发，测试，上线时的混乱。<br>一般来说，数据库版本会有一个baseline,之后所有的变化都通过升级脚本来更新。特别是对于生产库来讲，drop然后重新create是不可能的，必须通过升级脚本来升级数据库。</p>
<p><strong>版本控制策略</strong></p>
<p>将数据库脚本与源代码一起纳入repo的管理。应用程序的每一个release版本包含一个重新设立的基线脚本和增量升级脚本。</p>
<p>重新设立的基线baseline脚本用来初始化一个全新的数据库，而增量脚本则是针对上一个release版本发布以来，到当前release版本之间的数据库schema变化。<br>而且增量脚本绝对不容许跨多个release版本，只能是针对上一个release版本的变化。</p>
<p>对于一个全新的安装，比如测试安装，或者新客户安装，只要从代码库里检出需要的release版本，然后执行基线脚本就可以了，没有任何历史负担。<br>而对于升级安装来说，则需要执行增量升级脚本。</p>
<p>增量升级脚本必须检查应用程序当前的数据库版本，如果应用程序使用的数据库版本是上个release的数据库版本，则可以升级，否则拒绝升级。<br>这需要在数据库中设置版本记录表，比如：<br>记录应用程序版本<br>[sql]<br>CREATE TABLE appversion (<br> id INTEGER PRIMARY KEY,<br> name varchar(20),<br> version varchar(20),<br> applied_time time,<br> remarks varchar(255)<br>)<br>[/sql]</p>
<p>记录数据库版本:<br>[sql]<br>CREATE TABLE dbversion (<br> id INTEGER PRIMARY KEY,<br> name varchar(20),<br> version varchar(20),<br> applied_time time,<br> remarks varchar(255)<br>)<br>[/sql]</p>
<p>数据库版本号采用与应用程序一致的版本号，比如常用的主.次.修订.build。应用程序启动时如果发现数据库版本与其不一致，可以给出提示，拒绝启动。</p>
<p>由于schema变化导致的数据迁移脚本也要与增量脚本一起提供，基线版本则没有这个问题。</p>
<p>对于划分模块，每个模块负责自己的数据库设计和修改的情况，可以提供统一的shell脚本来逐一调用每个模块的基线和增量数据库脚本。<br>也就是每个模块维护自己的基线和数据库脚本，由调用shell脚本负责统一更新应用程序记载的数据库版本号。</p>
<p>基线脚本或增量脚本可以写在一个文件中，也可以拆分到几个文件中。脚本可以手写，当然也可以采用数据库提供的工具来自动生成。</p>
<p>增量升级时建议将Views, Stored Procedures和funcations等drop掉重新create,这样可以<a href="http://odetocode.com/blogs/scott/archive/2008/02/02/versioning-databases-views-stored-procedures-and-the-like.aspx">避免很多问题</a>。</p>
<p>采用这种版本策略，如果生产中的应用程序要跨版本升级是不可以的，必须逐个release依次增量升级。当然对于应用程序来讲，这有点儿繁琐，但确实可以保证应用程序和数据库时刻处于一致的状态。</p>
<p>下面是一个可能的版本库中数据库脚本的目录结构：<br>[html]<br>database/<br>– baseline<br> – bootstrap.sql<br> `– create_schema.sh<br>– increment<br> `– increment.sh<br>`– modules<br> – modules1<br> – baseline.sql<br> `– increment.sql<br> – modules2<br> – modules3<br> – modules4<br> `– modules5<br>[/html]</p>
<p>bootstrap.sql用于初始化系统的数据库脚本。</p>
<p>数据库版本纳入版本库统一管理后，更有利于应用程序和数据库的持续集成、测试、部署和升级。</p>
<p>而且可以快速搭建开发环境，开发人员从repo中检出一个release后，通过执行baseline脚本，可以迅速的搭建好开发环境需要的数据库环境，而且应用程序和数据库版本是一致的，没有混乱。</p>
<p>如果客户提交一个bug,可以根据客户的应用和数据库版本，迅速的搭建起与客户一致的环境，从而更容易的定位bug。</p>
<p>参考：<br><a href="http://odetocode.com/blogs/scott/archive/2008/01/30/three-rules-for-database-work.aspx">Three Rules for Database Work</a><br><a href="http://odetocode.com/blogs/scott/archive/2008/01/31/versioning-databases-the-baseline.aspx">Versioning Databases – The Baseline</a><br><a href="http://odetocode.com/blogs/scott/archive/2008/02/02/versioning-databases-change-scripts.aspx">Versioning Databases – Change Scripts</a><br><a href="http://odetocode.com/blogs/scott/archive/2008/02/02/versioning-databases-views-stored-procedures-and-the-like.aspx">Versioning Databases – Views, Stored Procedures, and the Like</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>dataguard archive gap 日志间隙处理</title>
    <url>/2016/05/12/dataguard-archive-gap-handle/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为网络故障或资源紧张，会使standby出现日志同步间隙(archive gap)。虽然设置好了FAL_CLIENT和FAL_SERVER参数，有时候仍然无法自动解决日志间隙问题。</p>
<p>比如由于CONTROL_FILE_RECORD_KEEP_TIME设置导致，较旧的主库归档日志记录被循环覆盖，standby无法自动获取相应的日志文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Fetching gap sequence <span class="keyword">in</span> thread <span class="number">1</span>, gap sequence <span class="number">19767</span>-<span class="number">19866</span></span><br><span class="line">Thu May <span class="number">12</span> <span class="number">09</span>:<span class="number">45</span>:<span class="number">47</span> <span class="number">2016</span></span><br><span class="line">FAL\[client\]: Failed to request gap sequence </span><br><span class="line"> GAP - thread <span class="number">1</span> sequence <span class="number">19767</span>-<span class="number">19866</span></span><br><span class="line"> DBID <span class="number">1276927241</span> branch <span class="number">874659493</span></span><br><span class="line">FAL\[client\]: All defined FAL servers have been attempted.</span><br><span class="line">-------------------------------------------------------------</span><br><span class="line">Check that the CONTROL_FILE_RECORD_KEEP_TIME initialization</span><br><span class="line">parameter is defined to a value that is sufficiently large</span><br><span class="line">enough to maintain adequate log <span class="keyword">switch</span> information to resolve</span><br><span class="line">archivelog gaps.</span><br><span class="line">-------------------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>如果standby缺少的归档日志尚未删除，可以拷贝缺少的日志到备库，然后在备库上注册，备库会apply这些归档日志。<br>如果归档日志已经被删除，则需要从主库做增量备份，然后在备库进行恢复来修复日志间隙。</p>
<p><strong>手工拷贝归档日志</strong></p>
<p>首先查看日志间隙:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; select * <span class="keyword">from</span> v$archive_gap;</span><br><span class="line">THREAD# LOW_SEQUENCE# HIGH_SEQUENCE#</span><br><span class="line">-------- ---------------- ----------------------</span><br><span class="line"><span class="number">1</span> <span class="number">19767</span> <span class="number">19866</span></span><br></pre></td></tr></table></figure>

<p>将对应的归档日志拷贝到备库端</p>
<p>最后在备库端注册这些归档日志：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; alter database register physical logfile <span class="string">&#x27;\\path\\to\\archive_log&#x27;</span></span><br></pre></td></tr></table></figure>

<p>备库会立即应用这些归档日志。如果日志数量过多,也可以使用以下语句来自动恢复数据库:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; ALTER DATABASE RECOVER AUTOMATIC STANDBY DATABASE;</span><br></pre></td></tr></table></figure>

<p><strong>创建备库导致的日志不同步问题</strong></p>
<p>最近遇到的一个案例是这样的,rman dupicate创建完备库后,因为没有使用dorecovery恢复增量备份,主库上的部分归档日志又被清除掉了,导致主备库无法进行同步,备库有类似如下错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Media Recovery Waiting <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">23943</span></span><br><span class="line">Fetching gap sequence <span class="keyword">in</span> thread <span class="number">1</span>, gap sequence <span class="number">23943</span>-<span class="number">24042</span></span><br><span class="line">Sun Jul <span class="number">24</span> <span class="number">13</span>:<span class="number">02</span>:<span class="number">27</span> <span class="number">2016</span></span><br><span class="line">FAL\[client\]: Failed to request gap sequence </span><br><span class="line"> GAP - thread <span class="number">1</span> sequence <span class="number">23943</span>-<span class="number">24042</span></span><br><span class="line"> DBID <span class="number">1276927241</span> branch <span class="number">874659493</span></span><br><span class="line">FAL\[client\]: All defined FAL servers have been attempted.</span><br><span class="line">-------------------------------------------------------------</span><br><span class="line">Check that the CONTROL_FILE_RECORD_KEEP_TIME initialization</span><br><span class="line">parameter is defined to a value that is sufficiently large</span><br><span class="line">enough to maintain adequate log <span class="keyword">switch</span> information to resolve</span><br><span class="line">archivelog gaps.</span><br><span class="line">-------------------------------------------------------------</span><br></pre></td></tr></table></figure>

<p>主库有类似如下错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">FAL Redo Shipping Client Established Network Login</span><br><span class="line">Failed to queue the whole gap</span><br><span class="line"> GAP - thread <span class="number">1</span> sequence <span class="number">23943</span>-<span class="number">24042</span></span><br><span class="line"> DBID <span class="number">1276927241</span> branch <span class="number">874659493</span></span><br></pre></td></tr></table></figure>

<p>此时备库查询v$archive_gap表是没有任何记录的,幸好还有一个备库有完整的归档日志,将相应的归档日志完整拷贝到新建的物理备库上,然后执行以下语句自动恢复数据库:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; ALTER DATABASE RECOVER AUTOMATIC STANDBY DATABASE;</span><br></pre></td></tr></table></figure>

<p>所有可用日志全部恢复完毕后,会有如下提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ALTER DATABASE RECOVER AUTOMATIC STANDBY DATABASE</span><br><span class="line">*</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">00279</span>: change <span class="number">7255663631</span> generated at <span class="number">07</span>/<span class="number">25</span>/<span class="number">2016</span> <span class="number">08</span>:<span class="number">51</span>:<span class="number">20</span> needed <span class="keyword">for</span> thread <span class="number">1</span></span><br><span class="line">ORA-<span class="number">00289</span>: suggestion : D:\\ARCHIVED_LOG\\ARC24380_0874659493<span class="number">.001</span></span><br><span class="line">ORA-00280: change 7255663631 for thread 1 is in sequence #24380</span><br><span class="line">ORA-<span class="number">00278</span>: log file <span class="string">&#x27;D:\\ARCHIVED_LOG\\ARC24380_0874659493.001&#x27;</span> no longer needed <span class="keyword">for</span> <span class="built_in">this</span> recovery</span><br><span class="line">ORA-<span class="number">00308</span>: cannot open archived log <span class="string">&#x27;D:\\ARCHIVED_LOG\\ARC24380_0874659493.001&#x27;</span></span><br><span class="line">ORA-<span class="number">27041</span>: unable to open file</span><br><span class="line">OSD-<span class="number">04002</span>: unable to open file</span><br><span class="line">O/S-<span class="built_in">Error</span>: (OS <span class="number">2</span>) 系统找不到指定的文件。</span><br></pre></td></tr></table></figure>

<p>这是因为已经没有日志可用于恢复了,此时重新打开实时日志应用就可以开始自动同步了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database recover managed standby database disconnect <span class="keyword">from</span> session;</span><br></pre></td></tr></table></figure>

<p>如果归档日志已经找不到了,则可以采用以下增量备份方式修复备库。</p>
<p><strong>增量备份修复备库</strong></p>
<ol>
<li> 查找恢复点SCN<br>备库端：<br>首先查看日志间隙:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; select * <span class="keyword">from</span> v$archive_gap;</span><br><span class="line">THREAD# LOW_SEQUENCE# HIGH_SEQUENCE#</span><br><span class="line">-------- ---------------- ----------------------</span><br><span class="line"><span class="number">1</span> <span class="number">19767</span> <span class="number">19766</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>主库端：<br>然后主库上查找日志间隙中低端日志序号的上一个日志的first_change#</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; select SEQUENCE#, FIRST_CHANGE# from v$archived_log where SEQUENCE#=19766;</span><br><span class="line">SEQUENCE# FIRST_CHANGE# </span><br><span class="line">--------- -------------</span><br><span class="line"><span class="number">19766</span> <span class="number">7008518015</span></span><br></pre></td></tr></table></figure>
<ol start="2">
<li> 备库停止apply log<br>备库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; alter database recover managed standby database cancel;</span><br></pre></td></tr></table></figure></li>
<li> 主库增量SCN备份<br>主库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target /</span><br><span class="line">RMAN&gt; backup incremental <span class="keyword">from</span> scn <span class="number">7008518015</span> database format <span class="string">&#x27;/path/to/stdby_%U.bak&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li> 生成备库控制文件<br>主库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; backup current controlfile <span class="keyword">for</span> standby format <span class="string">&#x27;/path/to/stdby_%U.ctl&#x27;</span>;</span><br></pre></td></tr></table></figure></li>
<li> 拷贝备份和控制文件到备库</li>
<li> 备库使用新生成的控制文件启动<br>备库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rman&gt; shutdown immediate;</span><br><span class="line">rman&gt; startup nomount;</span><br><span class="line">rman&gt; restore standby controlfile <span class="keyword">from</span> <span class="string">&#x27;/path/to/stdby_xxx.ctl&#x27;</span>;</span><br><span class="line">rman&gt; alter database mount</span><br></pre></td></tr></table></figure></li>
<li> 备库进行数据恢复<br>备库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; catalog start <span class="keyword">with</span> <span class="string">&#x27;/path/to_bak&#x27;</span>;</span><br><span class="line">RMAN&gt; recover database noredo;</span><br></pre></td></tr></table></figure></li>
<li> 备库恢复日志应用<br>备库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database recover managed standby database disconnect <span class="keyword">from</span> session;</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>References:<br>[1]<a href="http://www.programgo.com/article/9189574397/">DataGuard 中处理archive gap的方法</a><br>[2]<a href="https://shivanandarao-oracle.com/2012/03/26/roll-forward-physical-standby-database-using-rman-incremental-backup/">Roll Forward Physical Standby Database using RMAN incremental backup</a><br>[3]<a href="http://www.zhongweicheng.com/?p=1305">Oracle Physical DataGuard使用RMAN增量备份修复GAP</a><br>[4]<a href="http://docs.oracle.com/cd/B19306_01/backup.102/b14191/rcmdupdb.htm#BRADV05444">Using RMAN Incremental Backups to Refresh a Standby Database</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>DataGuard相关的初始化参数</title>
    <url>/2011/11/06/dataguard-init-paras/</url>
    <content><![CDATA[<p>dataguard环境下适用于primary和/或standby的初始化参数介绍</p>
<a id="more"></a>
<p><strong>ARCHIVE_LAG_TARGET</strong></p>
<p>适用: primary<br>格式: ARCHIVE_LAG_TARGET = <em>seconds</em><br>描述: 可选。按设定时间间隔seconds强制日志切换,单位秒。可减少日志丢失。<br>样例: ARCHIVE_LAG_TARGET = 1800</p>
<p><strong>COMPATIBLE</strong></p>
<p>适用: primary,physical standby,logical standby<br>格式: COMPATIBLE = _release_number_<br>描述: 控制数据库兼容性。DataGuard需要的最小值为9.2.0.1,将此参数设置为10.2.0.0以上可以利用10g 新特性。primary和standby需要设置同样的参数。<br>样例： COMPATIBLE = ‘10.2.0.0’</p>
<p><strong>CONTROL_FILE_RECORD_KEEP_TIME</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： CONTROL_FILE_RECORD_KEEP_TIME = <em>number_of_days</em><br>描述： 可选。在指定的天数内不可以覆盖控制文件中的可重用记录。这个参数的范围为0-365天,如果这个参数设置为0,系统会在需要的时候覆盖可重用的记录。<br>样例： CONTROL_FILE_RECORD_KEEP_TIME = 20</p>
<p><strong>CONTROL_FILES</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： CONTROL_FILES = <em>(‘control_file_name’,’control_file_name2’,…)</em><br>描述： 指定控制文件的名字,包括完整的路径。<br>样例： CONTROL_FILES = (‘/u01/oracle/oradata/control01.ctl’,<br>‘/u01/oracle/oradata/control02.ctl”)</p>
<p><strong>DB_FILE_NAME_CONVERT</strong></p>
<p>适用： physical standby<br>格式： DB_FILE_NAME_CONVERT = <em>(‘location_of_primary_database_datafile’,’location_of_standby_database_datafile’,…)</em><br>描述： 如果standby与primary在同一个系统上,或者standby的数据文件位置与primary的数据文件位置不同,必须设置此参数。这个参数必须指定成对的字符串,第一个字符串指定primary的数据文件位置,第二个字符串指定standby对应的数据文件位置,可以设置多对参数。<br>样例： 从primary的/dbs/t1/,转换到standby的/dbs/t1/standby<br>DB_FILE_NAME_CONVERT = (‘/dbs/t1/‘,’/dbs/t1/standby’)</p>
<p><strong>DB_NAME</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： DB_NAME = _database_name_<br>描述： 指定最多8个字符的数据库名。对于physical standby,把DB_NAME设置成与primary数据库初始化参数文件中相同的名字,也就是此参数physical standby与primary保持一致。但是对于logical standby,此参数不能与primary设置相同,可用DBNEWID(nid)为logical standby设置DB_NAME。<br>样例： DB_NAME = orcl</p>
<p><strong>DB_UNIQUE_NAME</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： DB_UNIQUE_NAME = <em>unique_service_provider_name_for_this_database</em><br>描述： 为本数据库指定一个独一无二的名字,primary和standby中此参数不能相同,此参数一般设置为oracle service name。<br>样例： DB_UNIQUE_NAME = primaryDB</p>
<p><strong>FAL_CLIENT与FAL_SERVER</strong>参数详见”<a href="https://openwares.net/database/fal_client_fal_server.html">FAL_CLIENT和FAL_SERVER参数详解</a>“</p>
<p><strong>LOG_ARCHIVE_CONFIG</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： LOG_ARCHIVE_CONFIG = _’DG_CONFIG(db_unique_name,db_unique_name,…)’_<br>描述： 使用DG_CONFIG属性标识出Data Guard配置中的primary数据库和各个standby数据库的DB_UNIQUE_NAME。此参数使primary发送redo日志到standby数据库,使standby数据库接收primary发送来的redo日志。<br>样例： LOG_ARCHIVE_CONFIG =’DG_CONFIG(PrimaryDB,StandbyDB1,StandbyDB2,…)’</p>
<p><strong>LOG_ARCHIVE_DEST_n</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： LOG_ARCHIVE_DEST_n = ‘LOCATION=path_name SERVICE=service_name, attribute,attribute’<br>描述： 必需。定义最多10个归档日志目的地。LOCATION用来指定本地归档日志路径,SERVICE用来指定远程归档目的地。<br>样例： LOG_ARCHIVE_DEST_1 = ‘SERVICE=StandbyDB OPTIONAL REOPEN=180’</p>
<p><strong>LOG_ARCHIVE_DEST_STATE_n</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： LOG_ARCHIVE_DEST_STATE_n = ENABLE DEFER ALTERNATE<br>描述： 用来指定由参数LOG_ARCHIVE_DEST_n定义的目的地的状态,每一个LOG_ARCHIVE_DEST_n参数都必须顶一个对应的LOG_ARCHIVE_DEST_STATE_n参数。<br>ENABLE - 指定该归档目的地可用<br>DEFER - 归档目的地不可用<br>ALTERNATE - 指定目的地不可用，但当其他目的地都失败时，这个目的地变为可用。<br>样例： LOG_ARCHIVE_DEST_STATE_1 = ENABLE</p>
<p><strong>LOG_ARCHIVE_FORMAT</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： LOG_ARCHIVE_FORMAT = log%d_%t_%s_%r.arc<br>描述： 如果指定了STANDBY_ARCHIVE_DEST参数,则需要指定此参数,此参数指定了归档redo日志文件名的格式。这个参数与STANDBY_ARCHIVE_DEST组合在一起形成standby数据库端完整的归档日志文件名。%d为database ID，%t为归档线程的thread id,%s为归档序列号。<br>样例： LOG_ARCHIVE_FORMAT = ‘log%d_%t_%s.arc’</p>
<p><strong>LOG_ARCHIVE_MAX_PROCESSES</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： LOG_ARCHIVE_MAX_PROCESSES = integer<br>描述： 指定数据库服务器调用的背景归档日志进程的数目，可设置值为1-30,缺省值是4。<br>样例： LOG_ARCHIVE_MAX_PROCESSES = 2</p>
<p><strong>LOG_ARCHIVE_MIN_SUCCEED_DEST</strong></p>
<p>适用： primary<br>格式： LOG_ARCHIVE_MIN_SUCCEED_DEST = integer<br>描述： 指定primary日志写进程在重新利用在线redo log文件之前必须成功接收redo log文件的目的地(LOG_ARCHIVE_DEST_n)的最小数目<br>样例： LOG_ARCHIVE_MIN_SUCCEED_DEST = 2</p>
<p><strong>LOG_ARCHIVE_TRACE</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： LOG_ARCHIVE_TRACE = integer<br>描述： 设置该参数来追踪redo log向standby数据库的传送,有效的参数值为0,1,2,4,8,16,32,64,128,256,512,1024,2048<br>样例： LOG_ARCHIVE_TRACE = 1</p>
<p><strong>LOG_FILE_NAME_CONVERT</strong></p>
<p>适用： physical standby<br>格式： LOG_FILE_NAME_CONVERT = (‘location_of_primary_redo_logs’,’location_of_standby_redo_logs’,…)<br>描述： 当standby与primary在同一个系统中,或者standby与primary的redo logs位置不同，这个参数用于在primary和standby之间转换red logs文件的路径。<br>样例： LOG_FILE_NAME_CONVERT = (‘/dbs/t1/‘,’/dbs/t1/stdby’,’dbs/t2/ ‘,’dbs/t2/stdby’)</p>
<p><strong>STANDBY_ARCHIVE_DEST</strong></p>
<p>适用： physical standby,logical standby<br>格式： STANDBY_ARCHIVE_DEST = path_to_received_redo_logs_of_standby<br>描述： 指定standby从primary接收的归档日志存放路径。此参数覆盖LOG_ARCHIVE_DEST_n参数设置的目录位置，STANDBY_ARCHIVE_DEST与LOG_ARCHIVE_FORMAT组合在一起形成standby端redo logs的文件名。<br>样例： STANDBY_ARCHIVE_DEST = ‘/u01/oracle/oradata/archive’</p>
<p><strong>STANDBY_FILE_MANAGEMENT</strong></p>
<p>适用： primary,physical standby<br>格式： STANDBY_FILE_MANAGEMENT = AUTO MANUAL<br>描述： 当此参数设置为AUTO，当primary增加或删除数据文件时，standby自动执行与primary相同的动作，如果设置为MANUAL则需要DBA在standby手动处理数据文件的变动。推荐设置为AUTO。<br>样例： STANDBY_FILE_MANAGEMENT = AUTO</p>
<p><strong>USER_DUMP_DEST</strong></p>
<p>适用： primary,physical standby,logical standby<br>格式： USER_DUMP_DEST = path_name_of_trace_files<br>描述： 指定服务器写debug trace文件的路径名<br>样例： USER_DUMP_DEST = ‘/u01/oracle/oradata/utrc’</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>Dataguard配置中primary不更新v$_archived_log的&#39;APPLIED&#39;列</title>
    <url>/2016/05/13/dataguard-not-update-v-archived-log-applied-column/</url>
    <content><![CDATA[<a id="more"></a>
<p>Dataguard配置中因为网络故障出现了日志gap,修复gap后，恢复自动同步。</p>
<p>备库看一切正常：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; SELECT max(sequence#), applied FROM v$archived_log GROUP BY applied;</span><br><span class="line">MAX(SEQUENCE#) APPLIED</span><br><span class="line">-------------- ---------</span><br><span class="line"> <span class="number">20114</span> YES</span><br></pre></td></tr></table></figure>

<p>但主库确显示日志并未应用:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; SELECT max(sequence#), applied FROM v$archived_log GROUP BY applied;</span><br><span class="line"></span><br><span class="line">MAX(SEQUENCE#) APPLIED</span><br><span class="line">-------------- ---------</span><br><span class="line"> <span class="number">20114</span> NO</span><br></pre></td></tr></table></figure>

<p>其实日志已经正确的同步并应用了，只是primary没有更新applied列的值而已，这是个bug, 编号1369630.1</p>
<p>主库上有一个指定的ARCn进程与远程的RFS进程通讯来更新applied列的值，如果此进程挂起，无法与远程通讯也就无法更新v$archived_log的applied列值。</p>
<p><strong>解决方案</strong></p>
<p>主库ALERT_sid.LOG文件查找最新的,包含以下类似信息的行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ARCn: Becoming the heartbeat ARCH</span><br></pre></td></tr></table></figure>

<p>说明ARCn进程/线程出问题挂起了,n是数字,比如ARC0</p>
<p>然后查找ARC0的进程/线程号,*nix平台是进程,windows平台是线程:</p>
<p>windows平台输出：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; SELECT spid, osuser, s.program FROM v$process p, v$session s WHERE p.addr=s.paddr and p.program like <span class="string">&#x27;%ARC0%&#x27;</span></span><br><span class="line">SPID OSUSER PROGRAM</span><br><span class="line">---------- ----------------- -----------------------</span><br><span class="line"><span class="number">2616</span> SYSTEM ORACLE.EXE (ARC0)</span><br></pre></td></tr></table></figure>

<p>将对应的进程/线程kill掉就可以了,oracle会重新启动相应的进程/线程。</p>
<p>*nix平台:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># kill -9 processid </span><br></pre></td></tr></table></figure>

<p>windows平台:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&gt; orakill sid threadid</span><br></pre></td></tr></table></figure>

<p>sid是oracle实例名</p>
<p><strong>或者更简单粗暴的重新启动oracle实例</strong></p>
<p>alert_sid.log文件中可能会出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">16401</span>: archivelog rejected by RFS</span><br></pre></td></tr></table></figure>

<p>sid_arc0_xxxx.trc文件中也会有：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Error</span> <span class="number">16401</span> creating standby archive log file at host <span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">ORA-<span class="number">16401</span>: archivelog rejected by RFS</span><br></pre></td></tr></table></figure>

<p>这是出现重复归档的错误提示，因为ARC0想重新归档已经应用到备库的日志，可以安全的忽略掉这些信息，ARC0会更新已经传输到备库的日志的APPLIED列。</p>
<p>ORA-16401也可能出现在多个主库和/或备库向同一个备库归档的情形下，这种情况一般是因为LOG_ARCHIVE_DEST_n参数配置错误。</p>
<p>References:<br>[1]<a href="http://oracle-artifacts.blogspot.com/2012/04/oracle-data-guard-issues-applied-column.html">Oracle Data-guard Issues - ‘APPLIED’-Column not updated in v$archived_log table</a><br>[2]<a href="https://docs.google.com/document/d/1drYAr6VVQh652kl7cvHFZXEmFlN5eYMrJr6q3hPtWO4/edit?pref=2&pli=1">Bug Note: 1369630.1</a><br>[3]<a href="http://topmanopensource.iteye.com/blog/1171271">ORACLE在windows上使用orakill结束oracle会话的线程</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>dataguard物理备库exp导出数据</title>
    <url>/2019/09/01/dataguard-physical-standby-exp/</url>
    <content><![CDATA[<a id="more"></a>
<p>物理备库是可以以只读模式打开的，然后就可以exp数据出来了，注意备库readonly模式打开时，是没有在apply日志的，所有exp出来的数据会少了主库在这段时间更新的数据。</p>
<p><strong>备库端：</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL;</span><br><span class="line">SQL&gt; alter database open read only;</span><br></pre></td></tr></table></figure>

<p>然后exp数据库:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ exp ...</span><br></pre></td></tr></table></figure>

<p>最后备库重新开始apply日志就好了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION; </span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 10g DataGuard手记之保护模式配置</title>
    <url>/2011/12/31/dataguard-protection-mode/</url>
    <content><![CDATA[<p>DataGuard共有三种数据保护模式,默认配置下运行于最大性能模式</p>
<a id="more"></a>
<p>最大保护,最大可用和最大性能三种模式对LOG_ARCHIVE_DEST_n参数的属性以及是否需要standby redo logs有不同的要求</p>
<p>最大保护和最大可用模式要求使用LGWR日志写进程,需要SYNC模式来传输redo日志,需要AFFIRM磁盘写操作模式,并且需要standby redo logs。使用AFFIRM磁盘写模式时,所有的归档日志和standby redo log日志的磁盘I/O是同步执行的,日志写进程要等待这些磁盘I/O执行完毕后才会继续运行,而NOAFFIRM磁盘写模式则是异步的。</p>
<p>最大性能模式则要求低一些,可以使用LGWR或者ARCH日志写进程,使用ARCH时需要使用SYNC模式,而使用LGWR时则SYNC和ASYNC模式皆可。磁盘写模式使用AFFIRM或NOAFFIRM皆可,可以不使用standby redo logs但推荐使用。</p>
<p>下面将DataGuard运行模式由默认的最大性能模式升级为最大可用模式。数据保护模式是由primary决定的,standby只能被动的接受这一切,没有特别说明的话以下步骤默认是在primary端执行。</p>
<p><strong>1、查看当前保护模式</strong><br>[sql]<br>SQL&gt;select protection_mode,protection_level from v$database;<br>PROTECTION_MODE PROTECTION_LEVEL</p>
<hr>
<p>MAXIMUM PERFORMANCE MAXIMUM PERFORMANCE<br>[/sql]<br>表明现在dataguard运行于默认的最高性能模式</p>
<p><strong>2、修改primary的初始化参数log_archive_dest_2</strong><br>[sql]<br>SQL&gt; ALTER SYSTEM SET LOG_ARCHIVE_DEST_2=’SERVICE=standby01<br> 2&gt; OPTIONAL LGWR SYNC AFFIRM<br> 3&gt; VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE)<br> 4&gt; DB_UNIQUE_NAME=standby01’;<br>[/sql]<br>主要就是增加了AFFIRM选项,在参数文件中增加该选项也是可以的。</p>
<p><strong>3、设置保护模式为最高可用模式</strong></p>
<p>如果是升级保护模式,比如从最高性能模式升级到最高可用模式,则需要先关闭数据库,然后mount数据库,如果是降级保护模式则直接从下面的alter语句开始执行<br>[sql]<br>SQL&gt;shutdown immediate;<br>SQL&gt;startup mount;<br>SQL&gt;alter database set standby database to maximize availability;<br>SQL&gt;alter database open;<br>[/sql]<br><strong>4、确认primary是否运行于最高可用模式</strong><br>[sql]<br>SQL&gt;select protection_mode,protection_level from v$database;</p>
<p>PROTECTION_MODE PROTECTION_LEVEL</p>
<hr>
<p>MAXIMUM AVAILABILITY MAXIMUM AVAILABILITY<br>[/sql]<br>dataguard已经运行于最高可用模式</p>
<p><strong>5、修改standby库(standby01)初始化参数log_archive_dest_2方便备库转变为主库角色(此步骤非必须)</strong><br>[sql]<br>SQL&gt; ALTER SYSTEM SET LOG_ARCHIVE_DEST_2=’SERVICE=primary OPTIONAL LGWR ASYNC AFFIRM VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=primary’;<br>[/sql]<br>顺便看下standby01现在运行的保护模式,应该与主库是一致的<br>[sql]<br>SQL&gt;select protection_mode,protection_level from v$database;<br>PROTECTION_MODE PROTECTION_LEVEL</p>
<hr>
<p>MAXIMUM AVAILABILITY MAXIMUM AVAILABILITY<br>[/sql]<br>配置成功。</p>
<p>PS:可以在配置dataguard时一并配置好适用于最高可用模式的初始化参数LOG_ARCHIVE_DEST_n,以后切换数据保护模式就更简单了。<br> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 10g dataguard手记之READ ONLY模式打开物理Standby</title>
    <url>/2012/01/10/dataguard-read-only-physical-standby/</url>
    <content><![CDATA[<p>通常情况下物理standby处于mounted模式</p>
<a id="more"></a>
<p>当standby正常应用redo数据时其打开模式处于mounted模式<br>[sql]<br>SQL&gt; select open_mode from v$database;<br>OPEN_MODE</p>
<hr>
<p>MOUNTED<br>[/sql]<br>要将物理Standby数据库从REDO应用状态启动到READ ONLY状态,并不能直接ALTER DATABASE OPEN打开数据库,首先要取消redo应用<br>[sql]<br>SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL;<br>[/sql]<br>然后再打开数据库：<br>[sql]<br>SQL&gt; alter database open;<br>[/sql]<br>查询打开模式<br>[sql]<br>SQL&gt; select open_mode from v$database;<br>OPEN_MODE </p>
<hr>
<p>READ ONLY<br>[/sql]<br>要从OPEN状态切换回REDO应用状态，并不需要SHUTDOWN数据库再启动，直接执行启用REDO应用的语句即可<br>[sql]<br>SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;<br>[/sql]</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 10g DataGuard手记之角色转换</title>
    <url>/2012/01/01/dataguard-role-transition/</url>
    <content><![CDATA[<p>一个DataGuard配置通常有一个primary库和几个standby库组成,通常它们的角色不会变化。</p>
<a id="more"></a>
<p>我们希望primary一直不停地提供服务直到forever,如果真的如此其实根本就不要DataGuard了。当primary库崩溃或者primary库需要维护时就需要在primary和其中一个standby库之间进行角色转换。</p>
<p>DataGuard支持两种角色转换switchover和failover</p>
<p>switchover</p>
<p>switchover通常由用户主动进行,角色转换不会丢失数据。switchover允许primary和其standby库中的一个进行角色转换,转换完毕后各数据库按照其新的角色继续服务于DataGuard配置。</p>
<p>failover</p>
<p>当因为各种可能的原因导致primary崩溃而且短时间内无法恢复时,就需要dataguard配置中的一个stangdby数据库转换到primary角色来顶包。如果崩溃的primary并未运行于高大保护模式时,可能会有些微的数据丢失。</p>
<p><strong>角色转换前的准备工作</strong></p>
<p>1、校验各数据库的初始化参数设置是否正确<br>2、确保将要成为primary的standby库处于archivelog模式<br>3、确保standby库的临时文件存在,并与primary库的临时文件匹配。当failover时,primary已经崩溃了,谁知道这鸟临时文件还一致不一致呢，以下语句可以查询临时文件<br>SQL&gt;select name from v$tempfile;<br>4、解决将要转换为primary的standby库任何可能尚未应用的redo logs,当然有时候数据丢失也是无法避免的<br>5、确保将要转换为primary的RAC standby只有一个instance是打开的,也就是在一个RAC standby向primary转换过程中,只有RAC的一个instance可以打开，角色转换完成后再启动RAC的其他instance</p>
<p><strong>物理standby的switchover</strong></p>
<p>确保primary处于open状态,物理standby处于mount状态,如果standby处于read-only模式,switchover仍然可以进行,但会花费更多的时间。一个switchover必须从当前primary库发起从目标物理standby库结束</p>
<p>switchover步骤如下：</p>
<p>1、检查当前primary是否可以执行switchover<br>[sql]<br>SQL&gt; select switchover_status from v$database;<br>SWITCHOVER_STATUS</p>
<hr>
<p>TO STANDBY<br>[/sql]<br>switchover_status的值为TO STANDBY说明primary可以转换为standby。switchover_status的值为SESSIONS ACTIVE,那是因为有活动的SQL会话会阻止switchover,当前sqlplus会话不包括在内,最好断掉这些会话后再执行swichover,当然也可以在执行switchover的SQL语句后附加语句WITH SESSION SHUTDOWN,但这样时间会比较长。switchover_status的值为空或其他值,请检查dataguard配置。</p>
<p>如果switchover_status的值为SESSIONS ACTIVE,可以如下解决：<br>1)查看有没有用户进程连接到oracle<br>[sql]<br>SQL&gt; SELECT SID, PROCESS, PROGRAM FROM V$SESSION;<br>[/sql]<br>如果有除当前sqlplus连接之外的连接,请将这些连接从oracle断开,比如应用程序连接或其他sqlplus连接或plsqldev连接等。<br>2)查看有没有用户级别的oracle会话<br>[sql]<br>SQL&gt;select sid,process,program from v$session where type=’USER’ and sid &lt;&gt; (select distinct sid from v$mystat);</p>
<p> SID PROCESS PROGRAM</p>
<hr>
<p> 4 3156 ORACLE.EXE (J000)<br>[/sql]<br>这里的这个J000是作业队列首进程,查看作业队列进程数量<br>[sql]<br>SQL&gt; SHOW PARAMETER JOB_QUEUE_PROCESSES;<br>[/sql]<br>通过将JOB_QUEUE_PROCESSES参数设置为0来将此进程取消掉,不要修改初始化参数文件,如下操作即可：<br>[sql]<br>SQL&gt;alter system set job_queue_processes=0;<br>[/sql]<br>稍过一会儿再查询就会发现J000进程已经消失了。<br>最后重新查询switchover_status应该为TO STANDBY了。</p>
<p>2、当前primary库执行switchover<br>SQL&gt;alter database commit to switchover to physical standby;<br>或者<br>SQL&gt;alter database commit to switchover to physical standby with session shutdown;<br>此后原primary转换为物理standby数据库,并将转换前的控制文件备份到trace文件。</p>
<p>3、关闭并重启原primary(新standby库)到mount<br>SQL&gt;shutdown immediate<br>SQL&gt;startup mount<br>在此时点上所有的数据库都被配置为standby</p>
<p>4、检查原standby库是否支持switchover<br>当原primary转换为standby后,原standby库会接收到switchover通知并做相应处理,检查其switchover_status的值来确认其是否处理该通知并准备妥当进行角色转换<br>SQL&gt;selct switchover_status from v$database;<br>SWITCHOVER_STATUS</p>
<hr>
<p>TO PRIMARY</p>
<p>switchover_status的值为TO PRIMARY说明原standby可以转换为primary。如果switchover_status的值为SESSIONS ACTIVE,那是因为有活动的SQL会话会阻止switchover,sqlplus会话也算,此时可在执行switchover的SQL语句后附加语句WITH SESSION SHUTDOWN。switchover_status的值为空或其他值,请检查dataguard配置。</p>
<p>5、切换原standby库为新的primary库<br>SQL&gt;alter database commit to switchover to primary;<br>或者<br>SQL&gt;alter database commit to switchover to primary with session shutdown;</p>
<p>6、打开新的primary数据库<br>如果原standby数据库没有以read-only模式打开,执行<br>SQL&gt;alter database open;<br>如果原standby以read-only模式打开,则执行<br>SQL&gt;shutdown immediate<br>SQL&gt;startup</p>
<p>7、如果有必要,在standby数据库上重新启动日志应用服务(log apply service)<br>对于新的standby数据库或者dataguard配置中的其他standby数据库,如果先前并没有配置log apply service在switchover后继续执行,那么应该执行以下语句重新启动日志应用服务</p>
<p>SQL&gt;alter database recover managed standby database disconnect from session;<br>或者<br>SQL&gt;ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;</p>
<p>8、校验switchover是否成功<br>在新主库执行<br>SQL&gt;alter system switch logfile;<br>然后查看primary和所有stangby库上的归档日志的最大sequence#是否一致,如一致说明switchover成功。</p>
<p><strong>物理standby的failover</strong></p>
<p>failover之后,原primary不再是dataguard配置的一部分。大多数情况下，dataguard配置中的其他的standby数据库并不直接参与failover,不需要做任何更改就可以继续接收并应用新primary发送来的归档日志，当然新的primary必须定义了针对其他原有standby数据库的归档目标(LOG_ARCHIVE_DEST_*),原有standby可能需要简单的调整fal_server参数为新的primary即可。但在某些极端情况下,配置好新的primary数据库后需要重建其他所有的standby数据库</p>
<p>failover完成后,数据库会进行一次resetlogs,产生一个新的incarnation，归档日志编号会从1开始重新编号。10g版本中引入了跨RESETLOGS恢复的特性，原理是将RESETLOGS的操作也记录到REDOLOG中，这样日志恢复会前后衔接起来。这是一个很好的特性。</p>
<p>如果待转换为primary的standby数据库运行于最大保护模式(最大可用模式不知道有没有影响？),那么首先需要在standby上用一下语句将其置于最大性能模式</p>
<p>SQL&gt;ALTER DATABASE SET STANDBY DATABASE TO MAXIMIZE PERFORMANCE;<br>等standby切换为新的primary后,可以再更改成任何想要的其他保护模式。</p>
<p>oracle不允许failover到一个运行于最大保护模式的standby。此外如果一个运行于最大保护模式的primary仍然与standby保持通讯,那么将standby从最大保护模式切换到最大性能模式的alter database语句会失败。因为failover会将primary从dataguard配置中移除,这一特性可以保护运行于最大保护模式的primary免受无意的failover影响。</p>
<p>如果待转换角色的standby数据库运行于最高保护或最高可用模式并使用LGWR归档进程的话,其归档日志应该是连续的,不存在任何间隙,因此可以从以下的第三步直接执行,否则请从以下的第一步开始执行</p>
<p>1、解决任何的归档日志间隙(gap)</p>
<p>如果有缺失的归档日志会造成日志间隙,所有的日志间隙记录在v$archive_gap视图中</p>
<p>查询日志间隙<br>SQL&gt;SELECT THREAD#, LOW_SEQUENCE#, HIGH_SEQUENCE# FROM V$ARCHIVE_GAP;</p>
<p>如果有记录返回,将日志号从LOW_SEQUENCE#到HIGH_SEQUENCE#的所有归档日志拷贝到standby并将它们注册到standby数据库</p>
<p>SQL&gt;ALTER DATABASE REGISTER PHYSICAL LOGFILE ‘\path\to\gap_logs’;</p>
<p>因为每次查询v$archive_gap视图时只返回顺序号最高的日志间隙,因此必须重复查询日志间隙、拷贝缺失的归档日志文件、注册缺失的日志文件直到查询日志间隙时没有任何记录返回。</p>
<p>2、拷贝任何缺失的归档日志文件到standby数据库</p>
<p>首先查询standby数据库上每个线程的最大归档日志号<br>SQL&gt;SELECT UNIQUE THREAD# AS THREAD, MAX(SEQUENCE#) OVER (PARTITION BY thread#) AS LAST from V$ARCHIVED_LOG;</p>
<p>然后确定primary数据库每个线程的最大归档日志号，如果primary已经不能查询,可以查看备份的primary归档日志文件来确定最大归档日志号。如果primary的最大归档日志号大于standby库的,那么将所有多出的归档日志从primary拷贝到standby数据库并将它们注册到standby数据库</p>
<p>SQL&gt;ALTER DATABASE REGISTER PHYSICAL LOGFILE ‘\path\to\miss_logs’;</p>
<p>3、在standby数据库上执行failover</p>
<p>SQL&gt;ALTER DATABASE RECOVER MANAGED STANDBY DATABASE FINISH FORCE;</p>
<p>FORCE关键字终止standby数据库上的活动的RFS进程,因此failover可以立即得到处理而不必等待网络连接超时</p>
<p>4、将standby数据库切换为primary数据库</p>
<p>SQL&gt;ALTER DATABASE COMMIT TO SWITCHOVER TO PRIMARY;</p>
<p>5、启动新的primary数据库</p>
<p>如果原standby数据库没有以read-only模式打开,执行<br>SQL&gt;alter database open;<br>如果原standby以read-only模式打开,则执行<br>SQL&gt;shutdown immediate<br>SQL&gt;startup</p>
<p>6、备份新的primary数据库</p>
<p>failover之后,原primary不再是dataguard配置的一部分,而dataguard配置中的其他的stangby数据库从现在开始从新的primary数据库接收并应用redo logs。<br>因此在执行startup语句之前最好完整备份一下新的primary数据库</p>
<p>7、恢复或重建失败的原primary数据库</p>
<p>failover之后,失败的primary不再是dataguard配置的一部分,修复之后可以将其作为物理standby加入到dataguard配置中。</p>
<p>从原理上讲,standby数据库必须沿着primary的方向前进,而且在时点上必须要小于或者说晚于primary库,也就是说通过应用primary传送过来的redo数据,standby完全可以变的和primary一模一样,standby必须紧跟primary的脚步而不能分道扬镖。所以当failover后,失败的primary如何修复、重建成为物理standby要依据情况而定。</p>
<p>第一种情况,failover过程中没有任何的数据丢失,新primary完全恢复了失败的primary的数据,而且失败的primary库在failoiver后没有进行任何的写操作,这种情况下,修复的primary可以直接作为standby加入到dataguard配置。</p>
<p>第二种情况,failover过程中丢失了部分数据,也就是新primary恢复到原primary失败之前的某个时点上,如果修复好的原primary可以flashback到前面提到的那个时点或者更早,那么修复好的原primary可以转化为standby库加入到dataguard配置。详见dataguard文档”Flashing Back a Failed Primary Database into a Physical Standby Database”。</p>
<p>其他情况下,原primary与新的primary已经分道扬镖,无法破镜重圆,修复好的priamry要依据当前primary重新建库,从头来过配置为standby加入到dataguard配置。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>datagurad环境下修改sys用户密码</title>
    <url>/2014/12/22/datagurad-change-sys-password/</url>
    <content><![CDATA[<a id="more"></a>
<p>dataguard环境下使用alter user sys identified by 语句修改主库的sys用户密码时,不会自动更新备库的密码文件。而Oracle Dataguard环境的日志传输安全机制依赖于密码文件，因为备库也需要做相应的修改才可以正常的进行日志恢复。而备库随时有可能成为主库，因此修改密码后应该将主库的密码文件同步到备库。</p>
<p>首先，停止备库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; shutdown immediate</span><br></pre></td></tr></table></figure>

<p>然后，将主库密码文件覆盖备库的密码文件<br>最后，启动备库，打开日志实时恢复</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; startup mount</span><br><span class="line">SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>datagurad实时应用日志错误</title>
    <url>/2016/08/17/datagurad-error-ora-38500/</url>
    <content><![CDATA[<a id="more"></a>
<p>物理备库执行实时日志应用时有如下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;</span><br><span class="line">ORA-<span class="number">38500</span>: USING CURRENT LOGFILE option not available without stand</span><br><span class="line"><span class="string">``</span><span class="string">`js</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">是因为没有standby redo log日志组，这次好像是丢失了。</span></span><br><span class="line"><span class="string">查看日志组:</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">idle&gt;select member <span class="keyword">from</span> v$logfile;</span><br><span class="line"></span><br><span class="line">MEMBER</span><br><span class="line">----------------------------------------------------------------------------------------------------</span><br><span class="line">E:\\ORACLE\\PRODUCT\\<span class="number">10.2</span><span class="number">.0</span>\\ORADATA\\ORCL\\REDO03.LOG</span><br><span class="line">E:\\ORACLE\\PRODUCT\\<span class="number">10.2</span><span class="number">.0</span>\\ORADATA\\ORCL\\REDO02.LOG</span><br><span class="line">E:\\ORACLE\\PRODUCT\\<span class="number">10.2</span><span class="number">.0</span>\\ORADATA\\ORCL\\REDO01.LOG</span><br></pre></td></tr></table></figure>
<p>只有online redo日志文件，没有standby redo日志文件，因此添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt;alter database add standby logfile group <span class="number">4</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO01.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br><span class="line">SQL&gt;alter database add standby logfile group <span class="number">5</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO02.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br><span class="line">SQL&gt;alter database add standby logfile group <span class="number">6</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO03.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br><span class="line">SQL&gt;alter database add standby logfile group <span class="number">7</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO04.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br></pre></td></tr></table></figure>

<p>重新执行日志实时应用就没问题了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>DCube3.ocx控件注册失败的解决办法</title>
    <url>/2010/07/12/dcube3-register-failure/</url>
    <content><![CDATA[<p>单位的某一个业务系统用到了DynamiCube组件，很多客户端的IE浏览器都无法正常下载并注册DynamiCube组件，导致页面无法正常显示。手工拷贝DCube3.cab到客户端并解出Dcube3.ocx，然后regsvr32 Dcube3.ocx会有错误提示“LoadLibrary(“DCube3.ocx”) 失败 - 内存分配访问无效”，英文的错误提示是“LoadLibrary(dcube3.ocx”) failed - Invalid Access to Memory Location”。其实这是因为Dcube3.ocx受到DEP(Data Eexcute Protection)阻止造成的。解决办法也很简单，先禁止DEP，然后注册Dcube3.ocx，然后再打开DEP即可。</p>
<p>XP SP3可以这样关闭DEP,打开boot.ini文件，将/noexecute的值改为AlwaysOff或者将/noexecute及等号后的值一起改为/execute,保存重启系统即可。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>dd命令测试磁盘IO性能</title>
    <url>/2019/11/15/dd-io-performance-test/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ time dd <span class="keyword">if</span>=<span class="regexp">/dev/</span>zero <span class="keyword">of</span>=<span class="regexp">/tmp/</span>test.img bs=1G count=<span class="number">1</span> oflag=dsync</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian 10 buster安装jdk8</title>
    <url>/2019/06/20/debian-10-buster-install-oracle-jdk8/</url>
    <content><![CDATA[<a id="more"></a>
<p>buster官方源里已经不再提供openjdk-8-jdk, default-jdk版本为openjdk-11-jdk</p>
<p>可以使用java-packge包来安装oracle jdk 8,或者build openjdk8u</p>
<p><em>1. oracle jdk 8</em></p>
<p><strong>安装</strong></p>
<p>安装java-package及其他需要的依赖包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install java-package java-common libgtk-<span class="number">3</span>-dev libcairo-gobject2</span><br></pre></td></tr></table></figure>

<p><strong>下载</strong></p>
<p>oracle官方下载jdk-8u211-linux-x64.tar.gz</p>
<p><strong>打包</strong></p>
<p>切换到下载目录执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ make-jpkg jdk-8u211-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>
<p>会在当前目录下生成oracle-java8-jdk_8u211_amd64.deb</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg -i oracle-java8-jdk_8u211_amd64.deb</span><br></pre></td></tr></table></figure>

<p><em>2. openjdk8u</em></p>
<p><a href="http://hg.openjdk.java.net/jdk8u/jdk8u/">openjdk8u</a>是openjdk8的更新版本，其官方代码仓库为<a href="http://hg.openjdk.java.net/jdk8u/jdk8u/">http://hg.openjdk.java.net/jdk8u/jdk8u/</a></p>
<p>根据其<a href="https://hg.openjdk.java.net/jdk8u/jdk8u/raw-file/tip/README-builds.html">官方build说明文件</a>，clone源代码并编译安装即可。</p>
<p>References:<br>[1]<a href="http://hg.openjdk.java.net/jdk8u/jdk8u/">OpenJDK / jdk8u / jdk8u</a><br>[2]<a href="https://hg.openjdk.java.net/jdk8u/jdk8u/raw-file/tip/README-builds.html">OpenJDK Build README</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian添加静态路由</title>
    <url>/2013/01/20/debian-add-static-route-item/</url>
    <content><![CDATA[<p>有线和无线分属不同网络,添加静态路由以使网络各行其道</p>
<a id="more"></a>
<p>debianx系统添加静态路由最简单的办法就是在/etc/network/interfaces文件里添加静态路由表项,路由表项经过那个接口就将其写在那个接口下面,比如在eth0接口下添加一条静态路由</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">auto eth0</span><br><span class="line">iface eth0 inet dhcp</span><br><span class="line"> up route add -net <span class="number">10.100</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span> gateway <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span> dev eth0</span><br><span class="line"> down route del -net <span class="number">10.100</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span> gateway <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span> dev eth0</span><br></pre></td></tr></table></figure>
<p>route命令的<a href="https://openwares.net/linux/linux_route_intro.html">详细用法</a>。</p>
<p>在接口eth0激活时添加一条静态路由,路由目的为网络10.100.0.0/24,网关为192.168.0.1,该条路由使用eth0接口。当接口eth0关闭时删除该条静态路由。</p>
<p>路由表项以下写法也是一样的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">route add -net <span class="number">10.100</span><span class="number">.0</span><span class="number">.0</span> netmask <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span> gateway <span class="number">192.168</span><span class="number">.0</span><span class="number">.1</span> dev eth0</span><br></pre></td></tr></table></figure>
<p>也可以将route命令添加到/etc/rc.local文件中使其成为永久静态路由。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Squeeze AMD64安装Oracle 10g x86_64 10.2.0.4数据库</title>
    <url>/2012/01/19/debian-amd64-install-10g-r2-database/</url>
    <content><![CDATA[<p>服务器操作系统为Debian Squeeze AMD64,没有安装X,通过ssh远程访问。客户端为debian testing,安装有gnome桌面环境。</p>
<a id="more"></a>
<p>先安装10.2.0.1,然后安装升级包10.2.0.4,比安装10g r2客户端多了一些操作,具体安装过程如下：</p>
<p><strong>一、安装10.2.0.1</strong></p>
<p><strong>1、下载oracle 10g r2</strong></p>
<p>下载回来的文件为10201_database_linux_x86_64.cpio.gz</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$gunzip 10201_database_linux_x86_64.cpio.gz</span><br><span class="line">$cpio -idmv &lt; 10201_database_linux_x86_64.cpio</span><br></pre></td></tr></table></figure>
<p>解压缩后所有的安装文件位于database目录下。</p>
<p><strong>2、检查硬件是否达到要求</strong></p>
<p>物理RAM必须大于512M,现在的机器内存都没问题。超过8GB RAM时,swap应该在物理RAM的0.75倍以上。Enterprise Edition安装类型大约使用2G硬盘空间。<br>通过以下命令检查,如果不满足需要做相应的调整</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$grep MemTotal /proc/meminfo <span class="comment">//检查物理内存大小</span></span><br><span class="line">$grep SwapTotal /proc/meminfo <span class="comment">//检查swap大小</span></span><br><span class="line">$df -h <span class="comment">//检查可用硬件空间大小</span></span><br></pre></td></tr></table></figure>
<p><strong>3、安装需要的软件包,创建需要的符号链接</strong></p>
<p>安装依赖包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$sudo apt-get install build-essential ia32-libs ia32-libs-dev libc6 libc6-i386 libc6-dev libc6-dev-i386 rpm libstdc++<span class="number">5</span> libaio1</span><br></pre></td></tr></table></figure>
<p>如果不安装ia32-libs,安装时会提示</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/.../client/runInstaller: <span class="number">63</span>: <span class="regexp">/.../</span>client/install/.oui: not found</span><br></pre></td></tr></table></figure>

<p>创建符号链接</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#ln -sf /usr/bin/awk /bin/awk</span><br><span class="line">#ln -sf /usr/bin/rpm /bin/rpm</span><br><span class="line">#ln -sf /usr/bin/basename /bin/basename</span><br></pre></td></tr></table></figure>
<p><strong>4、创建oracle需要的组和用户</strong></p>
<p>oracle安装使用的组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#groupadd oinstall</span><br></pre></td></tr></table></figure>
<p>系统管理使用的组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#groupadd dba</span><br></pre></td></tr></table></figure>
<p>创建用户oracle</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#useradd -g oinstall -G dba oracle</span><br></pre></td></tr></table></figure>
<p>为用户oracle设置密码</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#passwd oracle</span><br></pre></td></tr></table></figure>
<p>创建nobody用户和nobody组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#groupadd nobody</span><br></pre></td></tr></table></figure>
<p>debian默认已经创建了nobody用户,其属于nogroup组,但$ORACLE_HOME/root.sh为$ORACLE_HOME/bin/extjob设置的组为nobody,所以这里也要创建nobody组,否则root.sh会抱怨</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/bin/chgrp: invalid group: \<span class="string">`nobody&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>5、配置内核参数和oracle用户资源限制值</strong></p>
<p><strong>内核参数</strong></p>
<p>oracle 10g要求的内核参数值如下</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">semmsl <span class="number">250</span></span><br><span class="line">semmns <span class="number">32000</span></span><br><span class="line">semopm <span class="number">100</span></span><br><span class="line">semmni <span class="number">128</span></span><br><span class="line"></span><br><span class="line">shmmni <span class="number">4096</span> </span><br><span class="line">file-max <span class="number">65536</span> </span><br><span class="line">ip_local_port_range 最小:<span class="number">1024</span> 最大:<span class="number">65000</span></span><br><span class="line">rmem_default <span class="number">262144</span> </span><br><span class="line">rmem_max <span class="number">262144</span> </span><br><span class="line">wmem_default <span class="number">262144</span> </span><br><span class="line">wmem_max <span class="number">262144</span> </span><br></pre></td></tr></table></figure>
<p>shmall是全部允许使用的共享内存大小，shmmax是单个段允许使用的大小。可以直接将这两个参数设置为物理内存的大小或者是SGA值的大小。</p>
<p>shmall是按页计数的所有共享内存的数量,计算方法如下：<br>获取页面大小</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$getconf PAGE_SIZE</span><br><span class="line"><span class="number">4096</span></span><br></pre></td></tr></table></figure>
<p>也就是说页面大小为4K,如果物理内存或SGA总数为16G,则shmall的值为16<em>1024</em>1024/4=4194304</p>
<p>如果oracle出现以下错误提示</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">27102</span>: out <span class="keyword">of</span> memory</span><br><span class="line">Linux-x86_64 <span class="built_in">Error</span>: <span class="number">28</span>: No space left on device</span><br></pre></td></tr></table></figure>
<p>则需要适当增加内核参数shmall的值</p>
<p>如果系统默认的内核参数值高于oracle 10g需要的值,则保持默认参数不变,否则用oracle 10g要求的值来修改内核参数。修改参数时在/etc/sysctl.d目录下新建oracle.conf,将新的参数值写入此文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">kernel.sem = <span class="number">250</span> <span class="number">32000</span> <span class="number">100</span> <span class="number">128</span></span><br><span class="line">kernel.shmmax = <span class="number">8589934592</span></span><br><span class="line">net.ipv4.ip_local_port_range = <span class="number">1024</span> <span class="number">65000</span></span><br><span class="line">net.core.rmem_default = <span class="number">262144</span></span><br><span class="line">net.core.rmem_max = <span class="number">262144</span></span><br><span class="line">net.core.wmem_default = <span class="number">262144</span></span><br><span class="line">net.core.wmem_max = <span class="number">262144</span></span><br></pre></td></tr></table></figure>
<p>kernel.sem参数值按semmsl semmns semopm semmni这个顺序指定,中间以空格隔开</p>
<p>为oracle用户所在组赋予分配大内存页的权限</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#id oracle</span><br><span class="line">uid=<span class="number">1001</span>(oracle) gid=<span class="number">1001</span>(oinstall) groups=<span class="number">1001</span>(oinstall),<span class="number">1002</span>(dba)</span><br><span class="line">#echo <span class="string">&quot;1002&quot;</span> &gt; <span class="regexp">/proc/</span>sys/vm/hugetlb_shm_group</span><br></pre></td></tr></table></figure>
<p>这样oracle才有权限分配大内存页,否则建库时会有错误提示:<br>ORA-27125:unable to create shared memory segment</p>
<p>不过这样设置重启后参数就丢失了,可以在/etc/sysctl.conf或/etc/sysctl.d/oracle.conf文件里面添加该参数</p>
<p>vm.hugetlb_shm_group=1002<br>之后运行命令</p>
<p>#sysctl -p<br>或<br>#sysctl -p /etc/sysctl.d/oracle.conf</p>
<p>可使该参数在内核内存中立即生效</p>
<p><strong>oracle用户资源限制值</strong></p>
<p>在/etc/security/limits.d目录下新建文件oracle.conf,文件名随意,但扩展名一定要是conf,输入一下内容</p>
<h1 id=""><a href="#" class="headerlink" title=""></a></h1><p>oracle soft nproc 2047<br>oracle hard nproc 16384<br>oracle soft nofile 1024<br>oracle hard nofile 65536</p>
<p>在/etc/profile.d目录下新建文件oracle.sh,文件名随意,但扩展名一定要是sh,输入以下内容</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#<span class="keyword">for</span> oracle 10g r2</span><br><span class="line"><span class="keyword">if</span> \[ $USER = <span class="string">&quot;oracle&quot;</span> \]; then</span><br><span class="line"> <span class="keyword">if</span> \[ $SHELL = <span class="string">&quot;/bin/ksh&quot;</span> \]; then</span><br><span class="line"> ulimit -p <span class="number">16384</span></span><br><span class="line"> ulimit -n <span class="number">65536</span></span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> ulimit -u <span class="number">16384</span> -n <span class="number">65536</span></span><br><span class="line"> fi</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p><strong>6、创建oracle基准目录</strong></p>
<p>oracle安装目录的设置最好遵循oracle <a href="http://docs.oracle.com/cd/B19306_01/install.102/b15660/app_ofa.htm">OFA</a>(Optimal Flexible Architecture)规范的建议。</p>
<p>用以下命令来设置ORACLE BASE目录/u01/app/oracle</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mkdir -p /u01/app/oracle</span><br><span class="line">#chown -R oracle:oinstall /u01</span><br><span class="line">#chmod -R <span class="number">775</span> /u01/app/oracle</span><br></pre></td></tr></table></figure>
<p><strong>7、设置oracle用户的环境</strong></p>
<p>设置oracle的用户的主目录home为/u01/app/oracle</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#usermod -d /u01/app/oracle oracle</span><br></pre></td></tr></table></figure>
<p>修改oracle用户的shell为/bin/bash</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#usermod -s /bin/bash oracle</span><br></pre></td></tr></table></figure>
<p>从其他用户主目录下拷贝.profile,.bashrc,.bash_logout文件到oracle用户的主目录,在.bashrc文件增加下面的行<br>umask 022<br>然后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$source .bashrc</span><br></pre></td></tr></table></figure>
<p>最后设置oracle用户<a href="https://openwares.net/linux/x11_forward_over_ssh.html">远程ssh登录时启用X11 Forward</a></p>
<p>也可以不使用X远程静默安装oracle</p>
<p><strong>8、安装oracle 10g x86_64数据库</strong></p>
<p>登录到远程系统</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ssh -XY oracle@remotehost</span><br></pre></td></tr></table></figure>
<p>执行oracle安装程序</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$/path/to/client/runInstaller -ignoreSysPrereqs</span><br></pre></td></tr></table></figure>
<p>因为oracle 10g认证的linux系统只有redhat-3, SuSE-9, redhat-4, UnitedLinux-1.0, asianux-1 和 asianux-2这几个,所以在其他linux发行版上安装时需要指定命令行参数-ignoreSysPrereqs,否则会提示:<br> Checking operating system version: must be redhat-3, SuSE-9, redhat-4, UnitedLinux-1.0, asianux-1 or asianux-2<br> Failed &lt;&lt;&lt;&lt;<br>然后退出安装</p>
<p>之后在本地机器可以看到OUI(Oracle Universal Installer)界面,后面的安装根据提示来就可以了。安装目录修改为/u01/app/oracle/product/10.2.0/db_1</p>
<p>安装进度大约到65%时会有错误提示：<br>Error in invoking target ‘collector’ of makefile ‘/u01/app/oracle/product/10.2.0/db_1/sysman/lib/ins_emdb.mk’.<br>这是oracle安装程序的一个bug,可以忽略此错误继续安装,对系统没什么影响。同时oraInventory/logs/目录下的安装日志文件里面会有如下类似错误提示：</p>
<p>INFO: /usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib/snmccolm.o’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib/libnmccol.a(nmccole.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib/libnmcbuf.a(nmcbuft.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/ap<br>INFO: p/oracle/product/10.2.0/db_1/sysman/lib/libnmcbuf.a(nmcbufw.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib/libnmcbuf.a(nmcbufu.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib/libnmcbuf.a(snmcbufm.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib/<br>INFO: libnmcbuf.a(nmcbuff.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib//libnmadbg.a(nmadbg.o)’ is incompatible with i386:x86-64 output<br>/usr/bin/ld: i386 architecture of input file `/u01/app/oracle/product/10.2.0/db_1/sysman/lib//libnmadbg.a(snmadbg.o)’ is incompatible with i386:x86-64 output<br>collect2: ld returned 1 exit status</p>
<p>INFO: make[1]: Leaving directory `/u01/app/oracle/product/10.2.0/db_1/sysman/lib’</p>
<p>INFO: make[1]: <strong>* [/u01/app/oracle/product/10.2.0/db_1/sysman/lib/nmccollector] Error 1<br>make: *</strong> [nmccollector] Error 2</p>
<p>这是因为oracle 10.2.0.1安装包为这几个i386目标文件提供了错误版本的x86_64链接库,之后安装patchset 10.2.0.4时relink nmccollector会成功。<br>关于此错误更详细的信息请参考Metalink NOTE 957982.1和Bug 8993720。</p>
<p><strong>9、安装后配置</strong></p>
<p>安装完成后,在oracle用户的.bashrc文件中添加以下ORACLE环境变量</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> ORACLE_OWNER=oracle</span><br><span class="line"><span class="keyword">export</span> ORACLE_BASE=<span class="regexp">/u01/</span>app/oracle</span><br><span class="line"><span class="keyword">export</span> ORACLE_HOME=$ORACLE_BASE/product/<span class="number">10.2</span><span class="number">.0</span>/db_1</span><br><span class="line"><span class="keyword">export</span> PATH=$ORACLE_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">export</span> TNS_ADMIN=$ORACLE_HOME/network/admin</span><br><span class="line">#<span class="keyword">export</span> SQLPATH=$ORACLE_HOME/scripts</span><br></pre></td></tr></table></figure>
<p><strong>二、升级到patchset 10.2.0.4</strong></p>
<p><strong>1、升级软件</strong></p>
<p>首先停止所有oracle服务,实际上如果安装完成10.2.0.1后立即进行升级的话,oracle的所有服务并没有运行,也就不必去停止它们</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#/etc/init.d/oracle stop</span><br></pre></td></tr></table></figure>
<p>oracle数据库的启动和关闭控制见<a href="https://openwares.net/2012/01/25/debian_oracle_10g_init/">Debian配置Oracle 10g自启动</a></p>
<p>然后运行升级包升级软件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$/path/to/patchset_directory/Disk1/runInstaller -ignoreSysPrereqs</span><br></pre></td></tr></table></figure>
<p>按提示升级即可</p>
<p><strong>2、升级数据库</strong></p>
<p>如果此前并没有创建数据库,那么升级到10.2.0.4到此就结束了,然后可以去创建新的数据库。<br>如果此前已经创建了数据库,那么按以下步骤升级数据库到10.2.0.4版本</p>
<p>启动监听器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$lsnrctl start</span><br></pre></td></tr></table></figure>

<p>以sysdba身份登陆数据库并运行升级脚本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$sqlplus / <span class="keyword">as</span> sysdba;</span><br><span class="line">SQL&gt; STARTUP UPGRADE</span><br><span class="line">SQL&gt; SPOOL patch.log</span><br><span class="line">SQL&gt; @?<span class="regexp">/rdbms/</span>admin/catupgrd.sql</span><br><span class="line">SQL&gt; SPOOL OFF</span><br></pre></td></tr></table></figure>
<p>关闭并重启数据库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; SHUTDOWN IMMEDIATE</span><br><span class="line">SQL&gt; STARTUP </span><br></pre></td></tr></table></figure>
<p>编译无效PL/SQL包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; @?<span class="regexp">/rdbms/</span>admin/utlrp.sql</span><br></pre></td></tr></table></figure>
<p>检查升级是否成功</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; SELECT COMP_NAME, VERSION, STATUS FROM SYS.DBA_REGISTRY;</span><br></pre></td></tr></table></figure>
<p>如果所有组件的status都是valid表示升级成功</p>
<p>检查是否有升级错误</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select * <span class="keyword">from</span> utl_recomp_errors;</span><br></pre></td></tr></table></figure>
<p>如果使用Oracle Recovery Manager catalog, 需要对catalog进行升级，如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$rman catalog username/password@alias</span><br><span class="line">RMAN&gt; UPGRADE CATALOG; </span><br></pre></td></tr></table></figure>
<p>修改系统兼容性参数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter system set compatible=<span class="string">&#x27;10.2.0.4.0&#x27;</span> scope=spfile;</span><br><span class="line">SQL&gt; SHUTDOWN</span><br><span class="line">SQL&gt; STARTUP</span><br></pre></td></tr></table></figure>
<p>安装完成</p>
<p><strong>UPDATE:</strong></p>
<p>在Debian 当前的tesing分支Wheezy上安装oracle 10g时,需要增加以下两个符号链接：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#ln -sf /usr/lib/x86_64-linux-gnu/ <span class="regexp">/usr/</span>lib64</span><br><span class="line">#ln -sf /lib/x86_64-linux-gnu/libgcc_s.so<span class="number">.1</span> /lib64/libgcc_s.so<span class="number">.1</span></span><br></pre></td></tr></table></figure>
<p>这是因为Wheezy开始支持<a href="https://openwares.net/linux/multiarch_and_lib_dir.html">multiarch</a>,库路径做了比较大的调整。</p>
<p>References:<br>[1]<a href="https://wiki.debian.org/OracleDB">OracleDB</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>debian amd64 安装oracle 10g 即时客户端(instant client)</title>
    <url>/2011/10/28/debian-amd64-install-oracle-10g-instant-client/</url>
    <content><![CDATA[<p>oracle instant client是oracle提供的最轻量的客户端，支持多平台，除支持oracle原生的数据库存取协议外，还支持ODBC和JDBC,支持对数据库服务器的简单管理，减轻应用程序客户端分发的负担。</p>
<a id="more"></a>
<p><strong>下载安装包</strong></p>
<p>从oracle官方的<a href="http://www.oracle.com/technetwork/database/features/instant-client/index-097480.html">instant client</a>下载地址下载linux amd64版本对应的基本包basic-10.2.0.5.0-linux-x64.zip和sqlplus支持包sqlplus-10.2.0.5.0-linux-x64.zip，如需要还可下载其他支持包。</p>
<p><strong>安装</strong></p>
<p>将install client客户端安装到/opt/oracle目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mkdir /opt/oracle</span><br><span class="line">#unzip basic-<span class="number">10.2</span><span class="number">.0</span><span class="number">.5</span><span class="number">.0</span>-linux-x64.zip -d /opt/oracle</span><br><span class="line">#unzip sqlplus-<span class="number">10.2</span><span class="number">.0</span><span class="number">.5</span><span class="number">.0</span>-linux-x64.zip -d /opt/oracle</span><br></pre></td></tr></table></figure>

<p>在/opt/oracle目录下生成instantclient_10_2子目录，instant client客户端的文件都在此目录下</p>
<p><strong>配置</strong></p>
<p>~/.bashrc文件中添加如下内容：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> ORACLE_HOME=<span class="regexp">/opt/</span>oracle/instantclient_10_2</span><br><span class="line"><span class="keyword">export</span> LD_LIBRARY_PATH=$ORACLE_HOME:$LD_LIBRARY_PATH</span><br><span class="line"><span class="keyword">export</span> PATH=$ORACLE_HOME:$PATH</span><br><span class="line"><span class="keyword">export</span> TNS_ADMIN=$ORACLE_HOME</span><br><span class="line"><span class="keyword">export</span> SQLPATH=$ORACLE_HOME</span><br></pre></td></tr></table></figure>

<p>注意:tnsname.ora最好放置到$ORACLE_HOME/network/admin目录下。</p>
<p>然后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#source .bashrc</span><br></pre></td></tr></table></figure>

<p>在$ORACLE_HOME目录下添加并编辑tnsnames.ora文件，增加拟访问的oracle服务器tnsname</p>
<p><strong>连接</strong></p>
<p>sqlplus连接到数据库服务器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sqlplus username/passwd@tnsname</span><br></pre></td></tr></table></figure>

<p>如果有错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sqlplus: error <span class="keyword">while</span> loading shared libraries: libaio.so<span class="number">.1</span>: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>

<p>那么需要安装libaio1</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install libaio1</span><br></pre></td></tr></table></figure>

<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Wheezy AMD64编译安装原生ZFS文件系统</title>
    <url>/2012/04/27/debian-amd64-install-zfs/</url>
    <content><![CDATA[<p>由于license不兼容,ZFS一直无法进入linux kernel</p>
<a id="more"></a>
<p>ZFS使用CDDL(Common Development and Distribution License)协议分发,而linux kernel则采用了GPL2协议,由于这两个协议存在冲突,因而ZFS无法进入内核主线。</p>
<p>虽然之前有个用户空间的ZFS实现zfs-fuse,但是性能肯定是无法保证的,玩玩可以,真正使用还是算了吧。</p>
<p>虽然不能进入内核,但还是有办法将ZFS原生地移植到linux平台,那就是将ZFS作为内核模块来运行,这就是<a href="http://zfsonlinux.org/">ZFS on Linux</a>项目。ZFS on Linux是由美国能源部(Department of Energy)委托劳伦斯利弗莫尔国家实验室LLNL(Lawrence Livermore National Laboratory)开发的。</p>
<p>ZFS on Linux只支持64bits平台,包括两个组件SPL(Solaris Porting Layer)和ZFS,当前版本为0.6.0-rc8,支持的zfs pool版本为28,文件系统版本为5。</p>
<p><strong>安装solaris移植层SPL</strong></p>
<p>下载spl-0.6.0-rc8.tar.gz,解压生成spl-0.6.0-rc8子目录,进入该目录执行以下操作<br>$ sudo apt-get install build-essential gawk alien fakeroot linux-headers-$(uname -r)<br>$ ./configure<br>$ make deb</p>
<p>这会在当前目录下生成三个deb包<br>spl_0.6.0-1_amd64.deb<br>spl-modules_0.6.0-1_amd64.deb<br>spl-modules-devel_0.6.0-1_amd64.deb</p>
<p>安装生成的deb包<br>$sudo dpkg -i *_amd64.deb</p>
<p><strong>安装ZFS</strong></p>
<p>下载zfs-0.6.0-rc8.tar.gz,解压缩生成zfs-0.6.0-rc8子目录,进入该目录执行以下操作<br>$ sudo apt-get install zlib1g-dev uuid-dev libblkid-dev libselinux-dev parted lsscsi<br>$ ./configure<br>$ make deb</p>
<p>这会在当前目录下生成六个deb包<br>zfs_0.6.0-1_amd64.deb<br>zfs-dracut_0.6.0-1_amd64.deb<br>zfs-modules-devel_0.6.0-1_amd64.deb<br>zfs-devel_0.6.0-1_amd64.deb<br>zfs-modules_0.6.0-1_amd64.deb<br>zfs-test_0.6.0-1_amd64.deb</p>
<p>安装生成的deb包<br>$sudo dpkg -i *_amd64.deb</p>
<p>让系统启动时自动加载zfs内核模块,编辑/etc/modules文件,zfs作为单独的一行添加到文件中。</p>
<p><strong>测试</strong></p>
<p>加载ZFS模块</p>
<h1 id="modprobe-zfs"><a href="#modprobe-zfs" class="headerlink" title="modprobe zfs"></a>modprobe zfs</h1><p>查看zfs模块信息<br>$ lsmod grep zfs<br>Module Size Used by<br>zfs 791314 0<br>zunicode 324466 1 zfs<br>zavl 13115 1 zfs<br>zcommon 35811 1 zfs<br>znvpair 31373 2 zcommon,zfs<br>spl 120446 6 znvpair,zcommon,zavl,zunicode,zfs,splat</p>
<p>加载splat(Solaris Porting LAyer Test)模块<br>#modprobe splat</p>
<p>查看splat使用说明<br>#splat<br>usage: splat [hvla] [-t <a href="subsystem:">subsystem:</a>]<br> –help -h This help<br> –verbose -v Increase verbosity<br> –list -l List all tests in all subsystems<br> –all -a Run all tests in all subsystems<br> –test -t Run ‘test’ in subsystem ‘sub’<br> –exit -x Exit on first test error<br> –nocolor -c Do not colorize output</p>
<p>Examples:<br> splat -t kmem:all # Runs all kmem tests<br> splat -t taskq:0x201 # Run taskq test 0x201</p>
<p>执行kmem测试<br>#splat -t kmem:all<br>———–Running SPLAT Tests —————-<br> kmem:kmem_alloc Pass<br> kmem:kmem_zalloc Pass<br> kmem:vmem_alloc Pass<br> kmem:vmem_zalloc Pass<br> kmem:slab_small Pass<br> kmem:slab_large Pass<br> kmem:slab_align Pass<br> kmem:slab_reap Pass<br> kmem:slab_age Pass<br> kmem:slab_lock Pass<br> kmem:slab_overcommit Pass<br> kmem:vmem_size Pass</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian自动完成autocomplete与scp的自动完成</title>
    <url>/2011/06/24/debian-autocomplete-scp/</url>
    <content><![CDATA[<p>bash的TAB自动完成(autocomplete)是一项特别贴心的功能，可以省却很多击键时间，减少错误</p>
<a id="more"></a>
<p>Debian基本系统默认的自动完成功能较弱,只支持很有限的自动完成动作。可以通过安装包bash-completion来大大的提高自动完成的能力</p>
<p>$sudo apt-get install bash-completion</p>
<p>而且scp(secure cp)也是支持自动完成的,但前提是必须使用证书而不是使用密码来存取远端的文件,也就是使用证书自动登录才能使用scp的自动完成功能。ssh证书自动登录请参考<a href="https://openwares.net/linux/ssh_auto_login.html">debian:ssh安全自动登录设置</a>,其中有提及scp的使用。之所以用密码认证登录无法使用自动完成,应该是因为在使用tab自动完成时，还没有提示输入密码进行密码验证，所以无法提供自动完成的信息，而证书验证则不存在此问题。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian阻止个别软件包更新</title>
    <url>/2018/07/18/debian-block-package-update/</url>
    <content><![CDATA[<a id="more"></a>
<p>可以单独阻止个别软件包在执行update和dist-update命令时进行更新，也就是不让这些包从源里更新。</p>
<p>dpkg维护软件包的状态，分别有以下几种状态：</p>
<p>unknown – 用户并没描述他想对软件包进行什么操作。<br>install – 用户希望对软件包进行安装或升级。<br>remove – 用户希望删除软件包，但不想删除任何配置文件。<br>purge – 用户希望完全删除软件包，包括配置文件。<br>hold – 用户希望软件包保持现状，例如，用户希望保持当前的版本，当前的状态，当前的一切。</p>
<p>只要将软件包foobar的状态修改为hold就可以阻止更新：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">echo foobar hold sudo dpkg --set-selections</span><br></pre></td></tr></table></figure>

<p>如果要恢复软件包foobar的更新，只要将状态修改为install就可以了：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">echo foobar install sudo dpkg --set-selections</span><br></pre></td></tr></table></figure>

<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>debian buster en_US.UTF-8 locale下date输出格式问题</title>
    <url>/2019/11/06/debian-buster-en-us-utf-8-locale-date-output/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian buster升级后date命令默认输出12　hours格式，很不适应，locale一直使用en_US.UTF-8，这次升级en_US的默认时间显示格式调整了，这习惯还要变来变去吗？！</p>
<p>如果想继续显示24 hours格式，就要选择一个时间习惯是24 hours格式的locale</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo update-locale LC_TIME=C.UTF-<span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>此命令修改了/etc/default/locale，添加了一行LC_TIME=C.UTF-8</p>
<p>References:<br>[1]<a href="https://serverfault.com/questions/977598/date-in-terminal-now-in-12hr-format-on-debian-buster">``date`` in terminal now in 12hr format on Debian Buster</a><br>[2]<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=877900">general: en-us locale defaults to 24-hour “military” time on stock install</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian buster查看hba卡wwn序号</title>
    <url>/2019/07/16/debian-buster-find-hba-wwn/</url>
    <content><![CDATA[<a id="more"></a>
<p>存储配置主机映射时，需要指定主机HBA(Host Bus Adapter)卡端口的WWN(World Wide Name)<br>因此需要从主机端查看这些WWN,Debian buster系统中这样查看</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /sys/<span class="class"><span class="keyword">class</span>/<span class="title">fc_host</span>/<span class="title">host</span>*/<span class="title">port_name</span></span></span><br><span class="line"><span class="class">0<span class="title">x10000090fa181673</span></span></span><br><span class="line"><span class="class">0<span class="title">x10000090fa181ad6</span></span></span><br></pre></td></tr></table></figure>
<p>表明有两个HBA端口，其WWN分别为0x10000090fa181673和0x10000090fa181ad6<br>存储中配置完成后，分别是这个样的10:00:00:90:fa:18:16:73和10:00:00:90:fa:18:1a:d6</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian buster安装oracle 10g</title>
    <url>/2020/04/28/debian-buster-install-oracle-10g/</url>
    <content><![CDATA[<a id="more"></a>
<p>oracle 10g已经太老了，直接在debian buster上安装是不可以的。但可以迂回一下，先在debian squeeze上安装，然后将安装好的oracle文件打包拷贝到debian buster相同的目录结构下，并且使用相同的用户和组权限。</p>
<p><strong>一、安装</strong></p>
<p>1、安装squeeze及支持组件</p>
<p>下载squeeze最后的版本<a href="https://cdimage.debian.org/mirror/cdimage/archive/6.0.10/amd64/iso-cd/debian-6.0.10-amd64-netinst.iso">6.0.10</a>，脱机安装完毕后，编辑/etc/apt/sources.list使用以下源：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb http:<span class="comment">//archive.debian.org/debian squeeze main contrib non-free</span></span><br></pre></td></tr></table></figure>
<p>其他镜像源都已不可用，只有此归档源可以。</p>
<p>安装支持组件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install build-essential ia32-libs ia32-libs-dev libc6 libc6-i386 libc6-dev libc6-dev-i386 rpm libstdc++<span class="number">5</span> libaio1 gcc-multilib xauth unzip</span><br></pre></td></tr></table></figure>

<p>创建符号链接</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ln -sf /usr/bin/awk /bin/awk</span><br><span class="line"># ln -sf /usr/bin/rpm /bin/rpm</span><br><span class="line"># ln -sf /usr/bin/basename /bin/basename</span><br></pre></td></tr></table></figure>

<p>2、创建用户和组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># groupadd oinstall</span><br><span class="line"># groupadd dba</span><br><span class="line"># adduser oracle</span><br><span class="line"># usermod -g oinstall -G dba oracle</span><br><span class="line"><span class="comment">//# useradd -g oinstall -G dba oracle</span></span><br><span class="line"><span class="comment">//# passwd oracle</span></span><br><span class="line"># groupadd nobody</span><br><span class="line"># id oracle</span><br><span class="line">uid=<span class="number">1001</span>(oracle) gid=<span class="number">1001</span>(oinstall) groups=<span class="number">1001</span>(oinstall),<span class="number">1002</span>(dba)</span><br></pre></td></tr></table></figure>

<p>3、修改内核参数<br>添加文件/etc/sysctl.d/oracle.conf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">fs.file-max = <span class="number">65536</span></span><br><span class="line">fs.aio-max-nr = <span class="number">1048576</span></span><br><span class="line"># semaphores: semmsl, semmns, semopm, semmni</span><br><span class="line">kernel.sem = <span class="number">250</span> <span class="number">32000</span> <span class="number">100</span> <span class="number">128</span></span><br><span class="line"># (Oracle recommends total machine Ram -1 byte)</span><br><span class="line">kernel.shmmax = <span class="number">2147483648</span></span><br><span class="line">kernel.shmall = <span class="number">4194304</span></span><br><span class="line">kernel.shmmni = <span class="number">4096</span></span><br><span class="line">net.ipv4.ip_local_port_range = <span class="number">1024</span> <span class="number">65000</span></span><br><span class="line"># dba group</span><br><span class="line">vm.hugetlb_shm_group = <span class="number">1002</span></span><br><span class="line">vm.nr_hugepages = <span class="number">64</span></span><br></pre></td></tr></table></figure>

<p>4、修改资源限制<br>添加文件/etc/security/limits.d/oracle.conf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">oracle soft nproc <span class="number">2047</span></span><br><span class="line">oracle hard nproc <span class="number">16384</span></span><br><span class="line">oracle soft nofile <span class="number">1024</span></span><br><span class="line">oracle hard nofile <span class="number">65536</span></span><br><span class="line">oracle soft memlock <span class="number">204800</span></span><br><span class="line">oracle hard memlock <span class="number">204800</span></span><br></pre></td></tr></table></figure>

<p>5、准备目录结构</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mkdir -p /u01/app/oracle</span><br><span class="line">#chown -R oracle:oinstall /u01</span><br><span class="line"></span><br><span class="line">#chmod -R <span class="number">775</span> /u01/app/oracle</span><br><span class="line"></span><br><span class="line">#usermod -d /u01/app/oracle oracle</span><br><span class="line">#usermod -s /bin/bash oracle</span><br></pre></td></tr></table></figure>
<p>从其他用户主目录拷贝.profile，.bashrc，.bash_logout文件到oracle用户主目录</p>
<p>6、安装10.2.0.1<br>通过X11 forward远程安装，安装路径设定为/u01/app/oracle/product/10.2.0/db_1<br>只安装软件，不创建数据库，忽略ins_emdb.mk错误继续安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh -XC oracle@host</span><br><span class="line">$ gunzip 10201_database_linux_x86_64.cpio.gz</span><br><span class="line">$ cpio -idmv &lt; 10201_database_linux_x86_64.cpio</span><br><span class="line">$ database/runInstaller -ignoreSysPrereqs</span><br></pre></td></tr></table></figure>

<p>7、升级10.2.0.4</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ unzip p6810189_10204_Linux-x86-<span class="number">64.</span>zip</span><br><span class="line">$ Disk1/runInstaller -ignoreSysPrereqs</span><br></pre></td></tr></table></figure>
<p>升级时选择同一个实例，即OraDb10g_home1</p>
<p><strong>二、移植</strong></p>
<p>1、在squeeze上打包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tar zcvf /tmp/oracle.tar.gz /u01</span><br><span class="line">$ tar zcvf /tmp/oracle_conf.tar.gz /etc/oratab /etc/oraInst.loc /usr/local/bin/ <span class="regexp">/etc/</span>sysctl.d/oracle.conf /etc/security/limits.d/oracle.conf</span><br></pre></td></tr></table></figure>

<p>2、buster上创建用户组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#groupadd oinstall</span><br><span class="line">#groupadd dba</span><br><span class="line"># adduser oracle</span><br><span class="line"># usermod -g oinstall -G dba oracle</span><br><span class="line"><span class="comment">//# useradd -g oinstall -G dba oracle</span></span><br><span class="line"><span class="comment">//# passwd oracle</span></span><br><span class="line">#groupadd nobody</span><br></pre></td></tr></table></figure>

<p>3、准备目录结构</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mkdir -p /u01/app/oracle</span><br><span class="line">#chown -R oracle:oinstall /u01</span><br><span class="line">#chown -R oracle:oinstall /u01/app</span><br><span class="line">#chown -R oracle:oinstall /u01/app/oracle</span><br><span class="line">#chmod -R <span class="number">775</span> /u01/app/oracle</span><br><span class="line"></span><br><span class="line">#usermod -d /u01/app/oracle oracle</span><br><span class="line">#usermod -s /bin/bash oracle</span><br></pre></td></tr></table></figure>

<p>4、buster上还原oracle<br>将oracle.tar.gz和oracle_conf.tar.gz拷贝到/tmp目录，以oracle用户执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tar zxvf /tmp/oracle.tar.gz -C /</span><br></pre></td></tr></table></figure>
<p>以root用户执行:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># tar zxvf /tmp/oracle_conf.tar.gz -C /</span><br></pre></td></tr></table></figure>

<p>5、oracle用户配置<br>.bashrc添加如下环境变量</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> ORACLE_SID=orcl</span><br><span class="line"><span class="keyword">export</span> ORACLE_UNQNAME=orcl</span><br><span class="line"><span class="keyword">export</span> ORACLE_OWNER=oracle</span><br><span class="line"><span class="keyword">export</span> ORACLE_BASE=<span class="regexp">/u01/</span>app/oracle</span><br><span class="line"><span class="keyword">export</span> ORACLE_HOME=$ORACLE_BASE/product/<span class="number">10.2</span><span class="number">.0</span>/db_1</span><br><span class="line"><span class="keyword">export</span> PATH=$ORACLE_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">export</span> TNS_ADMIN=$ORACLE_HOME/network/admin</span><br><span class="line"><span class="keyword">export</span> SQLPATH=$ORACLE_HOME/scripts</span><br><span class="line"><span class="keyword">export</span> LD_LIBRARY_PATH=$ORACLE_HOME/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>

<p>安装完成，经测试可以正常创建数据库，正常使用。</p>
<p>References:<br>[1]<a href="https://wiki.debian.org/OracleDB">OracleDB</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>debian buster安装搜狗输入法</title>
    <url>/2020/01/14/debian-buster-install-sogou-im/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>下载</strong></p>
<p>下载64位<a href="https://pinyin.sogou.com/linux/?r=pinyin">安装包</a></p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install libqt4-declarative</span><br><span class="line">$ sudo dpkg -i sogoupinyin_2<span class="number">.3</span><span class="number">.1</span>.0112_amd64.deb</span><br><span class="line">$ sudo apt install -f</span><br></pre></td></tr></table></figure>

<p>如果不安装libqt4-declarative，搜狗输入法无法正常使用，并且会报<br>“搜狗输入法异常：删除~/.config/SogouPY并重新启动”，<br>如果终端内输入命令sogou-qimpanel，会提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sogou-qimpanel</span><br><span class="line">sogou-qimpanel: error <span class="keyword">while</span> loading shared libraries: libQtDeclarative.so<span class="number">.4</span>: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>

<p><strong>配置</strong><br>安装完毕后，运行fcitx-config-gtk3或者fcitx-configtool，然后在input method页签内点击+号添加sogou pinyin输入法，搜索输入法时去掉“only show current language”选项。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian buster安装wine-devel</title>
    <url>/2019/07/15/debian-buster-install-wine-devel/</url>
    <content><![CDATA[<a id="more"></a>
<p>wine是个伟大的工程。</p>
<p>wine有三个分支wine-stable,wine-devel和wine-staging，就好像debian的三个分支stable,testing和sid，devel分支其实很稳定的，也能支持更多的应用程序</p>
<p>但是debian buster上安装wine-devel出现依赖问题：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">wine-devel : Depends: wine-devel-amd64 (= <span class="number">4.12</span><span class="number">.1</span>~buster) but it is not going to be installed</span><br><span class="line"> Depends: wine-devel-i386 (= <span class="number">4.12</span><span class="number">.1</span>~buster)</span><br><span class="line">wine-devel-amd64 : Depends: libfaudio0 but it is not installable</span><br></pre></td></tr></table></figure>
<p>从wine4.5开始，wine-devel依赖libfaudio0,但是debian官方源并没有提供这个包，因此可以从参考[2]给出的链接下载amd64和i386两个架构的安装包libfaudio0_19.07-0_buster_amd64.deb和libfaudio0_19.07-0_buster_i386.deb<br>并手工安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg -i libfaudio0_19<span class="number">.07</span>-0_buster_amd64.deb</span><br><span class="line">$ sudo dpkg -i libfaudio0_19<span class="number">.07</span>-0_buster_i386.deb</span><br></pre></td></tr></table></figure>

<p>然后再安装wine-devel</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt -y install wine-devel</span><br></pre></td></tr></table></figure>

<p>注意wine-devel安装到/opt/wine-devel目录，因此要使用wine-devel需要在.bashrc中添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> PATH=<span class="regexp">/opt/</span>wine-devel/bin:$PATH</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://wiki.winehq.org/Debian">Installing WineHQ packages</a><br>[2]<a href="https://forum.winehq.org/viewtopic.php?f=8&t=32192">FAudio for Debian and Ubuntu</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian buster multipath 多路径设备配置</title>
    <url>/2019/07/03/debian-buster-multipath-configuration/</url>
    <content><![CDATA[<a id="more"></a>
<p>安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install multipath-tools</span><br></pre></td></tr></table></figure>

<p>查看多路径配置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo multipath -ll</span><br></pre></td></tr></table></figure>
<p>没有信息输出，多路径没有自动配置好，需要手工配置</p>
<p>查看路径信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo multipath -v3</span><br><span class="line">ul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> set open fds limit to <span class="number">1048576</span>/<span class="number">1048576</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> loading <span class="comment">//lib/multipath/libchecktur.so checker</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> checker tur: message table size = <span class="number">3</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> loading <span class="comment">//lib/multipath/libprioconst.so prioritizer</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> foreign library <span class="string">&quot;nvme&quot;</span> loaded successfully</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: udev property ID_WWN whitelisted</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: mask = <span class="number">0x1f</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: dev_t = <span class="number">8</span>:<span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: size = <span class="number">1167966208</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: vendor = IBM</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: product = ServeRAID M5015</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: rev = <span class="number">2.12</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: h:b:t:l = <span class="number">0</span>:<span class="number">2</span>:<span class="number">0</span>:<span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: tgt_node_name = </span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: path state = running</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: <span class="number">7166</span> cyl, <span class="number">255</span> heads, <span class="number">63</span> sectors/track, start at <span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: serial = 00f8ec7f2abe47c318d0451a04b00506</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: get_state</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: detect_checker = yes (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> failed to issue vpd inquiry <span class="keyword">for</span> pgc9</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: path_checker = tur (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: checker timeout = <span class="number">90</span> s (setting: kernel sysfs)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: tur state = up</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: uid_attribute = ID_SERIAL (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: uid = 3600605b0041a45d018c347be2a7fecf8 (udev)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: detect_prio = yes (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: prio = <span class="keyword">const</span> (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: prio args = <span class="string">&quot;&quot;</span> (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: <span class="keyword">const</span> prio = <span class="number">1</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sr0: blacklisted, udev property missing</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: udev property ID_WWN whitelisted</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: mask = <span class="number">0x1f</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: dev_t = <span class="number">8</span>:<span class="number">16</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: size = <span class="number">10538188800</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: vendor = IBM</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: product = <span class="number">1814</span> FAStT</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: rev = <span class="number">1060</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: h:b:t:l = <span class="number">1</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> SCSI target <span class="number">1</span>:<span class="number">0</span>:<span class="number">0</span> -&gt; FC rport <span class="number">1</span>:<span class="number">0</span>-<span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: tgt_node_name = <span class="number">0x20040080e52c8d92</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: path state = running</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: <span class="number">65535</span> cyl, <span class="number">255</span> heads, <span class="number">63</span> sectors/track, start at <span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: serial = SQ22101119</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: get_state</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: detect_checker = yes (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> loading <span class="comment">//lib/multipath/libcheckrdac.so checker</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> checker rdac: message table size = <span class="number">9</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: path_checker = rdac (setting: storage device autodetected)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: checker timeout = <span class="number">30</span> s (setting: kernel sysfs)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: rdac state = up</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: uid_attribute = ID_SERIAL (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: uid = 360080e50002c8d920000146c5d1bca10 (udev)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: detect_prio = yes (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> loading <span class="comment">//lib/multipath/libpriordac.so prioritizer</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: prio = rdac (setting: storage device configuration)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: prio args = <span class="string">&quot;&quot;</span> (setting: storage device configuration)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: rdac prio = <span class="number">14</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: udev property ID_WWN whitelisted</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: mask = <span class="number">0x1f</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: dev_t = <span class="number">8</span>:<span class="number">32</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: size = <span class="number">10538188800</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: vendor = IBM</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: product = <span class="number">1814</span> FAStT</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: rev = <span class="number">1060</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: h:b:t:l = <span class="number">4</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> SCSI target <span class="number">4</span>:<span class="number">0</span>:<span class="number">0</span> -&gt; FC rport <span class="number">4</span>:<span class="number">0</span>-<span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: tgt_node_name = <span class="number">0x20040080e52c8d92</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: path state = running</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: <span class="number">65535</span> cyl, <span class="number">255</span> heads, <span class="number">63</span> sectors/track, start at <span class="number">0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: serial = SQ22101611</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: get_state</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: detect_checker = yes (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: path_checker = rdac (setting: storage device autodetected)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: checker timeout = <span class="number">30</span> s (setting: kernel sysfs)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: rdac state = up</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: uid_attribute = ID_SERIAL (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: uid = 360080e50002c8d920000146c5d1bca10 (udev)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: detect_prio = yes (setting: multipath internal)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: prio = rdac (setting: storage device configuration)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: prio args = <span class="string">&quot;&quot;</span> (setting: storage device configuration)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: rdac prio = <span class="number">9</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> libdevmapper version <span class="number">1.02</span><span class="number">.155</span> (<span class="number">2018</span>-<span class="number">12</span>-<span class="number">18</span>)</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> DM multipath kernel driver v1<span class="number">.13</span><span class="number">.0</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: udev property ID_WWN whitelisted</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> wwid 3600605b0041a45d018c347be2a7fecf8 not <span class="keyword">in</span> wwids file, skipping sda</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sda: orphan path, only one path</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> <span class="keyword">const</span> prioritizer refcount <span class="number">1</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: udev property ID_WWN whitelisted</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> wwid 360080e50002c8d920000146c5d1bca10 not <span class="keyword">in</span> wwids file, skipping sdb</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdb: orphan path, only one path</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> rdac prioritizer refcount <span class="number">2</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: udev property ID_WWN whitelisted</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> wwid 360080e50002c8d920000146c5d1bca10 not <span class="keyword">in</span> wwids file, skipping sdc</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> sdc: orphan path, only one path</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> rdac prioritizer refcount <span class="number">1</span></span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> unloading rdac prioritizer</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> unloading <span class="keyword">const</span> prioritizer</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> unloading rdac checker</span><br><span class="line">Jul <span class="number">03</span> <span class="number">15</span>:<span class="number">22</span>:<span class="number">38</span> unloading tur checker</span><br><span class="line">===== paths list =====</span><br><span class="line">uuid hcil dev dev_t pri dm_st chk_st vend/prod</span><br><span class="line">3600605b0041a45d018c347be2a7fecf8 <span class="number">0</span>:<span class="number">2</span>:<span class="number">0</span>:<span class="number">0</span> sda <span class="number">8</span>:<span class="number">0</span> <span class="number">1</span> undef undef IBM,Serve</span><br><span class="line">360080e50002c8d920000146c5d1bca10 <span class="number">1</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span> sdb <span class="number">8</span>:<span class="number">16</span> <span class="number">14</span> undef undef IBM,<span class="number">1814</span> </span><br><span class="line">360080e50002c8d920000146c5d1bca10 <span class="number">4</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span> sdc <span class="number">8</span>:<span class="number">32</span> <span class="number">9</span> undef undef IBM,<span class="number">1814</span> </span><br></pre></td></tr></table></figure>


<p>或者可以直接查看存在的路径</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo multipath -d -v3 <span class="number">2</span>&gt;<span class="regexp">/dev/</span><span class="literal">null</span></span><br><span class="line">===== paths list =====</span><br><span class="line">uuid hcil dev dev_t pri dm_st chk_st vend/prod</span><br><span class="line">3600605b0041a45d018c347be2a7fecf8 <span class="number">0</span>:<span class="number">2</span>:<span class="number">0</span>:<span class="number">0</span> sda <span class="number">8</span>:<span class="number">0</span> <span class="number">1</span> undef undef IBM,Serve</span><br><span class="line">360080e50002c8d920000146c5d1bca10 <span class="number">1</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span> sdb <span class="number">8</span>:<span class="number">16</span> <span class="number">14</span> undef undef IBM,<span class="number">1814</span> </span><br><span class="line">360080e50002c8d920000146c5d1bca10 <span class="number">4</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span> sdc <span class="number">8</span>:<span class="number">32</span> <span class="number">9</span> undef undef IBM,<span class="number">1814</span> </span><br></pre></td></tr></table></figure>

<p>可以看到有两条路径有相同的wwid，添加此wwid到系统/etc/multipath/wwids配置文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo multipath -a 360080e50002c8d920000146c5d1bca10</span><br><span class="line">wwid <span class="string">&#x27;360080e50002c8d920000146c5d1bca10&#x27;</span> added</span><br></pre></td></tr></table></figure>

<p>重新启动multipathd服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl restart multipathd.service</span><br></pre></td></tr></table></figure>

<p>可以看到有多路径设备dm-0了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo multipath -l</span><br><span class="line">360080e50002c8d920000146c5d1bca10 dm-<span class="number">0</span> IBM,<span class="number">1814</span> FAStT</span><br><span class="line">size=<span class="number">4.</span>9T features=<span class="string">&#x27;5 queue_if_no_path pg_init_retries 50 queue_mode mq&#x27;</span> hwhandler=<span class="string">&#x27;1 rdac&#x27;</span> wp=rw</span><br><span class="line">-+- policy=<span class="string">&#x27;service-time 0&#x27;</span> prio=<span class="number">0</span> status=enabled</span><br><span class="line"> \<span class="string">`- 1:0:0:0 sdb 8:16 active undef running</span></span><br><span class="line"><span class="string">\`-+- policy=&#x27;service-time 0&#x27; prio=0 status=enabled</span></span><br><span class="line"><span class="string"> \`- 4:0:0:0 sdc 8:32 active undef running</span></span><br></pre></td></tr></table></figure>

<p>还不好，设备没有别名，访问起来很麻烦，添加一个多路径配置文件/etc/multipath/conf.d/multipath.conf,内容如下</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">multipaths &#123;</span><br><span class="line">multipath &#123;</span><br><span class="line">wwid 360080e50002c8d920000146c5d1bca10</span><br><span class="line">alias data</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后重新查看</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl restart multipathd.service</span><br><span class="line"></span><br><span class="line">$ sudo multipath -l</span><br><span class="line">data (360080e50002c8d920000146c5d1bca10) dm-<span class="number">0</span> IBM,<span class="number">1814</span> FAStT</span><br><span class="line">size=<span class="number">4.</span>9T features=<span class="string">&#x27;5 queue_if_no_path pg_init_retries 50 queue_mode mq&#x27;</span> hwhandler=<span class="string">&#x27;1 rdac&#x27;</span> wp=rw</span><br><span class="line">-+- policy=<span class="string">&#x27;service-time 0&#x27;</span> prio=<span class="number">14</span> status=active</span><br><span class="line"> \<span class="string">`- 1:0:0:0 sdb 8:16 active ready running</span></span><br><span class="line"><span class="string">\`-+- policy=&#x27;service-time 0&#x27; prio=9 status=enabled</span></span><br><span class="line"><span class="string"> \`- 4:0:0:0 sdc 8:32 active ready running</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ ls -l /dev/mapper/</span></span><br><span class="line"><span class="string">total 0</span></span><br><span class="line"><span class="string">crw------- 1 root root 10, 236 Jul 3 14:55 control</span></span><br><span class="line"><span class="string">lrwxrwxrwx 1 root root 7 Jul 3 15:45 data -&gt; ../dm-0</span></span><br><span class="line"><span class="string">lrwxrwxrwx 1 root root 7 Jul 3 15:45 data-part1 -&gt; ../dm-1</span></span><br></pre></td></tr></table></figure>

<p>/dev/mapper/data就是映射后的多路径块设备，和/dev/sda等一样操作就好了，其上存在一个分区/dev/mapper/data-part1</p>
<p>格式化为ext4文件系统，<strong>注意会破坏分区上的所有数据</strong>。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mkfs.ext4 /dev/mapper/data-part1 </span><br><span class="line">mke2fs <span class="number">1.44</span><span class="number">.5</span> (<span class="number">15</span>-Dec-<span class="number">2018</span>)</span><br><span class="line">Creating filesystem <span class="keyword">with</span> <span class="number">1317273339</span> 4k blocks and <span class="number">164659200</span> inodes</span><br><span class="line">Filesystem UUID: b60f85e2-<span class="number">5813</span>-48d7-856b-2f8dc7c1aad0</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line"> <span class="number">32768</span>, <span class="number">98304</span>, <span class="number">163840</span>, <span class="number">229376</span>, <span class="number">294912</span>, <span class="number">819200</span>, <span class="number">884736</span>, <span class="number">1605632</span>, <span class="number">2654208</span>, </span><br><span class="line"> <span class="number">4096000</span>, <span class="number">7962624</span>, <span class="number">11239424</span>, <span class="number">20480000</span>, <span class="number">23887872</span>, <span class="number">71663616</span>, <span class="number">78675968</span>, </span><br><span class="line"> <span class="number">102400000</span>, <span class="number">214990848</span>, <span class="number">512000000</span>, <span class="number">550731776</span>, <span class="number">644972544</span></span><br><span class="line"></span><br><span class="line">Allocating group tables: done </span><br><span class="line">Writing inode tables: done </span><br><span class="line">Creating journal (<span class="number">262144</span> blocks): done</span><br><span class="line">Writing superblocks and filesystem accounting information: </span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">$ blkid /dev/mapper/data-part1 </span><br><span class="line">/dev/mapper/data-part1: UUID=<span class="string">&quot;b60f85e2-5813-48d7-856b-2f8dc7c1aad0&quot;</span> TYPE=<span class="string">&quot;ext4&quot;</span> PARTUUID=<span class="string">&quot;ba6bcf54-89e3-4852-a993-4f44d8839531&quot;</span></span><br></pre></td></tr></table></figure>

<p>自动挂载/etc/fstab添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/dev/mapper/data-part1 /mnt/data ext4 defaults <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>挂载后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ df -h</span><br><span class="line">Filesystem Size Used Avail Use% Mounted on</span><br><span class="line">udev 16G <span class="number">0</span> 16G <span class="number">0</span>% /dev</span><br><span class="line">tmpfs <span class="number">3.</span>2G <span class="number">9.</span>3M <span class="number">3.</span>2G <span class="number">1</span>% /run</span><br><span class="line">/dev/sda2 516G <span class="number">1.</span>4G 488G <span class="number">1</span>% /</span><br><span class="line">tmpfs 16G <span class="number">0</span> 16G <span class="number">0</span>% <span class="regexp">/dev/</span>shm</span><br><span class="line">tmpfs <span class="number">5.</span>0M <span class="number">0</span> <span class="number">5.</span>0M <span class="number">0</span>% <span class="regexp">/run/</span>lock</span><br><span class="line">tmpfs 16G <span class="number">0</span> 16G <span class="number">0</span>% <span class="regexp">/sys/</span>fs/cgroup</span><br><span class="line">/dev/sda1 511M <span class="number">5.</span>1M 506M <span class="number">1</span>% <span class="regexp">/boot/</span>efi</span><br><span class="line">tmpfs <span class="number">3.</span>2G <span class="number">0</span> <span class="number">3.</span>2G <span class="number">0</span>% <span class="regexp">/run/u</span>ser/<span class="number">1000</span></span><br><span class="line">/dev/mapper/data-part1 <span class="number">4.</span>9T 89M <span class="number">4.</span>7T <span class="number">1</span>% <span class="regexp">/mnt/</span>data</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian buster tomcat9缺少控制台输出日志catalina.out</title>
    <url>/2019/10/18/debian-buster-tomcat9-no-stdout-log-catalina-out/</url>
    <content><![CDATA[<a id="more"></a>
<p>tomcat9 on debian buster没有catalina.out日志文件，修改/usr/share/tomcat9/bin/catalina.sh文件，大约380多行处</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">elif \[ <span class="string">&quot;$1&quot;</span> = <span class="string">&quot;run&quot;</span> \]; then</span><br><span class="line"></span><br><span class="line"> shift</span><br><span class="line"> #行添加开始</span><br><span class="line"> <span class="keyword">if</span> \[ -z <span class="string">&quot;$CATALINA_OUT_CMD&quot;</span> \] ; then</span><br><span class="line"> touch <span class="string">&quot;$CATALINA_OUT&quot;</span></span><br><span class="line"> catalina_out_command=<span class="string">&quot;&gt;&gt; \\&quot;</span>$CATALINA_OUT\\<span class="string">&quot; 2&gt;&amp;1&quot;</span></span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> catalina_out_command=<span class="string">&quot; $CATALINA_OUT_CMD&quot;</span></span><br><span class="line"> fi</span><br><span class="line"> #行添加结束</span><br><span class="line"> <span class="keyword">if</span> \[ <span class="string">&quot;$1&quot;</span> = <span class="string">&quot;-security&quot;</span> \] ; then</span><br><span class="line"> <span class="keyword">if</span> \[ $have_tty -eq <span class="number">1</span> \]; then</span><br><span class="line"> echo <span class="string">&quot;Using Security Manager&quot;</span></span><br><span class="line"> fi</span><br><span class="line"> shift</span><br><span class="line"> <span class="built_in">eval</span> exec <span class="string">&quot;\\&quot;</span>$_RUNJAVA\\<span class="string">&quot;&quot;</span> <span class="string">&quot;\\&quot;</span>$LOGGING_CONFIG\\<span class="string">&quot;&quot;</span> $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \\</span><br><span class="line"> -D$ENDORSED_PROP=<span class="string">&quot;\\&quot;</span>$JAVA_ENDORSED_DIRS\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -classpath <span class="string">&quot;\\&quot;</span>$CLASSPATH\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Djava.security.manager \\</span><br><span class="line"> -Djava.security.policy==<span class="string">&quot;\\&quot;</span>$CATALINA_BASE/policy/catalina.policy\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Dcatalina.base=<span class="string">&quot;\\&quot;</span>$CATALINA_BASE\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Dcatalina.home=<span class="string">&quot;\\&quot;</span>$CATALINA_HOME\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Djava.io.tmpdir=<span class="string">&quot;\\&quot;</span>$CATALINA_TMPDIR\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> #行尾添加$catalina_out_command</span><br><span class="line"> org.apache.catalina.startup.Bootstrap <span class="string">&quot;$@&quot;</span> start $catalina_out_command</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> <span class="built_in">eval</span> exec <span class="string">&quot;\\&quot;</span>$_RUNJAVA\\<span class="string">&quot;&quot;</span> <span class="string">&quot;\\&quot;</span>$LOGGING_CONFIG\\<span class="string">&quot;&quot;</span> $LOGGING_MANAGER $JAVA_OPTS $CATALINA_OPTS \\</span><br><span class="line"> -D$ENDORSED_PROP=<span class="string">&quot;\\&quot;</span>$JAVA_ENDORSED_DIRS\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -classpath <span class="string">&quot;\\&quot;</span>$CLASSPATH\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Dcatalina.base=<span class="string">&quot;\\&quot;</span>$CATALINA_BASE\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Dcatalina.home=<span class="string">&quot;\\&quot;</span>$CATALINA_HOME\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> -Djava.io.tmpdir=<span class="string">&quot;\\&quot;</span>$CATALINA_TMPDIR\\<span class="string">&quot;&quot;</span> \\</span><br><span class="line"> #行尾添加$catalina_out_command</span><br><span class="line"> org.apache.catalina.startup.Bootstrap <span class="string">&quot;$@&quot;</span> start $catalina_out_command</span><br><span class="line"> fi</span><br></pre></td></tr></table></figure>

<p>最后重新启动tomcat9服务就可以。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian更改默认java环境</title>
    <url>/2015/01/19/debian-change-java-jdk/</url>
    <content><![CDATA[<a id="more"></a>
<p>首先查看系统当前java版本和当前已经安装的java版本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$java -version</span><br><span class="line">java version <span class="string">&quot;1.7.0_65&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (IcedTea <span class="number">2.5</span><span class="number">.3</span>) (7u71-<span class="number">2.5</span><span class="number">.3</span>-<span class="number">2</span>)</span><br><span class="line">OpenJDK <span class="number">64</span>-Bit Server VM (build <span class="number">24.65</span>-b04, mixed mode)</span><br><span class="line"></span><br><span class="line">$ update-java-alternatives -l</span><br><span class="line">java-<span class="number">1.7</span><span class="number">.0</span>-openjdk-amd64 <span class="number">1071</span> /usr/lib/jvm/java-<span class="number">1.7</span><span class="number">.0</span>-openjdk-amd64</span><br><span class="line">jdk-<span class="number">8</span>-oracle-x64 <span class="number">318</span> /usr/lib/jvm/jdk-<span class="number">8</span>-oracle-x64</span><br></pre></td></tr></table></figure>

<p>可以看到系统当前java版本为openjdk 7,系统当前安装了两个java版本，分别是openjdk 7和 oracle jdk 8</p>
<p>然后更改系统默认java为oracle jdk 8</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># update-java-alternatives -s jdk-8-oracle-x64</span><br><span class="line">update-alternatives: error: no alternatives <span class="keyword">for</span> iceweasel-javaplugin.so</span><br></pre></td></tr></table></figure>

<p>因为没有使用iceweasel,所以忽略错误即可。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Starting DHCP server: dhcpd3check syslog for diagnostics</title>
    <url>/2009/12/28/debian-dhcp-error/</url>
    <content><![CDATA[<p>debian服务器sudo apt-get install dhcp3-server后，出现错误提示“Starting DHCP server: dhcpd3check syslog for diagnostics. failed!”<br>其实这是因为还没有配置dhcp引起的，打开/etc/dhcp3/dhcpd.conf增加一个subnet，比如：<br>subnet 192.168.1.0 netmask 255.255.255.0{<br> range 192.168.1.100 192.168.1.200;<br> option routers 192.168.1.1;<br>}<br>然后sudo /etc/init.d/dhcp3-server start就可以启动了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian无盘工作站安装指南</title>
    <url>/2010/09/12/debian-diskless-installation/</url>
    <content><![CDATA[<p>写此文缘于有一台老本IDE控制器坏掉了,无法正常使用硬盘，但其他硬件尚好，遂折腾之，将折腾过程记录於此。当然虽然安装成功，老本仍难免束之高阁。</p>
<p>一、服务器端安装配置</p>
<p>1、参考《<a href="https://openwares.net/it/linux/pxe_install_debian.html">PXE网络安装Debian</a>》安装配置好DHCP和TFTP服务</p>
<p>2、安装配置nfs服务器</p>
<p>sudo apt-get install nfs-common nfs-kernel-server,然后配置nfs,打开 /etc/exports文件，在最后添加一行,/srv/nfs/homes 192.168.1.0/24(rw,no_root_squash,no_subtree_check,sync),/srv/nfs/homes是服务器通过nfs对外提供的磁盘空间的根目录,当然无盘客户机可能不只一台，所以我们会在这个目录下再建立以无盘客户机的hostname为名字的子目录作为无盘机运行时的根文件系统。文中只有一台无盘客户机，hostname定为diskless</p>
<p>3、安装syslinux</p>
<p>sudo apt-get install syslinux,安装syslinux只是为了使用pxelinux.0文件，将此文件拷贝到tftpboot目录，sudo cp /usr/lib/syslinux/pxelinux.0 /var/lib/tftpboot/</p>
<a id="more"></a>
<p>4、创建支持nfs的initird和kernel,以便从pxe启动并使用nfs磁盘</p>
<p>修改服务器的/etc/initramfs-tools/initramfs.conf文件，修改MODULES行为MODULES=netboot,BOOT行为BOOT=nfs，然后生成支持nfs的初始化虚拟磁盘,$sudo mkinitramfs -o /var/lib/tftpboot/initrd.nfs</p>
<p>内核则可以直接使用服务器安装的内核,当然前提是架构要相同，比如都是amd64或i386,$sudo cp /boot/vmlinuz-*** /var/lib/tftpboot/vmlinuz</p>
<p>5、利用debootstrap生成一个无盘客户机登录后可使用的根文件系统</p>
<p>在/srv/nfs/homes目录下以无盘客户机的hostname为名建立无盘客户机登录后根文件系统所在的目录，这里是diskless目录，然后在此目录下生成一个可登录的debian基本系统,$ sudo debootstrap - -arch=i386 lenny /srv/nfs/homes/diskless <a href="http://ftp.debian.org.tw/debian/">http://ftp.debian.org.tw/debian/</a></p>
<p>6、建立无盘客户机配置文件</p>
<p>在/var/lib/tftpboot目录建立pxelinux.cfg目录，然后在pxelinux.cfg目录下建立default文件,也可以是以无盘客户机ip地址为文件名称,default为无盘客户机缺省的配置文件,default文件内容如下</p>
<p>DEFAULT debian<br>LABEL debian<br>kernel vmlinuz<br>append initrd=initrd.nfs root=/dev/nfs nfsroot=192.168.1.2:/srv/nfs/homes/diskless ip=dhcp rw vga=792<br>其中nfsroot指定了服务器的ip和客户机在该服务器上的根文件系统路径<br>至此无盘客户机应该可以通过PXE启动方式，进入一个字符终端，root密码为空。</p>
<p>二、无盘客户端安装配置</p>
<p>客户机端就比较简单了,以pxe方式启动，进入一个debian基本系统，虽然无盘客户机使用的内核是/var/lib/tftpboot/目录下的内核，但仍然需要安装一下内核，以解决这个基本系统的很多对内核的依赖问题，最好安装与启动内核一致的版本。安装好内核后就可以自由的安装其他软件了，当然安装X系统也是没问题的。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian启用巨页内存</title>
    <url>/2016/07/25/debian-enable-hugepages/</url>
    <content><![CDATA[<a id="more"></a>
<p>内存是分页管理的,传统上每页内存是4K大小,当系统内存很大时,页表项剧增,查找内存页表增加了系统的负担,因此出现了巨页.当前amd64架构支持2M内存页和1G内存页,默认巨页大小是2M.</p>
<p><strong>创建巨页内存组</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># groupadd hugetlbfs</span><br><span class="line"># getent group hugetlbfs</span><br><span class="line">hugetlbfs:x:<span class="number">1001</span>:</span><br><span class="line"># adduser postgres hugetlbfs</span><br></pre></td></tr></table></figure>

<p>把postgres用户加入巨页内存组,从而使postgresql可以分配巨页内存</p>
<p><strong>编辑/etc/sysctl.conf</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">vm.nr_hugepages = 13824 # 巨页内存池大小,系统保留多少页巨页内存,这里保留了13824*2M=27G</span><br><span class="line">vm.vm.hugetlb_shm_group = 1001 #巨页内存所属组</span><br></pre></td></tr></table></figure>

<p><strong>创建巨页内存挂载点</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mkdir /hugepages</span><br></pre></td></tr></table></figure>

<p><strong>编辑/etc/fstab自动挂载巨页内存文件系统</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">hugetlbfs /hugepages hugetlbfs mode=<span class="number">1770</span>,gid=<span class="number">1001</span> <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p><strong>配置生效</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># sysctl -p</span><br></pre></td></tr></table></figure>

<p>如果内存碎片化太严重而无法为巨页池保留足够的内存,可以重新启动系统,或者先试图释放系统缓存再重试sysctl命令</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># sync ; echo 3 &gt; /proc/sys/vm/drop_caches</span><br><span class="line"># sysctl -p</span><br></pre></td></tr></table></figure>

<p>查看巨页内存使用情况:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ grep <span class="string">&#x27;Huge&#x27;</span> /proc/meminfo </span><br><span class="line">AnonHugePages: <span class="number">0</span> kB</span><br><span class="line">HugePages_Total: <span class="number">13824</span></span><br><span class="line">HugePages_Free: <span class="number">13710</span></span><br><span class="line">HugePages_Rsvd: <span class="number">4096</span></span><br><span class="line">HugePages_Surp: <span class="number">0</span></span><br><span class="line">Hugepagesize: <span class="number">2048</span> kB</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://wiki.debian.org/Hugepages">Hugepages</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian系统firefox 5 隐藏标题栏titlebar</title>
    <url>/2011/06/28/debian-firefox-5-hide-titlebar/</url>
    <content><![CDATA[<p>linux系统下firefox不能自动隐藏标题栏,如果将tab栏放入标题栏titlebar,那么firefox将更简洁有更大的显示面积</p>
<a id="more"></a>
<p>现在用的firefox 5已经将标题栏titlebar,菜单栏mebubar,导航栏工具栏navigation toolbar全部隐藏了,看起来很清爽，有效显示面积更大,来张截图<br><a href="/images/2011/06/firefox_hidechrome.png"><img src="/images/2011/06/firefox_hidechrome.png" title="firefox_hidechrome"></a></p>
<p>隐藏firefox标题栏有如下方法,不过肯定还有更多的方法</p>
<p>第一种方法,安装hidechrome插件</p>
<p>hidechrome插件主要功能就是隐藏标题栏,但是最新版本与firefox 5不兼容,其实只要简单的修改一下xpi安装包里面install.rdf里面的最大版本号就可以了,使用起来完全正常。推荐用vim直接编辑xpi文件。</p>
<p>第二种方法,如果你使用pentadactyl的话,那就很简单了,在配置文件~/.pentadactylrc里面添加下面的语句</p>
<p>“hide window titlebar<br>js &lt;&lt;EOF<br>(function() {<br>var win_ctrl = document.getElementById(“window-controls”);<br>win_ctrl.setAttribute(“fullscreencontrol”, “false”);<br>win_ctrl.setAttribute(“hidden”, “false”);</p>
<p>var mainWindow = document.getElementById(“main-window”);<br>mainWindow.setAttribute(“hidechrome”, “true”);</p>
<p>window.maximize();<br>})();<br>EOF</p>
<p>重新启动firefox就可以了</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>debian 强制卸载软件包</title>
    <url>/2014/10/22/debian-force-uninstall/</url>
    <content><![CDATA[<a id="more"></a>
<p>有兽因为依赖问题有些包会无法正常卸载，提示一堆错误。这时候可以强制卸载。</p>
<p>apt包管理器的数据库位于/var/lib/dpkg目录。假设需要强制卸载的包名字为foo,执行以下命令:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># cd /var/lib/dpkg/info</span><br><span class="line"># rm foo.*</span><br><span class="line"># aptitude purge foo (或许# dpkg purge foo亦可,未尝试)</span><br></pre></td></tr></table></figure>

<p>包所属的文件可以直接从硬盘上删除</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian testing grub-pc安装失败解决方法</title>
    <url>/2011/06/18/debian-grub-install-fail/</url>
    <content><![CDATA[<p>全新的办公电脑到货了,CPU i3 2100/4G DDR3/1T HDD/AMD Radeon HD 6450 1G/21.5 LED,</p>
<a id="more"></a>
<p>3年前的老电脑可以退役了,新电脑果断安装Debian,window$就不考虑了。桌面就用testing吧,里面的包还是都够新的。</p>
<p>下载debian testing weekly build iso,刻盘,开始安装，熟悉的安装界面,虽然安装程序提供了btrfs，但还是选择了ext4，这样比较保险一些。根分区/分了10G,使用主分区sda1,然后是/home分区,使用主分区sda2,容量为1T去掉10G根分区和8G交换分区swap剩余的容量,最后是8G的swap，使用主分区sda3。硬件识别顺利,只安装基本系统，安装grub时出现了问题,错误提示如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">“Grub package failed to install into /target. Without GRUB boot loader, the installed system will not boot”</span><br></pre></td></tr></table></figure>
<p>竟然无法安装grub,跳过此步骤继续安装系统。</p>
<p>重新光盘引导进入rescue模式,命令行下输入</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ grub-installer</span><br></pre></td></tr></table></figure>
<p>出现错误提示</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Wrong number <span class="keyword">of</span> args: mapdevfs</span><br></pre></td></tr></table></figure>

<p>下载了debian testing daily build重新安装，问题依旧。使用前段时间刻录的debian squeeze 6.0.1a安装时竟然识别不出网卡，放弃。最后下载SystemRescueCd 2.2.0,引导系统，挂装硬盘上的根分区sda1,然后chroot安装grub-pc成功，步骤如下：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ifconfig eth0 192.168.0.8 netmask 255.255.255.0</span><br><span class="line"># route add default gw 192.168.0.1</span><br><span class="line"></span><br><span class="line"># mount -t ext4 /dev/sda1 /mnt</span><br><span class="line"># mount --bind /proc /mnt/proc</span><br><span class="line"># mount --bind /dev /mnt/dev</span><br><span class="line"># mount --bind /sys /mnt/sys</span><br><span class="line"># chroot /mnt /bin/bash</span><br><span class="line"># apt-get update</span><br><span class="line"># apt-get install grub-pc</span><br></pre></td></tr></table></figure>
<p>chroot后要检查一下/etc/apt/source.list文件,看看安装源是否正确。退出chroot重新启动硬盘引导,出现熟悉的grub引导界面。</p>
<p>chroot 重新绑定虚拟文件系统时，可以这样:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># for i in /dev /dev/pts /proc /sys /run; do mount -B $i /mnt $i; done</span><br></pre></td></tr></table></figure>

<p>-B参数就是–bind参数。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian修改主机名hostname</title>
    <url>/2012/05/18/debian-hostname-modify/</url>
    <content><![CDATA[<p>debian修改hostname步骤</p>
<a id="more"></a>
<ol>
<li> 编辑/etc/hostname,将其中记录的主机名替换为new_hostname</li>
<li> # hostname new_hostname</li>
<li> 编辑/etc/hosts文件,将其中所有涉及到的主机名替换为new_hostname</li>
<li> exit然后重新login</li>
</ol>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian hosts文件中的 127.0.1.1 主机地址</title>
    <url>/2013/01/30/debian-hosts-127-0-1-1/</url>
    <content><![CDATA[<p>有时候/etc/hosts文件会看到127.0.1.1这个地址,这是什么呢?</p>
<a id="more"></a>
<p>127.0.0.1这个loopback地址很常见，就是本地接口的回路/回环地址。但有时候/etc/hosts文件中还会出现127.0.1.1,这又是什么地址呢？这也是个本地回路/回环地址。</p>
<p>出现这个地址的原因是因为有些应用程序需要规范的全限定域名FQDN(Fully Qualified Domain Name)，FQDN不只需要主机名还需要主机域名，其表达形式为hostname.domainname</p>
<p>如果你的主机有一个静态IP地址，则FQDN名字解析到这个静态地址，否则解析到127.0.1.1这个本地回路地址。所以一般情况下不会看到127.0.1.1这个地址。</p>
<p>127.0.0.1一般只对应hostname，这也是二者的主要区别，如下</p>
<p>127.0.0.1 hostname<br>127.0.1.1 hostname.domainname</p>
<p>当然并一定非要用127.0.1.1这个IP,RFC规定的127.0.0.0/8这个IP段内的任意IP都可以，只要没有冲突，debian选择了127.0.1.1</p>
<p>查看主机名</p>
<h1 id="hostname"><a href="#hostname" class="headerlink" title="hostname"></a>hostname</h1><p>hostname</p>
<p>查看FQDN名字</p>
<h1 id="hostname-–fqdn"><a href="#hostname-–fqdn" class="headerlink" title="hostname –fqdn"></a>hostname –fqdn</h1><p>hostname.domainname</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian 安装 docker</title>
    <url>/2016/07/31/debian-install-docker/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian源里的docker叫docker.io,版本略低。这里从官方源安装docker,官方源里叫docker-engine。</p>
<p>安装docker要求内核必须为3.10以上版本，而且必须为64位架构。</p>
<p>debian版本最小支持到wheezy,但是wheezy必须添加backports源.</p>
<p>docker官方源使用https协议，因此先安装以下包：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install apt-transport-https ca-certificates</span><br></pre></td></tr></table></figure>

<p>导入doker公钥：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gpg --keyserver pgp.mit.edu --recv-keys 58118E89F3A912897C070ADBF76221572C52609D</span><br><span class="line">$ gpg --<span class="keyword">export</span> --armor 58118E89F3A912897C070ADBF76221572C52609D sudo apt-key add -</span><br></pre></td></tr></table></figure>

<p>/etc/apt/sources.list.d/docker.lis文件中添加官方源：</p>
<p>当前的testing stretch：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb https:<span class="comment">//apt.dockerproject.org/repo debian-stretch main</span></span><br></pre></td></tr></table></figure>

<p>jessie版本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb https:<span class="comment">//apt.dockerproject.org/repo debian-jessie main</span></span><br></pre></td></tr></table></figure>

<p>安装：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt update</span><br><span class="line"># apt update docker-engine</span><br></pre></td></tr></table></figure>

<p>运行docker daemon:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service docker start</span><br></pre></td></tr></table></figure>

<p>运行docker hello world：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo docker run hello-world</span><br><span class="line"></span><br><span class="line">Unable to find image <span class="string">&#x27;hello-world:latest&#x27;</span> locally</span><br><span class="line">latest: Pulling <span class="keyword">from</span> library/hello-world</span><br><span class="line">c04b14da8d14: Pull complete </span><br><span class="line">Digest: sha256:0256e8a36e2070f7bf2d0b0763dbabdd67798512411de4cdcf9431a1feb60fd9</span><br><span class="line">Status: Downloaded newer image <span class="keyword">for</span> hello-world:latest</span><br><span class="line"></span><br><span class="line">Hello <span class="keyword">from</span> Docker!</span><br><span class="line">This message shows that your installation appears to be working correctly.</span><br><span class="line"></span><br><span class="line">To generate <span class="built_in">this</span> message, Docker took the following steps:</span><br><span class="line"> <span class="number">1.</span> The Docker client contacted the Docker daemon.</span><br><span class="line"> <span class="number">2.</span> The Docker daemon pulled the <span class="string">&quot;hello-world&quot;</span> image <span class="keyword">from</span> the Docker Hub.</span><br><span class="line"> <span class="number">3.</span> The Docker daemon created a <span class="keyword">new</span> container <span class="keyword">from</span> that image which runs the</span><br><span class="line"> executable that produces the output you are currently reading.</span><br><span class="line"> <span class="number">4.</span> The Docker daemon streamed that output to the Docker client, which sent it</span><br><span class="line"> to your terminal.</span><br><span class="line"></span><br><span class="line">To <span class="keyword">try</span> something more ambitious, you can run an Ubuntu container <span class="keyword">with</span>:</span><br><span class="line"> $ docker run -it ubuntu bash</span><br><span class="line"></span><br><span class="line">Share images, automate workflows, and more <span class="keyword">with</span> a free Docker Hub account:</span><br><span class="line"> https:<span class="comment">//hub.docker.com</span></span><br><span class="line"></span><br><span class="line">For more examples and ideas, <span class="attr">visit</span>:</span><br><span class="line"> https:<span class="comment">//docs.docker.com/engine/userguide/</span></span><br></pre></td></tr></table></figure>

<p>docker安装正常。</p>
<p>docker daemon始终以root用户运行，但通过将用户加入docker组，可以使用户访问docker的客户程序不使用root权限来访问docker服务：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo gpasswd -a $USER docker</span><br><span class="line">Adding user xxx to group docker</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure>

<p>如果没有docker用户组，请自行建立。将foo替换成你想要的用户名，然后重新启动docker服务：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service docker restart</span><br></pre></td></tr></table></figure>

<p><strong>updated(07/07/2019)</strong>:<br>官方安装源地址发生变化，最新的安装说明参见[2]</p>
<p>References:<br>[1]<a href="https://docs.docker.com/engine/installation/linux/debian/">Installation on Debian - Docker</a><br>[2]<a href="https://docs.docker.com/install/linux/docker-ce/debian/">Get Docker CE for Debian</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian安装oracle  jdk</title>
    <url>/2015/01/19/debian-install-oracle-jdk/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian源里默认的java是openjdk,当前版本是7。如果需要安装oracle官方的jdk8,可以使用java-package打包官方jdk的方式来安装：</p>
<p>1、安装java-package</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install java-package</span><br></pre></td></tr></table></figure>

<p>2、下载<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">oracle jdk 8</a></p>
<p>下载linux x64的tar.gz包,当前下载回来的文件为:jdk-8u25-linux-x64.tar.gz</p>
<p>3、打包<br>进入jdk下载目录,执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ make-jpkg jdk-8u25-linux-x64.tar.gz</span><br></pre></td></tr></table></figure>
<p>简单回答几个问题,即可以生成oracle jdk 8的deb安装包oracle-java8-jdk_8u25_amd64.deb</p>
<p>如果遇到类似如下问题：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">dpkg-checkbuilddeps: Unmet build dependencies: libgl1-mesa-glx libxxf86vm1</span><br></pre></td></tr></table></figure>
<p>直接apt-get install就可以了：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo apt-get install libgl1-mesa-glx libxxf86vm1</span><br></pre></td></tr></table></figure>

<p>4、安装</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># dpkg -i oracle-java8-jdk_8u25_amd64.deb</span><br></pre></td></tr></table></figure>

<p>安装完成。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>debian安装rkt</title>
    <url>/2016/10/06/debian-install-rkt/</url>
    <content><![CDATA[<a id="more"></a>
<p>rkt是一个容器引擎和规范，Kubernetes已经支持rkt容器引擎，rkt兼容docker，但其更unix更安全。</p>
<p>Kubernetes + rkt可以组建基于容器的云计算平台，而openstack是为虚拟化而生。</p>
<p>openstack结合Kubernetes可以组建既有虚拟化又有容器的混合云计算平台。</p>
<p><strong>安装rkt</strong></p>
<p>当前debian官方只有sid源里有rkt包，而且版本略滞后，因此可以这样安装最新版本的rkt</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//raw.githubusercontent.com/coreos/rkt/master/scripts/install-rkt.sh</span></span><br><span class="line">$ chmod +x install-rkt.sh</span><br><span class="line">$ sudo ./install-rkt.sh</span><br></pre></td></tr></table></figure>

<p>install-rkt.sh脚本会生成deb包再安装。</p>
<p><strong>卸载</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt remove rkt --purge</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://coreos.com/rkt/docs/latest/distributions.html">Installing rkt on popular Linux distributions</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian jessie服务器安装时console-setup配置停滞</title>
    <url>/2014/11/18/debian-jessie-console-setup-hang/</url>
    <content><![CDATA[<a id="more"></a>
<p>最近使用带有<a href="http://cdimage.debian.org/cdimage/unofficial/non-free/cd-including-firmware/weekly-builds/amd64/iso-cd/">firmware</a>的debian netinst安装一台服务器时,安装进度到99%配置console-setup时进程停滞了，没有当机，只是进度不动，几个小时都不带动的，一直在：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">configuring <span class="built_in">console</span>-setup...</span><br></pre></td></tr></table></figure>

<p>CTRL+ALT+4查看安装日志，也没有错误提示，只是在等待。<br>重启进入rescue安装模式，在instaler环境下执行</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># dpkg --configure -a</span><br></pre></td></tr></table></figure>
<p>console-setup配置界面选择# american,安装时就是因为这里自动配置没过去，从而无限停滞了。</p>
<p>之后执行</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># grub-installer</span><br></pre></td></tr></table></figure>
<p>出现类似如下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Media change: please insert the disc labeled</span><br><span class="line"> <span class="string">&#x27;Debian GNU/Linux ... Official amd64 CD Binary-1 ...&#x27;</span></span><br><span class="line"><span class="keyword">in</span> the drive <span class="string">&#x27;/media/cdrom/&#x27;</span> and press enter</span><br></pre></td></tr></table></figure>
<p>无果。</p>
<p>其实大部分包已经装完了，只是还没有安装grub，配置root用户和添加新用户而已。<br>所以使用<a href="https://openwares.net/linux/debian_grub_install_fail.html">rescuecd引导系统安装grub</a><br>这时候root是没密码的，无法正常登录，grub引导时选择recovery模式，顺利以root登录系统，然后执行passwd命令为root设置密码，之后再添加普通用户即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian jessie 源列表</title>
    <url>/2015/03/24/debian-jessie-sourcelist/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb http:<span class="comment">//ftp.tw.debian.org/debian/ jessie main contrib non-free </span></span><br><span class="line">deb http:<span class="comment">//ftp.tw.debian.org/debian/ jessie-updates main contrib non-free </span></span><br><span class="line">deb http:<span class="comment">//ftp.tw.debian.org/debian/ jessie-backports main contrib non-free </span></span><br><span class="line">deb http:<span class="comment">//ftp.tw.debian.org/debian/ jessie-proposed-updates main contrib non-free </span></span><br><span class="line">deb http:<span class="comment">//security.debian.org/ jessie/updates main contrib non-free </span></span><br></pre></td></tr></table></figure>

<p>debian官方源是ftp.debian.org,美国镜像是ftp.us.debian.org,台湾官方镜像是ftp.tw.debian.org,中国官方源镜像是ftp.cn.debian.org<br>日本是jp,韩国是kr,…</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat 7 on Debian Jessie  for Eclipse Kepler配置</title>
    <url>/2013/10/25/debian-jessie-tomcat7-eclipse-kepler/</url>
    <content><![CDATA[<p>Debian系统tomcat 7官方安装包配置eclipse调式服务器。</p>
<a id="more"></a>
<p>Eclipse开发Dynamic Web Project需要添加一个web服务器来调式应用。有很多servlet容器可选，这里使用的是Tomcat 7。</p>
<p><strong>Tomcat多实例配置</strong></p>
<p>Eclipse配置tomcat服务器时，默认是创建了一个新的运行实例。也可以使用系统tomcat实例，或者自定义一个新的实例。</p>
<p>详见<a href="https://openwares.net/linux/tomcat7_multiinstances_setup.html">tomcat多实例配置</a>。</p>
<p><strong>Eclipse配置tomcat7服务器</strong></p>
<p><em>准备工作</em></p>
<p>由于Debian按<a href="http://www.pathname.com/fhs/">FHS文件系统标准</a>对tomcat包的拆分，虽然默认只有一个实例，$CATALINA_BASE和$CATALINA_HOME指向了不同的路径。为了应对Eclipse，需要做几个符号链接，让$CATALINA_HOME看起来像一个完整的tomcat实例。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ cd /usr/share/tomcat7</span><br><span class="line"># ln -sf /var/lib/tomcat7/conf conf </span><br><span class="line"><span class="comment">//或 # ln -sf /etc/tomcat7 conf</span></span><br><span class="line"># ln -s /etc/tomcat7/policy.d/03catalina.policy conf/catalina.policy </span><br><span class="line"><span class="comment">//或 cd conf; ln -sf policy.d/03catalina.policy catalina.policy</span></span><br><span class="line"># ln -sf /var/log/tomcat7 log </span><br></pre></td></tr></table></figure>

<p>否则配置服务器时Eclipse会提示错误：<br>Could not load the Tomcat server configuration at /usr/share/tomcat7/conf. The configuration may be corrupt or incomplete.<br>/usr/share/tomcat7/conf/catalina.policy (No such file or directory)</p>
<p>还要将运行Eclipse的当前用户加入到tomcat7用户组，然后注销重新登录。</p>
<h1 id="adduser-your-username-tomcat7"><a href="#adduser-your-username-tomcat7" class="headerlink" title="adduser ${your_username} tomcat7"></a>adduser ${your_username} tomcat7</h1><p>$ logout</p>
<p>因为配置服务器时Eclipse要读取tomcat-users.xml文件，否则会有错误提示：<br>Could not load the Tomcat server configuration at /usr/share/tomcat7/conf. The configuration may be corrupt or incomplete.<br>/usr/share/tomcat7/conf/tomcat-users.xml (Permission denied)</p>
<p><em>配置调式服务器</em></p>
<p>打开eclipse,Window -&gt; Preference -&gt; Server -&gt; Runtime Environments -&gt; Add 选择Apache Tomcat 7.0 Server,<br>选择下一步，Tomcat installation directory输入/usr/share/tomcat7,JRE选择java-7-openjdk-amd64,最后finish。</p>
<p>如果Add服务器这个环节，Server name字段为空，且无法输入，也无法点击下一步，可以这样解决：</p>
<ol>
<li> 关闭eclipse</li>
<li>{workspace-directory}/.metadata/.plugins/org.eclipse.core.runtime/.settings目录下，删除这个两个文件<br> org.eclipse.wst.server.core.prefs<br> org.eclipse.jst.server.tomcat.core.prefs</li>
</ol>
<p>关闭Eclipse,进入workspace工作目录下配置好的服务器的配置目录</p>
<p>$ cd ~/workspace/Servers/Tomcat v7.0 Server at localhost-config</p>
<p>修改server.xml,将其控制端口改为8006，只要不与其他运行实例冲突即可。否则会出现错误提示：</p>
<p>Several ports (8005, 80) required by Tomcat v7.0 Server at localhost are already in use. The server may already be running in another process, or a system process may be using the port. To start this server you will need to stop the other process or change the port number(s).</p>
<p>[xml]<br><Server port="8006" shutdown="SHUTDOWN"><br>[/xml]</p>
<p>将连接端口更改为8080或其他高于1024的端口号：<br>[xml]<br> <Connector URIEncoding="UTF-8" connectionTimeout="20000" port="8080" protocol="HTTP/1.1" redirectPort="8443"/><br>[/xml]</p>
<p>Eclipse貌似不能使用Authbind，所以即使没有进程占用80端口，也无法启动调试服务器，1024以上的端口则没问题。</p>
<p>这样Eclipse就可以使用tomcat7作为调试服务器正常运行了。</p>
<p><strong>update(01/15/2016)：服务器配置目录</strong></p>
<p>服务器的配置文件在~/workspace/.metadata/.plugins/org.eclipse.wst.server.core目录下，删除服务器时，如果没有其他服务器时，可以同时将此目录删除,这样不会有残留。<br>目录下的server.xml文件中可以修改启动超时时间start-timeout。</p>
<p>而tomcat的配置文件在~/workspace/Servers/Tomcat v8.0 Server at localhost-config目录下，与单独启动的tomcat配置一样。</p>
<p>参考：</p>
<p><a href="http://www.rockbb.com/blog/?p=349">Debian 7 Wheezy 安装 Eclipse</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Squeeze KVM虚拟机安装笔记(1):基础</title>
    <url>/2011/05/11/debian-kvm/</url>
    <content><![CDATA[<p>基于内核的虚拟机KVM(Kernel-based Virtual Machine)是linux平台上的全虚拟化解决方案</p>
<a id="more"></a>
<p>KVM需要包含虚拟化支持的x86硬件,intel VT或者AMD-V。KVM使用修改后的QEMU作为前端工具,QEMU通过/dev/kvm设备与KVM交互。自kernel版本2.6.20 KVM随主线内核一起发行。</p>
<p><strong>前提条件(prerequisite)</strong></p>
<p>可以使用KVM的前提条件是CPU支持虚拟化技术,Intel VT或者AMD-V</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ egrep <span class="string">&#x27;(svmvmx)&#x27;</span> /proc/cpuinfo</span><br></pre></td></tr></table></figure>
<p>如果有输出则说明CPU支持硬件虚拟化,SVM(Secure Virtual Machine)是AMD CPU支持硬件虚拟化的标志,VMX是INTEL CPU支持硬件虚拟化的标志</p>
<p><strong>KVM安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$sudo apt-get insall qemu-kvm</span><br></pre></td></tr></table></figure>
<p>从squeeze开始KVM的包名改为qemu-kvm,kvm只是个占位dummy包</p>
<p><strong>创建vdisk</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$qemu-img create -f qcow2 client.qcow2 60G</span><br></pre></td></tr></table></figure>
<p>创建一个60G的qcow2格式的虚拟磁盘文件,更多参数见man qemu-img</p>
<p><strong>桥接网络</strong></p>
<p>KVM支持很多网络类型,但是使用最方便的还是桥接网络,设置桥接网络,系统中必须存在以下三个命令<br>/sbin/ip<br>/usr/sbin/brctl<br>/usr/sbin/tunctl<br>所以需要安装一下包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$sudo apt-get install bridge-utils uml-utilities</span><br></pre></td></tr></table></figure>

<p>编辑/etc/network/interfaces文件增加网络桥,增加的网络桥接口名字为br0,将主机网络接口桥接到此网络桥<br> 1 # This file describes the network interfaces available on your system<br> 2 # and how to activate them. For more information, see interfaces(5).<br> 3<br> 4 # The loopback network interface<br> 5 auto lo<br> 6 iface lo inet loopback<br> 7<br> 8 # The primary network interface<br> 9 #allow-hotplug eth0<br>10 #iface eth0 inet static<br>11 #   address 192.168.0.18<br>12 #   netmask 255.255.255.0<br>13 #   network 192.168.0.0<br>14 #   broadcast 192.168.0.255<br>15 #   gateway 192.168.0.1<br>16 #   # dns-* options are implemented by the resolvconf package, if installed<br>17 #   dns-nameservers 211.137.191.26<br>18 #   dns-search localdomain<br>19<br>20 auto bond0<br>21 iface bond0 inet manual<br>22 #    address 192.168.0.18<br>23 #    netmask 255.255.255.0<br>24 #    network 192.168.0.0<br>25 #    broadcast 192.168.0.255<br>26 #    gateway 192.168.0.1<br>27     slaves eth0 eth1<br>28     bond-mode balance-rr<br>29     bond-miimon 100<br>30<br>31 auto br0<br>32 iface br0 inet static<br>33     address 192.168.0.18<br>34     netmask 255.255.255.0<br>35     network 192.168.0.0<br>36     broadcast 192.168.0.255<br>37     gateway 192.168.0.1<br>38     bridge_ports    bond0<br>39     bridge_stp  off<br>40     bridge_maxwait  0<br>41     bridge_fd   0   <br>42<br>43 #auto tap0<br>44 #iface tap0 inet manual<br>45 #up ifconfig $IFACE 0.0.0.0 up<br>46 #down ifconfig $IFACE down<br>47 #tunctl_user yourusername  </p>
<p>第38行 bridge_ports bond0,此处将主机的bonding接口bond0加入网络桥,如果没有网络接口聚合此处一般应为eth0<br>第47行将youeusername改为你登陆主机的用户名</p>
<p>使用桥接网络,客户机必须使用主机的一个tap设备将客户机的网络接口连接到主机的网络桥,tap设备可以用两种方式来设置</p>
<p>一种是静态方式，直接把tap设备的配置写道/etc/network/interfaces文件中，并将tap接口加入网络桥，将配置文件43-47行前的注释符#去掉，并将第38行改为如下<br>bridge_ports bond0 tap0<br>增加更多的tap接口依次类推</p>
<p>另一种为动态方式，网络配置文件中不写任何tap设备的配置，而由KVM的脚本/etc/kvm/kvm-ifup来动态完成tap接口的创建,以后创建客户机是会提到怎么用。</p>
<p><strong>半虚拟化驱动Virtio</strong></p>
<p>Virtio是KVM/Linux的I/O虚拟化框架，以增强KVM的IO效率,是与其他虚拟化平台的半虚拟化(Paravirtualized)类似的东西,主要应用于磁盘设备和网络接口设备。主流的linux发行版已经默认支持Virtio，如果客户机是linux则无需其他设置，直接可以使用Virtio设备，但是如果客户机是windows，则需要在客户机安装Virtio设备驱动，甚至在windows开始安装之前需要提前加载块设备驱动。windows Virtio驱动可从Fedora<a href="http://alt.fedoraproject.org/pub/alt/virtio-win/latest/images/bin/">下载</a>。</p>
<p>如何安装客户虚拟机下篇再议。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian系统架设L2TP/IPSec VPN服务器</title>
    <url>/2012/10/18/debian-l2tp-ipsec-server/</url>
    <content><![CDATA[<p>L2TP/IPSec是比较常见的VPN实施方式,平台兼容性比较好,各种常见的平台都可以很好的支持。</p>
<a id="more"></a>
<p>L2TP用于隧道建立和控制以及数据荷载的封装,IPSec用于分组加密和完整性校验。</p>
<h2 id="安装配置IPSec"><a href="#安装配置IPSec" class="headerlink" title="安装配置IPSec"></a><strong>安装配置IPSec</strong></h2><p>linux系统有两种比较常见的IPSec实现,Openswan和strongSwan,二者都fork自FreeS/WAN(Free Secure Wide-Area Networking)。</p>
<p><strong>安装openswan</strong></p>
<p>#apt-get install openswan</p>
<p><strong>配置</strong></p>
<p>使用PSK(Pre-Shared Key)加密方式<br>编辑ipsec配置文件/etc/ipsec.conf如下<br> 1 version 2.0 # 遵循ipsec.conf 2.0 配置规范<br> 2<br> 3 config setup # 基本配置<br> 4     dumpdir=/var/run/pluto/ # core dump目录<br> 5     nat_traversal=yes # NAT 穿越<br> 6     #私网地址段<br> 7     virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12,%v4:25.0.0.0/8,%v6:fd00::/8,%v6:fe80::/10<br> 8     oe=off # 关闭随机加密Opportunistic Encryption<br> 9     protostack=netkey # 使用内核ipsec栈,openswan自己的协议栈叫KLIPS<br>10<br>11 conn L2TP-PSK   # 配置使用ipsec服务的连接规范,名字随意<br>12     # 连接两端相互认证的方式,secreti - 用于共享密钥,比如PSK方式,rsasig - RSA数字签名方式,never - 不建立安安全连接<br>13     authby=secret <br>14     pfs=no<br>15     auto=add # ipsec启动时的默认动作<br>16     keyingtries=3 # 建立连接的尝试次数<br>17     rekey=no # 连接将要过期时是否重新协商<br>18     ikelifetime=8h # 连接重新协商前,key通道的持续时间<br>19     salifetime=8h  # 协商成功后连接的持续时间,它有两个别名keylife和lifetime<br>20     # IPSec连接类型<br>21         # tunnel - 主机到主机host-to-host,主机到子网host-to-subnet,子网到子网subnet-to-subnet隧道模式<br>22         # transport - 主机到主机host-to-host传输模式,这里不使用ipsec建立隧道,只使用其加密传输<br>23         # passthrough - 不进行IPSec处理,分组原样流过连接<br>24         # drop - 丢弃分组<br>25         # reject - 丢弃分组,并返回一个ICMP通知<br>26     type=transport <br>27     # left 和right分别用于指定连接两侧的参与者IP地址,left和right用于指定任何一端皆可,二者是对等的<br>28     # 但习惯上left用于指定本地端(local),right用于指定远程端(remote),方便记忆<br>29     left=192.168.0.2<br>30     # leftprotoport和rightprotoport用于指定两端使用的协议和端口,要与left和right指定的端匹配<br>31     # 这里本地端为服务端,使用UDP的1701端口,这是ipsec的默认端口,远端使用UDP协议的任意端口 <br>32     leftprotoport=UDP/1701<br>33     # leftsubnet 指定左侧参与者left后面的私有子网,格式为network/netmask,如果省略该参数则实际指定为left/32,<br>34     # 也就是该连接左侧只有这一个参与者<br>35     right=%any<br>36     rightprotoport=UDP/%any<br>37     rightsubnet=vhost:%priv </p>
<p>打开/etc/ipsec.secrets文件添加PSK密钥<br>x.x.x.x %any: PSK “yourpsk”</p>
<p>x.x.x.x为服务器端IP地址,yourpsk设置你想设置的字符串</p>
<p><strong>修改内核参数</strong></p>
<p>root账户运行以下命令<br>for each in /proc/sys/net/ipv4/conf/*<br> do<br> echo 0 &gt; $each/accept_redirects<br> echo 0 &gt; $each/send_redirects<br>done</p>
<p><strong>校验IPSec是否正常</strong><br>先安装lsof</p>
<h1 id="apt-get-install-lsof"><a href="#apt-get-install-lsof" class="headerlink" title="apt-get install lsof"></a>apt-get install lsof</h1><p>校验</p>
<h1 id="ipsec-verify"><a href="#ipsec-verify" class="headerlink" title="ipsec verify"></a>ipsec verify</h1><p> Checking your system to see if IPsec got installed and started correctly:<br>Version check and ipsec on-path                                 [OK]<br>Linux Openswan U2.6.37-g955aaafb-dirty/K3.2.0-2-amd64 (netkey)<br>Checking for IPsec support in kernel                            [OK]<br> SAref kernel support                                           [N/A]<br> NETKEY:  Testing XFRM related proc values                      [OK]<br>        [OK]<br>        [OK]<br>Checking that pluto is running                                  [OK]<br> Pluto listening for IKE on udp 500                             [OK]<br> Pluto listening for NAT-T on udp 4500                          [OK]<br>Checking for ‘ip’ command                                       [OK]<br>Checking /bin/sh is not /bin/dash                               [WARNING] </p>
<h1 id="安装配置l2tp"><a href="#安装配置l2tp" class="headerlink" title="安装配置l2tp"></a><strong>安装配置l2tp</strong></h1><p> <strong>安装xl2tpd</strong></p>
<h1 id="apt-get-install-xl2tpd"><a href="#apt-get-install-xl2tpd" class="headerlink" title="apt-get install xl2tpd"></a>apt-get install xl2tpd</h1><p><strong>配置</strong></p>
<p>编辑/etc/xl2tpd/xl2tpd.conf<br> 1 [global]                                ;全局参数<br> 2 ; 使用IPSec 安全关联追踪,打开此参数IPSec会在分组上附加额外的字段,用来追踪一个NAT IP地址后面的多个客户端<br> 3 ; 当前只有Openswan的协议栈KLIPS支持此参数,NETKEY尚未支持<br> 4 ipsec saref = yes<br> 5<br> 6 [lns default]                           ; LNS(L2TP Network Server)配置 <br> 7 ip range = 10.100.0.2-10.100.0.9        ; 私有IP分配范围<br> 8 local ip = 10.100.0.1                   ; 服务器使用的私有IP<br> 9 length bit = yes                        ; <br>10 refuse pap = yes                        ; 拒绝PAP认证<br>11 refuse chap = yes                       ; 拒绝CHAP认证 <br>12 require authentication = yes            ; 需要端点认证<br>13 ppp debug = yes                         ; <br>14 pppoptfile = /etc/ppp/options.xl2tpd    ; 对应的ppp配置文件 </p>
<h2 id="安装配置ppp"><a href="#安装配置ppp" class="headerlink" title="安装配置ppp"></a><strong>安装配置ppp</strong></h2><p><strong>安装</strong><br>#apt-get install ppp</p>
<p><strong>配置</strong><br>编辑配置文件/etc/ppp/options.xl2tpd<br> 1 require-mschap-v2       # 使用mschap v2认证<br> 2 ms-dns 8.8.8.8        # 推送的DNS服务器<br> 4 asyncmap 0              # 异步字符映射位图<br> 5 auth                    # 需要端认证<br> 6 crtscts                 # 使用硬件流控RTS/CTS<br> 7 lock                    # 锁定设备<br> 8 hide-password           # 当记录PAP包内容时不记录密码<br> 9 modem                   # <br>10 debug<br>11 name l2tpd              # 用于认证目地的本地系统名字<br>12 proxyarp                # 代理arp<br>13 lcp-echo-interval 30    # 用于确认对端是否仍然在线<br>14 lcp-echo-failure 4 </p>
<p><strong>添加VPN拨号用户</strong></p>
<p>编辑/etc/ppp/chap-secrets,添加</p>
<h1 id="Secrets-for-authentication-using-CHAP"><a href="#Secrets-for-authentication-using-CHAP" class="headerlink" title="Secrets for authentication using CHAP"></a>Secrets for authentication using CHAP</h1><h1 id="client-server-secret-IP-addresses"><a href="#client-server-secret-IP-addresses" class="headerlink" title="client server secret IP addresses"></a>client server secret IP addresses</h1><p>test l2tpd test *<br>test1 l2tpd test1 *</p>
<p>重新启动xl2tpd完成L2TP/IPSec VPN设置。</p>
<p><strong>转发</strong></p>
<p>如果允许VPN客户端通过VPN服务器访问其他网络,可以设置网络转发。</p>
<h1 id="echo-1-gt-proc-sys-net-ipv4-ip-forward"><a href="#echo-1-gt-proc-sys-net-ipv4-ip-forward" class="headerlink" title="echo 1 &gt; /proc/sys/net/ipv4/ip_forward"></a>echo 1 &gt; /proc/sys/net/ipv4/ip_forward</h1><h1 id="iptables-table-nat-append-POSTROUTING-jump-MASQUERADE"><a href="#iptables-table-nat-append-POSTROUTING-jump-MASQUERADE" class="headerlink" title="iptables - -table nat - -append POSTROUTING - -jump MASQUERADE"></a>iptables - -table nat - -append POSTROUTING - -jump MASQUERADE</h1><p><strong>端口映射</strong></p>
<p>如果L2TP/IPSec服务器位于NAT网关后面,没有公网IP,则需要映射以下端口<br>UDP/1701 #L2TP使用的端口<br>UDP/500 #IKE(Internet Key Exchange)使用的端口<br>UDP/4500 #IPSec NAT-T(NAT Traversal)使用的端口</p>
<p>一般建议L2TP/IPSec服务器使用公网IP</p>
<h2 id="NAT后面的多个客户端"><a href="#NAT后面的多个客户端" class="headerlink" title="NAT后面的多个客户端"></a><strong>NAT后面的多个客户端</strong></h2><p>因为linux内核自带的IPSec协议栈NETKEY当前还不支持SAref特性,因此同一个NAT网关后共享一个IP的机器无法同时登录VPN,也就是同一时刻只能有一台机器拨到VPN服务器。</p>
<p>如果需要NAT后的多个客户端同时与服务器建立VPN连接,可以考虑安装IPSec的KLIPS协议栈,或者改用OpenVPN,OpenVPN是一项很优秀的VPN技术。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Debian lenny backports源</title>
    <url>/2009/11/24/debian-lenny-backports/</url>
    <content><![CDATA[<p>backport的含义是“向后移植”，就是将软件新版本的某些功能移植到旧版本上来,这种行为就称为backport。</p>
<p>Debian向来以稳定性著称，所以就存在一个问题，官方源分发的软件版本比软件本身的版本总是要慢一拍，所以就有了backports源。backports主要从testing源，部分安全更新从unstable源重新编译包，使这些包不依赖于新版本的库就可以在debian的stable发行版上面运行。所以backports是stable和testing的一个折衷。</p>
<p>backports源的使用方法如下：<br>在/etc/apt/sources.list增加下面的行<br>deb <a href="http://www.backports.org/debian/">http://www.backports.org/debian/</a> lenny-backports main contrib non-free<br>deb-src <a href="http://www.backports.org/debian/">http://www.backports.org/debian/</a> lenny-backports main contrib non-free<br>然后安装backports源的GnuPG archive key<br>sudo apt-get update<br>sudo apt-get install debian-backports-keyring<br>就可以正常的使用backports源了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Squeeze lnmp一键安装脚本</title>
    <url>/2011/04/06/debian-lnmp-one-click-install/</url>
    <content><![CDATA[<p>很简单的脚本,方便nginx,mysql,php安装,使用dotdeb.org的安装源。</p>
<a id="more"></a>
<p>执行./lnmp_install.sh安装,安装过程中需要设置mysql root密码,安装完毕后,只需在nginx virtualhox配置文件中增加include php-fpm.php;即可让虚拟主机支持PHP程序,额外再添加include wordpress.conf;即可支持wordpress程序</p>
<p><a href="/downloads/lnmp_install.sh">脚本下载</a></p>
<p> 1 #!/bin/bash<br> 2<br> 3 ########################<br> 4 # <a href="https://openwares.net/">http://openwares.net</a> #<br> 5 ########################<br> 6<br> 7 <strong>set</strong> -e<br> 8<br> 9 #dotdeb source<br>10 sudo <strong>sed</strong> -i <strong>‘</strong>$a\\n#dotdeb for nginx,mysql,php\ndeb <a href="http://packages.dotdeb.org/">http://packages.dotdeb.org</a> squeeze all*<em>‘** /etc/apt/sources.list <br>11<br>12 wget <a href="http://www.dotdeb.org/dotdeb.gpg">http://www.dotdeb.org/dotdeb.gpg</a><br>13 cat dotdeb.gpg sudo apt-key add -<br>14 <strong>rm</strong> dotdeb.gpg<br>15<br>16 sudo apt-get update<br>17<br>18 ###install nginx,php5(fastcgi),mysql5###<br>19 sudo apt-get -y <strong>install</strong> nginx-light mysql-server php5-cli php5-fpm php5-mysql<br>20<br>21 ###awstats,perl-fcgi modules###<br>22 #sudo apt-get -y install awstats<br>23 #sudo apt-get -y install libfcgi-perl libfcgi-procmanager-perl libio-all-perl<br>24<br>25 #php config file for nginx<br>26 sudo sh -c <strong>‘**echo “#pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\nlocation ~ \.php$ {\n\tfastcgi_pass\t127.0.0.1:9000;\n\tfastcgi_index\tindex.php;\n\tinclude\t\t\tfastcgi_params;\n}” &gt; /etc/nginx/php-fpm.conf</strong>‘**<br>27<br>28 #nginx rewrite rules for wordpress<br>29 sudo sh -c **’**echo “#rewrite rules for wordpress\nlocation / {\n\tif (-d \$request_filename){\n\t\trewrite (.</em>) /\$1/index.php last;\n\t}\n\tif (!-f \$request_filename){\n\t\trewrite (.*) /index.php?\$1 last;\n\t}\n}” &gt; /etc/nginx/wordpress.conf**’**<br>30<br>31 sudo /etc/init.d/nginx <strong>start</strong><br>32 sudo /etc/init.d/php5-fpm <strong>start</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>linux挂载windows共享目录/磁盘</title>
    <url>/2013/01/28/debian-mount-smb-cifs-share/</url>
    <content><![CDATA[<p>linux系统可以mount挂载windows系统共享出来的文件夹或磁盘</p>
<a id="more"></a>
<p>windows使用SMB(Server Message Block)/CIFS(Common Internet File System)协议来共享资源,CIFS是SMB的后继升级版本。linux系统对SMB/CIFS提供完整的支持,包括文件共享和打印共享。</p>
<p>smbclient命令行可以访问windows文件共享,但mount挂载SMB/CIFS共享文件资源使用起来更方便。当前linux内核已经移除了smbfs模块,仅使用cifs内核模块来访问SMB/CIFS共享。</p>
<p>安装mount.cifs</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install cifs-utils</span><br></pre></td></tr></table></figure>
<p>挂载windows共享目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mount -t cifs -o guest,file_mode=<span class="number">0777</span>,dir_mode=<span class="number">0777</span> <span class="comment">//windows_server/sharename /mnt/winshare</span></span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount.cifs -o guest,file_mode=0777,dir_mode=0777 //windows_server/sharename /mnt/weinshare</span><br></pre></td></tr></table></figure>

<p>使用guest选项则使用guest用户访问共享并且不会提示输入密码，也可以在选项中指定访问共享使用的用户名username和密码password,比如</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mount -t cifs -o username=&lt;username&gt;,password=&lt;password&gt;,file_mode=<span class="number">0777</span>,dir_mode=<span class="number">0777</span> </span><br><span class="line">　　　　<span class="comment">//windows_server/sharename /mnt/winshare</span></span><br></pre></td></tr></table></figure>
<p>其他选项详见man mount.cifs</p>
<p>也可以写入/etc/fstab开机自动挂载SMB/CIFS共享</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//windows_server/sharename /mnt/winshare cifs guest,file_mode=0777,dir_mode=0777 0 0</span></span><br></pre></td></tr></table></figure>

<p><strong>Update(11/15/2016):</strong></p>
<p>某天开始，-o guest选项挂载时，提示错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mount error(<span class="number">13</span>): Permission denied</span><br><span class="line">Refer to the mount.cifs(<span class="number">8</span>) manual page (e.g. man mount.cifs)</span><br></pre></td></tr></table></figure>

<p>选项更改为-o user=guest,password=null问题解决。<br>或者</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount -t cifs -o password,file_mode=0777,dir_mode=0777 //windows_server/sharename /mnt/weinshare</span><br></pre></td></tr></table></figure>

<p><strong>Update(10/04/2019):</strong><br>当前稳定版debian buster挂载windows 2003 R2的共享文件系统时又出现错误了：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">No dialect specified on mount. Default has changed to a more secure dialect, SMB2<span class="number">.1</span> or later (e.g. SMB3), <span class="keyword">from</span> CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which <span class="keyword">do</span> not support SMB3 (or SMB2<span class="number">.1</span>) specify vers=<span class="number">1.0</span> on mount.</span><br><span class="line">CIFS VFS: cifs_mount failed w/<span class="keyword">return</span> code = -<span class="number">512</span></span><br></pre></td></tr></table></figure>
<p>是说，cifs挂装文件系统时，默认开始使用更安全的SMB2.1或者更新的协议版本，如果要挂装比较旧的、不支持新协议的服务器上的cifs文件系统，需要指定协议版本vers=1.0，因此新的命令行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mount.cifs -o user=guest,password=<span class="literal">null</span>,file_mode=<span class="number">0777</span>,dir_mode=<span class="number">0777</span>,vers=<span class="number">1.0</span> <span class="comment">//windows_server/sharename /mnt/winshare/</span></span><br></pre></td></tr></table></figure>
<p>新的/etc/fstab</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//windows_server/sharename /mnt/winshare cifs user=guest,password=null,file_mode=0777,dir_mode=0777,vers=1.0 0 0</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian系统单网络接口绑定多IP地址</title>
    <url>/2013/01/09/debian-multi-ip-for-one-nic/</url>
    <content><![CDATA[<p>有时候需要一块网卡绑定多个IP</p>
<a id="more"></a>
<p>debian系统下只要简单的修改下/etc/network/interfaces文件就可以了,比如在eth0接口上绑定更多的IP地址,只需添加如下行:<br>auto eth0:0<br>iface eth0:0 inet static<br> address 192.168.0.200<br> netmask 255.255.255.0</p>
<p>auto eth0:1<br>iface eth0:1 inet static<br> address 192.168.0.201<br> netmask 255.255.255.0<br>这样就添加了另外两个IP,192.168.0.200和192.168.0.201,完整的interfaces文件看起来是这样的:</p>
<p>auto eth0<br>iface eth0 inet static<br> address 192.168.0.203<br> netmask 255.255.255.0<br> network 192.168.0.0<br> broadcast 192.168.0.255<br> gateway 192.168.0.1</p>
<h1 id="dns-options-are-implemented-by-the-resolvconf-package-if-installed"><a href="#dns-options-are-implemented-by-the-resolvconf-package-if-installed" class="headerlink" title="dns-* options are implemented by the resolvconf package, if installed"></a>dns-* options are implemented by the resolvconf package, if installed</h1><p> dns-nameservers 8.8.8.8<br> dns-search localdomain</p>
<p>auto eth0:0<br>iface eth0:0 inet static<br> address 192.168.0.200<br> netmask 255.255.255.0</p>
<p>auto eth0:1<br>iface eth0:1 inet static<br> address 192.168.0.201<br> netmask 255.255.255.0</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian NFS服务配置</title>
    <url>/2016/08/31/debian-nfs-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>服务器安装配置</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install nfs-kernel-server</span><br></pre></td></tr></table></figure>

<p>编辑/etc/exports文件，添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/srv/homes <span class="number">10.100</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span>(rw) <span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span>(rw)</span><br></pre></td></tr></table></figure>

<p><strong>客户端安装配置</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install nfs-common</span><br></pre></td></tr></table></figure>

<p>客户端查看服务器资源：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># showmount -e 10.100.0.30</span><br><span class="line">Export list <span class="keyword">for</span> <span class="number">10.100</span><span class="number">.0</span><span class="number">.30</span>:</span><br><span class="line">/srv/homes <span class="number">10.100</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span></span><br></pre></td></tr></table></figure>

<p>如果出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rpc mount <span class="keyword">export</span>: RPC: Authentication error; why = Failed (unspecified error)</span><br></pre></td></tr></table></figure>
<p>可以查看nfs服务器/etc/hosts.allow和/etc/hosts.deny的配置，是否允许客户机访问nfs资源，可以简单粗暴的允许所有主机访问，在/etc/hosts.allow最末尾添加ALL:ALL</p>
<p>客户端挂载服务器共享资源：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount 10.100.0.30:/srv/homes /mnt/share</span><br></pre></td></tr></table></figure>

<p>自动挂载编辑/etc/fstab：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># nfs</span><br><span class="line"><span class="number">10.100</span><span class="number">.0</span><span class="number">.30</span>:<span class="regexp">/svr/</span>homes /mnt/share nfs defaults <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian配置Oracle 10g自启动</title>
    <url>/2012/01/25/debian-oracle-10g-init/</url>
    <content><![CDATA[<p>linux平台下默认安装的oracle 10g数据库是没有启动而且不会随系统自动启动的。</p>
<a id="more"></a>
<p>配置oracle 10g数据库自启动的步骤如下：</p>
<p><strong>1、配置/etc/oratab 文件</strong></p>
<p>oratab文件中项的格式为<br>$ORACLE_SID:$ORACLE_HOME:NY<br>每个$ORACLE_SID只能有一个项<br>默认安装后,入口项的最后是N,将N修改为Y,使其可以通过dbstart工具启动</p>
<p><strong>2、配置$Oracle_HOME/bin/dbstart文件</strong></p>
<p>将dbstart文件中大约78行的ORACLE_HOME_LISTNER变量的值修改为$ORACLE_HOME所在的路径,此处为<br>ORACLE_HOME_LISTNER=/u01/app/oracle/product/10.2.0/db_1</p>
<p><strong>3、运行dbstart,dbshut测试数据库是否正确启动和关闭</strong></p>
<p>以oracle用户登陆,执行以下命令进行测试</p>
<p>$ dbstart<br>$ ps aux grep ora_<br>$ ps aux grep LISTEN<br>$ lsnrctl status<br>$ dbshut</p>
<p>数据库启动的日志文件为$ORACLE_HOME/startup.log,关闭的日志文件为$ORACLE_HOME/shutdown.log,监听器的日志文件$ORACLE_HOME/listener.log</p>
<p><strong>4、创建启动init脚本</strong></p>
<p>以root用户在/etc/init.d目录下创建文件oracle,其内容如下</p>
<p> 1 #!/bin/sh<br> 2<br> 3 ### BEGIN INIT INFO<br> 4 # Provides: oracle<br> 5 # Required-Start: $local_fs<br> 6 # Required-Stop: $local_fs<br> 7 # Default-Start: 2 3 4 5<br> 8 # Default-Stop: 0 1 6<br> 9 # Short-Description:oracle database init script<br>10 # Description: starts and stops oracle database and listeners<br>11 ### END INIT INFO<br>12<br>13 set-e<br>14<br>15 ORACLE_HOME=“/u01/app/oracle/product/10.2.0/db_1”<br>16 ORACLE_OWNER=“oracle”<br>17<br>18 do_start() {<br>19     echo”starting oracle databases…”<br>20     su - $ORACLE_OWNER -c “$ORACLE_HOME/bin/dbstart $ORACLE_HOME” &gt;&gt; /var/log/oracle<br>21     touch /var/lock/oracle<br>22     echo”ok”<br>23 }<br>24<br>25 do_stop() {<br>26     echo”Stopping oracle databases…”<br>27     su - $ORACLE_OWNER -c “$ORACLE_HOME/bin/dbshut $ORACLE_HOME” &gt;&gt; /var/log/oracle<br>28     rm -f /var/lock/oracle<br>29     echo”ok”<br>30 }<br>31<br>32 status() {<br>33     if [ -f /var/lock/oracle ]; then<br>34         echo”oracle database is running.”<br>35     else<br>36         echo”oracle database is not running.”<br>37     fi<br>38 }<br>39<br>40 case “$1” in<br>41     start)<br>42         do_start<br>43         ;;<br>44     stop)<br>45         do_stop<br>46         ;;<br>47     restart)<br>48         do_stop<br>49         do_start<br>50         ;;<br>51     reload)<br>52         ;;<br>53     force-reload)<br>54         ;;<br>55     status)<br>56         status<br>57         ;;<br>58     *)<br>59         echo”$0 {startstoprestartreloadforce-reloadstatus}”<br>60 esac<br>61<br>62 exit 0</p>
<p>然后在各个运行级对应的启动脚本目录下创建符号连接<br>#update-rc.d oracle defaults</p>
<p>还有一点,因为init脚本是用su切换到oracle用户执行数据库启动和关闭的,所以为了设置用户资源限制,需要为/etc/pam.d/su文件增添下面的行<br>session required pam_limits.so</p>
<p>配置完毕后,oracle数据库会随系统自动启动和关闭,手工控制以debian常见的方式进行</p>
<p>#/etc/init.d/oracle startstopstatusrestart</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian pc speaker 驱动错误提示</title>
    <url>/2013/01/28/debian-pc-speaker-driver-error-tips/</url>
    <content><![CDATA[<p>debian启动时会有pc speaker驱动的错误提示</p>
<a id="more"></a>
<p>Error: Driver ‘pcspkr’ is already registered, aborting…</p>
<p>这是因为近期的内核又增加了一个内核模块snd-pcsp，此内核模块也是pc喇叭的驱动，将pc喇叭模拟出声卡接口，这样pc speaker就有了两个内核模块，导致出现冲突</p>
<p>看下这两个模块的详细信息</p>
<h1 id="modinfo-pcspkr"><a href="#modinfo-pcspkr" class="headerlink" title="modinfo pcspkr"></a>modinfo pcspkr</h1><p>filename: /lib/modules/3.2.0-4-amd64/kernel/drivers/input/misc/pcspkr.ko<br>alias: platform:pcspkr<br>license: GPL<br>description: PC Speaker beeper driver<br>author: Vojtech Pavlik<br>depends:<br>intree: Y<br>vermagic: 3.2.0-4-amd64 SMP mod_unload modversions </p>
<h1 id="modinfo-snd-pcsp"><a href="#modinfo-snd-pcsp" class="headerlink" title="modinfo snd-pcsp"></a>modinfo snd-pcsp</h1><p>modifilename: /lib/modules/3.2.0-4-amd64/kernel/sound/drivers/pcsp/snd-pcsp.ko<br>alias: platform:pcspkr<br>license: GPL<br>description: PC-Speaker driver<br>author: Stas Sergeev<br>depends: snd-pcm,snd<br>intree: Y<br>vermagic: 3.2.0-4-amd64 SMP mod_unload modversions<br>parm: nforce_wa:Apply NForce chipset workaround (expect bad sound) (bool)<br>parm: index:Index value for pcsp soundcard. (int)<br>parm: id:ID string for pcsp soundcard. (charp)<br>parm: enable:Enable PC-Speaker sound. (bool)<br>parm: nopcm:Disable PC-Speaker PCM sound. Only beeps remain. (bool)</p>
<p>两个都是pc speaker驱动,所以解决方法就是屏蔽掉其中的一个，甚至全部屏蔽掉,pc speaker现在也没多大用处了。</p>
<p>/etc/modprobe.d目录下新建sound-blacklist.conf文件，添加如下两行<br>blacklist snd-pcsp<br>blacklist pcspkr</p>
<p>以后再启动机器就不会有这个错误提示了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>postfix邮件系统之SMTP认证配置</title>
    <url>/2014/01/03/debian-postfix-sasl-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>SASL基础配置</strong></p>
<p>postfix支持SASL认证,可以使用Cyrus SASL或Dovecot SASL实现,通常使用Cyrus SASL。<br>因为postfix链接了libsasl库,所以是直接通过函数调用的方式与Cyrus SASL通信,因此无需saslauthd守护程序的支持。<br>认证配置文件的名字为smtpd.conf,其中smtpd由postfix传递给Cyrus SASL库,cyrus添加后缀.conf。cyrus会先搜索/usr/lib/sasl2/目录查找smtpd.conf,如果找到则不继续查找。debian发行版此配置文件的路径为/etc/postfix/sasl/smtpd.conf</p>
<p>Cyrus SASL支持多种认证方式,通过saslauthd守护程序支持/etc/shadow,PAM和IMAP server，然后通过插件机制(叫做auxiliary property plugins)支持其他认证方式。</p>
<p>auxprop插件有如下几个:</p>
<ul>
<li>  sasldb<br>帐号存储在Berkeley DB中</li>
<li>  sql<br>帐号存储在SQL数据库中,比如mysql,PostgreSQL。要使用sql插件,必须安装libsasl2-modules-sql<h1 id="apt-get-install-libsasl2-modules-sql"><a href="#apt-get-install-libsasl2-modules-sql" class="headerlink" title="apt-get install libsasl2-modules-sql"></a>apt-get install libsasl2-modules-sql</h1></li>
<li>  ldapdb<br>帐号存储在LDAP数据库中</li>
</ul>
<p>下面的配置文件/etc/postfix/sasl/smtpd.conf使用sql插件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">pwcheck_method: auxprop</span><br><span class="line">auxprop_plugin: sql</span><br><span class="line">mech_list: PLAIN LOGIN CRAM-MD5 DIGEST-MD5 NTLM</span><br><span class="line">sql_engine: mysql</span><br><span class="line">sql_hostnames: <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line">sql_user: postfix</span><br><span class="line">sql_passwd: postfix</span><br><span class="line">sql_database: mail</span><br><span class="line">sql_select: SELECT password FROM users WHERE email = <span class="string">&#x27;%u@%r&#x27;</span></span><br></pre></td></tr></table></figure>
<p>其中:<br>sql_hostnames - 指定localhost则通过UNIX-domain socket连接到mysql,如果指定127.0.0.1则通过tcp连接mysql</p>
<p>为了启用sasl认证,必须在/etc/postfix/main.cf中指定:<br>smtpd_sasl_auth_enable = yes</p>
<p>reload postfix,测试一下sasl auth</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ telnet localhost <span class="number">25</span></span><br><span class="line">Trying ::<span class="number">1.</span>..</span><br><span class="line">Connected to openwares.net.</span><br><span class="line">Escape character is <span class="string">&#x27;^\]&#x27;</span>.</span><br><span class="line"><span class="number">220</span> openwares.net ESMTP Postfix (Debian/GNU)</span><br><span class="line">EHLO test</span><br><span class="line"><span class="number">250</span>-openwares.net</span><br><span class="line"><span class="number">250</span>-PIPELINING</span><br><span class="line"><span class="number">250</span>-SIZE <span class="number">10240000</span></span><br><span class="line"><span class="number">250</span>-VRFY</span><br><span class="line"><span class="number">250</span>-ETRN</span><br><span class="line"><span class="number">250</span>-STARTTLS</span><br><span class="line"><span class="number">250</span>-AUTH PLAIN LOGIN CRAM-MD5 DIGEST-MD5 NTLM &lt;---smtp认证启用</span><br><span class="line"><span class="number">250</span>-ENHANCEDSTATUSCODES</span><br><span class="line"><span class="number">250</span>-8BITMIME</span><br><span class="line"><span class="number">250</span> DSN</span><br></pre></td></tr></table></figure>

<p>也可以通过saslauthd + PAM + pam_mysql的方式来使用mysql数据库存储账户,可以支持密码加密。</p>
<p>有些客户端不能正确的识别AUTH,在main.cf中添加如下指令来支持这些客户端:<br>broken_sasl_auth_clients = yes</p>
<p><strong>SMTP认证策略</strong></p>
<p>有以下几个认证策略用于限制SASL的认证机制:</p>
<ul>
<li>  noanonymous<br>不允许匿名认证的SASL认证机制</li>
<li>  noplaintext<br>不允许传输未加密的用户名和密码信息的SASL认证机制</li>
<li>  nodictionary<br>不允许容易被字典攻击的SASL认证机制</li>
<li>  forward_secrecy<br>在会话之间传递密钥</li>
<li>  mutual_auth<br>仅使用客户和服务器相互认证的机制</li>
</ul>
<p><em>未加密STML会话</em><br>默认的认证策略是允许SASL匿名认证之外的所有其他认证机制,在main.cf中:<br>smtpd_sasl_security_options = noanonymous</p>
<p><em>加密SMTP会话(TLS)</em><br>在加密的SMTP会话中有一个单独的参数控制认证策略,一般在main.cf中如下设置:</p>
<p>smtpd_sasl_security_options = noanonymous, noplaintext<br>smtpd_sasl_tls_security_options = noanonymous</p>
<p>如果只有在TLS加密的前提下才提供AUTH认证,可以在main.cf中添加:<br>smtpd_tls_auth_only = yes</p>
<p><strong>SASL授权</strong><br>客户端通过SASL认证后,postfix给于客户适当的授权</p>
<p><em>中继授权</em><br>通过在中继策略中添加permit_sasl_authenticated选项,postfix允许认证的客户端向本域之外的远程其他域收件人发送邮件。<br>/etc/postfix/main.cf中:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># postfix 2.0 and later</span><br><span class="line">smtpd_relay_restrictions =</span><br><span class="line"> permit_mynetworks</span><br><span class="line"> permit_sasl_authenticated &lt;---</span><br><span class="line"> reject_unauth_destination</span><br><span class="line"># postfix 2.0 and before</span><br><span class="line">smtpd_recipient_restrictions =</span><br><span class="line"> permit_mynetworks</span><br><span class="line"> permit_sasl_authenticated &lt;---</span><br><span class="line"> reject_unauth_destination</span><br></pre></td></tr></table></figure>

<p><strong>注意:postfix版本2.9.6,main.cf中设置smtpd_relay_restrictions参数,重新加载postfix时会提示:<br>postconf: warning: /etc/postfix/main.cf: unused parameter: smtpd_relay_restrictions=permit_mynetworks,permit_sasl_authenticated,reject_unauth_destination,因为2.10及以下版本需要使用smtpd_recipient_restrictions参数</strong></p>
<p><strong>拒绝未认证的客户端</strong></p>
<p>main.cf配置文件中添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">smtpd_delay_reject = yes</span><br><span class="line">smtpd_client_restrictions = permit_sasl_authenticated, reject</span><br></pre></td></tr></table></figure>
<p>注意：这样设置可能会导致拒绝接受其他smtp投递过来的信件。</p>
<p><em>发送者地址授权</em></p>
<p>如果没有SMTP认证，SMTP客户端可以使用MAIL FROM命令随意指定信封上的发件者邮件地址,因为smtp服务器不只知道smtp客户的用户名。<br>使用SASL认证之后,postfix可以通过维护一张信封地址和认证用户之间的映射表就可以控制smtp用户只能使用自己拥有的信封地址来发送邮件。<br>/etc/postfix/main.cf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">smtpd_sender_login_maps = hash:<span class="regexp">/etc/</span>postfix/controlled_envelope_senders</span><br></pre></td></tr></table></figure>
<p>/etc/postfix/controlled_envelope_senders:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># envelope sender owners (SASL login names)</span><br><span class="line"> john@example.com john@example.com</span><br><span class="line"> helpdesk@example.com john@example.com, mary@example.com</span><br><span class="line"> postmaster admin@example.com</span><br><span class="line"> @example.net barney, fred, john@example.com, mary@example.com</span><br></pre></td></tr></table></figure>

<p><strong>SASL其他选项</strong></p>
<p><em>每帐号控制</em><br>postfix可以通过sasl用户名来实现每个账户的单独控制。通常用于保留(HOLD)或拒绝(REJECT)存在问题帐号的邮件。<br>/etc/postfix/main.cf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">smtpd_recipient_restrictions = </span><br><span class="line">permit_mynetworks </span><br><span class="line">check_sasl_access hash:<span class="regexp">/etc/</span>postfix/sasl_access</span><br><span class="line">permit_sasl_authenticated</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>/etc/postfix/sasl_access:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># Use this when smtpd_sasl_local_domain is empty.</span><br><span class="line">username HOLD</span><br><span class="line"># Use this when smtpd_sasl_local_domain=example.com.</span><br><span class="line">username@example.com HOLD</span><br></pre></td></tr></table></figure>

<p><em>默认认证域</em><br>为没有域名部分的SASL登录名添加域名,比如登录名为john,替换为<a href="mailto:&#x6a;&#111;&#104;&#x6e;&#x40;&#x65;&#120;&#97;&#x6d;&#112;&#x6c;&#101;&#x2e;&#99;&#111;&#x6d;">&#x6a;&#111;&#104;&#x6e;&#x40;&#x65;&#120;&#97;&#x6d;&#112;&#x6c;&#101;&#x2e;&#99;&#111;&#x6d;</a><br>/etc/postfix/main.cf:<br> smtpd_sasl_local_domain = example.com</p>
<p><em>隐藏sasl认证</em><br>可以为部分客户或网络隐藏SASL认证,因为有些不需要认证的客户如果发现服务提供SASL认证能力,那么他们会试图去认证,但客户端有没有提供认证信息,这样客户就一直处于认证失败状态。</p>
<p>/etc/postfix/main.cf:<br> smtpd_sasl_exceptions_networks = !192.0.2.171/32, 192.0.2.0/24</p>
<p><em>添加sasl登录名到邮件头</em></p>
<p>在发送邮件的头部Received字段添加SASL认证登录名</p>
<p>参考:<br><a href="http://www.postfix.org/SASL_README.html">Postfix SASL Howto</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian安装P1008打印机</title>
    <url>/2014/01/06/debian-printer-1008-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p>直接连上打印机虽然看起来好像是安装成功了，但是不能打印的，因为缺少firmware。</p>
<p>printer-driver-foo2zjs带了应用程序getweb可以用来下载对应的firmware并转换到linux可以使用的格式:</p>
<h1 id="getweb-P1008"><a href="#getweb-P1008" class="headerlink" title="getweb P1008"></a>getweb P1008</h1><p>sihpP1006.img</p>
<p>(c) Copyright Hewlett-Packard 2009</p>
<p>这样/lib/firmware/hp下会安装了P1008可以使用的firmware文件sihpP1006.dl</p>
<p>这样就可以正常使用P1008了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian架设轻量XMPP/JABBER服务器Prosody</title>
    <url>/2012/10/21/debian-prosody-setup/</url>
    <content><![CDATA[<p><a href="http://prosody.im/">Prosody</a>用LUA语言开发的,易于安装配置的,轻量级的跨平台XMPP/JABBER服务器。</p>
<a id="more"></a>
<h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a><strong>安装配置</strong></h2><p>#apt-get install prosody</p>
<p>编辑/etc/prosody/prosody.cfg.lua</p>
<p>找到VirtualHost “example.com”这行,将后面的域名更改为自己的域名或者IP地址,然后注释掉或删除其后的一行<br>enabled = false – Remove this line to enable this host</p>
<p>其余参数保持不变,保存后<br>#/etc/init.d/prosody restart<br>或<br>#prosodyctl restart</p>
<h2 id="添加用户账号"><a href="#添加用户账号" class="headerlink" title="添加用户账号"></a><strong>添加用户账号</strong></h2><p>prosody默认使用文件存储信息,使用的文件位于/var/lib/prosody/目录下,也可以配置prosody使用数据库作为后端数据存储,比如postgrsql等。</p>
<p><strong>客户自注册账户</strong></p>
<p>默认设置是不允许客户端自行注册账户的,开启客户注册功能,首先要确保加载register模块</p>
<p>modules_enabled = {<br>…<br>“register”; – Allow users to register on this server using a client and change passwords<br>…<br>}</p>
<p>然后设置参数<br>allow_registration = true</p>
<p><strong>手动添加账户</strong></p>
<p>#prosodyctl adduser <a href="mailto:&#x75;&#x73;&#x65;&#x72;&#x6e;&#97;&#x6d;&#x65;&#x40;&#100;&#111;&#x6d;&#x61;&#x69;&#x6e;&#110;&#x61;&#109;&#101;&#46;&#x63;&#111;&#x6d;">&#x75;&#x73;&#x65;&#x72;&#x6e;&#97;&#x6d;&#x65;&#x40;&#100;&#111;&#x6d;&#x61;&#x69;&#x6e;&#110;&#x61;&#109;&#101;&#46;&#x63;&#111;&#x6d;</a></p>
<p>删除账户<br>#prosodyctl deluser <a href="mailto:&#117;&#115;&#101;&#x72;&#x6e;&#97;&#x6d;&#101;&#64;&#x64;&#111;&#x6d;&#97;&#x69;&#110;&#110;&#x61;&#x6d;&#x65;&#46;&#99;&#x6f;&#x6d;">&#117;&#115;&#101;&#x72;&#x6e;&#97;&#x6d;&#101;&#64;&#x64;&#111;&#x6d;&#97;&#x69;&#110;&#110;&#x61;&#x6d;&#x65;&#46;&#99;&#x6f;&#x6d;</a></p>
<p>更改用户密码<br>#prosodyctl passwd <a href="mailto:&#x75;&#115;&#101;&#114;&#110;&#x61;&#109;&#x65;&#x40;&#100;&#111;&#109;&#97;&#105;&#110;&#110;&#97;&#109;&#101;&#46;&#99;&#111;&#109;">&#x75;&#115;&#101;&#114;&#110;&#x61;&#109;&#x65;&#x40;&#100;&#111;&#109;&#97;&#105;&#110;&#110;&#97;&#109;&#101;&#46;&#99;&#111;&#109;</a></p>
<h2 id="端口映射"><a href="#端口映射" class="headerlink" title="端口映射"></a><strong>端口映射</strong></h2><p>XMPP服务器的著名端口为TCP/5222,XMPP服务器间互联的著名端口为TCP/5269</p>
<p><strong>XMPP/JABBER客户端</strong></p>
<p>只要符合XMPP协议标准的客户端都可以连接到prosody服务器。推荐开源跨平台的XMPP客户端<a href="http://psi-im.org/">Psi</a>,Psi界面使用QT开发,可以在Linux/MacOS/Windows等平台上运行。其他常见的客户端还有,<a href="http://gajim.org/downloads.php?lang=en">Gajim</a>(GTK+开发),<a href="http://pandion.im/">Pandion</a>等。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian下python3读取MDB数据库</title>
    <url>/2013/11/11/debian-python-access-mdb-database/</url>
    <content><![CDATA[<p>linux平台上可以使用unixodbc和libmdbodbc1读取mdb</p>
<a id="more"></a>
<p>unixODBC是unix like平台上ODBC规范的开源实现,而libmdbodbc1则是mdbtools提供的mdb数据库的odbc驱动。<br>如果不通过编程方式，只是单纯查看mdb，可以<a href="https://openwares.net/linux/access_mdb_viewer.html">Debian查看Acess MDB数据库文件</a></p>
<p><strong>安装</strong></p>
<p>unixODBC和libmdbodbc1</p>
<p>#apt-get install unixodbc libmdbodbc1</p>
<p><strong>配置odbc</strong></p>
<p>/etc/odbcinst.ini配置odbc驱动<br>[html]<br>[MDBTools]<br>Description=MDBTools Driver<br>Driver=libmdbodbc.so.1<br>Setup=libmdbodbc.so.1<br>FileUsage=1<br>UsageCount=1<br>[/html]</p>
<p>/etc/odbc.ini配置数据源<br>[html]<br>[test]<br>Driver = MDBTools<br>Database = /path/to/mdb/file/test.mdb<br>[/html]<br>也可以在在程序中动态设置数据源</p>
<p><strong>python3访问mdb</strong></p>
<p>python3使用<a href="https://code.google.com/p/pypyodbc/">pypyodbc</a>或者<a href="https://code.google.com/p/pyodbc/">pyodbc</a>可以访问odbc数据库</p>
<ul>
<li>  <em>pypyodbc</em></li>
</ul>
<p>先看pypyodbc,这是个python实现的odbc访问模块</p>
<p>安装pypyodbc</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># python3 setup.py</span><br></pre></td></tr></table></figure>

<p>使用pypyodbc读取mdb</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ python3</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">import</span> pypyodbc</span><br><span class="line">&gt;&gt;&gt; conn=pypyodbc.connect(<span class="string">&#x27;Driver=MDBTools;DBQ=/path/to/Record.mdb&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; print(conn.cursor().execute(<span class="string">&#x27;SELECT * FROM Build&#x27;</span>).fetchone()\[<span class="number">0</span>\])</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"> File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> File <span class="string">&quot;/usr/local/lib/python3.3/dist-packages/pypyodbc.py&quot;</span>, line <span class="number">1805</span>, <span class="keyword">in</span> fetchone</span><br><span class="line"> value_list.append(buf_cvt_func(alloc_buffer.value))</span><br><span class="line">ValueError: invalid literal <span class="keyword">for</span> int() <span class="keyword">with</span> base <span class="number">10</span>: b<span class="string">&#x27;\\xe0&#x27;</span></span><br></pre></td></tr></table></figure>
<p>mdb文件中中文字符编码为GB码，出现问题,pypyodbc直接崩溃了。</p>
<ul>
<li>  <em>pyodbc</em></li>
</ul>
<p>pyodbc是C实现的odbc访问模块</p>
<p>安装pyodbc</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install python3-dev mdbtools-dev</span><br><span class="line"># python3 setup.py build install</span><br></pre></td></tr></table></figure>
<p>使用pyodbc读取mdb</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ python3</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">import</span> pyodbc</span><br><span class="line">&gt;&gt;&gt; conn=pyodbc.connect(<span class="string">&#x27;Driver=MDBTools;DBQ=/path/to/Record.mdb&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; s1=conn.cursor().execute(<span class="string">&#x27;SELECT * FROM Build&#x27;</span>).fetchone()\[<span class="number">0</span>\]</span><br><span class="line">&gt;&gt;&gt; s1</span><br><span class="line"><span class="string">&#x27;냥\\ue59a\\ua7ba鯥\\ue9bd薙&#x27;</span></span><br></pre></td></tr></table></figure>

<p>这次pyodbc没有崩溃，但是输出了乱码。不知是libmdbodbc1还是pyodbc的问题，总之是没有正确的识别GB码，有时间再翻源代码看。</p>
<p><strong>其他方式访问mdb</strong></p>
<ul>
<li>  <em>isql</em></li>
</ul>
<p>mdbtools自带的isql可以查看mdb,但不能使用动态数据源，只能使用/etc/odbc.ini文件里配置好的数据源，比如这样</p>
<p>$ isql test</p>
<ul>
<li>  <em>mdb-export导出表到csv文件</em></li>
</ul>
<p>$ mdb-export /path/to/foo.mdb table &gt;&gt; table.csv</p>
<p>mdb-export导出的csv编码是正确的，没有出现乱码。然后可以用pyhton3来处理csv文件。</p>
<ul>
<li>  <em><a href="https://code.google.com/p/mdb-sqlite/">mdb-sqlie</a>转换mdb到sqlite格式</em></li>
</ul>
<p>还可以使用mdb-sqlite将mdb数据库转换到sqlite数据库，然后再用python3访问sqlite数据库，这个没有测试。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>debian安装shadowsocks-qt5</title>
    <url>/2015/11/14/debian-shadowsocks-qt5-install/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian官方源里的shadowsocks最近用不了了。/var/log/shadowsocks.log里出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR M2Crypto is required to use aes-<span class="number">256</span>-cfb, please run apt-get install python-m2crypto</span><br></pre></td></tr></table></figure>

<p>但是实际上python-m2crypto已经安装了，重新安装也不行。那就换个客户端shadowsocks-qt5试试。</p>
<p><strong>安装依赖</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install qt5-qmake qtbase5-dev libqrencode-dev libappindicator-dev libzbar-dev libbotan1<span class="number">.10</span>-dev</span><br></pre></td></tr></table></figure>

<p><strong>安装libQtShadowsocks</strong><br>shadowsocks-qt5依赖于libQtShadowsocks,所以先安装libQtShadowsocks。</p>
<p>下载或clone libQtShadowsocks,项目根目录下执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dpkg-buildpackage -uc -us -b</span><br></pre></td></tr></table></figure>

<p>在上一级目录中生成三个deb包:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">libqtshadowsocks_1<span class="number">.8</span><span class="number">.0</span>-1_amd64.deb </span><br><span class="line">libqtshadowsocks-dev_1<span class="number">.8</span><span class="number">.0</span>-1_amd64.deb </span><br><span class="line">shadowsocks-libqtshadowsocks_1<span class="number">.8</span><span class="number">.0</span>-1_amd64.deb</span><br></pre></td></tr></table></figure>

<p>安装前两个即可</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg -i libqtshadowsocks_1<span class="number">.8</span><span class="number">.0</span>-1_amd64.deb </span><br><span class="line">$ sudo dpkg -i libqtshadowsocks-dev_1<span class="number">.8</span><span class="number">.0</span>-1_amd64.deb </span><br></pre></td></tr></table></figure>

<p><strong>安装shadowsocks-qt5</strong><br>下载或clone shadowsocks-qt5，项目根目录下执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dpkg-buildpackage -uc -us -b</span><br></pre></td></tr></table></figure>

<p>在上一级目录中生成：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">shadowsocks-qt5_2<span class="number">.6</span><span class="number">.0</span>-1_amd64.deb</span><br></pre></td></tr></table></figure>

<p>安装deb包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg -i shadowsocks-qt5_2<span class="number">.6</span><span class="number">.0</span>-1_amd64.deb</span><br></pre></td></tr></table></figure>

<p>安装完成，配置见<a href="https://openwares.net/linux/shadowsocks_fuck_gfw.html">Shadowsocks科学上网</a>。</p>
<p>References:<br>[1]<a href="https://github.com/shadowsocks/shadowsocks-qt5">shadowsocks-qt5</a><br>[2]<a href="https://github.com/shadowsocks/libQtShadowsocks">libQtShadowsocks</a><br>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Squeeze 多网卡bonding设置</title>
    <url>/2011/05/09/debian-squeeze-bonding-setup/</url>
    <content><![CDATA[<p>通过多网卡bonding可以提供负载均衡,或者网卡热备(hot standby)</p>
<a id="more"></a>
<p><strong>介绍</strong></p>
<p>先来看下官方文档/usr/src/linux/Documentation/networking/bonding.txt对bonding的介绍</p>
<p>The Linux bonding driver provides a method for aggregating multiple network interfaces into a single logical “bonded” interface.The behavior of the bonded interfaces depends upon the mode; generally speaking, modes provide either hot standby or load balancing services.Additionally, link integrity monitoring may be performed.</p>
<p>linux bonding驱动提供了聚合多个网络接口成为一个单一逻辑绑定网络接口的方法。绑定网络接口的行为依赖于绑定模式，一般来说，绑定模式不外乎网卡热备(hot standby)或者负载均衡(load balancing)。此外，bonding驱动还会监视链路的完整性。</p>
<p>也就是说bonding通过绑定多个网络接口为一个逻辑网络接口来提供网络可靠性或均衡网络流量，这对于服务器来讲是很重要的。对于重要的应用bonding可以通过hot standby来提供failover特性，提高系统的可靠性。而对于像文件服务器这样的对网络要求很高的场合,bonding可以极大的提高网络IO性能。</p>
<p><strong>配置</strong></p>
<p>bonding并不需要网络接口卡型号完全一致,我绑定了两块物理网卡，一块是intel 82574L,另一个块是intel 82576，配置完成后没有任何问题。</p>
<p>1、安装ifenslave-2.6<br>$sudo apt-get install ifenslave-2.6</p>
<p>2、修改网络接口配置文件/etc/network/interfaces<br> 1 # This file describes the network interfaces available on your system<br> 2 # and how to activate them. For more information, see interfaces(5).<br> 3<br> 4 # The loopback network interface<br> 5 auto lo<br> 6 iface lo inet loopback<br> 7<br> 8 # The primary network interface<br> 9 auto bond0<br>10 iface bond0 inet static<br>11     address 192.168.0.18<br>12     netmask 255.255.255.0<br>13     network 192.168.0.0<br>14     broadcast 192.168.0.255<br>15     gateway 192.168.0.1<br>16     slaves eth0 eth1<br>17     bond-mode balance-rr<br>18     bond-miimon 100  </p>
<p>第16行 slaves eth0 eth1，说明绑定两个“从网卡”eth0和eth1到bond0逻辑接口,如果要绑定多个网络接口,继续在该行附加网络接口名字即可。</p>
<p>第17行 bond-mode balance-rr，指定绑定模式为采用Round-robin策略的负载均衡模式,两个网络接口会均匀分担网络负载，另一个常用模式为active-backup，也就是hot standby模式，支持网络接口failover</p>
<p>3、重新启动网络</p>
<p>$sudo /etc/init.d/networking restart</p>
<p>如果重新启动网络时有bonding: Warning:字样的提示，则需要在/etc/modprobe.d目录下新建文件aliases-bond.conf,内容为<br>alias bond0 bonding<br>为bonding模块建立一个别名bond0,通过别名bonding模块可以支持多个bonding逻辑接口。</p>
<p>配置完成。</p>
<p><strong>UPDATE:</strong></p>
<p>在Debian Squeezy(kernel 2.6.32-5-amd64,kvm 0.12.5)上配置bonding曾经遇到问题,<a href="https://twitter.com/#!/openwares/status/75503003687337984">网络极度不稳定</a>,怀疑是兼容性问题。今天刚好发现有个家伙也遇到<a href="http://www.spinics.net/lists/kvm/msg54612.html">bonding后速度极其缓慢</a>,和我一样的系统环境。这家伙说关闭网卡的LRO(<a href="https://openwares.net/internet/lro_intro.html">Large receive offload</a>)特性后恢复正常。不过查看两块网卡接口的LRO特性都是关闭的,怀疑中,抽空实验一下。</p>
<p>**UPDATE:**在debian wheezy(kernel 3.2.0.2-amd64,kvm 1.0)上bonding问题依旧,active-backup模式,从外部根本无法ping通客户机,去掉bonding就没由任何问题,而且网卡的LRO特性都是关闭的。基本可以确认KVM与bonding加桥接网络存在兼容性问题。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian 6.0 squeeze 安装oracle 10g 客户端</title>
    <url>/2011/02/15/debian-squeeze-oracle-10g-client/</url>
    <content><![CDATA[<p>oracle为debian/ubuntu用户提供了一个apt源，来提供oracle 10g express edition版本的安装</p>
<a id="more"></a>
<p>/etc/apt/source.list增加一行<br>deb <a href="http://oss.oracle.com/debian">http://oss.oracle.com/debian</a> unstable main non-free</p>
<p>然后sudo apt-get update,sudo apt-get install oracle-xe-client<br>安装成功后，在用户主目录下的.bashrc文件里面增加以设置相关的环境变量</p>
<p>export ORACLE_HOME=/usr/lib/oracle/xe/app/oracle/product/10.2.0/client<br>export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$LD_LIBRARY_PATH;<br>export PATH=$ORACLE_HOME/bin:$PATH<br>export TNS_ADMIN=$ORACLE_HOME/network/admin</p>
<p>TNS_ADMIN变量用来指定tnsnames.ora文件所在的位置,在tnsnames.ora里面设定好服务器的相关信息就可以连接oracle服务器进行相关操作了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Stretch安装nodejs TLS版本</title>
    <url>/2017/09/26/debian-stretch-nodejs-tls/</url>
    <content><![CDATA[<a id="more"></a>
<p>当前稳定发行版的nodejs有很多安全性问题，可以从<a href="https://nodesource.com/">nodesource</a>安装当前的6.X TLS版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ curl -sL https:<span class="comment">//deb.nodesource.com/setup_6.x sudo -E bash -</span></span><br><span class="line">$ sudo apt-get install -y nodejs</span><br></pre></td></tr></table></figure>

<p>有时可能会从源包构建组件，所以可以先安装build环境：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install -y build-essential libssl-dev</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/nodesource/distributions#debinstall">Installation instructions</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>debian stretch 启用rc.local</title>
    <url>/2019/06/12/debian-stretch-open-rc-local/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian stretch默认不再支持rc.local，但是系统提供了systemd服务rc-local，可以用来添加rc.local支持，详见<a href="https://sb.sb/blog/debian-9-rc-local/">[1]</a></p>
<p>如果需要指定工作目录，可以在rc.local中exit之前这样写：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">(cd /opt/reps &amp;&amp; ./reps)</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://sb.sb/blog/debian-9-rc-local/">Debian 9 Stretch 解决 /etc/rc.local 开机启动问题</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian sudo &#39;command not found&#39;</title>
    <url>/2009/04/19/debian-sudo-command-not-found/</url>
    <content><![CDATA[<p>在自己的主目录下面建了一个bin子目录，把自己撰写的一些简单的脚本放在这里执行，因为debian lenny用户主目录下的.profile文件默认把$HOME/bin路径放入了环境变量$PATH中，因此自撰的脚本就可以像系统提供的应用程序一样来运行了。</p>
<p>但是今天写了一个脚本需要root权限来运行，sudo一下居然提示”sudo:  xxx.sh:  command not found”。很明显这是$PATH的问题，切换到root，设置好$PATH，运行这个脚本是没问题的。看来是sudo的问题了，浏览了sudo的man page，然后google了一下后发现了问题所在。</p>
<p>原来Debian在编译sudo包的时候默认开启了- -with-secure-path选项，在我机器上这个完整的选项是： - -with-secure-path=”/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/X11R6/bin”。当sudo时$PATH变量就会被secure-path所代替，所以即便你更改/etc/environment中的PATH也没有用。此问题由来已久，没想到在lenny中仍然存在。</p>
<p>后来有一个sudo options SECURE_PATH可以override此内置设置，在/etc/sudoers文件内增加这么一行：</p>
<p>Defaults secure_path=”/bin:/usr/bin:/usr/local/bin:…”<br>但是这样很不方便。</p>
<p>其他的workround我知道有这么几个：<br>1、使用脚本的完全路径，不是办法的办法。<br>2、使用sudo的env选项，像这样sudo env PATH=$PATH xxx.sh<br>3、把脚本拷贝或链接到系统$PATH中</p>
<p>这些方法都很别扭，所以最终的解决方案就是：<br>重新编译sudo，千万别再带- -with-secure-path选项了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Suqeeze安装配置OpenVPN服务器端</title>
    <url>/2011/04/08/debian-suqeeze-openvpn-install-config/</url>
    <content><![CDATA[<p>Debian 6.0 OpenVPN服务器端安装配置简单手记</p>
<a id="more"></a>
<p><strong>安装</strong></p>
<p>$sudo apt-get install openvpn</p>
<p><strong>生成服务器和客户端证书</strong></p>
<ul>
<li>  初始化</li>
</ul>
<p>$cd /usr/share/doc/openvpn/examples/easy-rsa/2.0<br>$sudo su<br>#source vars<br>#./clean-all</p>
<ul>
<li>  生成ca</li>
</ul>
<p>#./build-ca<br>所有的问题回车默认即可,在/usr/share/doc/openvpn/examples/easy-rsa/2.0/keys目录下生ca.crt,ca.key两个文件</p>
<ul>
<li>  生成服务器端证书</li>
</ul>
<p>#./build-key-server server<br>一路回车,后面两个问题Sign the certificate输入y,1 out of 1 certificate requests certified, commit?输入y,keys目录下生成server.crt,server.csr和server.key</p>
<ul>
<li>  生成客户端证书</li>
</ul>
<p>./build-key client1<br>一路回车，最后面两个问题Sign the certificate输入y,1 out of 1 certificate requests certified, commit?输入y,keys目录下生成client1.crt,client1.csr和client1.key,为其他客户端生成证书时选择不同的客户端名字即可，比如client2,client3…</p>
<ul>
<li>  创建DH(Diffie Hellman)</li>
</ul>
<p>#./build-dh<br>keys目录下生成dh1024.pem文件</p>
<ul>
<li>  将keys目录移动到/etc/openvpn目录下</li>
</ul>
<p>#mv /usr/share/doc/openvpn/examples/easy-rsa/2.0/keys /etc/openvpn/</p>
<p><strong>编辑服务器端配置文件</strong></p>
<p>#cp /usr/share/doc/openvpn/examples/sample-config-files/server.conf.gz /etc/openvpn/<br>#cd /etc/openvpn<br>#gunzip server.conf.gz</p>
<p>打开server.conf修改相应配置,配置样例文件如下：<br> 23 # Which local IP address should OpenVPN<br> 24 # listen on? (optional)<br> 25 ;local a.b.c.d<br> 26 #服务器IP地址<br> 27 local x.x.x.x<br> 28<br> 29 # Which TCP/UDP port should OpenVPN listen on?<br> 30 # If you want to run multiple OpenVPN instances<br> 31 # on the same machine, use a different port<br> 32 # number for each one.  You will need to<br> 33 # open up this port on your firewall.\<br> 34 #openvpn使用的端口号<br> 35 port 6194<br> 36<br> 37 # TCP or UDP server?<br> 38 ;proto tcp<br> 39 #使用UDP协议<br> 40 proto udp<br> 41<br> 42 # “dev tun” will create a routed IP tunnel,<br> 43 # “dev tap” will create an ethernet tunnel.<br> 44 # Use “dev tap0” if you are ethernet bridging<br> 45 # and have precreated a tap0 virtual interface<br> 46 # and bridged it with your ethernet interface.<br> 47 # If you want to control access policies<br> 48 # over the VPN, you must create firewall<br> 49 # rules for the the TUN/TAP interface.<br> 50 # On non-Windows systems, you can give<br> 51 # an explicit unit number, such as tun0.<br> 52 # On Windows, use “dev-node” for this.<br> 53 # On most systems, the VPN will not function<br> 54 # unless you partially or fully disable<br> 55 # the firewall for the TUN/TAP interface.<br> 56 ;dev tap<br> 57 #使用tunnel设备<br> 58 dev tun<br> 59<br> 60 # Windows needs the TAP-Win32 adapter name<br> 61 # from the Network Connections panel if you<br> 62 # have more than one.  On XP SP2 or higher,<br> 63 # you may need to selectively disable the<br> 64 # Windows firewall for the TAP adapter.<br> 65 # Non-Windows systems usually don’t need this.<br> 66 ;dev-node MyTap<br> 67<br> 68 # SSL/TLS root certificate (ca), certificate<br> 69 # (cert), and private key (key).  Each client<br> 70 # and the server must have their own cert and<br> 71 # key file.  The server and all clients will<br> 72 # use the same ca file.<br> 73 #<br> 74 # See the “easy-rsa” directory for a series<br> 75 # of scripts for generating RSA certificates<br> 76 # and private keys.  Remember to use<br> 77 # a unique Common Name for the server<br> 78 # and each of the client certificates.<br> 79 #<br> 80 # Any X509 key management system can be used.<br> 81 # OpenVPN can also use a PKCS #12 formatted key file<br> 82 # (see “pkcs12” directive in man page).<br> 83 #指定CA及服务器端证书<br> 84 ca /etc/openvpn/keys/ca.crt<br> 85 cert /etc/openvpn/keys/server.crt<br> 86 key /etc/openvpn/keys/server.key  # This file should be kept secret<br> 87<br> 88 # Diffie hellman parameters.<br> 89 # Generate your own with:<br> 90 #   openssl dhparam -out dh1024.pem 1024<br> 91 # Substitute 2048 for 1024 if you are using<br> 92 # 2048 bit keys.<br> 93 #指定DH文件<br> 94 dh /etc/openvpn/keys/dh1024.pem<br> 95<br> 96 # Configure server mode and supply a VPN subnet<br> 97 # for OpenVPN to draw client addresses from.<br> 98 # The server will take 10.8.0.1 for itself,<br> 99 # the rest will be made available to clients.<br>100 # Each client will be able to reach the server<br>101 # on 10.8.0.1. Comment this line out if you are<br>102 # ethernet bridging. See the man page for more info.<br>103 #分配给客户端使用的IP地址段<br>104 server 10.8.0.0 255.255.255.0<br>105<br>106 # Maintain a record of client &lt;-&gt; virtual IP address<br>107 # associations in this file.  If OpenVPN goes down or<br>108 # is restarted, reconnecting clients can be assigned<br>109 # the same virtual IP address from the pool that was<br>110 # previously assigned.<br>111 ifconfig-pool-persist ipp.txt<br>112<br>113 # Configure server mode for ethernet bridging.<br>114 # You must first use your OS’s bridging capability<br>115 # to bridge the TAP interface with the ethernet<br>116 # NIC interface.  Then you must manually set the<br>117 # IP/netmask on the bridge interface, here we<br>118 # assume 10.8.0.4/255.255.255.0.  Finally we<br>119 # must set aside an IP range in this subnet<br>120 # (start=10.8.0.50 end=10.8.0.100) to allocate<br>121 # to connecting clients.  Leave this line commented<br>122 # out unless you are ethernet bridging.<br>123 ;server-bridge 10.8.0.4 255.255.255.0 10.8.0.50 10.8.0.100<br>124<br>125 # Configure server mode for ethernet bridging<br>126 # using a DHCP-proxy, where clients talk<br>127 # to the OpenVPN server-side DHCP server<br>128 # to receive their IP address allocation<br>129 # and DNS server addresses.  You must first use<br>130 # your OS’s bridging capability to bridge the TAP<br>131 # interface with the ethernet NIC interface.<br>132 # Note: this mode only works on clients (such as<br>133 # Windows), where the client-side TAP adapter is<br>134 # bound to a DHCP client.<br>135 ;server-bridge<br>136<br>137 # Push routes to the client to allow it<br>138 # to reach other private subnets behind<br>139 # the server.  Remember that these<br>140 # private subnets will also need<br>141 # to know to route the OpenVPN client<br>142 # address pool (10.8.0.0/255.255.255.0)<br>143 # back to the OpenVPN server.<br>144 ;push “route 192.168.10.0 255.255.255.0”<br>145 ;push “route 192.168.20.0 255.255.255.0”<br>146<br>147 # To assign specific IP addresses to specific<br>148 # clients or if a connecting client has a private<br>149 # subnet behind it that should also have VPN access,<br>150 # use the subdirectory “ccd” for client-specific<br>151 # configuration files (see man page for more info).<br>152<br>153 # EXAMPLE: Suppose the client<br>154 # having the certificate common name “Thelonious”<br>155 # also has a small subnet behind his connecting<br>156 # machine, such as 192.168.40.128/255.255.255.248.<br>157 # First, uncomment out these lines:<br>158 ;client-config-dir ccd<br>159 ;route 192.168.40.128 255.255.255.248<br>160 # Then create a file ccd/Thelonious with this line:<br>161 #   iroute 192.168.40.128 255.255.255.248<br>162 # This will allow Thelonious’ private subnet to<br>163 # access the VPN.  This example will only work<br>164 # if you are routing, not bridging, i.e. you are<br>165 # using “dev tun” and “server” directives.<br>166<br>167 # EXAMPLE: Suppose you want to give<br>168 # Thelonious a fixed VPN IP address of 10.9.0.1.<br>169 # First uncomment out these lines:<br>170 ;client-config-dir ccd<br>171 ;route 10.9.0.0 255.255.255.252<br>172 # Then add this line to ccd/Thelonious:<br>173 #   ifconfig-push 10.9.0.1 10.9.0.2<br>174<br>175 # Suppose that you want to enable different<br>176 # firewall access policies for different groups<br>177 # of clients.  There are two methods:<br>178 # (1) Run multiple OpenVPN daemons, one for each<br>179 #     group, and firewall the TUN/TAP interface<br>180 #     for each group/daemon appropriately.<br>181 # (2) (Advanced) Create a script to dynamically<br>182 #     modify the firewall in response to access<br>183 #     from different clients.  See man<br>184 #     page for more info on learn-address script.<br>185 ;learn-address ./script<br>186<br>187 # If enabled, this directive will configure<br>188 # all clients to redirect their default<br>189 # network gateway through the VPN, causing<br>190 # all IP traffic such as web browsing and<br>191 # and DNS lookups to go through the VPN<br>192 # (The OpenVPN server machine may need to NAT<br>193 # or bridge the TUN/TAP interface to the internet<br>194 # in order for this to work properly).<br>195 push “redirect-gateway def1 bypass-dhcp”<br>196<br>197 # Certain Windows-specific network settings<br>198 # can be pushed to clients, such as DNS<br>199 # or WINS server addresses.  CAVEAT:<br>200 # <a href="http://openvpn.net/faq.html#dhcpcaveats">http://openvpn.net/faq.html#dhcpcaveats</a><br>201 # The addresses below refer to the public<br>202 # DNS servers provided by opendns.com.<br>203 push “dhcp-option DNS 208.67.222.222”<br>204 push “dhcp-option DNS 8.8.8.8”<br>205 ;push “dhcp-option DNS 208.67.220.220”<br>206<br>207 # Uncomment this directive to allow different<br>208 # clients to be able to “see” each other.<br>209 # By default, clients will only see the server.<br>210 # To force clients to only see the server, you<br>211 # will also need to appropriately firewall the<br>212 # server’s TUN/TAP interface.<br>213 ;client-to-client<br>214<br>215 # Uncomment this directive if multiple clients<br>216 # might connect with the same certificate/key<br>217 # files or common names.  This is recommended<br>218 # only for testing purposes.  For production use,<br>219 # each client should have its own certificate/key<br>220 # pair.<br>221 #<br>222 # IF YOU HAVE NOT GENERATED INDIVIDUAL<br>223 # CERTIFICATE/KEY PAIRS FOR EACH CLIENT,<br>224 # EACH HAVING ITS OWN UNIQUE “COMMON NAME”,<br>225 # UNCOMMENT THIS LINE OUT.<br>226 ;duplicate-cn<br>227<br>228 # The keepalive directive causes ping-like<br>229 # messages to be sent back and forth over<br>230 # the link so that each side knows when<br>231 # the other side has gone down.<br>232 # Ping every 10 seconds, assume that remote<br>233 # peer is down if no ping received during<br>234 # a 120 second time period.<br>235 keepalive 10 120<br>236<br>237 # For extra security beyond that provided<br>238 # by SSL/TLS, create an “HMAC firewall”<br>239 # to help block DoS attacks and UDP port flooding.<br>240 #<br>241 # Generate with:<br>242 #   openvpn –genkey –secret ta.key<br>243 #<br>244 # The server and each client must have<br>245 # a copy of this key.<br>246 # The second parameter should be ‘0’<br>247 # on the server and ‘1’ on the clients.<br>248 ;tls-auth ta.key 0 # This file is secret<br>249<br>250 # Select a cryptographic cipher.<br>251 # This config item must be copied to<br>252 # the client config file as well.<br>253 ;cipher BF-CBC        # Blowfish (default)<br>254 ;cipher AES-128-CBC   # AES<br>255 ;cipher DES-EDE3-CBC  # Triple-DES<br>256<br>257 # Enable compression on the VPN link.<br>258 # If you enable it here, you must also<br>259 # enable it in the client config file.<br>260 #压缩数据流<br>261 comp-lzo<br>262<br>263 # The maximum number of concurrently connected<br>264 # clients we want to allow.<br>265 ;max-clients 100<br>266<br>267 # It’s a good idea to reduce the OpenVPN<br>268 # daemon’s privileges after initialization.<br>269 #<br>270 # You can uncomment this out on<br>271 # non-Windows systems.<br>272 ;user nobody<br>273 ;group nogroup<br>274<br>275 # The persist options will try to avoid<br>276 # accessing certain resources on restart<br>277 # that may no longer be accessible because<br>278 # of the privilege downgrade.<br>279 persist-key<br>280 persist-tun<br>281<br>282 # Output a short status file showing<br>283 # current connections, truncated<br>284 # and rewritten every minute.<br>285 status openvpn-status.log<br>286<br>287 # By default, log messages will go to the syslog (or<br>288 # on Windows, if running as a service, they will go to<br>289 # the “\Program Files\OpenVPN\log” directory).<br>290 # Use log or log-append to override this default.<br>291 # “log” will truncate the log file on OpenVPN startup,<br>292 # while “log-append” will append to it.  Use one<br>293 # or the other (but not both).<br>294 ;log         openvpn.log<br>295 ;log-append  openvpn.log<br>296<br>297 # Set the appropriate level of log<br>298 # file verbosity.<br>299 #<br>300 # 0 is silent, except for fatal errors<br>301 # 4 is reasonable for general usage<br>302 # 5 and 6 can help to debug connection problems<br>303 # 9 is extremely verbose<br>304 verb 3<br>305<br>306 # Silence repeating messages.  At most 20<br>307 # sequential messages of the same message<br>308 # category will be output to the log.<br>309 ;mute 20  </p>
<p><strong>服务器端网络设置</strong></p>
<p>因为vpn使用了一个虚拟的私有网段,需要将数据包转发到服务器物理网卡上才可以让客户端正常访问网络，打开/etc/sysctl.conf文件,去掉net.ipv4.ip_forward=1前面的注释变为<br>net.ipv4.ip_forward=1</p>
<p>在/etc/network/if-up.d目录下新建文件iptables,输入以下内容:<br>1 #!/bin/sh<br>2<br>3 iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE  </p>
<p><strong>最后</strong></p>
<p>1 $sudo /etc/init.d/networking restart <br>2 $sudo /etc/init.d/openvpn restart</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian从BIOS启动切换到UEFI启动</title>
    <url>/2015/10/07/debian-switch-boot-from-biso-to-uefi/</url>
    <content><![CDATA[<a id="more"></a>
<p>系统重装了一次，本来Debian installer已经支持UEFI安装了，但是可能是这台机器兼容性的问题，UEFI安装时，字符和图形安装界面都是花屏，根本无法安装。只好设置成legacy模式(BIOS兼容方式)来安装。</p>
<p>安装完后,Debian是使用GRUB-PC来启动的，也就是legacy模式启动的。注意，legacy模式的GRUB是无法引导UEFI启动方式的其他系统的。</p>
<p>当然也可以切换到UEFI启动方式，其原理就是临时以UEFI方式引导Debian,然后安装配置grub-efi,因为只有UEFI方式启动的系统才能更改系统固件(NVRAM)中的UEFI Boot Manager配置。</p>
<p>可以使用live CD/USB来引导系统访问当前的Debian,此时需要chroot来安装配置grub-efi。另一种方法为使用rEFInd来直接引导当前的Debian系统，此时无需chroot。</p>
<p>下面是使用rEFInd引导管理器的操作步骤:</p>
<ul>
<li>  rEFInd USB启动盘制作</li>
</ul>
<p>去<a href="http://www.rodsbooks.com/refind/getting.html">Getting rEFInd</a>页面下载A USB flash drive image file,将下载的zip文件解压后，进入refind-flashdrive-x.x.x文件夹，将img文件写入usb盘</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># dd if=refind-flashdrive-x.x.x.img of=/dev/sdb</span><br></pre></td></tr></table></figure>
<p>注意自己usb闪存的设备名</p>
<ul>
<li>  挂载ESP分区</li>
</ul>
<p>使用rEFInd引导usb盘以UEFI方式引导系统，进入rEFInd界面，选择引导硬盘上的Debian系统。<br>然后，将GPT硬盘上的ESP分区,也就是EFI System Partition挂载到/boot/efi目录下</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount /dev/sda2 /boot/efi</span><br></pre></td></tr></table></figure>
<ul>
<li>  安装grub-efi<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install --reinstall grub-efi</span><br><span class="line"># grub-install /dev/sda</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>grub-install最后会向UEFI Boot Manager写入启动项,而只有UEFI方式启动的系统才能更改系统固件(NVRAM)中的UEFI Boot Manager。</p>
<p>不过，参考[2]介绍了一个trick,legacy启动方式下，将grub的镜像拷贝一份为efi/boot/bootx64.efi，这路径是相对于ESP分区的根。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># cp /boot/efi/efi/debian/grubx64.efi /boot/efi/efi/boot/bootx64.efi</span><br></pre></td></tr></table></figure>
<p>然后重新启动系统会自动以UEFI方式引导Debian系统，然后重新执行grub-insall就可以了。</p>
<p>为什么这样可以呢？据说是因为UEFI Boot Manager如果没有配置指定的efi镜像，会自动寻找efi/boot/bootx64.efi来引导。没有实验到底是否可行，如果本来就存在多系统，这trick也就不太好用了。</p>
<ul>
<li>  重新生成grub配置<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># update-grub</span><br></pre></td></tr></table></figure></li>
<li>  确认安装</li>
</ul>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># file /boot/efi/EFI/debian/grubx64.efi </span><br><span class="line">/boot/efi/EFI/debian/grubx64.efi: PE32+ executable (EFI application) x86-<span class="number">64</span> (stripped to external PDB), <span class="keyword">for</span> MS Windows</span><br></pre></td></tr></table></figure>
<p>bootloader已正确安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># efibootmgr --verbose grep debian</span><br><span class="line">Boot0003* debian HD(<span class="number">2</span>,GPT,80d7a129-<span class="number">458e-4395</span>-a20d-edd18f128d19,<span class="number">0x1f4800</span>,<span class="number">0x82000</span>)/File(\\EFI\\debian\\grubx64.efi)</span><br></pre></td></tr></table></figure>
<p>系统UEFI boot manager固件(NVRAM)中debian引导项已正确创建</p>
<p>去掉rEFInd启动盘，重新启动系统，UEFI中设置debian优先启动即可。</p>
<p>References:<br>[1]<a href="https://wiki.debian.org/GrubEFIReinstall">GrubEFIReinstall</a><br>[2]<a href="http://tanguy.ortolo.eu/blog/article51/debian-efi">Debian: switch to UEFI boot</a><br>[3]</p>
<p><strong>==<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Untitled Post - 105</title>
    <url>/2015/04/06/6283/</url>
    <content><![CDATA[<p>ext4文件系统的时间戳精度达到了nanosecond,而之前的ext2和ext3文件系统的时间戳精度只有second。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>debian tesing安装cassandra</title>
    <url>/2013/11/24/debian-tesing-install-cassandra/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>添加cassandra源</strong></p>
<p>新建source list文件/etc/apt/source.list.d/cassandra.list,在其中添加cassandra源</p>
<p>[javascript]<br>deb <a href="http://www.apache.org/dist/cassandra/debian">http://www.apache.org/dist/cassandra/debian</a> 20x main<br>deb-src <a href="http://www.apache.org/dist/cassandra/debian">http://www.apache.org/dist/cassandra/debian</a> 20x main<br>[/javascript]</p>
<p>20x表示使用2.0.x系列版本，20x目前是最新的,可选12x,11x等。</p>
<p><strong>添加源的public key</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gpg --keyserver pgp.mit.edu --recv-keys F758CE318D77295D</span><br><span class="line">$ gpg --<span class="keyword">export</span> --armor F758CE318D77295D sudo apt-key add -</span><br><span class="line">$ gpg --keyserver pgp.mit.edu --recv-keys 2B5C1B00</span><br><span class="line">$ gpg --<span class="keyword">export</span> --armor 2B5C1B00 sudo apt-key add -</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">gpg: requesting key 8D77295D <span class="keyword">from</span> hkp server pgp.mit.edu</span><br><span class="line">gpg: key 8D77295D: public key <span class="string">&quot;Eric Evans &quot;</span> imported</span><br><span class="line">gpg: no ultimately trusted keys found</span><br><span class="line">gpg: Total number processed: <span class="number">1</span></span><br><span class="line">gpg: imported: <span class="number">1</span> (RSA: <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">gpg: requesting key 2B5C1B00 <span class="keyword">from</span> hkp server pgp.mit.edu</span><br><span class="line">gpg: key 2B5C1B00: public key <span class="string">&quot;Sylvain Lebresne (pcmanus) &quot;</span> imported</span><br><span class="line">gpg: Total number processed: <span class="number">1</span></span><br><span class="line">gpg: imported: <span class="number">1</span> (RSA: <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>安装cassandra</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get update</span><br><span class="line"># apt-get install cassandra</span><br></pre></td></tr></table></figure>

<p><strong>update(06/21/2019)</strong></p>
<p>当前最新的release版本系列为311x，当前还在支持的release版本系列还有30x, 22x, or 21x<br>22x的最新版本为2.2.14，下面以安装2.2.14为例：</p>
<p>添加源</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ echo <span class="string">&quot;deb http://www.apache.org/dist/cassandra/debian 22x main&quot;</span> sudo tee -a /etc/apt/sources.list.d/cassandra.sources.list</span><br></pre></td></tr></table></figure>

<p>添加仓库公钥key</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ curl https:<span class="comment">//www.apache.org/dist/cassandra/KEYS sudo apt-key add -</span></span><br></pre></td></tr></table></figure>

<p>安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt update</span><br><span class="line"></span><br><span class="line">$ apt-cache show cassandra</span><br><span class="line"></span><br><span class="line">Package: cassandra</span><br><span class="line">Version: <span class="number">2.2</span><span class="number">.14</span></span><br><span class="line">Architecture: all</span><br><span class="line">Maintainer: Eric Evans &lt;eevans@apache.org&gt;</span><br><span class="line">Installed-Size: <span class="number">32142</span></span><br><span class="line">Depends: openjdk-<span class="number">7</span>-jre-headless java7-runtime, adduser, python (&gt;= <span class="number">2.7</span>)</span><br><span class="line">Recommends: ntp time-daemon</span><br><span class="line">Suggests: cassandra-tools</span><br><span class="line">Conflicts: apache-cassandra1</span><br><span class="line">Replaces: apache-cassandra1</span><br><span class="line">Homepage: http:<span class="comment">//cassandra.apache.org</span></span><br><span class="line">Priority: extra</span><br><span class="line">Section: misc</span><br><span class="line">Filename: pool/main/c/cassandra/cassandra_2<span class="number">.2</span>.14_all.deb</span><br><span class="line">Size: <span class="number">24139668</span></span><br><span class="line">SHA256: 17cbe0fffe313eb066f4b446cc23883fa82f96e42e076f82389c7f0c8e1d7ac3</span><br><span class="line">SHA1: 2636dd7a5eb5f02572f42e09cf85c2dc01842484</span><br><span class="line">MD5sum: e0ad56afe1b5c428bb296312cef6b73a</span><br><span class="line">Description: distributed storage system <span class="keyword">for</span> structured data</span><br><span class="line"> Cassandra is a distributed (peer-to-peer) system <span class="keyword">for</span> the management</span><br><span class="line"> and storage <span class="keyword">of</span> structured data.</span><br><span class="line">Description-md5: 449c17857a17bf5afa4d96fab0cc89e5</span><br><span class="line"></span><br><span class="line">$ sudo apt install cassandra</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://cassandra.apache.org/download/">Downloading Cassandra</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>debian testing amd64安装firefox 5</title>
    <url>/2011/07/03/debian-testing-amd64-install-firefox5/</url>
    <content><![CDATA[<p>debian官方是没有firefox的，只有iceweasel,这是因为debian的洁癖,但这也正是debian的独特之处</p>
<a id="more"></a>
<p>现在firefox玩起了版本号游戏,分发版很难跟上其步伐，特别是像debian这么严谨的分发版,所以要用最近的firefox就只能自己动手，丰衣足食了。</p>
<p>首先下载官方<a href="ftp://ftp.mozilla.org/pub/firefox/releases/5.0/linux-x86_64/en-US/firefox-5.0.tar.bz2">firefox 5 amd64 build</a>，下载后，执行如下指令</p>
<p>$sudo tar jxvf firefox-5.0.tar.bz2 -C /opt/firefox</p>
<p>这样安装就算完成了,firefox的可执行文件为/opt/firefox/firefox,建立一个快捷方式指向此命令就可以方便的使用firefox 5了。squeeze上也是一样的安装方法。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>debian testing基本系统安装无声音问题解决</title>
    <url>/2011/11/20/debian-testing-base-system-sound/</url>
    <content><![CDATA[<p>使用debian testing netinst只安装基本系统，安装完毕后声卡没有声音</p>
<a id="more"></a>
<p><strong>首先检查系统声卡驱动</strong></p>
<p>#lspci grep Audio<br>00:1b.0 Audio device: Intel Corporation 82801I (ICH9 Family) HD Audio Controller (rev 03)</p>
<p>说明系统已经识别出了声卡</p>
<p>#lsmod grep snd<br>snd_hda_codec_conexant 45375 1<br>snd_hda_intel 26140 0<br>snd_hda_codec 72699 2 snd_hda_codec_conexant,snd_hda_intel<br>snd_hwdep 13186 1 snd_hda_codec<br>snd_seq 45208 0<br>snd_pcm 68104 2 snd_hda_intel,snd_hda_codec<br>snd_timer 22581 2 snd_seq,snd_pcm<br>snd_page_alloc 13043 2 snd_hda_intel,snd_pcm<br>snd_seq_device 13137 1 snd_seq<br>snd 52823 9 snd_hda_codec_conexant,snd_hda_intel,thinkpad_acpi,snd_hda_codec,snd_hwdep,snd_seq,snd_pcm,snd_timer,snd_seq_device<br>soundcore 13152 1 snd</p>
<p>系统也加载了相应的内核模块</p>
<p><strong>然后检查系统音量</strong></p>
<p>#alsamixer<br>声卡各通道音量正常</p>
<p><strong>最后尝试初始化声卡</strong></p>
<p>alsaconf命令已经被剔除，所以要用alsactl命令来配置声卡</p>
<p>#alsactl init</p>
<p>Found hardware: “HDA-Intel” “Conexant CX20561 (Hermosa)” “HDA:14f15051,17aa211c,00100000 HDA:14f12c06,17aa2122,00100000” “0x17aa” “0x20f2”<br>Hardware is initialized using a generic method</p>
<p>问题解决，看来主要问题在于基本系统没有初始化声卡，需要手工初始化一下。</p>
<p>还可以用alsa-utils来控制声卡的关闭，启动，重启动，reset等<br>#/etc/init.d/alsa-utils start[card] stop [card] restart [card] reset [card]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian testing桌面安装手记</title>
    <url>/2011/06/24/debian-testing-desktop-install/</url>
    <content><![CDATA[<p>Ubuntu越来越蛋疼,用的越来越不爽,还是用回debian吧,其实testing做桌面也是很爽的</p>
<a id="more"></a>
<p>刚好办公室新换电脑,带的OEM的windows 7 home basic 32bits,只启动了一次就惨遭毒手,换成了debian testing单系统。</p>
<p>下载<a href="http://cdimage.debian.org/cdimage/daily-builds/daily/arch-latest/amd64/iso-cd/debian-testing-amd64-netinst.iso">debian testing netinst iso amd64 daily build</a>或<a href="http://cdimage.debian.org/cdimage/weekly-builds/amd64/iso-cd/debian-testing-amd64-CD-1.iso">debian testing iso amd64 cd1 weekly build</a>,当然首选netinst。</p>
<p>使用netinst安装基本系统。1T硬盘,分三个主分区,/dev/sda1分配给根文件系统/,/dev/sda2分配给home文件系统/home,/dev/sda3分配给swap分区,因为有4G内存,所以swap分了8G,其余都给了home。一步步按提示安装即可。只是现在的testing有点儿问题,grub-pc会安装失败,解决方法见<a href="https://openwares.net/linux/debian_grub_install_fail.html">debian testing grub-pc安装失败解决方法</a></p>
<p>安装完基本系统后,安装AMD显卡官方驱动,开源驱动3D性能还是差了不少,这里选择安装debian打包好的驱动,当然也可以去AMD官方下载驱动安装。</p>
<p>安装方法如下:</p>
<p>1、为/etc/apt/source.list增加non-free安装源<br>deb <a href="http://ftp.debian.org/debian">http://ftp.debian.org/debian</a> testing main contrib non-free<br>更新源<br>#apt-get update</p>
<p>2、安装内核对应的linux-header包及驱动包<br>#apt-get install linux-headers-2.6-$(uname -r) fglrx-control fglrx-driver</p>
<p>3、卸载radeon和drm模块<br>#modprobe -r radeon drm</p>
<p>4、配置驱动<br>#aticonfig –initial </p>
<p>最后安装xorg,gnome和gdm<br>#apt-get install xserver-xorg-core gnome-core gdm3</p>
<p>这样就安装好了基本的gnome桌面,本来想用fvwm做桌面,折腾了两天后发现这玩意儿一时半会儿上不了手,以后有时间再搞吧。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>non-free firmware</title>
    <url>/2014/01/08/debian-testing-netinst-iso-add-non-free-firmware/</url>
    <content><![CDATA[<p>使用Debian,拥抱自由!</p>
<a id="more"></a>
<p>Debian是真正完全自由的linux发行版,甚至因为mozilla firefox的商标原因,而修改firefox的标识为iceweasel再集成到debian中。<br>对于一些非自由的firmware和软件,Debian采用了隔离的策略,将他们放入non-free源,由用户来决定是不是使用这些非自由的BLOB。</p>
<p>一直喜欢使用netinst iso来安装debian,但有时候也会有麻烦,主要就是non-free的firmware。安装桌面的时候如果使用intel的wifi网络适配器,那么有很大几率要使用non-free的firmware-iwlwifi。如果安装服务器,那么QLogic的卡子多半又会使用non-free的firmware-qlogic。那么安装的时候还需要再提供这些non-free的firmware才能正确的安装设备。</p>
<p>有一个脚本<a href="https://github.com/YunoHost/cd_build/blob/master/add-firmware-to">add-firmware-to</a>可以向debian官方的iso文件内添加non-free的firmware包。其内部自动下载发行版对应的firmware包,然后使用genisoimage重新打包生成iso。</p>
<p>其用法为:</p>
<h1 id="add-firmware-to-sh"><a href="#add-firmware-to-sh" class="headerlink" title="./add-firmware-to.sh"></a>./add-firmware-to.sh</h1><p>比如这样:</p>
<h1 id="add-firmware-to-sh-netinst-iso-firmware-netinst-iso-squeeze"><a href="#add-firmware-to-sh-netinst-iso-firmware-netinst-iso-squeeze" class="headerlink" title="./add-firmware-to.sh netinst.iso firmware-netinst.iso squeeze"></a>./add-firmware-to.sh netinst.iso firmware-netinst.iso squeeze</h1><p>从源代码看这个脚本只支持发行版lenny和squeeze</p>
<p>其实官方网站已经有unoffice集成firmware的<a href="http://cdimage.debian.org/cdimage/unofficial/non-free/cd-including-firmware/weekly-builds/amd64/iso-cd/">firmware-testing-amd64-netinst.iso</a>可以下载了,所以不用大费周章,直接使用这个版本就得了。</p>
<p><a href="http://cdimage.debian.org/cdimage/unofficial/non-free/cd-including-firmware/">Unofficial non-free CDs including firmware packages</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian testing 编译gcc 4</title>
    <url>/2017/03/06/debian-testing-%E7%BC%96%E8%AF%91gcc-4/</url>
    <content><![CDATA[<p>编译QCAD需要gcc 4,而当前debian系统的gcc版本为6.3.0，因此需要编译gcc 4。</p>
<a id="more"></a>
<p><strong>获取源代码</strong><br>可以从官方svn或者git镜像检出gcc 4分支的最新代码4.9.4</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ svn co svn:<span class="comment">//gcc.gnu.org/svn/gcc/tags/gcc_4_9_4_release gcc</span></span><br><span class="line">$ git clone git:<span class="comment">//gcc.gnu.org/git/gcc.git --branch gcc-4_9_4-release</span></span><br></pre></td></tr></table></figure>

<p>或者从<a href="https://gcc.gnu.org/mirrors.html">官方镜像</a>直接下载打包好的源码包。</p>
<p><strong>安装依赖</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install libgmp-dev libmpfr-dev libmpc-dev</span><br></pre></td></tr></table></figure>
<p>或者进入解压后的源代码目录下执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./contrib/download_prerequisites</span><br></pre></td></tr></table></figure>
<p>会自动下载并部署依赖</p>
<p><strong>配置、编译和安装</strong></p>
<p>新建一个目标文件目录比如叫dest,然后配置源代码</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mkdir dest</span><br><span class="line">$ cd dest</span><br><span class="line">$ ../gcc-<span class="number">4.9</span><span class="number">.4</span>/configure --prefix=$HOME/gcc_4 --enable-languages=c,c++ --disable-multilib</span><br></pre></td></tr></table></figure>

<p>安装目录设定为用户主目录下的gcc_4，不需要支持32位架构。</p>
<p>最后编译、安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ make</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure>

<p>如果有提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">checking LIBRARY_PATH variable... contains current directory</span><br><span class="line">configure: error: </span><br><span class="line">*** LIBRARY_PATH shouldn<span class="string">&#x27;t contain the current directory when</span></span><br><span class="line"><span class="string">*** building gcc. Please change the environment variable</span></span><br><span class="line"><span class="string">*** and run configure again.</span></span><br></pre></td></tr></table></figure>
<p>只要</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ unset LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>就可以了</p>
<p>References:<br>[1]<a href="https://gcc.gnu.org/wiki/InstallingGCC">InstallingGCC</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian配置时间同步服务器和客户端</title>
    <url>/2015/05/16/debian-time-server-setting/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>服务器</strong></p>
<p>安装</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install ntp</span><br></pre></td></tr></table></figure>

<p>时间服务器的同步信息</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ntpq -p</span><br></pre></td></tr></table></figure>

<p>时间服务器溯源</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ntptrace -n</span><br></pre></td></tr></table></figure>

<p><strong>客户端</strong></p>
<p>安装</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install ntpdate</span><br></pre></td></tr></table></figure>

<p>手动同步</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ntpdate your_time_server_ip</span><br><span class="line"><span class="number">16</span> May <span class="number">13</span>:<span class="number">53</span>:<span class="number">44</span> ntpdate\[<span class="number">14151</span>\]: adjust time server <span class="number">192.168</span><span class="number">.6</span><span class="number">.12</span> offset <span class="number">0.058389</span> sec</span><br></pre></td></tr></table></figure>

<p>参数-d打开debug模式,会输出与时间服务器的交互信息。如果服务器确实运行了,但客户端无法同步时间,且有类似输出:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ntpdate -d 192.168.1.1</span><br><span class="line"><span class="number">16</span> May <span class="number">13</span>:<span class="number">56</span>:<span class="number">13</span> ntpdate\[<span class="number">14195</span>\]: ntpdate <span class="number">4.2</span>.6p5@<span class="number">1.2349</span>-o Fri Apr <span class="number">10</span> <span class="number">19</span>:<span class="number">04</span>:<span class="number">04</span> UTC <span class="number">2015</span> (<span class="number">1</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>)</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>: Server dropped: no data</span><br><span class="line">server <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>, port <span class="number">123</span></span><br><span class="line">stratum <span class="number">0</span>, precision <span class="number">0</span>, leap <span class="number">00</span>, trust <span class="number">000</span></span><br><span class="line">refid \[<span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span>\], delay <span class="number">0.00000</span>, dispersion <span class="number">64.00000</span></span><br><span class="line">transmitted <span class="number">4</span>, <span class="keyword">in</span> filter <span class="number">4</span></span><br><span class="line">reference time: <span class="number">00000000</span><span class="number">.00000000</span> Mon, Jan <span class="number">1</span> <span class="number">1900</span> <span class="number">8</span>:<span class="number">05</span>:<span class="number">43.000</span></span><br><span class="line">originate timestamp: <span class="number">00000000</span><span class="number">.00000000</span> Mon, Jan <span class="number">1</span> <span class="number">1900</span> <span class="number">8</span>:<span class="number">05</span>:<span class="number">43.000</span></span><br><span class="line">transmit timestamp: d9015a83.e61c3641 Sat, May <span class="number">16</span> <span class="number">2015</span> <span class="number">13</span>:<span class="number">56</span>:<span class="number">19.898</span></span><br><span class="line">filter delay: <span class="number">0.00000</span> <span class="number">0.00000</span> <span class="number">0.00000</span> <span class="number">0.00000</span> </span><br><span class="line"> <span class="number">0.00000</span> <span class="number">0.00000</span> <span class="number">0.00000</span> <span class="number">0.00000</span> </span><br><span class="line">filter offset: <span class="number">0.000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line"> <span class="number">0.000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">delay <span class="number">0.00000</span>, dispersion <span class="number">64.00000</span></span><br><span class="line">offset <span class="number">0.000000</span></span><br><span class="line"></span><br><span class="line"><span class="number">16</span> May <span class="number">13</span>:<span class="number">56</span>:<span class="number">21</span> ntpdate\[<span class="number">14195</span>\]: no server suitable <span class="keyword">for</span> synchronization found</span><br></pre></td></tr></table></figure>
<p>多半是因为防火墙阻止了时间服务器的UDP端口123。</p>
<p>自动同步</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># crontab -e</span><br></pre></td></tr></table></figure>
<p>在打开的用户crontab文件最后输入：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># m h dom mon dow command</span><br><span class="line"><span class="number">0</span> * * * * ntpdate your_time_server_ip</span><br></pre></td></tr></table></figure>
<p>这样一个小时会自动进行一次时间同步。</p>
<p>cron的运行日志见/var/log/syslog。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian 时区与时间设定</title>
    <url>/2011/06/28/debian-timezone-datetime/</url>
    <content><![CDATA[<p>硬件时间,UTC时间,时区timezone和本地时间这几者还真容易让人头晕,所以还是写一下以备忘吧</p>
<a id="more"></a>
<p><strong>时区</strong></p>
<p>我们是东八区,正确的时区设置应该是Asia/Shanghai,可以用命令</p>
<p>$sudo dpkg-reconfigure tzdata</p>
<p>来设定正确的时区,先选择asia,再选择shanghai,时区配置会写入到/etc/timezone文件中</p>
<p><strong>硬件时间与系统配置</strong></p>
<p>不间断的时间信息是由BIOS来保持的,这就是硬件时间。系统会读取BIOS时间,再根据时区设置以及UTC设置来计算本地时间。</p>
<p>文件/etc/default/rcS中有一行UTC=yesno来决定BIOS中存储的是UTC时间还是本地时间,如果UTC=yes，那么系统会读取BIOS时间然后加上时区时差来得到本地时间,东八区就是BIOS时间加8。如果UTC=no,那么系统直接把BIOS时间当作本地时间。</p>
<p>一般BIOS里面设置的都是本地时间,而/etc/default/rcS中的UTC默认也是yes,所以设置了正确的时区后,会发现系统本地时间快了8个小时，就是这个原因。</p>
<p>所以在时区设置正确的前提下，一般就有两种正确的设置:</p>
<p>BIOS时间为本地时间,UTC=no<br>BIOS时间为UTC时间,UTC=yes</p>
<p><strong>时间显示</strong></p>
<p>$date #显示本地时间<br>$date -u #显示UTC时间</p>
<p><strong>校时</strong></p>
<p>硬件时间会有误差,服务器系统一般要保持精确的时间,可以安装ntp或ntpdate来自动与时间服务器联系校准时间,推荐使用ntp来校时。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian使用dvd iso镜像配置本地源</title>
    <url>/2020/05/19/debian-use-dvd-iso-set-apt-source/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为某云在某个网络内没有debian安装源，所以只能使用本地源。<br>debian支持的软件包很多，amd64架构的dvd iso竟然有16张之多，bd格式iso则只有4张，这里使用dvd格式的iso。</p>
<p>首先，下载debian 10.1.0 amd64架构的dvd iso，<a href="https://cdimage.debian.org/cdimage/archive/10.1.0/amd64/iso-dvd/">http方式只能下载前三个iso</a>,下载其他iso需要使用jigdo方式即时下载在线制作iso文件。</p>
<p>debian系统安装jigdo-file使用jigdo-lite命令，输入iso的jigdo文件url即可下载制作iso镜像。debian 10.1.0 dvd iso的<a href="https://cdimage.debian.org/cdimage/archive/10.1.0/amd64/jigdo-dvd/">jigdo下载地址在此</a>。<br>因为需要安装的包postgresql-11-postgis-2.5不在前三张dvd，所以使用jigdo下载了第四张dvd镜像。</p>
<p>然后，将四张dvd iso分别挂载到/media目录的挂载点:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount /path/to/debian-10.1.0-amd64-DVD-1.iso /media/cdrom1/</span><br><span class="line"># mount /path/to/debian-10.1.0-amd64-DVD-2.iso /media/cdrom2/</span><br><span class="line"># mount /path/to/debian-10.1.0-amd64-DVD-3.iso /media/cdrom3/</span><br><span class="line"># mount /path/to/debian-10.1.0-amd64-DVD-4.iso /media/cdrom4/</span><br></pre></td></tr></table></figure>
<p>也可以添加到/etc/fstab:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/srv/debsrcs/debian-<span class="number">10.1</span><span class="number">.0</span>-amd64-DVD-<span class="number">1.</span>iso/media/cdrom1udf,iso9660 loop <span class="number">0</span> <span class="number">0</span></span><br><span class="line">/srv/debsrcs/debian-<span class="number">10.1</span><span class="number">.0</span>-amd64-DVD-<span class="number">2.</span>iso/media/cdrom2udf,iso9660 loop <span class="number">0</span> <span class="number">0</span></span><br><span class="line">/srv/debsrcs/debian-<span class="number">10.1</span><span class="number">.0</span>-amd64-DVD-<span class="number">3.</span>iso/media/cdrom3udf,iso9660 loop <span class="number">0</span> <span class="number">0</span></span><br><span class="line">/srv/debsrcs/debian-<span class="number">10.1</span><span class="number">.0</span>-amd64-DVD-<span class="number">4.</span>iso/media/cdrom4udf,iso9660 loop <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>然后</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount -a</span><br></pre></td></tr></table></figure>
<p>编辑/etc/apt/sources.list文件，添加如下行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb \[ trusted=yes \] file:<span class="regexp">/media/</span>cdrom1/ buster main contrib </span><br><span class="line">deb \[ trusted=yes \] file:<span class="regexp">/media/</span>cdrom2/ buster main contrib </span><br><span class="line">deb \[ trusted=yes \] file:<span class="regexp">/media/</span>cdrom3/ buster main contrib </span><br><span class="line">deb \[ trusted=yes \] file:<span class="regexp">/media/</span>cdrom4/ buster main contrib </span><br></pre></td></tr></table></figure>

<p>最后，apt update后正常安装软件即可，如果要安装的软件还是找不到，可能需要下载更多的dvd iso镜像。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>设计模式乱弹</title>
    <url>/2013/12/13/design-patterns/</url>
    <content><![CDATA[<a id="more"></a>
<h3 id="概括总结"><a href="#概括总结" class="headerlink" title="概括总结"></a>概括总结</h3><p>设计模式千变万化，但万变不离其宗</p>
<p>设计模式可以使用以下几个简单的词汇进行总结:</p>
<ul>
<li><p><strong>间接(indirection)</strong></p>
<p>  通过引入间接层来解耦。</p>
</li>
<li><p>  **高内聚(cohesion)，低耦合(decoupling)**。</p>
</li>
<li><p><strong>隔离变化</strong></p>
<p>  将变化的部分和不变的部分隔离开来，使经常变化的部分发生变化时，不变的部分不受影响。 这叫做”以不变应万变”。</p>
</li>
</ul>
<h3 id="基本原则"><a href="#基本原则" class="headerlink" title="基本原则"></a>基本原则</h3><p>软件设计实践中有几个比较重要的原则,是各种设计模式的指导性原则。简述如下:</p>
<ul>
<li><p><strong>开闭原则(Open Closed Principle,OCP)</strong></p>
<p>  开闭原则认为一个软件实体应当对扩展开放，而对修改关闭。在设计一个模块时，应使这个模块在未来不修改的前提下扩展其功能。 也就是可以在不修改源代码的情况下，改变这个模块的行为。 遵循OCP原则,可以通过扩展已有软件系统，提供新的行为，以满足对软件的新的需求，使变化中的软件有一定的适应性和灵活性。 已有软件模块，特别是最重要的抽象层模块不能再修改，这使变化中的软件系统有一定的稳定性和延续性。</p>
</li>
<li><p><strong>接口隔离原则(Interface Segregation Principle,ISP)</strong></p>
<p>  客户不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。使用多个专门的接口比使用单一的总接口总要好。 过于臃肿的接口是对接口的污染，不应该强迫客户依赖于它们用不到的方法。</p>
</li>
<li><p><strong>里氏替换原则(Liskov Substitution Principle,LSP)</strong></p>
<p>  子类型(subtype)必须能够替换他们的基类型,也就是，所有父类可以出现的地方，子类也必须可以出现。</p>
</li>
<li><p><strong>依赖倒置原则(Dependency Inversion Principle,DIP)</strong></p>
<p>  DIP的两大原则：</p>
<ol>
<li><p> 高层模块不应该依赖于低层模块,二者都应该依赖于抽象。</p>
</li>
<li><p>抽象不应该依赖于细节,细节应该依赖于抽象。</p>
<p>具体来讲，依赖倒置的核心思想是针对接口而不是实现编程。 应用DIP可以降低模块之间的耦合度，只要接口保持稳定，模块可以独立演化而互不影响。</p>
</li>
</ol>
</li>
<li><p><strong>单一职责原则(Single Responsibility Principle,SRP)</strong></p>
<p>  There should never be more than one reason for a class to change。 一个类应该只有一个引起它变化的原因。一个类应该只有一个职责。如果类有一个以上的职责，这些职责就耦合在了一起。这会导致脆弱的设计。 当一个职责发生变化时，可能会影响其它的职责。另外，多个职责耦合在一起，会影响复用性。</p>
</li>
<li><p><strong>迪米特法则(Law of Demeter,LoD）或者叫最少知识原则(Least Knowledge Principle,LKP)</strong></p>
<p>  一个对象应该尽可能少的了解其他对象。类之间的关系越密切，耦合度越大，当其中一个发生变化时，必定会对另一个产生影响， 应该把这种影响降到最低。</p>
</li>
<li><p><strong>组合/聚合复用原则(Composite/Aggregate Reuse Principle,CARP)</strong></p>
<p>  优先使用合成/聚合而不是继承。</p>
<p>  继承作为面向对象三大特性之一，在给程序设计带来巨大便利的同时，也带来了弊端。 比如使用继承会给程序带来侵入性，程序的可移植性降低，增加了对象间的耦合性， 如果一个类被其他的类所继承，则当这个类需要修改时，必须考虑到所有的子类， 并且父类修改后，所有涉及到子类的功能都有可能会产生故障。</p>
<p>  <em>合成/聚合复用</em></p>
<p>  优点： 新对象存取成分对象的唯一方法是通过成分对象的接口； 这种复用是黑箱复用，因为成分对象的内部细节是新对象所看不见的； 这种复用支持包装； 这种复用所需的依赖较少； 每一个新的类可以将焦点集中在一个任务上； 这种复用可以在运行时动态进行，新对象可以使用合成/聚合关系将新的责任委派到合适的对象。</p>
<p>  缺点： 通过这种方式复用建造的系统会有较多的对象需要管理。</p>
<p>  <em>继承复用</em></p>
<p>  优点： 新的实现较为容易，因为基类的大部分功能可以通过继承关系自动进入派生类； 修改或扩展继承而来的实现较为容易。</p>
<p>  缺点： 继承复用破坏包装，因为继承将基类的实现细节暴露给派生类，这种复用也称为白箱复用； 如果基类的实现发生改变，那么派生类的实现也不得不发生改变； 从基类继承而来的实现是静态的，不可能在运行时发生改变，不够灵活。</p>
</li>
<li><p><strong>机制与策略分离原则</strong></p>
<p>  机制是要做什么,而策略是要怎么做。或者说,”<a href="http://www.zeuux.com/blog/content/1729/">机制是需要提供什么功能,而策略则是怎样实现这些功能</a>”。更简单明了一些,接口就是机制，而实现则是策略。</p>
<p>  机制与策略分离是UNIX的一大设计哲学,也是UNIX设计的如此灵活的重要基石。</p>
<p>  本质上,机制与策略分离原则仍然讲的是将不变的和经常变化的部分进行隔离的原则。机制是稳定不变的,而策略通常可以是千变万化的。</p>
</li>
<li><p>  <strong>DRY原则</strong></p>
</li>
</ul>
<p>Don’t repeat yourself!</p>
<ul>
<li>  <strong>Less is more</strong></li>
</ul>
<h3 id="延伸"><a href="#延伸" class="headerlink" title="延伸"></a>延伸</h3><p>GoF(Gang of Four)的Design Pattern列举了23种经典设计模式,除此之外,还有其他许许多多的设计模式。设计模式无论如何变化，纷繁复杂，其本质仍然符合上面的概括和列举的设计原则。 理解了设计模式的本质，才不会被各种设计模式晃花了眼睛。</p>
<p>注:这一篇post是用markdown写，使用pandoc转换为html，然后贴过来的。markdown果然好用。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>debian下使sqlplus具有命令历史回溯和命令行编辑功能</title>
    <url>/2011/10/30/debian%E4%B8%8B%E4%BD%BFsqlplus%E5%85%B7%E6%9C%89%E5%91%BD%E4%BB%A4%E5%8E%86%E5%8F%B2%E5%9B%9E%E6%BA%AF%E5%92%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%BE%91%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<p>sqlplus默认是很难用的，无法调出历史命令，无法编辑命令行，无法使用自动完成。有一点点儿问题就要重新输入，太不爽了</p>
<a id="more"></a>
<p>借助于rlwrap这个对readline的包装程序，sqlplus可以获得完整的像bash一样的命令行特性，用起来就方便多了。</p>
<p><strong>安装rlwrap</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#apt-get install rlwrap</span><br></pre></td></tr></table></figure>
<p><strong>为sqlplus设置别名</strong></p>
<p>~/.bashrc文件添加alias</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias sqlplus=<span class="string">&#x27;rlwrap sqlplus&#x27;</span></span><br></pre></td></tr></table></figure>
<p><strong>最后</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ source .bashrc</span><br></pre></td></tr></table></figure>
<p>现在的sqlplus就好用多了,在此基础上应该也可以添加命令行自动完成功能,有时间研究一下。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>检测浏览器对HTML5新input类型的支持</title>
    <url>/2014/07/17/detect-new-input-type/</url>
    <content><![CDATA[<a id="more"></a>
<p>HTML5新增加了很多input元素类型,比如color,date,datetime,datetime-local,email,month,number,range,search,tel,time,url,week等。</p>
<p>通过以下方法可以检测浏览器是否支持这些新的input类型:</p>
<p>[html]<br>var i = document.createElement(‘input’);<br>i.setAttribute(‘type’, ‘date’);<br>//浏览器不支持date类型<br>if(i.type == ‘text’){<br>}<br>[/html]<br>这里为新添加的input元素设置type特性(attribute)为date,如果浏览器支持date类型,则其对应的dom对象的type属性(property)会设置为date,否则会设置为text,这里一定要注意”特性(attribute)”和”属性(property)”的区别。attribute是标签的特性,而property是标签对应的DOM对象的属性。</p>
<p>所以，即使浏览器不支持新的input类型,虽然其DOM对象的type属性被设置为text,但其标签的type特性仍然是原来设置的值，对上面这个栗子来说就是date</p>
<p>[html]<br>i.getAttribute(‘type’) == ‘date’; //true<br>[/html]</p>
<p>特性与属性的区别见”<a href="https://openwares.net/linux/dom_property_element_attribute.html">DOM对象属性(property)与HTML标签特性(attribute)</a>“</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>软件开发文档管理</title>
    <url>/2013/12/10/dev-docs/</url>
    <content><![CDATA[<p>软件开发文档是软件质量保证的重要一环，所有软件开发文档都应该纳入版本管理之中。</p>
<a id="more"></a>
<p>这里分为两类文档来讨论，一种是与源代码一起书写的文档，另一种是单独撰写的文档。</p>
<p><strong>代码中的注释和API(接口)文档</strong></p>
<p>这种类型的文档一般语言层面上都有专门的文档生成工具，比如java有javadoc,javascript有jsdoc,python也有自己的文档注释标准和文档生成工具。只要按照语言的注释文档规范书写文档即可。</p>
<p>数据库设计文档也应该从sql建库脚本中自动生成,只要自定义一些注释标签，然后使用工具自动生成即可。已经在使用自定义的标签书写sql建库脚本，下一步会开发sqldoc工具来自动生成数据库设计文档。</p>
<p>还有大名鼎鼎的文档生成工具<a href="http://www.doxygen.org/">Doxygen</a>，可以处理绝大多数语言的注释文档。</p>
<p>注释文档的好处是比较容易同步，修改代码时可以比较方便的同步修改文档。而且文档与代码一起纳入版本库管理。</p>
<p><strong>单独撰写的文档</strong></p>
<p>单独撰写的文档也有很多，比如用户需求规格说明书，系统概要设计，系统详细设计，用户使用手册，测试文档等。这些也应该纳入版本库统一管理。</p>
<p>这些文档最好不要使用专有的文档格式撰写，而且要采用文本格式，而不是二进制格式，方便进行版本管理。</p>
<p>LaTeX是很专业的排版软件，可以用于撰写软件开发文档，但显然有些过于重量级了，比较复杂，有学习曲线，而且有大材小用之嫌。而Markdown则语法简单，功能不弱，适合开发文档的撰写，而且很容易纳入git版本库进行管理。</p>
<p>Mac下有一个很不错的Markdown编辑软件叫做<a href="http://mouapp.com/">Mou</a>。<br>vim也可以找到很多的Markdown语法高亮和<a href="http://howiefh.github.io/2013/05/16/vim-markdown-preview/">实时预览</a>插件。<br>还有一个好玩的基于git仓库的使用Markdown语法的wiki系统<a href="http://gitit.net/">gitit</a>。</p>
<p>使用Markdown撰写的文档，后期可以通过<a href="http://johnmacfarlane.net/pandoc/">pandoc</a>输出到其他多种交换格式，比如html5,LaTex，PDF(via LaTeX)等。<br>Markdown语法十分简单，五分钟入门够了。语法可以看<a href="http://jianshu.io/p/q81RER">献给写作者的 Markdown 新手指南</a>，<a href="http://zh.wikipedia.org/wiki/Markdown">Markdown</a>,<a href="http://markdown.tw/">Markdown语法说明</a>和<a href="http://wowubuntu.com/markdown/">Markdown 语法说明 (简体中文版)</a> 。<br>这里还有两篇Markdown和LaTeX结合的文章，<a href="http://blog.yesmryang.net/markdown-latex/">用markdown来写LaTeX</a>和<a href="http://jianshu.io/p/PpDNMG">Markdown写作浅谈</a></p>
<p>Markdown的<a href="http://daringfireball.net/projects/markdown/">老家</a>。</p>
<p><strong>详细设计文档与注释(API/接口)文档</strong></p>
<p>详细设计文档撰写应该早于编码进行，是编码的指导性文件。</p>
<p>详细设计文档提供模块设计上的考虑、核心决策，包括模块与概要(总体)设计的关系、重要操作的处理流程、重要的业务规则设计、采用的核心算法等等信息，提供了对模块设计的概述性信息。详细设计宜使用一些图表来更直观的表达设计意图。</p>
<p>详细设计文档也不要过细，一些十分细节的设计问题应该放到代码文档注释中。详细设计文档的粒度应该介于概要(总体)设计和文档注释之间。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>DHCP Option 60 选项</title>
    <url>/2013/12/21/dhcp-option-60/</url>
    <content><![CDATA[<p><a href="http://www.ietf.org/rfc/rfc3925.txt">Option 60</a>选项作用于DHCP客户端可选地向DHCP服务器报告客户端厂商类型和配置。而DHCP服务器如果向DHCP客户端返回制造商相关信息必须使用Option 43。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>diff和patch</title>
    <url>/2014/02/24/diff-and-patch/</url>
    <content><![CDATA[<p>diff和patch是一对好基友。diff用于产生两个文件(或者说一个文件的两个版本)之间的差异补丁,patch用于应用补丁,从而使文件从一个版本变迁到另一个版本。</p>
<a id="more"></a>
<p><strong>diff</strong><br>diff命令生成的补丁有多种格式,目前最常用的是unified context格式。</p>
<p>用法:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ diff -Nur file1 file2 &gt; patchfile</span><br></pre></td></tr></table></figure>
<p>命令行参数:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-N,--<span class="keyword">new</span>-file 如果比较时找不到其中的一个文件,则找不到的文件视为空文件</span><br><span class="line">-u, -U NUM, --unified\[=NUM\] 输出的unified context格式上下文行数,默认为<span class="number">3</span>行。指定生成的补丁格式为unified context。</span><br><span class="line">-r, --recursive 递归比较子目录</span><br></pre></td></tr></table></figure>

<p>生成的补丁文件格式:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">--- file1 <span class="number">2014</span>-<span class="number">02</span>-<span class="number">24</span> <span class="number">13</span>:<span class="number">35</span>:<span class="number">58.441441353</span> +<span class="number">0800</span></span><br><span class="line">+++ file2 <span class="number">2014</span>-<span class="number">02</span>-<span class="number">24</span> <span class="number">13</span>:<span class="number">39</span>:<span class="number">54.361863099</span> +<span class="number">0800</span></span><br><span class="line">@@ -<span class="number">1</span>,<span class="number">5</span> +<span class="number">1</span>,<span class="number">7</span> @@</span><br><span class="line"> <span class="number">1</span></span><br><span class="line"> <span class="number">2</span></span><br><span class="line">-<span class="number">3</span></span><br><span class="line"> <span class="number">4</span></span><br><span class="line"> <span class="number">5</span></span><br><span class="line">+<span class="number">6</span></span><br><span class="line">+<span class="number">7</span></span><br><span class="line">+<span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>其中:<br>第一行指明变动前的旧文件,后面是文件的时间戳,包括时区。<br>第二行指明变动后的新文件<br>第三行指明变动的起始行和变动的范围。-1,5表明旧文件影响从第一行开始的5行范围,+1,7表示新文件影响从第一行开始的7行。<br>注意默认输出变动行前后的3行作为上下文,上下文也是包含在范围之内的。</p>
<p>最后就是实际的变动内容。行前面有-号的表示删除的号,有+号的表示添加的号,其他没有前缀符号的是上下文。</p>
<p><strong>patch</strong></p>
<p>patch命令应用差异补丁,从而使文件从一个版本变迁到一个新的版本。</p>
<p>用法:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ patch -p\[num\] &lt; patchfile</span><br></pre></td></tr></table></figure>
<p>参数:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-pnum or --strip=num 从补丁文件中读出的文件名剥除掉num指定个数的前导斜线(/),如果有两个连续的斜线视为一个剥除。</span><br><span class="line">这主要是用于消除生成补丁文件和应用补丁文件所处的目录层次不同造成的路径差异。如果不指定-p参数,则忽略所有的路径信息,</span><br><span class="line">只使用补丁文件中的文件名。如果指定-p0,则使用全部的路径信息。-p1则剥除掉补丁文件中左侧开始的第一个斜线及其之前的内容,</span><br><span class="line">以此类推。</span><br><span class="line">-R or --reverse 假设生成补丁文件时的新旧文件交换了位置。所以在正常打过补丁后,可以使用-R参数恢复到打补丁之前的状态。</span><br></pre></td></tr></table></figure>

<p><strong>git diff和git apply</strong></p>
<p>git diff命令可以比较两个提交之间,两个分支之间,提交和工作目录之间,未暂存(staged)的更改与提交之间等等的差异。</p>
<ul>
<li>  尚未暂存的文件差异<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git diff \[filename\]</span><br></pre></td></tr></table></figure>
如果不指定文件名则比较所有的文件</li>
<li>  暂存的文件和上次提交之间的差异<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git diff --cached \[filename\]</span><br></pre></td></tr></table></figure>
如果不指定文件名则比较所有的文件</li>
<li>  两个提交之间的差异<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git diff d2909531\[:filename\] c940bcfd\[:filename\] </span><br></pre></td></tr></table></figure>
比较两个提交之间的差异，不指定文件名则比较所有的文件。通过hash值来指定对应的提交。</li>
<li>  两个分支之间的差异<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git diff master..devel</span><br></pre></td></tr></table></figure>
比较master分支与devel分支的差异,<br>或者更简单的比较当前分支与devel分支的差异:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git diff devel</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>git diff生成补丁文件是unified context格式的变体:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">diff --git a/js/dwz.tree.js b/js/dwz.tree.js</span><br><span class="line">index b7e85ad..cbac93e <span class="number">100644</span></span><br><span class="line">--- a/js/dwz.tree.js</span><br><span class="line">+++ b/js/dwz.tree.js</span><br><span class="line">@@ -<span class="number">201</span>,<span class="number">7</span> +<span class="number">201</span>,<span class="number">7</span> @@</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">var</span> $checkbox = $(<span class="string">&quot;:checkbox&quot;</span>, parent);</span><br><span class="line"> <span class="keyword">if</span> (aClass == <span class="string">&quot;checked&quot;</span>) $checkbox.attr(<span class="string">&quot;checked&quot;</span>,<span class="string">&quot;checked&quot;</span>);</span><br><span class="line">-<span class="keyword">else</span> $checkbox.removeAttr(<span class="string">&quot;checked&quot;</span>);</span><br><span class="line">+<span class="keyword">else</span> <span class="keyword">if</span> (aClass == <span class="string">&quot;unchecked&quot;</span>) $checkbox.removeAttr(<span class="string">&quot;checked&quot;</span>);</span><br><span class="line"> </span><br><span class="line"> parent._checkParent();</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>第一行表示这是git diff格式的补丁文件,比较的文件为a版本的js/dwz.tree.js(变动前)和b版本的js/dwz.tree.js(变动后)<br>第二行指定两个版本文件的hash值和文件的模式(普通文件,访问权限为644)<br>其他与普通的unified context格式补丁文件一样。<br>因为使用a/和b/来标识两个版本,因此使用patch命令时需要将a/和b/剥除。</p>
<p>git diff生成的补丁可以使用patch也可以使用git apply来应用。</p>
<p><strong>git format-patch和git am</strong></p>
<p>git format-patch生成的是邮件格式的git专用补丁文件,包含了更丰富的信息，需要使用git am来应用这种格式的补丁。</p>
<p><strong>注意</strong></p>
<p>如果在windows和linux之间使用diff和patch,一定要注意这两个平台之间行结束符的不同,明明看上其相同的两行,diff和patch会认为是不同的行,从而出现错误。<br>比如提示这样的错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Hunk #1 FAILED at xx (different line endings).</span><br><span class="line"><span class="number">1</span> out <span class="keyword">of</span> <span class="number">1</span> hunk FAILED -- saving rejects to file xxx.xxx.rej</span><br></pre></td></tr></table></figure>

<p>windows下的行结束符为’/r/n’,而linux的行结束符为’/n’。</p>
<p>使用diff命令时可以使用参数<code>-w, --ignore-all-space</code>忽略所有的空白,包括tab,carriage return,newline,vertical tab,form feed和space。<br>使用patch命令时可以使用参数<code>-l,--ignore-whitespace</code>来进行松散匹配,但这参数只忽略tab和space。</p>
<p>最好还是使文件的格式一致,vim里可以使用:set fileformat修改文件格式,比如修改为unix或dos格式:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:set fileformat=unix</span><br></pre></td></tr></table></figure>

<p>references:<br>[1]<a href="http://www.ruanyifeng.com/blog/2012/08/how_to_read_diff.html">读懂diff</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>依赖倒置(DIP),控制反转(IoC)与依赖注入(DI)</title>
    <url>/2013/10/08/dip-ioc-di/</url>
    <content><![CDATA[<p>DIP,IoC与DI概念解析</p>
<a id="more"></a>
<p><strong>依赖倒置</strong><br>DIP(Dependency Inversion Principle)</p>
<p>DIP的两大原则：<br>1、高层模块不应该依赖于低层模块,二者都应该依赖于抽象。<br>2、抽象不应该依赖于细节,细节应该依赖于抽象。</p>
<p>具体来讲，依赖倒置的核心思想是针对接口而不是实现编程。<br>应用DIP可以降低模块之间的耦合度，只要接口保持稳定，模块可以独立演化而互不影响。</p>
<p><strong>控制反转</strong><br>IoC(Inversion of Control)</p>
<p>通常情况下，class A依赖于class B,或者应用DIP之后依赖于Interface B,那么在运行时，我们必须自行主动的去实例化Interface B接口的实现类实例，然后将其引用传递给Class A，在传统的编程模型下，我们经常这样干。这样耦合度仍然很高，我们必须知道所依赖的实现类的一些细节。</p>
<p>而IoC则是将实例化被依赖模块的责任交出去，不再主动去做依赖装配工作，这样我们就可以彻底的只针对接口编程，而无需关心具体的实现。<br>IoC容器成为一个系统的对象容器和粘合剂，它负责创建对象的实例，并按照它们声明的依赖关系把它们粘合起来共同工作。通过配置文件或注解的方法，IoC容器会自动的满足模块之间的依赖关系，而无需我们再主动去处理依赖关系，只要被动接受就可以了。</p>
<p>这种依赖关系的满足由主动实现到被动接受的转变，就是所谓的控制反转了。<br>IoC与好莱坞原则(Don’t call me,i’ll call you!)比较相似。</p>
<p><strong>依赖注入</strong><br>DI(Dependency Injection)</p>
<p>依赖注入是实现控制反转的主要方式，另一种方式是依赖查找。</p>
<p>两者的区别在于，依赖注入是被动的接收对象，而依赖查找是主动索取响应名称的对象，获得依赖对象的时间也可以在代码中自由控制。依赖查找更加主动，在需要的时候通过调用框架提供的方法来获取对象，获取时需要提供相关的配置文件路径、key等信息来确定获取对象的状态。比如使用JNDI来查找资源。</p>
<p>依赖注入有以下几种实现方式：<br>1、<strong>接口注入</strong>或叫Type 1型注入。需要实现特定接口以供外部容器注入所依赖类型的对象。这里有一个写的比较好的<a href="http://richnewman.wordpress.com/about/code-listings-and-diagrams/dependency-injection-examples/dependency-injection-example-interface-injection/">例子</a>。这种注入方式很少用到。<br>2、<strong>setter注入</strong>或叫Type 2型注入。实现特定属性的public set方法，来让外部容器调用传入所依赖类型的对象。这种注入方式是最常见的。<br>3、<strong>构造函数注入</strong>或叫Type 3型注入。实现特定参数的构造函数，在新建对象时传入所依赖类型的对象。<br>4、<strong>注解注入</strong>。基于Java的注解功能，在私有变量前加“@Autowired”等注解，不需要显式的定义以上三种代码，便可以让外部容器传入对应的对象。该方案相当于定义了public的set方法，但是因为没有真正的set方法，从而不会为了实现依赖注入导致暴露了不该暴露的接口（因为set方法只想让容器访问来注入而并不希望其他依赖此类的对象访问）。注解注入是比较好的注入实现方式。</p>
<p>总的来讲，依赖倒置(DIP)是一种设计原则，控制反转(IoC)是一种处理对象间依赖关系的方式，与传统的主动方式正好相反，而依赖注入(DI)则是IoC容器实现控制反转的主要方式。</p>
<p>参考：<br><a href="http://www.cnblogs.com/leoo2sk/archive/2009/06/17/1504693.html">依赖注入那些事儿</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐HTML5在线教程</title>
    <url>/2013/06/11/dive-into-html5/</url>
    <content><![CDATA[<p>推荐一篇不错的HTML5在线教程，<a href="http://diveintohtml5.info/">dive into html5</a>,有时间要好好看看。</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>DNS over HTTPS</title>
    <url>/2019/07/20/dns-over-https/</url>
    <content><![CDATA[<a id="more"></a>
<p>DNS over HTTPS用于解决DNS解析的隐私问题</p>
<p><strong>Debian</strong><br>可以使用<a href="https://github.com/DNSCrypt/dnscrypt-proxy/wiki">dnscrypt-proxy</a></p>
<p><strong>MacOSX</strong><br>建议使用<a href="https://github.com/DNSCrypt/dnscrypt-proxy/wiki">dnscrypt-proxy</a></p>
<p><em>安装cloudflared</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install cloudflare/cloudflare/cloudflared</span><br><span class="line">$ cloudflared --version</span><br><span class="line">cloudflared version <span class="number">2019.7</span><span class="number">.0</span> (built <span class="number">2019</span>-<span class="number">07</span>-<span class="number">11</span>-<span class="number">1655</span> UTC)</span><br></pre></td></tr></table></figure>

<p><em>添加配置文件config.yaml</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mkdir -p /usr/local/etc/cloudflared</span><br><span class="line">$ cat &lt;&lt; EOF &gt; <span class="regexp">/usr/</span>local/etc/cloudflared/config.yml</span><br><span class="line">proxy-dns: <span class="literal">true</span></span><br><span class="line">proxy-dns-upstream:</span><br><span class="line"> - https:<span class="comment">//1.1.1.1/dns-query</span></span><br><span class="line"> - https:<span class="comment">//1.0.0.1/dns-query</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p><em>安装服务</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo cloudflared service install</span><br><span class="line">INFO\[<span class="number">0000</span>\] Installing Argo Tunnel client <span class="keyword">as</span> a system launch daemon. Argo Tunnel client will run at boot </span><br><span class="line">INFO\[<span class="number">0000</span>\] Outputs are logged to /Library/Logs/com.cloudflare.cloudflared.err.log and /Library/Logs/com.cloudflare.cloudflared.out.log</span><br></pre></td></tr></table></figure>

<p><em>卸载cloudflare</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo cloudflared service uninstall</span><br><span class="line">$ brew uninstall cloudflare/cloudflare/cloudflared</span><br></pre></td></tr></table></figure>

<p><em>校验</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dig +short @<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> cloudflare.com A</span><br><span class="line"><span class="number">198.41</span><span class="number">.214</span><span class="number">.162</span></span><br><span class="line"><span class="number">198.41</span><span class="number">.215</span><span class="number">.162</span></span><br><span class="line">$ dig +short @<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> cloudflare.com AAAA</span><br><span class="line"><span class="number">2606</span>:<span class="number">4700</span>::c629:d7a2</span><br><span class="line"><span class="number">2606</span>:<span class="number">4700</span>::c629:d6a2</span><br></pre></td></tr></table></figure>

<p><em>设置系统dns</em></p>
<p>将系统DNS设置为127.0.0.1</p>
<p><strong>Firefox浏览器</strong></p>
<p><em>DOH设置</em></p>
<p>地址栏输入about:config进入配置界面，修改以下参数配置DOH：</p>
<p>network.trr.mode = 3<br>#3为只使用DOH，1为关闭DOH特性，2为优先使用DOH，还可以fallback到传统dns</p>
<p>network.trr.uri = <a href="https://1.1.1.1/dns-query">https://1.1.1.1/dns-query</a><br>#cloudflare提供的DOH公共服务器</p>
<p><em>ESNI设置</em></p>
<p>同一个IP地址可以托管很多的站点,在建立TLS链接时<a href="https://openwares.net/2009/09/21/server_name_indication/">SNI</a>域名会明文发送，Encrypted SNI就是为了解决这个问题，防止第三方窃取隐私。</p>
<p>network.security.esni.enabled设置为true打开Encrypted SNI浏览器支持</p>
<p><em>服务器端</em></p>
<p>OpenSSL尚未支持ESNI，因此下游的nginx当前亦不支持，相信很快就会支持。<br><a href="https://defo.ie/">DEfO</a>是一个为OpenSSL添加ENSI支持的项目<a href="https://github.com/sftcd/openssl/tree/master/esnistuff">github地址</a>。</p>
<p><strong>chrome浏览器</strong></p>
<p>即将支持:-(，参考[5]<br>今年10月晚期发布的chrome 78会开始实验性的支持DOH，参见[9]<br>ESNI一样尚未支持</p>
<p>版本78以后，打开Secure DNS lookups<br>（chrome://flags/#dns-over-https）标志，并将系统dns设置为1.1.1.1和/或1.0.0.1</p>
<p><strong>References:</strong><br>[1]<a href="https://program-think.blogspot.com/2018/10/Comparison-of-DNS-Protocols.html">对比4种强化域名安全的协议——DNSSEC，DNSCrypt，DNS over TLS，DNS over HTTPS</a><br>[2]<a href="https://www.cloudflare.com/ssl/encrypted-sni/">Browsing Experience Security Check</a><br>[3]<a href="https://github.com/curl/curl/wiki/DNS-over-HTTPS">DNS over HTTPS</a><br>[4]<a href="https://wiki.mozilla.org/Trusted_Recursive_Resolver">Trusted Recursive Resolver</a><br>[5]<a href="https://chromium-review.googlesource.com/c/chromium/src/+/1639663">Add DNS-over-HTTPS to chrome://flags</a><br>[6]<a href="https://developers.cloudflare.com/1.1.1.1/dns-over-https/cloudflared-proxy/">Running a DNS over HTTPS Client</a><br>[7]<a href="https://github.com/jedisct1/dnscrypt-proxy">dnscrypt-proxy</a><br>[8]<a href="https://blog.ysoup.org/tech/doh.html">MacOS 开启 DNS over HTTPS (DoH)</a><br>[9]<a href="https://www.zdnet.com/article/google-to-run-dns-over-https-doh-experiment-in-chrome/">Google to run DNS-over-HTTPS (DoH) experiment in Chrome</a><br>[10]<a href="https://wiki.mozilla.org/Trusted_Recursive_Resolver">Trusted Recursive Resolver</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>dnscrypt-proxy</title>
    <url>/2019/10/10/dnscrypt-proxy/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>端口绑定错误</strong><br>dnscrypt-proxy默认设置是绑定到53端口，1024以下的端口为特权端口，普通用户并无权绑定，启动时提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[FATAL\] listen udp <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">53</span>: bind: permission denied</span><br></pre></td></tr></table></figure>
<p>尝试authbind无果，/lib/systemd/system/dnscrypt-proxy.service文件中的ExecStart修改为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ExecStart=<span class="regexp">/usr/</span>bin/authbind --deep /usr/sbin/dnscrypt-proxy -config /etc/dnscrypt-proxy/dnscrypt-proxy.toml</span><br></pre></td></tr></table></figure>
<p>并设置了authbind的byport,byuid,byaddr皆无果，修改User=root了事。</p>
<p><strong>动态生成blacklist</strong><br>官方提供了一个python脚本<a href="https://github.com/DNSCrypt/dnscrypt-proxy/tree/master/utils/generate-domains-blacklists">generate-domains-blacklist.py</a>，可以从多个来源动态生成blacklist列表文件。</p>
<p>下载generate-domains-blacklist.py，domains-blacklist-local-additions.txt，domains-blacklist.conf，domains-time-restricted.txt，domains-whitelist.txt这几个文件，然后执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./generate-domains-blacklist.py &gt; blacklist.txt</span><br></pre></td></tr></table></figure>
<p>dnscrypt-proxy.toml中配置blacklist使用生成的blacklist.txt文件即可。<br>可以使用cron周期性自动重新生成/更新blacklist.txt文件。</p>
<p>References:<br>[1]<a href="https://github.com/DNSCrypt/dnscrypt-proxy/wiki">dnscrypt-proxy wiki</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>docker环境下运行gdb错误的问题</title>
    <url>/2017/12/15/docker-gdb-error/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为MacOS安全与权限的问题，运行gdb需要用证书签名gdb，好麻烦。所以使用docker运行debian stretch容器，执行gdb时出现类似错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">warning: <span class="built_in">Error</span> disabling address space randomization: Operation not permitted</span><br></pre></td></tr></table></figure>

<p>那么在运行容器的时候添如下参数就可以了：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">--security-opt seccomp=unconfined</span><br></pre></td></tr></table></figure>

<p>如果需要ptrace，可以添加如下参数：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">--cap-add=SYS_PTRACE</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>使用cookie</title>
    <url>/2014/02/25/document-cookie/</url>
    <content><![CDATA[<p>cookie用于在客户端存储少量的数据。</p>
<a id="more"></a>
<p>cookie是与document相关联的,也就是说cookie是属于某一个文档的。</p>
<p>语法:</p>
<p>设置cookie</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">document</span>.cookie = updatedCookie;</span><br></pre></td></tr></table></figure>

<p>获取所有cookies</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">allCookies = <span class="built_in">document</span>.cookie;</span><br></pre></td></tr></table></figure>

<p>cookie设置格式:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">document</span>.cookie=<span class="string">&#x27;cookie_name=值\[;max-age=max-age-in-seconds</span></span><br><span class="line"><span class="string"> ;expires=date-in-GMTString-format;path=访问控制路径;domain=访问控制域名;secure\]&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://developer.mozilla.org/en-US/docs/Web/API/document.cookie">document.cookie</a><br>[2]<a href="http://mrasong.com/a/js-cookie">js操作cookie</a><br>[3]<a href="http://www.itivy.com/jquery/archive/2011/7/20/jquery-cookie-plugin-usage.html">基于jQuery的Cookie操作插件</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>DOM对象属性(property)与HTML标签特性(attribute)</title>
    <url>/2014/05/20/dom-property-element-attribute/</url>
    <content><![CDATA[<a id="more"></a>
<p>HTML中property与attribute是极易混淆的两个概念。大多数时候这两个单词都翻译为“属性”,为了区分二者，一般将property翻译为”属性”，attribute翻译为”特性”。</p>
<p>每一个HTML标签(tag)都对应一个DOM接口HTMLXxxElement,比如Span标签对应的是HTMLSpanElement。这些标签的DOM接口都继承自HTMLElement接口，而HTMLElement又继承自Element。我们知道所有的标签都是一个元素结点,因此Element接口又继承自Node接口。其实HTML文档树中的所有东西都是结点,只不过有不同的结点类型而已。</p>
<p>property就是DOM对象的属性,就像普通的javascript对象的属性一样一样的,因为DOM对象就是一个地道的javascript对象，也有自己的原型链。<br>而attribute则是HTML标签的特性,比如</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;div id=<span class="string">&quot;div1&quot;</span> title=<span class="string">&quot;title1&quot;</span>&gt;test&lt;div&gt;</span><br></pre></td></tr></table></figure>
<p>这里id和title是HTML标签div的特性,虽然对应的DOM对象HTMLDivElement也有这两个属性，但它们却是完全不一样的东西。有些特性与属性是同步的。</p>
<p>HTML标签的attribute以<a href="https://openwares.net/js/javascript_array_like_object.html">类数组</a>的形式存储在对应DOM对象的属性attributes中,attributes属性的类型为NamedNodeMap对象。<br>DOM对象提供了方法setAttribute，getAttribute和removeAttribute来操纵HTML标签的特性。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">DOMString getAttribute(<span class="keyword">in</span> DOMString name);</span><br><span class="line"><span class="keyword">void</span> setAttribute(<span class="keyword">in</span> DOMString name, <span class="keyword">in</span> DOMString value) raises(DOMException);</span><br></pre></td></tr></table></figure>

<p>HTML标签attribute的名字和值都必须为字符串类型，而DOM对象的property没有此限制，可以是任何类型。</p>
<p>有些HTML标签的attribute有对应的DOM对象property,但它们的取值却不一定是相同的。一般来说相对应的attribute与property其名字是一样的，但是class特性有所不同，因为class在javascript中为关键字，所以其所对应的property名字为className。</p>
<p>有些简单的特性,比如id,两者的取值是一样的。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> id1=elem.id;</span><br><span class="line"><span class="keyword">var</span> id2=elem.getAttribute(<span class="string">&#x27;id&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>但对于input的value,使用getAttribute获取的永远是写HTML标签时指定的那个值,而value属性则获取到的是input当前输入的值。<br>而另一些特性比如checked,只要checked特性存在，无论其值是什么，DOM对象的checked属性的值都是true。这里checked属性已经不是字符串而是布尔类型了。</p>
<p>还有一些特性比如style和onclick,其对应的DOM属性完全是返回一个对象了,比如elem.style属性就返回一个CSSStyleDeclaration对象。</p>
<p>HTML自定义attribute没有对应的DOM对象property。</p>
<p>References:<br>[1]<a href="http://stylechen.com/attribute-property.html">attribute和property的区别</a><br>[2]<a href="http://www.liyao.name/2013/09/differences-between-property-and-attribute-in-javascript.html">JavaScript中的property和attribute的区别</a><br>[3]<a href="http://www.w3help.org/zh-cn/causes/SD9006">SD9006: IE 混淆了 DOM 对象属性（property）及 HTML 标签属性（attribute），造成了对 setAttribute、getAttribute 的不正确实现</a><br>[4]<a href="http://www.w3schools.com/jsref/dom_obj_all.asp">The HTML DOM Element Object</a><br>[5]<a href="http://www.cnblogs.com/wangfupeng1988/p/3631853.html">DOM元素的特性（Attribute）和属性（Property）</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>删除还有活动连接的PostgreSQL数据库</title>
    <url>/2013/11/06/drop-database-has-activie-connections/</url>
    <content><![CDATA[<p>如果数据库尚有活动连接，则drop数据库时会失败并有错误提示。</p>
<a id="more"></a>
<p>[sql]<br>postgres=# DROP DATABASE testdb;</p>
<p>ERROR: database “testdb” is being accessed by other users<br>DETAIL: There are 3 other sessions using the database.<br>[/sql]</p>
<p>可以先用下面的语句把testdb的活动连接中止，然后再DROP数据库就可以了。<br>[sql]<br>postgres=# SELECT pg_terminate_backend(pid)<br>postgres-# FROM pg_stat_activity<br>postgres-# WHERE datname=’testdb’ AND pid&lt;&gt;pg_backend_pid();</p>
<h2 id="pg-terminate-backend"><a href="#pg-terminate-backend" class="headerlink" title=" pg_terminate_backend "></a> pg_terminate_backend </h2><p> t<br> t<br> t<br>(3 rows)<br>[/sql]</p>
<p>pg_stat_activity是一个系统视图，表中的每一行代表一个服务进程的属性和状态。</p>
<p>boolean pg_terminate_backend(pid int)是一个系统函数，用于终止一个后端服务进程。</p>
<p>int pg_backend_pid()系统函数用于获取附加到当前会话的服务器进程的ID</p>
<p>使用的数据库版本PostgreSQL 9.3</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>DS5020存储Unreadable Sectors故障修复</title>
    <url>/2019/07/15/ds5020-unreadable-sectors-fix/</url>
    <content><![CDATA[<a id="more"></a>
<p>一台IBM DS5020(1814-20 FAStT) RAID5存储阵列，OS报错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[ 274.331664\] sd 4:0:0:0: \[sdc\] tag#5206 Add. Sense: Unrecovered read error</span><br><span class="line">\[ <span class="number">274.331673</span>\] print_req_error: critical medium error, dev sdc, sector <span class="number">177668608</span></span><br><span class="line">\[ <span class="number">274.331752</span>\] print_req_error: critical medium error, dev dm-<span class="number">0</span>, sector <span class="number">177668608</span></span><br><span class="line">\[ 274.371749\] sd 4:0:0:0: \[sdc\] tag#5206 Add. Sense: Unrecovered read error</span><br><span class="line">\[ <span class="number">274.371757</span>\] print_req_error: critical medium error, dev sdc, sector <span class="number">177668632</span></span><br><span class="line">\[ <span class="number">274.371848</span>\] print_req_error: critical medium error, dev dm-<span class="number">0</span>, sector <span class="number">177668632</span></span><br></pre></td></tr></table></figure>

<p>连上存储，有报警信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Failure Entry <span class="number">1</span>: USM_UNREADABLE_SECTORS_EXIST-Recovery Failure Type Code: <span class="number">75</span></span><br><span class="line">Storage array: Unnamed</span><br><span class="line">Unreadable sectors detected: <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>有两个不可读取的扇区，可以进一步看到这两个扇区位于哪个磁盘驱动器，这种故障一般就是硬盘不稳定了，该换就换吧。</p>
<p>存储管理EMW(Enterprise Manage Window)窗口找到存储阵列，右击弹出context菜单中选择“Exectute script…”</p>
<p>脚本窗口中执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">show storageArray unreadableSectors;</span><br></pre></td></tr></table></figure>
<p>结果窗口输出:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Executing script...</span><br><span class="line">Volume LUN Accessible By <span class="built_in">Date</span>/Time Volume LBA Drive Location Drive LBA Failure Type </span><br><span class="line"><span class="number">1</span> <span class="number">0</span> Host Group ibm <span class="number">7</span>/<span class="number">11</span>/<span class="number">19</span> <span class="number">3</span>:<span class="number">07</span>:<span class="number">58</span> AM <span class="number">0xa97021e</span> Tray <span class="number">85</span>, Slot <span class="number">2</span> <span class="number">0x12d391e</span> Logical </span><br><span class="line"><span class="number">1</span> <span class="number">0</span> Host Group ibm <span class="number">7</span>/<span class="number">11</span>/<span class="number">19</span> <span class="number">3</span>:<span class="number">07</span>:<span class="number">58</span> AM <span class="number">0xa97061e</span> Tray <span class="number">85</span>, Slot <span class="number">6</span> <span class="number">0x12d391e</span> Physical </span><br><span class="line"></span><br><span class="line">Script execution complete.</span><br></pre></td></tr></table></figure>
<p>可以看到这两个扇区的详细状况，然后继续执行命令清除这两个扇区</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">clear allVolumes unreadableSectors;</span><br></pre></td></tr></table></figure>

<p>最后重新查看</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">show storageArray unreadableSectors;</span><br><span class="line">Executing script...</span><br><span class="line">There are currently no unreadable sectors on the storage array.</span><br><span class="line">Script execution complete.</span><br></pre></td></tr></table></figure>
<p>可以看到已经没有不可读取的扇区了，阵列的报警灯也恢复正常。<br>注意，那两个扇区的数据应该是丢失了，应用程序如果需要这些数据应该通过其他途径恢复数据。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ECC错误提示</title>
    <url>/2013/01/30/ecc-errors/</url>
    <content><![CDATA[<p>一台服务器出现内存故障提示</p>
<a id="more"></a>
<p>Message from syslogd@patchsvr at Jan 30 10:24:02 …<br> kernel:[171000.744035] [Hardware Error]: CPU:6 MC4_STATUS[OverCEMiscV-AddrVCECC]: 0xdc04400032080a13</p>
<p>Message from syslogd@patchsvr at Jan 30 10:24:02 …<br> kernel:[171000.744097] [Hardware Error]: MC4_ADDR: 0x00000001f3f37860</p>
<p>Message from syslogd@patchsvr at Jan 30 10:24:02 …<br> kernel:[171000.744128] [Hardware Error]: Northbridge Error (node 3): DRAM ECC error detected on the NB.</p>
<p>Message from syslogd@patchsvr at Jan 30 10:24:02 …<br> kernel:[171000.744224] [Hardware Error]: cache level: L3/GEN, mem/io: MEM, mem-tx: RD, part-proc: RES (no timeout)</p>
<p>MC4_STATUS为MSR(Model Specific Registers)模型相关寄存器之一,主要用于记录cpu L3 cache和前端总线FSB(Front Side Bus)错误,MC为Machine Check之意，还有其他的MCx_STATUS寄存器</p>
<p>MC4_ADDR与MC4_STATUS对应，用来记录引起MC4_STATUS所记载错误的线性地址或物理地址。</p>
<p>此处有提示北桥错误，检查到DRAM ECC校验错误，看来ECC内存出问题了。<br>服务器有4颗双核Opteron 8218 HE处理器，CPU 6报错误，是第三颗CPU的本地内存出故障了吗？？<br>系统仍然正常运行，抽时间memtest下，老服务器了。<br>不知道多CPU硬件环境下，去掉某个CPU的本地内存系统能不能启动呢？</p>
<p>**P.S.**用memtest86+检测了一下内存，内存竟然没有问题！难道是北桥出问题了？？？</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ECC 内存故障</title>
    <url>/2019/06/01/ecc-memory-defect/</url>
    <content><![CDATA[<a id="more"></a>
<p>一台很老旧的服务器terminal不断吐出一些错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[ <span class="number">1250.944486</span>\] mce: \[Hardware <span class="built_in">Error</span>\]: Machine check events logged</span><br><span class="line">\[ <span class="number">1250.944493</span>\] \[Hardware <span class="built_in">Error</span>\]: Corrected error, no action required.</span><br><span class="line">\[ <span class="number">1250.948666</span>\] \[Hardware <span class="built_in">Error</span>\]: CPU:<span class="number">24</span> (<span class="number">10</span>:<span class="number">9</span>:<span class="number">1</span>) MC4_STATUS\[OverCEMiscV-AddrVCECC\]: <span class="number">0xdc0a400079080a13</span></span><br><span class="line">\[ <span class="number">1250.952631</span>\] \[Hardware <span class="built_in">Error</span>\]: <span class="built_in">Error</span> Addr: <span class="number">0x00000004abffce80</span></span><br><span class="line">\[ <span class="number">1250.952633</span>\] \[Hardware <span class="built_in">Error</span>\]: MC4 <span class="built_in">Error</span> (node <span class="number">6</span>): DRAM ECC error detected on the NB.</span><br><span class="line">\[ 1250.952654\] EDAC MC6: 1 CE on mc#6csrow#3channel#0 (csrow:3 channel:0 page:0x4abffc offset:0xe80 grain:0 syndrome:0x7914)</span><br><span class="line">\[ <span class="number">1250.952656</span>\] \[Hardware <span class="built_in">Error</span>\]: cache level: L3/GEN, mem/io: MEM, mem-tx: RD, part-proc: RES (no timeout)</span><br></pre></td></tr></table></figure>

<p>可以看到是内存出现了错误，不过错误被纠正了，但内存显然是出现故障了。</p>
<p>先看看系统cpu节点信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lscpu</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPU op-mode(s): <span class="number">32</span>-bit, <span class="number">64</span>-bit</span><br><span class="line">Byte Order: Little Endian</span><br><span class="line">Address sizes: <span class="number">48</span> bits physical, <span class="number">48</span> bits virtual</span><br><span class="line">CPU(s): <span class="number">32</span></span><br><span class="line">On-line CPU(s) list: <span class="number">0</span>-<span class="number">31</span></span><br><span class="line">Thread(s) per core: <span class="number">1</span></span><br><span class="line">Core(s) per socket: <span class="number">8</span></span><br><span class="line">Socket(s): <span class="number">4</span></span><br><span class="line">NUMA node(s): <span class="number">8</span></span><br><span class="line">Vendor ID: AuthenticAMD</span><br><span class="line">CPU family: <span class="number">16</span></span><br><span class="line">Model: <span class="number">9</span></span><br><span class="line">Model name: AMD Opteron(tm) Processor <span class="number">6128</span></span><br><span class="line">Stepping: <span class="number">1</span></span><br><span class="line">CPU MHz: <span class="number">800.000</span></span><br><span class="line">CPU max MHz: <span class="number">2000.0000</span></span><br><span class="line">CPU min MHz: <span class="number">800.0000</span></span><br><span class="line">BogoMIPS: <span class="number">4000.04</span></span><br><span class="line">Virtualization: AMD-V</span><br><span class="line">L1d cache: 64K</span><br><span class="line">L1i cache: 64K</span><br><span class="line">L2 cache: 512K</span><br><span class="line">L3 cache: 5118K</span><br><span class="line">NUMA node0 CPU(s): <span class="number">0</span>-<span class="number">3</span></span><br><span class="line">NUMA node1 CPU(s): <span class="number">4</span>-<span class="number">7</span></span><br><span class="line">NUMA node2 CPU(s): <span class="number">8</span>-<span class="number">11</span></span><br><span class="line">NUMA node3 CPU(s): <span class="number">12</span>-<span class="number">15</span></span><br><span class="line">NUMA node4 CPU(s): <span class="number">16</span>-<span class="number">19</span></span><br><span class="line">NUMA node5 CPU(s): <span class="number">20</span>-<span class="number">23</span></span><br><span class="line">NUMA node6 CPU(s): <span class="number">24</span>-<span class="number">27</span></span><br><span class="line">NUMA node7 CPU(s): <span class="number">28</span>-<span class="number">31</span></span><br><span class="line">Flags: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm 3dnowext 3dnow constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid amd_dcm pni monitor cx16 popcnt lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt nodeid_msr hw_pstate vmmcall npt lbrv svm_lock nrip_save pausefilter</span><br></pre></td></tr></table></figure>

<p>共有四个socket，四颗cpu，每颗CPU有八个核心，总共是32核心，对于NUMA结构的机器，一般来讲每颗CPU应该至少有一个本地的内存控制器</p>
<p>安装edac-util，查看内存控制器信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install edac-utils</span><br><span class="line">$ edac-util -vs</span><br><span class="line">edac-util: EDAC drivers are loaded. <span class="number">4</span> MCs detected:</span><br><span class="line"> mc0:F10h</span><br><span class="line"> mc2:F10h</span><br><span class="line"> mc4:F10h</span><br><span class="line"> mc6:F10h</span><br></pre></td></tr></table></figure>
<p>可以看到有四个内存控制器，再查看每个内存控制器可能存在的错误</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">$ edac-util -v</span><br><span class="line">mc0: <span class="number">0</span> Uncorrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc0: <span class="number">0</span> Corrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc0: csrow2: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc0: csrow2: mc#0csrow#2channel#0: 0 Corrected Errors</span><br><span class="line">mc0: csrow3: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc0: csrow3: mc#0csrow#3channel#0: 0 Corrected Errors</span><br><span class="line">mc2: <span class="number">0</span> Uncorrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc2: <span class="number">0</span> Corrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc2: csrow2: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc2: csrow2: mc#2csrow#2channel#0: 0 Corrected Errors</span><br><span class="line">mc2: csrow3: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc2: csrow3: mc#2csrow#3channel#0: 0 Corrected Errors</span><br><span class="line">mc4: <span class="number">0</span> Uncorrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc4: <span class="number">0</span> Corrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc4: csrow2: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc4: csrow2: mc#4csrow#2channel#0: 0 Corrected Errors</span><br><span class="line">mc4: csrow3: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc4: csrow3: mc#4csrow#3channel#0: 0 Corrected Errors</span><br><span class="line">mc6: <span class="number">0</span> Uncorrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc6: <span class="number">0</span> Corrected Errors <span class="keyword">with</span> no DIMM info</span><br><span class="line">mc6: csrow2: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc6: csrow2: mc#6csrow#2channel#0: 2 Corrected Errors</span><br><span class="line">mc6: csrow3: <span class="number">0</span> Uncorrected Errors</span><br><span class="line">mc6: csrow3: mc#6csrow#3channel#0: 4 Corrected Errors</span><br></pre></td></tr></table></figure>

<p>或者这样查看:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ grep \[<span class="number">0</span>-<span class="number">9</span>\] /sys/devices/system/edac/mc/mc*<span class="regexp">/csrow*/</span>*ce_count</span><br><span class="line">/sys/devices/system/edac/mc/mc0/csrow2/ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc0/csrow2/ch0_ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc0/csrow3/ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc0/csrow3/ch0_ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc2/csrow2/ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc2/csrow2/ch0_ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc2/csrow3/ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc2/csrow3/ch0_ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc4/csrow2/ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc4/csrow2/ch0_ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc4/csrow3/ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc4/csrow3/ch0_ce_count:<span class="number">0</span></span><br><span class="line">/sys/devices/system/edac/mc/mc6/csrow2/ce_count:<span class="number">3</span></span><br><span class="line">/sys/devices/system/edac/mc/mc6/csrow2/ch0_ce_count:<span class="number">3</span></span><br><span class="line">/sys/devices/system/edac/mc/mc6/csrow3/ce_count:<span class="number">6</span></span><br><span class="line">/sys/devices/system/edac/mc/mc6/csrow3/ch0_ce_count:<span class="number">6</span></span><br></pre></td></tr></table></figure>

<p>可以看到出现错误的内存位于MC6,csrow2和csrow3，也就是问题出现在第四个(CPU的)内存控制器的0通道DIMM0内存这里。</p>
<p>References:<br>[1]<a href="http://fibrevillage.com/sysadmin/240-how-to-identify-defective-dimm-from-edac-error-on-linux-2">How to identify defective DIMM from EDAC error on Linux</a><br>[2]<a href="http://lzz5235.github.io/2015/04/21/memory.html">内存条物理结构分析</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>echofon抛弃小众平台</title>
    <url>/2010/09/12/echofon-drop-minor-platform/</url>
    <content><![CDATA[<p>echofon官方已经<a href="http://blog.echofon.com/2010/08/basic-auth-support-discontinue-on.html">宣布</a>暂时不支持一些小众平台，包括64位平台,FreeBSD,OpenSolaris等，很不幸，我使用的正是ubuntu 10.04 amd64版本，所以升级到echofon 1.9.6.6后，启动firefox会提示”Echofon does not support this platform or custom build Firefox. (Can’t get OAuth signer.) / Cc[‘@naan.net/twitterfox-sign;1’] is undefined (Fx version 3.6.9 / ABI x86_64-gcc3)”,杯具。1.9.6.4版本可以继续使用，echofon还是很不错的，为什么要抛弃用户呢？官方说正在做工作支持这些小众平台，谁知道猴年马月呢！</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>Eclipse Kepler自动完成时崩溃问题解决</title>
    <url>/2013/12/28/eclipse-autocomplete-crash/</url>
    <content><![CDATA[<p>Eclipse突然就开始崩溃不止了,估计与系统升级有关吧,总之又遇到坑了。</p>
<a id="more"></a>
<p>系统环境:</p>
<p>debian testing jessie amd64 + openjdk7 + eclipse kepler</p>
<p>新安装第一次打开,过几秒崩溃退出,没有任何提示,log里也完全看不出什么状况。</p>
<p>新建个工程,import时,出现自动完成,敲几下键就界面停滞,崩溃了,没有任何错误提示。</p>
<p>据说这就是Eclipse的风格。</p>
<p>因为用vim写java实在太费劲了,那些又臭又长的包,各种长的名字,用vim敲起来挺费劲,所以就偶尔用用这货,这货的重构功能不错,亮点还是有的。就是经常的崩溃不止,速度慢的要死的样子，让人心烦。8G的内存,SSD硬盘都是感觉慢吞吞的。</p>
<p>先把这坑填了再说。</p>
<p>在eclipse.ini文件最后添加下面的行:</p>
<p>-Dorg.eclipse.swt.browser.DefaultType=mozilla</p>
<p>别说,还真管用。</p>
<p>这时世界暂时又清静了。</p>
<p>不过我已经开始尝试Netbeans了,eclipse这货,不省心！</p>
<p>参考:</p>
<p><a href="http://stackoverflow.com/questions/16282249/eclipse-4-2-juno-crashes-on-ubuntu-12-04-precise">Eclipse 4.2 (Juno) crashes on Ubuntu 12.04 (Precise)</a><br><a href="https://bugs.eclipse.org/bugs/show_bug.cgi?id=404776#c6">Bug 404776</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>en_US.UTF-8环境下让lunar-applet显示中文</title>
    <url>/2010/05/03/en-us-utf-8-lunar-applet-chinese/</url>
    <content><![CDATA[<p>en_US.UTF-8环境下luna-applet默认用拼音来显示农历，可以把 /usr/share/locale/zh_CN/LC_MESSAGES/liblunar.mo 复制到/usr/share/locale/en/LC_MESSAGES/ 下即可让lunar-applet在英文环境下用汉字来显示农历。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Enter your zip code here</title>
    <url>/2014/07/02/enter-your-zip-code-here/</url>
    <content><![CDATA[<p>postgresql psql命令修改列去掉非空约束: ALTER TABLE table_name ALTER COLUMN column_name DROP NOT NULL;</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Enter your zip code here</tag>
      </tags>
  </entry>
  <entry>
    <title>让wordpress支持发布status</title>
    <url>/2017/12/02/enable-wordpress-post-status/</url>
    <content><![CDATA[<a id="more"></a>
<p>现在post格式的支持放在theme里，打开当前使用的theme的function.php，找到</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Enable support for Post Formats.</span></span><br><span class="line"><span class="comment"> * See http://codex.wordpress.org/Post_Formats</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"> add_theme_support( <span class="string">&#x27;post-formats&#x27;</span>, array(</span><br><span class="line"> <span class="string">&#x27;aside&#x27;</span>, <span class="string">&#x27;image&#x27;</span>, <span class="string">&#x27;video&#x27;</span>, <span class="string">&#x27;quote&#x27;</span>, <span class="string">&#x27;link&#x27;</span>, <span class="string">&#x27;status&#x27;</span>,</span><br><span class="line"> ) );</span><br></pre></td></tr></table></figure>

<p>在format列表里添加status即可。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>escape,encodeURI与encodeURIComponent</title>
    <url>/2014/02/25/escape-encodeuri-encodeuricomponent/</url>
    <content><![CDATA[<p>Javascript中有3个常见的字符编码函数escape,encodeURI和encodeURIComponent,相对应的解码函数为unescape,和。</p>
<a id="more"></a>
<p><strong>1、escape/unescape</strong></p>
<p>语法:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">escape</span>(str)</span><br><span class="line"><span class="built_in">unescape</span>(str)</span><br></pre></td></tr></table></figure>

<p>不编码的字符:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">@ * _ + - . /</span><br></pre></td></tr></table></figure>

<p>escape与unescape函数已经被ECMA标准废弃,处于deprecated状态,所以新的程序不应该再使用这两个函数,而应该选择使用encodeURI/decodeURI或encodeURIComponent/decodeURIComponent。</p>
<p>escape使用16进制转义序列(hexadecimal escape sequence)编码输入的字符串,除 <strong><code>@ * _ + - . /</code></strong> 之外的所有字符都被转义编码。</p>
<p>小于0xFF的字符被编码为两位16进制转义序列,形如%xx,而大于0xFF的字符被编码为双字节的unicode转移码,形如%uxxxx。</p>
<p><strong>2、encodeURI/decodeURI</strong></p>
<p>语法:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">encodeURI</span>(URI)</span><br><span class="line"><span class="built_in">decodeURI</span>(encodedURI)</span><br></pre></td></tr></table></figure>

<p>encodeURI将URI中的某些字符编码为1,2,3或4个字节的对应的utf-8编码。</p>
<p>encodeURI不编码以下字符:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">; , / ? : @ &amp; = + $</span><br><span class="line">字母 数字 - _ . ! ~ * <span class="string">&#x27; ( )</span></span><br><span class="line"><span class="string">#</span></span><br></pre></td></tr></table></figure>

<p>encodeURI不编码URI中有特殊意义的字符(比如**”/“<strong>和</strong>“,”**),因此编码后的URI还可以当作正常的URL使用。<br>但是encodeURI不能用于编码GET和POST请求参数,因为 “&amp;”, “+”, 和 “=”没有被编码,所以这种情况应该使用encodeURIComponent</p>
<p><strong>3、encodeURIComponent/decodeURIComponent</strong></p>
<p>语法:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">encodeURIComponent</span>(str);</span><br><span class="line"><span class="built_in">decodeURIComponent</span>(encodedURI)</span><br></pre></td></tr></table></figure>

<p>不编码的字符:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">字母 数字 - _ . ! ~ * <span class="string">&#x27; ( )</span></span><br></pre></td></tr></table></figure>

<p>encodeURIComponent与encodeURI基本一样,除了编码更多的字符。encodeURIComponent编码除*<em>“字母 数字 - _ . ! ~ * ‘ ( )”*</em>之外的所有其他字符。</p>
<p>由于encodeURIComponent转义HTTP协议中的特殊字符,因此URI编码之后样子会完全不同。</p>
<p><strong>4. 用法</strong></p>
<p>如果传递GET或POST参数,应该使用encodeURIComponent进行编码,以防止出现意外。cookie值应该使用encodeURIComponent进行编码,其他情况下使用encodeURI一般就够了。</p>
<p>references:<br>[1]<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/escape">escape()</a><br>[2]<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/encodeURIComponent">encodeURI()</a><br>[3]<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/encodeURIComponent">encodeURIComponent()</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>基于JAVA的企业Web应用系统总体架构设计思考</title>
    <url>/2013/10/21/enterprise-web-application-architecture/</url>
    <content><![CDATA[<p>没有最好的架构，只有适合的架构。</p>
<a id="more"></a>
<p>“No Silver Bullet”,对于架构设计同样适用。</p>
<p><strong>背景</strong></p>
<p>这是一个中型企业应用，数据操作密集，业务逻辑不复杂也不简单，持久层使用关系数据库。用户在地理位置上分散，但都处于同一个地区。<br>拥有丰富的用户角色。</p>
<p>拟采用的技术堆栈为DWZ + Spring MVC + Spring IoC + MyBatis + PostgreSQL，目标是建设成为一个用户体验良好的SPA(Single Page Application) web应用程序。</p>
<p><strong>前后端完全分离</strong></p>
<p>前后端完全分离，表现逻辑和业务逻辑都会更清晰，两端的耦合度也降到最低。只要制定好稳定的API接口，前后端通过API进行通讯即可。<br>前端采用AJAX + JSON的方式调用后端服务API接口。后端提供的服务以类Restful风格的URI暴露给前端。制定应用层协议，规范JSON请求数据和响应数据的格式，基本上以动作加数据的模式为主。当然只要前端页面和后端服务达成一致即可。</p>
<p>比如JSON请求数据：<br>[xml]<br>{<br> “action”:”save”,<br> “person”:<br> {<br> “name”:”zhangsan”<br> }<br>}<br>[/xml]</p>
<p>JSON响应数据：<br>[xml]<br>{<br> “status”:”ok”<br>}<br>[/xml]</p>
<p>前后端完全分离后，只要保持接口不变，前端和后端完全可以独立演化，相互不会影响。这样十分又有利于工作细分，前端只要关注html,javascript,css即可，后端也完全不用管前端用什么技术来展现数据。<br>虽然有些原来属于后端的计算负载现在转移到了前端，但以现在的机器性能和javascript引擎技术，这是完全可以忽略不计的。</p>
<p>现在的前端技术发展迅猛，前端框架百花齐放。在客户端渲染大量数据已完全不再话下，甚至如AngularJS等框架实现了表现层的MVC分层架构，当然AngularJS自称是MVW框架。还有MVVM等类MVC架构的框架。</p>
<p>JQuery,Underscore,prototype,backbone.js,seajs…各种框架和库已经数不胜数。在这种情形下，前后端完全分离架构已经有了十分成熟的技术基础。<br>客户端组件技术已经成为发展趋势，而其用户体验也比传统的展现层技术要好的多。</p>
<p><strong>前端</strong></p>
<p>前端拟采用<a href="http://jui.org/">DWZ</a>框架,其整个设计简单实用，UI组件齐全，适合快速企业应用开发。</p>
<p>前端只使用AJAX POST方法向后端发送JSON数据。所有的数据在组装之前都要做语法校验，为了方便程序化自动校验，可以为字段设置一个自定义属性targetType，对应数据实际的数据类型，比如int,float,date,datatime或者其他应用程序自定义的类型，然后为这些targetType类型制定对应的regexp校验器。这样通过在一个输入元素容器比如form内扫描就可以验证所有的输入元素了。</p>
<p>如有必要还可以为页面单独定制语义检验脚本，当然这种脚本不是通用的，是业务逻辑相关的。<br>一定要在客户端做所有可以做的校验，不要延迟到服务端校验，发现错误再返回客户端，这样的成本是比较高的。<br>因为企业应用的页面元素会比较多，可以采用序列化技术来组装元素，最后形成JSON数据包发送给后端。</p>
<p><strong>后端</strong></p>
<p>后端采用Spring MVC + Spring IoC + MyBatis来实现。</p>
<p>这几天也看了一些贫血模型和充血模型的文字，感觉其实二者并没有孰优孰劣之分，只是适用的场景不同而已。至于有人说只有属性没有行为的领域对象就是不OO的，这点不敢赞同。现实世界中的有些对象就是只有属性，没有行为的。比如一块石头，有颜色，大小，重量等属性，但是它没有行为，它是被动的，你可以捡起石头了，但石头永远不会把自己捡起来。很多被动的对象是没有行为的，不强加给它行为才更符合OO的设计原则。</p>
<p>后端分为两层，service层负责业务逻辑，dao层负责持久化。上层只依赖下层，不能跨层访问。</p>
<p>整个业务过程的数据流向是这样的：<br>[java]<br>client(browser) &lt;—JSON—&gt; controller &lt;—VO—&gt; service &lt;—PO/BO—&gt; dao &lt;—&gt; database<br>[/java]</p>
<p><em>service</em></p>
<p>Controller是业务逻辑无知的，只负责将从前端接收到的JSON数据包转换成VO,可以使用@RequestBody自动转换，然后调用service对象的固定方法比如run(),然后将service返回的VO对象直接返回给客户端，可以通过@ResponseBody自动从VO转换为JSON数据。</p>
<p>service层负责全部的业务逻辑和事务处理。可以将Controller传递过来的VO拆解成失血的领域对象(Domain Object),或者叫Business Object，这些对象也是只有属性没有行为，其对应到业务层面上的实体，不像单纯的PO(Persistent Object)一样是对应单个数据库表记录。业务层面的BO一般来说都是跨数据库表的。</p>
<p>为什么要把VO拆解成DO/BO呢？因为前台页面提交的数据是比较杂乱的，包括很多辅助性的数据，业务逻辑无关的数据。拆解成BO/DO更方便业务逻辑对象(Business Logical Object)来处理业务。</p>
<p>这里提到的业务逻辑对象BLO只有操作/行为，没有属性，只是纯粹的业务操作类，可以在业务对象BO上施加各种业务规则，调用DAO层持久化业务对象BO。</p>
<p>这样service更像是一个Facade，根据VO需要的业务逻辑请求类型调度业务逻辑对象BLO来完成业务处理，最后返回处理结果。一个BLO对应一个客户请求Action。</p>
<p><em>DAO</em></p>
<p>MyBatis实现的mapper接口代理就是DAO对象，每个表对应一个mapper接口，提供针对单表的CRUD操作，包括条件和批量操作。而PO就是简单的对应单表记录的POJO对象。DAO的方法参数尽量传递PO对象。</p>
<p>也可以为业务层面的对象DO/BO提供DAO操作类，这样BLO就可以直接将BO丢给DAO，而不用关心多表关联的操作了。</p>
<p><strong>可移植性</strong></p>
<p>业务逻辑的实现尽最大可能不用存储过程，当然有些后台作业，查询分析之类的还是用存储过程实现比较妥当，但应将存储过程的使用压缩到最少。<br>MyBatis的mapper映射要用可移植的SQL语句来实现，也就是要符合SQL标准。主要使用的数据库会是PostgreSQL,但也有可能会在Oracle上面运行，因此可移植性是很重要的。如果必要甚至会提供两套mapper接口，每一套针对不同的数据库。这方面Hibernate可能做的更好，因为完全隔离了SQL代码。</p>
<p><strong>通用组件</strong></p>
<p>登录和权限控制采用AOP方式,实现RBAC(Role-Based Access Control)模型，业务逻辑代码做到完全不用关心权限问题。对于字段级别的权限，通过拦截过滤要返回给客户的VO或BO对象中的字段，这样可以不侵入业务逻辑中，而且这样对于从各种数据源获取的数据都适用。</p>
<p>审计日志也通过AOP实现，通过拦截请求/响应的URL和携带的JSON数据记录审计日志。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>提取、修改、重建deb包</title>
    <url>/2010/10/11/extract-modify-rebuilde-deb-package/</url>
    <content><![CDATA[<p>以下皆以fglrx驱动deb包为例,fglrx文件夹用来存放解包后的所有文件,fglrx_8.753-0ubuntu1_amd64.deb为需要修改的deb包</p>
<a id="more"></a>
<p>创建fglrx文件夹<br>$ mkdir fglrx</p>
<p>解包deb<br>$dkpg-deb -x fglrx_8.753-0ubuntu1_amd64.deb fglrx</p>
<p>提取deb包控制信息<br>$dpkg-deb -e fglrx_8.753-0ubuntu1_amd64.deb fglrx/DEBIAN</p>
<p>修改fglrx目录下的相关文件后就可以重新打包为deb,名字随便,此处为new_fglrx.deb<br>$dpkg-deb -b fglrx new_fglrx.deb</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>FAL_CLIENT和FAL_SERVER参数详解</title>
    <url>/2011/11/01/fal-client-fal-server/</url>
    <content><![CDATA[<p>FAL_CLIENT和FAL_SERVER是配置dataguard用到的两个参数,FAL指获取归档日志(Fetch Archived Log)</p>
<a id="more"></a>
<p>在一定的条件下，或者因为网络失败，或者因为资源紧张，会在primary和standby之间产生裂隙，也就是有些归档日志没有及时的传输并应用到standby库。因为MRP(managed recovery process)/LSP(logical standby process)没有与primary直接通讯的能力来获取丢失的归档日志。因此这些gaps通过FAL客户和服务器来解决，由初始化参数定义FAL_CLIENT和FAL_SERVER。</p>
<p>FAL_SERVER指定一个Oracle Net service name,standby数据库使用这个参数连接到FAL server,这个参数适用于standby站点。比如,FAL_SERVER = PrimaryDB,此处PrimaryDB是一个TNS name,指向primary库。</p>
<p>FAL_CLIENT指定一个FAL客户端的名字，以便FAL Server可以引用standby库，这也是一个TNS name，primary库必须适当配置此TNS name指向stanby库。这个参数也是在standby库端设置。比如，FAL_CLIENT = StandbyDB,StandbyDB是standby库的TNS name。</p>
<p>FAL_CLIENT和FAL_SERVER应该成对设置或改变。</p>
<p>这两个参数只需在standby库设置，但也可以在primary库设置这两个参数，以方便switchover或failover时primary库转变为standby角色。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>FastCGI介绍</title>
    <url>/2011/04/22/fastcgi-intro/</url>
    <content><![CDATA[<p>FastCGI是web服务器与交互式应用程序之间的接口协议。</p>
<a id="more"></a>
<p>FastCGI是早期CGI(Common Gateway Interface)的进化,FastCGI的主要目标是减少web服务器与CGI程序接口之间的性能开销，允许服务器一次处理更多的web页面请求。</p>
<p><strong>历史渊源</strong></p>
<p>CGI是web服务器与外部应用程序的接口协议。CGI程序运行在与web服务器分离的单独进程中,web服务器的每一个请求到来时建立CGI进程，请求结束时销毁CGI进程。这种“每个请求建立一个新进程”的模型，使CGI程序十分容易实现，但是严重限制了效率和伸缩性。在负载很高时，操作系统的进程创建和销毁负担变的很重。此外，CGI进程模型限制了资源复用技术，比如重用数据库连接，内存缓冲等</p>
<p>为了克服CGI的这些缺陷，Open Market公司开发了FastCGI,1990年代中期在他们的服务器产品中第一次引入了FastCGI技术。Open Market起初开发FastCGI技术是为了与Netscape专有的，用于开发web应用程序的web服务器进程内API(NSAPI)竞争。</p>
<p>虽然最初由Open Market开发，FastCGI也被其他的一些web服务器实现。FastCGI与其他加速和简化服务器与应用程序通讯的技术产生了竞争。Apache的mod_perl和mod_php模块也在同一时期出现，并且很快流行起来。时至今日，这些不同的技术，也包括古老的CGI技术，都还在不同的场合使用。</p>
<p><strong>FastCGI实现</strong></p>
<p>相对于每个请求建立一个新的进程，FastCGI使用一个持续的进程来处理一系列的请求。这些进程归属于FastCGI服务器而不是web服务器。</p>
<p>为了满足一个请求，web服务器通过unix domain socket(FastCGI进程与web服务器在一台机器上)或者TCP连接(FastCGI进程在远程服务器上或者FastCGI进程与web服务器在一台机器上)向FastCGI进程发送环境变量信息和页面请求信息。FastCGI的回应通过原路返回给web服务器，web服务器随即向最终用户交付这个响应。连接可能在响应结束后关闭，但是web服务器和FastCGI服务进程是持续存在的。</p>
<p>每一个单独的FastCGI进程在它的生命周期内可以处理很多的请求，因此避免了每请求进程创建和销毁的开销。可以配置多个FastCGI服务器来增加可靠性和伸缩性。</p>
<p>web站点管理员和开发者会发现web应用程序从web服务器分离到FastCGI比起那些嵌入式的解释器比如mod_perl和mod_php等有更多的优势。这种分离允许web服务器和应用程序进程可以独立的重新配置和启动，对于一些繁忙的站点来说这很重要。不同类型的请求可以分发到为此种请求优化过的、更高效的专用FastCGI服务器处理。</p>
<p><strong>PHP-FPM</strong></p>
<p>PHP-FPM (FastCGI Process Manager)是PHP的一个FastCGI实现，从PHP 5.3.3开始php-fpm已经并入php core，随php一起发行。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
  </entry>
  <entry>
    <title>批量替换多个文件中的字符串</title>
    <url>/2014/06/11/files-batch-subtitute/</url>
    <content><![CDATA[<a id="more"></a>
<p>以替换google在线字体为国内CDN镜像为例：</p>
<p>1、使用find,sed以及grep</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;s/fonts\\.googleapis/fonts\\.useso/g&#x27;</span> \<span class="string">`find . xargs grep -rl &#x27;fonts.googleapis&#x27;\`</span></span><br></pre></td></tr></table></figure>

<p>2、使用find和perl</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find . xargs perl -pi -e <span class="string">&#x27;sfonts\\.googleapisfonts\\.usesog&#x27;</span></span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ perl -pi -e <span class="string">&#x27;sfonts\\.googleapisfonts\\.usesog&#x27;</span> \<span class="string">`find .\`</span></span><br></pre></td></tr></table></figure>

<p>3、不使用find也行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ grep oldString -rl /path xargs sed -i <span class="string">&quot;s/oldString/newString/g&quot;</span> </span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&quot;s/oldString/newString/g&quot;</span> \<span class="string">`grep oldString -rl /path\`</span></span><br></pre></td></tr></table></figure>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>查找可用的twitter hosts ip</title>
    <url>/2010/10/20/find-available-twitter-hosts-ip/</url>
    <content><![CDATA[<p>修改hosts ip来登录twitter是简单易行的方法之一,在linux平台上修改/etc/hosts文件,增加下面两行即可</p>
<a id="more"></a>
<p>xxx.xxx.xxx.xxx twitter.com<br>xxx.xxx.xxx.xxx api.twitter.com</p>
<p>当然一定要用https来访问,包括从浏览器和从客户端访问.但可用的ip经常被墙掉,下面就说一个查找可用IP的方法.</p>
<p>登录<a href="http://just-ping.com/%E6%88%96%E8%80%85%E6%AD%A4%E7%B1%BB%E6%8F%90%E4%BE%9B%E5%9C%A8%E7%BA%BFping%E7%BD%91%E5%9D%80%E7%9A%84%E7%BD%91%E7%AB%99,%E5%9C%A8%E7%BA%BFping%E4%B8%80%E4%B8%8Bapi.twitter.com,%E7%84%B6%E5%90%8E%E6%A0%B9%E6%8D%AEping%E8%A7%A3%E6%9E%90%E5%87%BA%E6%9D%A5%E7%9A%84ip%E5%9C%B0%E5%9D%80%E4%BB%8E%E6%9C%AC%E6%9C%BAping%E8%BF%87%E5%8E%BB,%E5%8F%AA%E8%A6%81%E8%83%BD%E6%9C%AC%E6%9C%BA%E8%83%BDping%E9%80%9A%E7%9A%84ip%E5%8D%B3%E5%8F%AF%E5%A1%AB%E5%85%A5hosts%E6%96%87%E4%BB%B6%E4%BD%BF%E7%94%A8">http://just-ping.com/或者此类提供在线ping网址的网站,在线ping一下api.twitter.com,然后根据ping解析出来的ip地址从本机ping过去,只要能本机能ping通的ip即可填入hosts文件使用</a>.</p>
<p>经过我的测试发现,使用gprs连接时所有的ip都ping不同,我还没遇到过通的,说明移动公司可能封了整个网段,太狠了.而通过联通的网络却可以ping通大部分ip,其他运营商尚未测试.</p>
<p>另: 如果网站上提到twitter这个敏感词太多会不会网站被墙掉啊? #FuckGFW</p>
<p>更新:果然“<a href="http://lordong.net/tools/getip.php">GFW对api.twitter.com的整个网段下手</a>”了</p>
]]></content>
      <categories>
        <category>Social</category>
      </categories>
      <tags>
        <tag>Twitter</tag>
      </tags>
  </entry>
  <entry>
    <title>find命令参照参考文件按指定时间或时间段查找文件</title>
    <url>/2012/05/27/find-files-according-time/</url>
    <content><![CDATA[<p>find有一个newer参数,可以用此参数按指定时间或时间段来查找文件</p>
<a id="more"></a>
<p>实际上有三个相关参数anewer,cnewer和newer,这三个参数后面都一个参照文件来分别比较其atime(access time),ctime(change time)和mtime(modify time),找出比参照文件更新的文件。</p>
<p>读取文件或者执行文件时更改文件的atime,文件的内容发生改变时系统会修改其mtime,在文件内容发生变化或者修改文件的属性,比如更改所有者、权限或链接设置时,随着文件索引节点Inode 的内容更改,系统修改其ctime。</p>
<p>所以找到一个合适的参照文件就可以按时间或时间段来查找文件,如果没有合适的参照文件,可以用touch来新建一个。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ touch -t <span class="number">201205280000</span> reference_file</span><br></pre></td></tr></table></figure>

<p>-t参数的格式为<br>-t stamp<br> use [[CC]YY]MMDDhhmm[.ss] instead of current time</p>
<p><strong>查找比参照文件新的所有文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find . -newer reference_file</span><br></pre></td></tr></table></figure>
<p>查找结果为比reference_file的mtime更新的文件,但不包含reference_file</p>
<p><strong>查找比参照文件旧的所有文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find . ! -newer reference_file</span><br></pre></td></tr></table></figure>
<p>查找结果包含reference_file</p>
<p><strong>查找比参照文件旧的所有文件并删除</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find . ! -newer reference_file -exec rm &#123;&#125; \\;</span><br><span class="line">$ find . -maxdepth <span class="number">1</span> ! -newer reference_file -a ! -name <span class="string">&#x27;tmp&#x27;</span> -exec mv &#123;&#125; tmp/&#123;&#125; \\; <span class="comment">/*查找到的文件(不包含tmp目录)移动到当前目录下的tmp目录*/</span></span><br></pre></td></tr></table></figure>
<p>查找结果包含reference_file</p>
<p><strong>查找指定时间段内的文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find . -newer reference_file_older -a ! -newer reference_file_newer</span><br></pre></td></tr></table></figure>
<p>查找比reference_file_older新但比reference_file_newer旧的所有文件,查找结果包含reference_file_newer,但不包含reference_file_older</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu:firefox 3.5 png图片颜色显示不正确</title>
    <url>/2009/07/05/firefox-3-5-png-color/</url>
    <content><![CDATA[<p>等不及ubuntu官方更新源,自己下载了firefox 3.5正式版,嗯,不错,感觉还挺爽。但是发了篇文章后，发现用firefox 3.5浏览文章里面的png图片出现了点儿小问题,彩色的png图片颜色变暗显示出来成灰度图像了,这就不爽了。</p>
<a id="more"></a>
<p>先说一下我的桌面环境，其他环境下有可能不会遇到该问题。<br>32bits ubuntu 9.04,en_US.UTF-8 locale,firefox 3.5 en<br>这个问题是由firefox的色彩校正(color correction)引起的,这应该不是firefox 3.5的bug,可能是因为没有找到正确的ICC(International Color Consortium) color profile配置文件造成的，现在解决这个问题最简单的办法是关闭色彩校正功能。<br>地址栏输入about:config,找到gfx.color_management.mode这个配置选项,将其值修改为0,重新启动firefox就可以了。<br>gfx.color_management.mode有3个选项,其含义如下:</p>
<ul>
<li>  0 - 关闭色彩校正 (firefox 3的默认值)</li>
<li>  1 - 为所有图片打开色彩校正功能</li>
<li>  2 - 仅为具备颜色标签的图片打开色彩校正功能 (firefox 3.5的默认值)</li>
</ul>
<p>还有一个选项gfx.color_management.display_profile用来指定ICC color profile,如果没有指定，firefox会查询操作系统，并使用操作系统使用的ICC color profile,此处的问题应该就是ubuntu提供的ICC color profile引起。</p>
<p>关于色彩校正更详细的说明,请查阅<a href="https://developer.mozilla.org/En/ICC_color_correction_in_Firefox">官方文档</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>Firefox中元素获取焦点函数focus不起作用的解决方法</title>
    <url>/2012/10/27/firefox-element-focus-not-work/</url>
    <content><![CDATA[<p>元素获取焦点函数focus()在IE中正常Firefox中却不起作用。</p>
<a id="more"></a>
<p>js校验输入框的函数<br>function is_number(feild){<br>    var strRegExp = /^\d+(\.\d{1,2})?$/;<br>    <strong>if</strong>(!strRegExp.test(feild.value)){<br>        <strong>alert</strong>(“请输入有效的数字,小数点后最多只能输入两位!”);<br>        feild.focus();<br>        <strong>return</strong> false;<br>    }<br>} </p>
<p>在IE中可以正常工作,在Firefox/(windows or linux)上却无法重新获取焦点。</p>
<p><strong>有两种解决办法:</strong></p>
<p>1、让元素先失去焦点再获取焦点<br>…<br>feild.blur();<br>feild.focus();<br>…</p>
<p>这种方法在Firefox/windows上行为是正常的,但在firefox/linux平台上仍然无法获取焦点</p>
<p>2、定时器<br>…<br>setTimeout(function(){feild.focus();},0);<br>…</p>
<p>这种方法在firefox/windows和firefox/linux平台上都可以正常工作。</p>
]]></content>
      <categories>
        <category>Firefox</category>
      </categories>
  </entry>
  <entry>
    <title>为firefox安装java插件</title>
    <url>/2012/03/14/firefox-java-plugin/</url>
    <content><![CDATA[<p>Debian AMD64系统,firefox 11安装java plugin</p>
<a id="more"></a>
<p>google docs上传文件夹需要安装java applet,已经安装了sun java 6 jdk和jre,但仍然提示firefox不支持java,只是因为friefox没有找到java plugin而已,在firefox查找的plugin目录下为java plugin建立一个符号链接即可</p>
<p>$cd ~/.mozilla/plugins<br>$sudo ln -sf /usr/lib/jvm/java-6-sun/jre/lib/amd64/libnpjp2.so .</p>
<p>然后restart firefox,在plugins页面已经可以看到Java(TM) Plug-in 1.6.0_26,google docs安装applet成功。</p>
<p>如果你使用openjdk那就更简单了,安装包icedtea-plugin就可以了</p>
<p>$sudo apt-get install icedtea-plugin</p>
<p>这个插件的名字叫IcedTea-Web Plugin</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>Firefox变身其他浏览器</title>
    <url>/2011/03/10/firefox-to-other-browsers/</url>
    <content><![CDATA[<p>很多移动应用程序官方网站不提供普通桌面下载链接,要求用手机去market、app store或者用手机浏览器去下载,如果想从电脑上下载怎么办呢？</p>
<a id="more"></a>
<p>Firefox插件User Agent Switcher可以做到。User Agent Switcher的原理就是切换Firefox浏览器向服务器报告的浏览器类型标志(User Agent)，从而使服务器把浏览器当作它自己报告的类型来处理。</p>
<p>　　安装好之后会在tools工具栏下面增加切换User Agent的项,插件默认带的User Agent很少,可以去<a href="http://techpatterns.com/forums/about304.html">这个地方</a>下载已经整理好的<a href="http://techpatterns.com/downloads/firefox/useragentswitcher.xml">User Agent xml</a>文件,然后从User Agent Switcher里选择Import导入此文件,这样浏览器类型就很全面了,切换User Agent后再浏览网站就可以了。<br><a href="/images/2011/03/user_agent_switcher.jpg"><img src="/images/2011/03/user_agent_switcher.jpg" title="user_agent_switcher"></a></p>
]]></content>
      <categories>
        <category>Firefox</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>linux无损flac与ape刻录音频CD及转换为320K mp3</title>
    <url>/2011/12/23/flac-ape-wav-audio-cd-320k-mp3/</url>
    <content><![CDATA[<p>flac与ape都是优秀的无损音频压缩格式,flac与开源平台的兼容性更好,有纠错能力,flac格式相比更有优势,而ape在国内十分流行。</p>
<a id="more"></a>
<p><strong>准备</strong></p>
<p>安装flac,ape解码器及转换工具shntool,cuetools,cue2toc当然还有大名鼎鼎的lame</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install flac monkeys-audio cuetools lame cue2toc</span><br></pre></td></tr></table></figure>
<p><strong>解码转换为wav文件</strong></p>
<p>先将flac和ape格式文件解码为PCM wav格式文件,方便刻录CD或编码为320K mp3文件</p>
<p>flac格式：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ shntool conv -o wav foo.flac</span><br><span class="line">或</span><br><span class="line">$ flac -d -o foo.wav foo.flac</span><br></pre></td></tr></table></figure>

<p>ape格式：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ shntool conv -o wav bar.ape</span><br></pre></td></tr></table></figure>

<p>这样在当前目录下生成同名的wav格式文件,也可以与find结合转换目录下所有的flac,ape文件</p>
<p><strong>刻录Audio CD</strong></p>
<p>安装刻录软件,如果命令行下刻录可以只安装cdrdao,图形界面的话brasero是很不错的选择</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install cdrdao brasero</span><br></pre></td></tr></table></figure>
<p>命令行下刻录audio CD需要先转换或者编辑一个toc(Table Of Content)文件,这是一个纯文本格式的文件,具体格式请参考cdrdao(1)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$cdrdao write --speed <span class="number">8</span> --eject -v <span class="number">2</span> --device /dev/cdrw foobar.toc</span><br></pre></td></tr></table></figure>
<p>使用brasero则简单的多,选择Audio CD project直接把wav文件添加到project,然后刻录就可以了</p>
<p><strong>编码为320K mp3格式</strong></p>
<p>无损格式占用空间很大,而且与320K的mp3音频质量差距很小,为了节约空间可以考虑编码为320K的mp3格式文件,mp3编码方面lame是当之无愧的老大,lame参数繁多,其预设的压缩模式就可以很好的满足要求</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lame --preset insane foo.wav</span><br></pre></td></tr></table></figure>
<p>这样就可以在当前目录下生成同名的音质极好的320K mp3文件foo.mp3</p>
<p><strong>update[07/11/2016]：lame可以直接解码flac格式的输入文件。</strong></p>
<p><strong>转换.cue文件为.toc文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cue2toc -d -o tocfile cuefile</span><br></pre></td></tr></table></figure>
<p>这样可以将整碟的cue文件转为toc文件,方面整碟刻录</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>flatpak简单介绍</title>
    <url>/2018/11/28/flatpak-intro/</url>
    <content><![CDATA[<a id="more"></a>
<p>GIMP改用flatpak打包，flatpak以前叫xdg-app，现在flatpak是指flat package吗?</p>
<p>flatpak是一种致力于减少依赖的通用应用打包格式，与之竞争的还有snap和AppImage</p>
<p><strong>安装</strong></p>
<p>flatpak已经进入debian当前的testing buster源和sid源， debian stretch可以从官方的backports源<code>deb http://ftp.tw.debian.org/debian stretch-backports main contrib non-free</code>安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ apt install flatpak</span><br></pre></td></tr></table></figure>

<p>添加flatpak官方源</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo flatpak remote-add --<span class="keyword">if</span>-not-exists flathub https:<span class="comment">//flathub.org/repo/flathub.flatpakrepo</span></span><br></pre></td></tr></table></figure>

<p>因为flatpak本身就是一种app打包格式，官方应该提供一个自举安装的shell脚本才显得更专业:)</p>
<p><strong>安装gimp</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ flatpak install https:<span class="comment">//flathub.org/repo/appstream/org.gimp.GIMP.flatpakref</span></span><br></pre></td></tr></table></figure>

<p>可以使用桌面图标运行，或者使用以下命令：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ flatpak run org.gimp.GIMP<span class="comment">//stable</span></span><br></pre></td></tr></table></figure>

<p><strong>flatpak文件系统布局</strong></p>
<p>flatpak支持系统范围安装和用户安装，系统安装在/var/lib/flatpak,<br>安装的app系统配置在/var/lib/flatpak/app，其他子目录为flatpak本身系统范围的配置<br>安装的app的当前用户配置在$HOME/.var/app，flatpak本身的当前用户配置在$HOME/.local/share/flatpak</p>
<p>References:<br>[1]<a href="https://flatpak.org/">Flatpak</a><br>[2]<a href="https://github.com/flatpak/flatpak/wiki/Filesystem">Flatpak filesystem layout</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>FlexBox布局模型</title>
    <url>/2014/03/03/flexbox-layout/</url>
    <content><![CDATA[<a id="more"></a>
<p>一直以来我们都是使用float,position还有早期的table来做页面布局。现在几乎没有人会用table布局了,但float和position仍然是布局的中坚力量。</p>
<p>虽然table,float,position可以用来布局, 但它们都不是布局元素,只是用它们来做布局比较方便罢了。这都是trick。</p>
<p>float的本意是图文混排时的环绕,而position则用于针对单个元素的定位,table则用于展示表格。不过运用一些巧妙的手段(所以叫做trick)可以做到页面布局而已。<br>但无疑这种布局方式是繁琐的,要经过复杂的计算,填各种浏览器的各种坑,最后得到的布局极有可能自适应性也是很差的。</p>
<p>那么什么叫布局(layout)呢?布局关心的不是单个的元素,布局着眼于如何从整体上划分页面,让划分后页面的各个部分自然的相互联系在一起。如果布局容器的尺寸发生变化,其子页面通过重排会自动的适应这种变化,无需任何额外的计算。设计布局时只要指定好布局的各项属性就可以了。</p>
<p>其实布局管理器的概念在桌面开发中已经出现了好多年了,比如java,gtk等都有各种可用的布局管理器。这二者的概念是比较相近的。</p>
<p>那么为什么要用table,float和position等来做布局呢？因为在以往没有其他更好的选择。但是现在不一样了,最新的CSS标准提供了几个真正的布局模块。其中当前已经可用的而且十分好用的是flex伸缩布局(Flexible Box Layout)。</p>
<p>flex伸缩布局已于09/18/2012进入CR(Candidate Recommendation)状态,当前各大浏览器对flex布局的支持已经基本上十分完善。IE10使用旧版的flex语法,<br>firefox要到版本28才支持flex多行布局,也就是支持flex-wrap属性的wrap和wrap-reverse。safari还在使用浏览器前缀-webkit-,opera则完整的支持最新的语法。firefox 28差不多两周就可以发布了。如果不考虑那些老旧的、到处是坑的IE浏览器,现在已经可以正式的使用flex布局了。拥抱标准,大胆的抛弃那些“上古神兵”吧！</p>
<p><strong>flex伸缩布局</strong></p>
<p><strong>基础概念</strong></p>
<ul>
<li>  布局轴线<br>传统上，行内布局采用水平轴,而块布局使用垂直轴。flex伸缩布局使用了完全不同的概念。flex采用主轴(main axis)和侧轴(cross axis)来管理布局,而且主轴和侧轴的方向并不是固定的。看下面的两张图:<br><img src="http://www.w3.org/html/ig/zh/wiki/images/b/bf/Flex-direction-terms-new.zh-hans.png" alt="flex axis"><br><img src="https://developer.mozilla.org/files/3739/flex_terms.png" alt="flex axis"><br>主轴有可能是水平的也有可能是垂直的,而侧轴一定时垂直于主轴的。主轴的水平/垂直方向由flex-direction决定,取值row和row-reverse时,主轴是水平的。此时水平的主轴还有从左到右和从右到左之分,这依赖于writing-mode的取值。一般来讲,常见的文字都是left to right方向的,此时主轴的方向是从左到右的。第一张图就是最常见的情形,主轴水平从左到右,所有的flex子元素沿主轴排列布局。</li>
<li>  flex布局容器(container)<br>flex布局需要一个布局容器,容器内的子元素按既定规则在容器内排列。flex支持多层嵌套布局,也就是flex容器内的子元素也可以成为其子元素的布局容器。声明一个flex布局容器十分简单:<br>[css]<br>display: flex;<br>display: -webkit-flex<br>[/css]</li>
<li>  flex子元素(items)<br>在flex容器内部的子元素按指定的规则进行排列。直接包含在flex容器内的文本自动的被一个匿名flex item包裹,如果匿名的flex子元素只包含空白,那么这个匿名子元素是不显示的,被指定属性display:none。<br>相邻flex子元素的margin不会被折叠(collapse)</li>
</ul>
<p><strong>flex布局容器属性</strong></p>
<ul>
<li><p>  flex-direction<br>指定flex容器主轴的方向,取值:</p>
</li>
<li><p>  row<br>主轴为水平的,其水平上的方向依赖于writing-mode指定的值,默认为left to right,子元素按水平上的方向依次排列。</p>
</li>
<li><p>  row-reverse<br>主轴为水平的,其水平上的方向与writing-mode指定的值刚好相反。比如writing-mode指定为left to right,则其主轴水平方向为从右到左。子元素则从右到左依次排列。</p>
</li>
<li><p>  column<br>主轴为垂直的,其垂直上的方向与writting-mode指定的方向相同。</p>
</li>
<li><p>  column-reverse<br>主轴为垂直的,其垂直上的方向与writting-mode指定的方向相反。</p>
</li>
<li><p>  flex-wrap<br>指定flex容器是否可以换行,取值:</p>
</li>
<li><p>  nowrap<br>不能换行,如果flex items过宽则溢出容器。</p>
</li>
<li><p>  wrap<br>flex items可以在容器内换行,新行的方向与writtng-mode指定的方向相同。firefox从版本28开始才支持。</p>
</li>
<li><p>  wrap-reverse<br>flex items可以在容器内换行,新行的方向与writting-mode指定的方向相反。firefox从版本28开始才支持。</p>
</li>
<li><p>  justify-content<br>主轴方向上对齐flex items,取值:</p>
</li>
<li><p>  flex-start<br>flex items沿主轴起始方向按指定顺序排列</p>
</li>
<li><p>  flex-end<br>flex items靠主轴结束方向按指定顺序排列</p>
</li>
<li><p>  center<br>flex items在主轴方向上靠容器中间按指定顺序排列</p>
</li>
<li><p>  space-between<br>容器内剩余的空间在flex items之间平均分配,第一个flex item和最后一个flex item与容器边缘之间没有空隙。</p>
</li>
<li><p>  space-around<br>容器内剩余的空间在flex items以及flex item与容器边缘之间平均分配。也就是所有flex items之间,flex item与容器边缘之间都有相同的空隙。</p>
</li>
<li><p>  align-items<br>侧轴方向上对齐flex items,取值:</p>
</li>
<li><p>  flex-start<br>flex items沿侧轴起始方向排列。</p>
</li>
<li><p>  flex-end<br>flex items沿侧轴结束方向排列。</p>
</li>
<li><p>  center<br>flex items沿侧轴居中排列。</p>
</li>
<li><p>  baseline<br>flex items沿侧轴方向依照其基线排列。</p>
</li>
<li><p>  stretch<br>flex items沿侧轴拉伸排列。</p>
</li>
<li><p>  align-content<br>当在侧轴上有空间时,如何对齐flex容器内的多行flex items,如果flex容器内只有单行子元素,则此属性无效。取值:</p>
</li>
<li><p>  flex-start<br>容器内的多行靠测轴起始方向并排排列。</p>
</li>
<li><p>  flex-end<br>容器内的多行靠侧轴结束方向并排排列。</p>
</li>
<li><p>  center<br>容器内的多行沿测轴居中并排排列。</p>
</li>
<li><p>  space-between<br>侧轴方向的空白平均分配到容器内的多行之间,第一行与容器边缘以及最后一行与容器边缘之间没有空隙。</p>
</li>
<li><p>  space-around<br>侧轴方向的空白平均分配到各行以及行与容器边缘之间,子元素行与行之间,已经行与容器边缘之间有相同的空隙。</p>
</li>
<li><p>  stretch<br>容器内的行沿侧轴方向拉伸,自由空间平均分配到各行。</p>
</li>
<li><p>  flex-flow<br>flex-flow为flex-direction和flex-wrap的组合缩写属性,其格式为:<br>[css]<br>flex-flow: flex-direction flex-wrap;<br>[/css]</p>
</li>
</ul>
<p><strong>flex布局子元素属性</strong></p>
<ul>
<li>  order<br>指定flex item在容器内的显示顺序。无需修改html源代码即可为flex item指定新的显示次序,但是语音与导航仍然使用源代码中的顺序,因此这个属性有可能会破坏文档的可访问性(accessibility)。</li>
<li>  flex<br>指定子元素的扩展因子,收缩因子和伸缩基准值。其格式为:<br>[css]<br>flex: flex-grow flex-shrink flex-basis<br>[/css]<br>flex-grow为正向伸展比例因子,主轴方向上的剩余空间会按比例分配到各个flex itme。初始值为0,指定负数无效。<br>flex-shrink为负向收缩比例因子,当flex items在主轴方向上将会溢出容器时,每个item会按指定的收缩比例因子进行收缩,从而防止items溢出容器。初始值为1,指定负数无效。<br>flex-basis指定子元素的伸缩基准值。在伸缩基准值的基础上,剩余空间或空间不足时按伸展比例因子或收缩比例因子进行按比例伸缩。<br>flex属性是这三个属性的组合缩写,也可以单独指定这些属性。</li>
<li>  align-self<br>子元素覆盖容器的align-items属性,如果子元素在侧轴方向的margin设置为auto,则此属性被忽略。</li>
<li>  margin<br>margin指定为auto会合并剩余的空间,可以使item水平和垂直都居中。也可以通过在容器上使用align-items:center;justify-content:center;来使item水平垂直居中。</li>
</ul>
<p><strong>不影响flex布局的公共属性</strong><br>float,clear,vertical-align属性对flex items没有影响。对item指定float属性只是使其display值计算为block。</p>
<p>References:<br>[1]<a href="https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Flexible_boxes">Using CSS flexible boxes</a><br>[2]<a href="http://hikejun.com/blog/2013/05/03/%E4%B8%80%E8%A7%88css%E5%B8%83%E5%B1%80%E6%A0%87%E5%87%86/">一览CSS布局标准</a><br>[3]<a href="http://msdn.microsoft.com/zh-cn/library/ie/hh673531(v=vs.85).aspx">Internet Explorer 10 中弹性框（“Flexbox”）布局</a><br>[4]<a href="http://msdn.microsoft.com/zh-cn/library/ie/dn265027(v=vs.85).aspx">弹性框（“Flexbox”）布局更新</a><br>[5]<a href="http://zh.learnlayout.com/">学习CSS布局</a><br>[6]<a href="http://www.w3cplus.com/css3/using-flexbox.html">使用Flexbox：新旧语法混用实现最佳浏览器兼容</a><br>[7]<a href="http://www.cnblogs.com/yansi/p/3335916.html">flexbox 布局使用体会</a><br>[8]<a href="http://dev.oupeng.com/articles/advanced-cross-browser-flexbox">跨浏览器弹性布局进阶教程</a><br>[9]<a href="http://www.w3cplus.com/css/master-new-css-layout-properties.html">Hold住CSS布局新属性</a><br>[10]<a href="http://the-echoplex.net/flexyboxes/">Flexy Boxes</a><br>[11]<a href="http://www.w3cplus.com/css3/responsive-design-of-the-future-with-flexbox.html">响应式设计的未来——Flexbox</a><br>[12]<a href="http://dev.oupeng.com/articles/flexbox-basics">伸缩布局 — 打开布局天堂之门？</a></p>
<p>===<br><strong>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>手动强制卸载broken包</title>
    <url>/2019/12/26/force-remove-broken-package/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mv /<span class="keyword">var</span>/lib/dpkg/info/PACKAGE_NAME.* <span class="regexp">/tmp/</span></span><br><span class="line">$ sudo dpkg --remove --force-remove-reinstreq PACKAGE_NAME</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>GCC编译链接时移除未使用的代码</title>
    <url>/2018/11/30/gcc-remove-unused-code/</url>
    <content><![CDATA[<a id="more"></a>
<p>编译时把数据和函数放到单独的section中，然后链接的时候抛弃掉未使用的section就可以了。</p>
<p>也就是组合使用CFLAGS: <code>-ffunction-sections -fdata-sections</code> 和 LDFLAGS: <code>-Wl,--gc-sections</code></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cc foo.c -o foo -Os -fdata-sections -ffunction-sections -Wl,--gc-sections -s</span><br></pre></td></tr></table></figure>

<p>-s 选项剥离掉调试信息，可以进一步减小目标文件的尺寸。</p>
<p>References:<br>[1]<a href="https://embeddedfreak.wordpress.com/2009/02/10/removing-unused-functionsdead-codes-with-gccgnu-ld/">Removing Unused Functions/Dead Codes with GCC/GNU-ld</a><br>[2]<a href="http://gcc.gnu.org/ml/gcc-help/2003-08/msg00128.html">Re: Removing unused functions/dead code</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>为Gerrit2添加verified label</title>
    <url>/2014/01/21/gerrit-add-verified-label/</url>
    <content><![CDATA[<a id="more"></a>
<p>gerrit从2.6开始,默认不再添加verified category,也就是changes上就看不到verified label了。</p>
<p>具体的原因见gerrit的<a href="https://gerrit-review.googlesource.com/#/c/44084/">Change 44084</a>。这是为了简化out of the box工作流,如果需要与jenkins等CI环境集成,则需要手动添加verified category,只要在All-Projects的project.config文件里添加5行文本就可以了。</p>
<p><strong>添加V标签</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mkdir temp &amp;&amp; cd temp</span><br><span class="line">$ git clone ssh:<span class="comment">//cr/All-Projects.git</span></span><br><span class="line"></span><br><span class="line">Cloning into <span class="string">&#x27;All-Projects&#x27;</span>...</span><br><span class="line">remote: Counting objects: <span class="number">22</span>, done</span><br><span class="line">remote: Finding sources: <span class="number">100</span>% (<span class="number">22</span>/<span class="number">22</span>)</span><br><span class="line">remote: Total <span class="number">22</span> (delta <span class="number">1</span>), reused <span class="number">6</span> (delta <span class="number">1</span>)</span><br><span class="line">Receiving objects: <span class="number">100</span>% (<span class="number">22</span>/<span class="number">22</span>), <span class="number">5.33</span> KiB <span class="number">0</span> bytes/s, done.</span><br><span class="line">Resolving deltas: <span class="number">100</span>% (<span class="number">1</span>/<span class="number">1</span>), done.</span><br><span class="line">Checking connectivity... done.</span><br><span class="line">Note: checking out <span class="string">&#x27;a30b5de24cdd7993bbe3398e57b1cb771cbb1fc2&#x27;</span>.</span><br><span class="line"></span><br><span class="line">You are <span class="keyword">in</span> <span class="string">&#x27;detached HEAD&#x27;</span> state. You can look around, make experimental</span><br><span class="line">changes and commit them, and you can discard any commits you make <span class="keyword">in</span> <span class="built_in">this</span></span><br><span class="line">state without impacting any branches by performing another checkout.</span><br><span class="line"></span><br><span class="line">If you want to create a <span class="keyword">new</span> branch to retain commits you create, you may</span><br><span class="line"><span class="keyword">do</span> so (now or later) by using -b <span class="keyword">with</span> the checkout command again. Example:</span><br><span class="line"></span><br><span class="line"> git checkout -b new_branch_name</span><br><span class="line"></span><br><span class="line">$ cd All-Projects</span><br><span class="line">$ vim project.config</span><br></pre></td></tr></table></figure>
<p>在文件project.config中添加如下5行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[label <span class="string">&quot;Verified&quot;</span>\]</span><br><span class="line"> <span class="function"><span class="keyword">function</span> = <span class="title">MaxWithBlock</span></span></span><br><span class="line"><span class="function"> <span class="title">value</span> = -1 <span class="title">Fails</span></span></span><br><span class="line"><span class="function"> <span class="title">value</span> = 0 <span class="title">No</span> <span class="title">score</span></span></span><br><span class="line"><span class="function"> <span class="title">value</span> = +1 <span class="title">Verified</span></span></span><br></pre></td></tr></table></figure>

<p>然后提交到远程仓库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git commit -a -m <span class="string">&quot;add verified category&quot;</span></span><br><span class="line">$ git push origin HEAD:refs/meta/config</span><br><span class="line"></span><br><span class="line">Counting objects: <span class="number">15</span>, done.</span><br><span class="line">Delta compression using up to <span class="number">4</span> threads.</span><br><span class="line">Compressing objects: <span class="number">100</span>% (<span class="number">3</span>/<span class="number">3</span>), done.</span><br><span class="line">Writing objects: <span class="number">100</span>% (<span class="number">3</span>/<span class="number">3</span>), <span class="number">323</span> bytes <span class="number">0</span> bytes/s, done.</span><br><span class="line">Total <span class="number">3</span> (delta <span class="number">1</span>), reused <span class="number">0</span> (delta <span class="number">0</span>)</span><br><span class="line">remote: Resolving deltas: <span class="number">100</span>% (<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">remote: Processing changes: refs: <span class="number">1</span>, done </span><br><span class="line">To ssh:<span class="comment">//cr/All-Projects.git</span></span><br><span class="line"> 93dc4d8..22b46f7 HEAD -&gt; refs/meta/config</span><br></pre></td></tr></table></figure>
<p>因为在分离头(detached HEAD)状态,所以手工指定将当前HEAD push到远程引用refs/meta/config。</p>
<p>登录gerrit站点,changes上面就有V标签了。</p>
<p><a href="https://gerrit-review.googlesource.com/Documentation/config-labels.html#label_Verified">verified label</a>的用法见官方文档。</p>
<p>References:<br>[1]<a href="http://blog.bruin.sg/2013/04/how-to-edit-the-project-config-for-all-projects-in-gerrit/">HOW TO EDIT THE PROJECT.CONFIG FOR ALL PROJECTS IN GERRIT</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Gerrit项目权限设置</title>
    <url>/2014/01/23/gerrit-privilege-setup/</url>
    <content><![CDATA[<p>Gerrit新建项目的权限继承自内置项目All-Projects,默认的权限已经十分完善,但仍然需要做一些微调来满足实际的需要。</p>
<a id="more"></a>
<p>但是不要动All-Projects的默认权限,只修改本项目的权限,可以覆盖掉不想要的继承来的权限和添加新的权限。</p>
<p><strong>master分支</strong></p>
<p>项目的master分支默认只有administrators和Project Owners可以不经代码审核直接推送,但是允许其他用户向master分支推送changes接受评审。这里调整为Registered Users组用户不能向master推送changes,而只能向devel分支推送changes。devel分支的权限默认即可。项目只有两个常设分支master和devel,日常开发只在devel分支上,只有管理员才能touch master分支。</p>
<p>Project-&gt;list(选定项目)-&gt;Access-&gt;Edit-&gt;Add Reference</p>
<p>reference的名字为:refs/for/refs/heads/master,然后添加push权限,添加组”Registered Users”,选择对应的push权限为deny,同时勾选Exclusive，覆盖掉该ref继承和被通配符所涵盖的权限。</p>
<p><strong>Code Review和submit</strong></p>
<p>gerrit默认只给Registered Users组用户Code View -1分到1分的权限,这样Registered Users组用户就无法独立完成代码审核,而developer都集中在这个组中,因此将其Code View权限调整为-2分到2分。而且改组用户没有submit的权限,无法合并补丁到仓库中,下面一并添加submit权限。</p>
<p>Project-&gt;list(选定项目)-&gt;Access-&gt;Edit-&gt;Add Reference</p>
<p>reference的名字为:refs/heads/*,然后添加Label Code-Review,添加组”Registered Users”,将其权限调整为-2 ~ 2。然后再添加Submit权限,添加组”Registered Users”,其权限为ALLOW。</p>
<p><strong>sandbox分支</strong></p>
<p>个人分支还是十分有必要的,在开发成果还没有达到可以参加评审之前,用户可以在个人分支暂存自己的代码。stash暂存区并不能替代个人分支。Gerrit也考虑到了这一点,可以通过配置为每个开发者提供一个独立的区域,可以不用参与代码评审,完全是个人私有的领域。</p>
<p>添加如下引用:<br>refs/heads/sandbox/${username}/*<br>然后选择权限Create Reference和push,让”Registered Users”组对应的权限皆为ALLOW就可以了。</p>
<p><strong>调整后的权限</strong></p>
<p><img src="/downloads/gerrit_priv.png" alt="gerrit privillege"></p>
<p>References:<br>[1]<a href="https://gerrit-documentation.storage.googleapis.com/Documentation/2.8.1/user-changeid.html">Gerrit Code Review - Access Controls</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Gerrit工作流</title>
    <url>/2014/01/21/gerrit-workflow/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>账户配置</strong></p>
<p>提交到gerrit的changes中的用户名和邮箱地址必须与gerrit用户信息一致,否则会被拒绝,除非有Forge XXX权限。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git config --<span class="built_in">global</span> user.name <span class="string">&quot;username&quot;</span></span><br><span class="line">$ git config --<span class="built_in">global</span> user.email <span class="string">&quot;mailbox@domain.tld&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>克隆gerrit仓库</strong><br>一般来说为ssh主机设置别名可以省很多事,不用每次输入复杂的远程仓库地址了:</p>
<p>~/.ssh/config文件中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Host cr</span><br><span class="line"> Hostname review.domain.tld</span><br><span class="line"> User admin</span><br><span class="line"> Port <span class="number">29418</span></span><br><span class="line"> #如果私钥名字为id_rsa,可以省略下面一行</span><br><span class="line"> IdentityFile ~<span class="regexp">/.ssh/</span>admin_rsa</span><br></pre></td></tr></table></figure>

<p>然后可以这样克隆远程仓库了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone ssh:<span class="comment">//cr/project</span></span><br></pre></td></tr></table></figure>
<p>而且以后都可以使用cr这个别名来代替远程gerrit仓库地址</p>
<p><strong>安装commit-msg钩子</strong></p>
<p>commit-msg是gerrit提供的钩子脚本,会为每个提交添加Change-Id行。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ scp cr:hooks/commit-msg .git/hooks/</span><br></pre></td></tr></table></figure>

<p><strong>提交changes</strong></p>
<p>首先checkout出devel分支。根据不同的策略,master有可能是禁止推送更新的。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ git checkout devel</span><br><span class="line">$ git remote update #更新远程仓库</span><br></pre></td></tr></table></figure>

<p>经过一段时间的工作,有了commit后,就可以将commit提交到服务器接受代码审核。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push origin HEAD:refs/<span class="keyword">for</span>/devel</span><br></pre></td></tr></table></figure>

<p>直接git push推送到远程devel分支是被禁止的,推送到refs/for/devel会在gerrit服务器上生成新的需要评审的changes。</p>
<p>可以通过增加一个远程配置来进一步简化命令行:</p>
<p>.git/config中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[remote <span class="string">&quot;review&quot;</span>\]</span><br><span class="line"> url = ssh:<span class="comment">//cr/project</span></span><br><span class="line"> push = HEAD:refs/<span class="keyword">for</span>/devel</span><br></pre></td></tr></table></figure>

<p>之后就可以这样推送changes了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push review</span><br></pre></td></tr></table></figure>

<p><strong>使用git-review</strong></p>
<p>git-review是针对gerrit的一个命令</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install git-review</span><br></pre></td></tr></table></figure>

<p>git-review默认使用gerrit远程仓库别名</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git remote add gerrit ssh:<span class="comment">//cr/project</span></span><br></pre></td></tr></table></figure>

<p>然后在工程根目录下建立git-review配置文件.gitreview</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">\[gerrit\]</span><br><span class="line"> host=review.domain.tld</span><br><span class="line"> port=<span class="number">29418</span></span><br><span class="line"> project=project_name</span><br><span class="line"> defaultbranch=devel #提交changes到devel分支,也就是推送到refs/for/devel</span><br><span class="line"> defaultremote=gerrit #默认即为gerrit</span><br><span class="line"> defaultrebase=0 #默认提交前不执行rebase操作</span><br></pre></td></tr></table></figure>
<p>最后通过</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git review</span><br></pre></td></tr></table></figure>
<p>就可以推送changes了。</p>
<p><strong>verify和code review</strong></p>
<p>通过不应该通过开发人员进行verify,CI服务器会在changes提交后自动进行verify。<br>Code Review可以通过gerrit web接口进行。通过verify和code review的changes可以通过submit合并到目标分支。</p>
<p><strong>个人分支</strong></p>
<p>如果gerrit服务器提供了sandbox个人分支,那么可以将自己的阶段性工作保存在sandbox中而不用提交到gerrit服务器进行评审,直到感觉可以参加评审时再向devel分支提交changes。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git checkout devel</span><br><span class="line">$ git checkout -b sandbox/yourname/foo</span><br><span class="line">$ git push --set-upstream origin sandbox/yourname/foo</span><br><span class="line">...</span><br><span class="line">$ git push</span><br></pre></td></tr></table></figure>

<p>一般来说为了devel分支的整洁,建议先在个人分支工作,等工作比较成熟后再合并回devel分支,然后再向gerrit服务器推送changes。</p>
<p>References:<br>[1]<a href="https://gerrit-documentation.storage.googleapis.com/Documentation/2.8.1/user-upload.html">Gerrit Code Review - Uploading Changes</a><br>[2]<a href="https://gerrit-documentation.storage.googleapis.com/Documentation/2.8.1/user-changeid.html">Gerrit Code Review - Change-Ids</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Gerrit2安装配置</title>
    <url>/2014/01/16/gerrit2-setup/</url>
    <content><![CDATA[<p>Gerrit是用于Git版本控制系统的代码审核系统。</p>
<a id="more"></a>
<p><strong>下载</strong></p>
<p>当前最新版本的gerrit为2.8.1,从<a href="http://gerrit-releases.storage.googleapis.com/index.html">官方下载</a>二进制war包即可。</p>
<p><strong>数据库设置</strong></p>
<p>gerrit可以使用H2,PostgreSQL,MySql和Oracle数据库。这个安装使用PostgreSQL数据库。</p>
<p>创建gerrit使用的用户和数据库:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ createuser --username=postgres -RDIElPS gerrit2</span><br><span class="line">$ createdb --username=postgres -E UTF-<span class="number">8</span> -O gerrit2 reviewdb</span><br></pre></td></tr></table></figure>
<p>这里使用PostgreSQL提供的shell工具,也可以登录PostgreSQL使用psql来CREATE ROLE和CREATE DATABASE。</p>
<p><strong>创建用户</strong></p>
<p>为gerrit创建单独的用户gerrit2,用于运行gerrit,但是禁止gerrit2用户登录系统。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># adduser gerrit2</span><br><span class="line"># passwd --delete gerrit2</span><br></pre></td></tr></table></figure>

<p><strong>安装</strong></p>
<p>切换到gerrit2用户,使用gerrit2主目录下的review目录作为gerrit site的根目录</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># sudo su - gerrit2</span><br><span class="line"># java -jar gerrit-2.8.1.war init -d review</span><br></pre></td></tr></table></figure>

<p>进入交互式安装,具体的安装配置如下:</p>
<p>[bash gutter=”false”]<br><strong>* Gerrit Code Review 2.8.1<br>*</strong> 选项中大写字母为默认选项,如使用默认选项回车即可</p>
<p>Create ‘/home/gerrit2/review’ [Y/n]? </p>
<p><strong>* Git Repositories<br>*</strong> gerrit用于存储git仓库的目录,相对于根目录review</p>
<p>Location of Git repositories [git]: </p>
<p>*** SQL Database</p>
<hr>
<p>Database server type [h2]: postgresql<br>Server hostname [localhost]:<br>Server port [(postgresql default)]:<br>Database name [reviewdb]:<br>Database username [gerrit2]:<br>gerrit2’s password :<br> confirm password : </p>
<p><strong>* User Authentication<br>*</strong> 使用HTTP认证,OPENID需要服务器连接互联网,还可以使用LDAP认证服务</p>
<p>Authentication method [OPENID/?]: http<br>Get username from custom HTTP header [y/N]?<br>SSO logout URL : </p>
<p><strong>* Email Delivery<br>*</strong> gerrit发送邮件设置,可以使用本地或远程SMTP服务器,<br>*** 只要在smtp服务器上有帐号即可。</p>
<p>SMTP server hostname [localhost]: mail.openwares.net<br>SMTP server port [(default)]: 25<br>SMTP encryption [NONE/?]: tls<br>SMTP username [gerrit2]: <a href="mailto:&#x67;&#x65;&#114;&#114;&#105;&#x74;&#x32;&#64;&#111;&#112;&#x65;&#x6e;&#x77;&#x61;&#x72;&#101;&#115;&#46;&#110;&#101;&#116;">&#x67;&#x65;&#114;&#114;&#105;&#x74;&#x32;&#64;&#111;&#112;&#x65;&#x6e;&#x77;&#x61;&#x72;&#101;&#115;&#46;&#110;&#101;&#116;</a><br><a href="mailto:&#103;&#101;&#x72;&#114;&#105;&#x74;&#x32;&#64;&#x6f;&#112;&#x65;&#x6e;&#119;&#x61;&#114;&#x65;&#x73;&#x2e;&#x6e;&#x65;&#x74;">&#103;&#101;&#x72;&#114;&#105;&#x74;&#x32;&#64;&#x6f;&#112;&#x65;&#x6e;&#119;&#x61;&#114;&#x65;&#x73;&#x2e;&#x6e;&#x65;&#x74;</a>‘s password :<br> confirm password : </p>
<p><strong>* Container Process<br>*</strong> 使用gerrit2用户运行gerrit</p>
<p>Run as [gerrit2]:<br>Java runtime [/usr/lib/jvm/java-7-openjdk-amd64/jre]:<br>Copy gerrit-2.8.1.war to /home/gerrit2/review/bin/gerrit.war [Y/n]?<br>Copying gerrit-2.8.1.war to /home/gerrit2/review/bin/gerrit.war</p>
<p><strong>* SSH Daemon<br>*</strong> gerrit自带的ssh服务,与服务器自身的ssh服务无关,监听默认端口即可<br>*** 注意:如要使用低于1024的特权端口,需authbind授权,否则ssh会绑定端口失败<br>Listen on address [*]:<br>Listen on port [29418]: </p>
<p>Gerrit Code Review is not shipped with Bouncy Castle Crypto v144<br> If available, Gerrit can take advantage of features<br> in the library, but will also function without it.<br>Download and install it now [Y/n]?<br>Downloading <a href="http://www.bouncycastle.org/download/bcprov-jdk16-144.jar">http://www.bouncycastle.org/download/bcprov-jdk16-144.jar</a> … OK<br>Checksum bcprov-jdk16-144.jar OK<br>Generating SSH host key … rsa… dsa… done</p>
<p><strong>* HTTP Daemon<br>*</strong> 这里使用nginx反向代理gerrit,所以只在loop接口监听即可。<br>*** 如果使用域名访问gerrit,最好将规范URL设置为域名形式,发送校验邮件时会使用到</p>
<p>Behind reverse proxy [y/N]? y<br>Proxy uses SSL (https://) [y/N]?<br>Subdirectory on proxy server [/]:<br>Listen on address [*]: 127.0.0.1<br>Listen on port [8081]:<br>Canonical URL [<a href="http://127.0.0.1//]:http://review.domain.tld/">http://127.0.0.1/\]:http://review.domain.tld/</a></p>
<p><strong>* Plugins<br>*</strong> 选装插件</p>
<p>Install plugin download-commands version v2.8.1 [y/N]?<br>Install plugin reviewnotes version v2.8.1 [y/N]?<br>Install plugin replication version v2.8.1 [y/N]?<br>Install plugin commit-message-length-validator version v2.8.1 [y/N]? </p>
<p>Initialized /home/gerrit2/review<br>Executing /home/gerrit2/review/bin/gerrit.sh start<br>Starting Gerrit Code Review:<br><strong>* 因为为ssh服务选在了低于1024的端口,且没有authbind端口授权,所以会出现如下错误,高于1024端口不会。<br>*</strong> FAILED<br><strong>* error: cannot start Gerrit: exit status 1<br>Waiting for server on 127.0.0.1:80 … OK<br>*</strong> 服务器上没有X,所以使用浏览器打开连接失败<br>Opening <a href="http://127.0.0.1/#/admin/projects/">http://127.0.0.1/#/admin/projects/</a> …FAILED<br>Open Gerrit with a JavaScript capable browser:<br> <a href="http://127.0.0.1/#/admin/projects/">http://127.0.0.1/#/admin/projects/</a></p>
<p>*** 交互式安装完毕</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">**gerrit自启动服务**</span><br><span class="line"></span><br><span class="line">添加&#x2F;etc&#x2F;default&#x2F;gerritcodereview文件,其内容如下:</span><br><span class="line">GERRIT_SITE&#x3D;&#x2F;path&#x2F;to&#x2F;gerrit</span><br><span class="line"></span><br><span class="line">然后</span><br><span class="line"></span><br><span class="line">&#96;&#96;&#96;js</span><br><span class="line"># ln -sf &#x2F;home&#x2F;gerrit2&#x2F;review&#x2F;bin&#x2F;gerrit.sh &#x2F;etc&#x2F;init.d&#x2F;gerrit</span><br><span class="line"># ln -sf &#x2F;etc&#x2F;init.d&#x2F;gerrit &#x2F;etc&#x2F;rc3.d&#x2F;S90gerrit</span><br></pre></td></tr></table></figure>

<p><strong>nginx配置</strong></p>
<p>使用nginx反向代理gerrit,并且nginx承担http认证,gerrit不会对用户进行认证。gerrit将http认证成功后第一个登录的用户作为管理员,其他用户皆为普通用户。用户第一次http认证成功后,gerrit会为用户生成同名的gerrit用户,只要进一步完善账户即可。比如添加email和公钥。管理员为其他普通用户授权。</p>
<p><em>nginx反向代理配置</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123; </span><br><span class="line"> listen <span class="number">80</span>;</span><br><span class="line"> server_name review.domain.tld;</span><br><span class="line"> location / &#123;</span><br><span class="line"> auth_basic <span class="string">&quot;Gerrit2 Code Review&quot;</span>;</span><br><span class="line"> auth_basic_user_file /home/gerrit2/htpasswd.conf;</span><br><span class="line"> proxy_pass http:<span class="comment">//127.0.0.1:8081;</span></span><br><span class="line"> proxy_set_header X-Forwarded-For $remote_addr;</span><br><span class="line"> proxy_set_header Host $host;</span><br><span class="line"> &#125;</span><br><span class="line"> location /login/ &#123;</span><br><span class="line"> proxy_pass http:<span class="comment">//127.0.0.1:8081;</span></span><br><span class="line"> proxy_set_header X-Forwarded-For $remote_addr;</span><br><span class="line"> proxy_set_header Host $host;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><em>http认证文件</em></p>
<p>使用htpasswd命令为管理云用户生成http认证配置文件,如果没有htpasswd文件需要安装apache2-utils包。</p>
<h1 id="htpasswd-d-htpasswd-conf-admin"><a href="#htpasswd-d-htpasswd-conf-admin" class="headerlink" title="htpasswd -d htpasswd.conf admin"></a>htpasswd -d htpasswd.conf admin</h1><p>以后添加gerrit用户时,同样需要先为其配置http认证,然后用户登录后gerrit会为其自动生成用户帐号,名字与http认证名字一致。</p>
<p><strong>账户配置</strong></p>
<p>第一次成功登录的用户会被gerrit作为管理员用户。登录后点击右上角的”匿名懦夫”Anonymous Coward -&gt; Settings来配置账户。</p>
<p><em>电子邮件</em></p>
<p>选择左侧Contact Information页签,添加用户全称。然后注册新邮件Register New Email,输入管理员的邮件地址后,gerrit会向新邮箱发送<br>校验邮件,校验通过后才是有效的邮箱。这时候安装时配置Canonical URL就有用处了,校验邮件的域名部分就是Canonical URL,如果当时配置的是<a href="http://127.0.0.1/,%E9%82%A3%E8%BF%99%E6%97%B6%E5%80%99%E5%B0%B1%E8%A6%81%E6%89%8B%E5%B7%A5%E4%BF%AE%E6%94%B9%E5%9F%9F%E5%90%8D%E9%83%A8%E5%88%86%E5%86%8D%E6%89%A7%E8%A1%8C%E9%AA%8C%E8%AF%81%E4%BA%86%E3%80%82">http://127.0.0.1/,那这时候就要手工修改域名部分再执行验证了。</a></p>
<p>发送校验邮件有时候不太方便,可以使用gerrit提供的远程ssh shell来为用户添加有效邮箱。当然首先管理员要添加了SSH公钥才能远程访问gerrit的ssh shell。<br>语法如下:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ssh review gerrit set-account --add-email username@openwares.net username</span><br></pre></td></tr></table></figure>
<p>这是review是.ssh/config中配置的远程ssh主机别名。</p>
<p>也可以通过直接修改gerrit数据库表的方式来添加用户邮件,但这活着实有点儿脏,不建议使用。</p>
<p><em>SSH公钥</em></p>
<p>要使用gerrit必须要提供用户的公钥。选择页面左侧的SSH Public Keys为当前用户添加公钥。直接将公钥粘贴到Add SSH Public Key框内,然后点击add即可。<br>之后用户就可以用ssh来访问gerrit了。当然无法登录服务器,只能使用gerrit提供的shell。</p>
<p><strong>添加其他普通账户</strong></p>
<p>如果采用http认证,那么添加其他账户时,需要现添加http认证账户。用htpasswd创建的用户时，并没有往gerrit中添加账号，只有当该用户通过web登陆gerrit服务器时,该账号才会被添加进gerrit数据库中。使用http认证方式,不要使用gerrit ssh shell命令来新增用户,通过http认证第一次认证成功的用户,gerrit会为其自动创建账户,之后只要完善账户就可以了。使用ssh shell创建的用户无法与http认证后自动创建的用户关联起来,即是二者的用户名是完全一样的。</p>
<p>其他用户帐号的配置与管理员的配置方式一样。</p>
<p><strong>SSH访问gerrit</strong></p>
<p>添加ssh公钥后就可以使用ssh来使用gerrit了。</p>
<h1 id="ssh-p-29418-i-ssh-id-rsa-gerrit-x61-100-x6d-105-110-64-114-x65-x76-105-101-119-x2e-x64-111-109-x61-105-110-46-116-x6c-x64"><a href="#ssh-p-29418-i-ssh-id-rsa-gerrit-x61-100-x6d-105-110-64-114-x65-x76-105-101-119-x2e-x64-111-109-x61-105-110-46-116-x6c-x64" class="headerlink" title="ssh -p 29418 -i ~/.ssh/id_rsa.gerrit &#x61;&#100;&#x6d;&#105;&#110;&#64;&#114;&#x65;&#x76;&#105;&#101;&#119;&#x2e;&#x64;&#111;&#109;&#x61;&#105;&#110;&#46;&#116;&#x6c;&#x64;"></a>ssh -p 29418 -i ~/.ssh/id_rsa.gerrit <a href="mailto:&#x61;&#100;&#x6d;&#105;&#110;&#64;&#114;&#x65;&#x76;&#105;&#101;&#119;&#x2e;&#x64;&#111;&#109;&#x61;&#105;&#110;&#46;&#116;&#x6c;&#x64;">&#x61;&#100;&#x6d;&#105;&#110;&#64;&#114;&#x65;&#x76;&#105;&#101;&#119;&#x2e;&#x64;&#111;&#109;&#x61;&#105;&#110;&#46;&#116;&#x6c;&#x64;</a></h1><p>如果私钥名字为id_rsa可以不用使用-i参数。为ssh主机配置别名访问起来更简单,~/.ssh/config文件中添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Host review</span><br><span class="line"> Hostname review.domain.tld</span><br><span class="line"> User admin</span><br><span class="line"> Port <span class="number">29418</span></span><br><span class="line"> #如果私钥名字为id_rsa,可以省略下面一行</span><br><span class="line"> IdentityFile ~<span class="regexp">/.ssh/i</span>d_rsa.gerrit</span><br></pre></td></tr></table></figure>

<p>这样ssh访问gerrit就可以了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ssh review</span><br><span class="line">**** Welcome to Gerrit Code Review ****</span><br><span class="line"></span><br><span class="line"> Hi username, you have successfully connected over SSH.</span><br><span class="line"></span><br><span class="line"> Unfortunately, interactive shells are disabled.</span><br><span class="line"> To clone a hosted Git repository, <span class="attr">use</span>:</span><br><span class="line"></span><br><span class="line"> git clone ssh:<span class="comment">//admin@review.domain.tld:29418/REPOSITORY_NAME.git</span></span><br><span class="line"></span><br><span class="line">Connection to review.tafdc.org closed.</span><br></pre></td></tr></table></figure>
<p>查看gerrit shell帮助</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ssh review gerrit --help</span><br><span class="line">gerrit \[COMMAND\] \[ARG ...\] \[--\] \[--help (-h)\]</span><br><span class="line"></span><br><span class="line"> -- : end <span class="keyword">of</span> options</span><br><span class="line"> --help (-h) : display <span class="built_in">this</span> help text</span><br><span class="line"></span><br><span class="line">Available commands <span class="keyword">of</span> gerrit are:</span><br><span class="line"></span><br><span class="line"> ban-commit Ban a commit <span class="keyword">from</span> a project<span class="string">&#x27;s repository</span></span><br><span class="line"><span class="string"> create-account Create a new batch/role account</span></span><br><span class="line"><span class="string"> create-group Create a new account group</span></span><br><span class="line"><span class="string"> create-project Create a new project and associated Git repository</span></span><br><span class="line"><span class="string"> flush-caches Flush some/all server caches from memory</span></span><br><span class="line"><span class="string"> gc Run Git garbage collection</span></span><br><span class="line"><span class="string"> gsql Administrative interface to active database</span></span><br><span class="line"><span class="string"> ls-groups List groups visible to the caller</span></span><br><span class="line"><span class="string"> ls-members Lists the members of a given group</span></span><br><span class="line"><span class="string"> ls-projects List projects visible to the caller</span></span><br><span class="line"><span class="string"> ls-user-refs List refs visible to a specific user</span></span><br><span class="line"><span class="string"> plugin </span></span><br><span class="line"><span class="string"> query Query the change database</span></span><br><span class="line"><span class="string"> receive-pack Standard Git server side command for client side git push</span></span><br><span class="line"><span class="string"> rename-group Rename an account group</span></span><br><span class="line"><span class="string"> review Verify, approve and/or submit one or more patch sets</span></span><br><span class="line"><span class="string"> set-account Change an account&#x27;</span>s settings</span><br><span class="line"> set-members Modifies members <span class="keyword">of</span> specific group or number <span class="keyword">of</span> groups</span><br><span class="line"> set-project Change a project<span class="string">&#x27;s settings</span></span><br><span class="line"><span class="string"> set-project-parent Change the project permissions are inherited from</span></span><br><span class="line"><span class="string"> set-reviewers Add or remove reviewers on a change</span></span><br><span class="line"><span class="string"> show-caches Display current cache statistics</span></span><br><span class="line"><span class="string"> show-connections Display active client SSH connections</span></span><br><span class="line"><span class="string"> show-queue Display the background work queues, including replication</span></span><br><span class="line"><span class="string"> stream-events Monitor events occurring in real time</span></span><br><span class="line"><span class="string"> test-submit </span></span><br><span class="line"><span class="string"> version Display gerrit version</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">See &#x27;</span>gerrit COMMAND --help<span class="string">&#x27; for more information.</span></span><br></pre></td></tr></table></figure>
<p><strong>导入现存git代码库</strong></p>
<p>最简单的办法就是直接将现在的git裸仓库拷贝到gerrit管理的仓库目录下</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#cp -r /path/to/old.git /path/to/gerrit/git/</span><br></pre></td></tr></table></figure>

<p>或者稍微繁琐一些的方法：在gerrit中新建一个project,不要做init commit,然后将新建的仓库做为已经存在仓库的远程仓库,然后push就可以了。<br>可以设置gerrit该仓库不经过审核,就可以直接将整个仓库push过来了。</p>
<p><strong>gitweb集成</strong></p>
<p>debian系统只要安装了gitweb包, gerrit就可以自动关联到gitweb,通过gitweb来浏览git仓库。</p>
<h1 id="apt-get-install-gitweb"><a href="#apt-get-install-gitweb" class="headerlink" title="apt-get install gitweb"></a>apt-get install gitweb</h1><p><strong>其他问题</strong></p>
<p><strong>SMTP证书</strong></p>
<p>如果为gerrit配置的SMTP服务器是SSL/TLS加密的,并且SMTP服务器的证书是自签的,当gerrit试图发送邮件时会抛出异常:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sun.security.validator.ValidatorException: PKIX path building failed: </span><br><span class="line">sun.security.provider.certpath.SunCertPathBuilderException: </span><br><span class="line">unable to find valid certification path to requested target</span><br></pre></td></tr></table></figure>

<p>因为自签的证书是不受信任的,最简单的解决办法就是告诉gerrit不要校验STMP服务的证书:</p>
<p>编辑~/review/etc/gerrit.config,添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[sendmail\]</span><br><span class="line"> sslverify=<span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>或者更复杂的解决办法,将SMTP的SSL证书添加到JAVA的truststore里,参考[3]里有对此问题的详细描述。</p>
<p><strong>Sign Out</strong></p>
<p>使用http认证登录gerrit后,并无法通过点击”Sign Out”退出登录,只能通过直接关闭浏览器窗口来退出当前会话。</p>
<p><strong>如果需要重新安装gerrit,记得将数据库drop掉再重新创建。</strong></p>
<p>References:<br>[1]<a href="https://gerrit-documentation.storage.googleapis.com/Documentation/2.8.1/index.html">Gerrit Code Review for Git</a><br>[2]<a href="http://blog.csdn.net/benkaoya/article/details/8680886">烤鸭的gerrit使用总结</a><br>[3]<a href="http://blog.163.com/guaiguai_family/blog/static/20078414520124224465323/">代码评审系统 ReviewBoard 和 Gerrit (下)</a> </p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git裸仓库设置默认分支</title>
    <url>/2014/03/25/git-bare-repository-set-defaut-branch/</url>
    <content><![CDATA[<a id="more"></a>
<p>删除一个远程分支时出现错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push --<span class="keyword">delete</span> origin foobar</span><br></pre></td></tr></table></figure>
<p>remote: error: By default, deleting the current branch is denied, because the next<br>remote: error: ‘git clone’ won’t result in any file checked out, causing confusion.<br>remote: error:<br>remote: error: You can set ‘receive.denyDeleteCurrent’ configuration variable to<br>remote: error: ‘warn’ or ‘ignore’ in the remote repository to allow deleting the<br>remote: error: current branch, with or without a warning message.<br>remote: error:<br>remote: error: To squelch this message, you can set it to ‘refuse’.<br>remote: error: refusing to delete the current branch: refs/heads/foobar<br>To cisvr:<del>/reis.git<br> ! [remote rejected] foobar (deletion of the current branch prohibited)<br>error: failed to push some refs to ‘cisvr:</del>/reis.git’</p>
<p>也就是foobar是远程仓库的当前分支(由于使用<code>git clone --bare</code>生成裸仓库造成的),因为远程仓库是裸仓库,所以不能使用普通的git checkout命令切换分支。在裸仓库中使用如下命令来切换当前分支:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git symbolic-ref HEAD refs/heads/devel</span><br></pre></td></tr></table></figure>
<p>这样就将裸仓库的当前分支切换为devel分支,删除foobar分支就没问题了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push origin :foobar</span><br></pre></td></tr></table></figure>
<p>这个命令实质上是修改了.git/HEAD文件,使其内容为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ref: refs/heads/devel</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>命令行获取macos系统相关信息</title>
    <url>/2020/02/23/get-macos-sysinfo-from-shell/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="http://teczd.com/2015/09/23/osx-get-system-info-from-command-line/">Get OS X System Info from the Command Line</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>git分支策略模型</title>
    <url>/2014/01/21/git-brantch-model/</url>
    <content><![CDATA[<a id="more"></a>
<p>荷兰程序员<a href="http://nvie.com/about/">Vincent Driessen</a>的A successful Git branching model[1]对于集中式的中小型项目是一个相当不错的分支模型。他还制作了一副pdf大图<a href="http://nvie.com/files/Git-branching-model.pdf">Git-branching-model</a>。</p>
<p><strong>分支模型</strong></p>
<p>有两个常设分支,master和devel(或叫develop,or whatever)。master分支用于最终产品发布,而devel分支用于日常开发。</p>
<p>其他临时性分支包括特性分支feature或叫topic分支,预发布分支release,热补丁分支hotfix。</p>
<p>feature用于新功能开发,分支自devel,新功能开发完毕必须merge回devel分支,或者不再需要此特性,直接丢弃分支。命名方式一般为feature-特性名或者特性编号。</p>
<p>release用于产品正式发布前的预发布,分支自devel。命名方式一般为release-(即将发布的版本号),比如release-1.2。release分支功能上不应该再发生变化,只是一些小的完善或者bug的修复还有实施版本策略。确认版本可以发布后,将release合并到master,并在master上打版本tag。release同时要合并回devel分支,之后可以删除release分支。</p>
<p>hotfix用于正式发布产品的紧急bug修复,分支自master。命名方式一般为hotfix-bug编号,比如hotfix-1312,bug编号来自bug tracking系统,比如<a href="http://trac.edgewall.org/">Trac</a>。bug修复完毕后,将hotfix分支合并回master分支,并更新产品号以及打新的tag。如果当前存在release分支,则应将hotfix合并到release分支而不是master分支。hotfix还需要合并回devel分支。之后可以将hotfix分支删除。</p>
<p>合并分支时使用- -no-ff选项,不让分支fast forwarding以保持完整清晰的版本历史。</p>
<p><strong>个人分支</strong></p>
<p>除了常设分支和临时分支外,每个开发人员还可以设立自己的个人分支(personal branch)。个人分支以自己的名字命名,分支自devel。个人分支方便开发人员保存和在不同机器间同步未最终完成的工作成果,代码重构,并且可以减少devel分支的commit,保持devel分支的整洁。个人分支上的工作告一段落后,更新本地代码库,将个人分支上的工作成果合并到devel分支,然后推送devel分支到中央仓库。</p>
<p><strong>代码审核</strong></p>
<p>master分支只有项目管理员可以touch,其他开发人员无法向master推送更新。而开发人员向devel分支推送的更新必须经过<a href="https://code.google.com/p/gerrit/">gerrit</a>代码审核服务器,在通过其他开发人员的code review和CI服务器的自动verify后,才可以正式merge到devel分支。</p>
<p>其他临时分支和个人分支不经过gerrit,直接进入中央仓库。</p>
<p><strong>持续集成</strong></p>
<p>每当开发人员向devel推送更新,这在gerrit叫做change,CI服务器会自动对新提交的change进行编译和运行单元测试,根据结果给于适当的verify值。</p>
<p>当代码通过审核merge到devel后,自动触发CI服务器,拉取devel分支,然后编译部署到测试环境进行自动化测试和人工测试。</p>
<p>而master分支发布产品时也可以通过触发CI进行自动编译和部署到产品环境。</p>
<p>References:<br>[1]<a href="http://nvie.com/posts/a-successful-git-branching-model/">A successful Git branching model</a><br>[2]<a href="http://www.ruanyifeng.com/blog/2012/07/git.html">Git分支管理策略</a><br>[3]<a href="http://yedingding.com/2013/09/11/practical-git-flow-for-startups.html">实用 Git 工作流</a><br>[4]<a href="http://www.uml.org.cn/pzgl/201112163.asp">一个成功的Git分支模型</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git diff,git apply和patch小问题三则</title>
    <url>/2014/03/07/git-diff-git-apply-patch/</url>
    <content><![CDATA[<p>使用补丁维护git仓库时遇到的小问题</p>
<a id="more"></a>
<p>1、包含二进制文件时的diff和apply</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">foo$ git diff HEAD^..HEAD &gt; foobar.patch</span><br><span class="line"></span><br><span class="line">bar$ git apply foobar.patch</span><br><span class="line">...</span><br><span class="line">error: cannot apply binary patch to <span class="string">&#x27;root/images/back_disabled.png&#x27;</span> without full index line</span><br><span class="line">error: root/images/back_disabled.png: patch does not apply</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>git apply提示错误,无法应用补丁。是因为普通的diff格式文件是不支持二进制文件的,新增的或者发生变化的二进制文件无法在diff文件中体现。git扩展了diff使其支持二进制格式,生成补丁时指定选项<code>--binary</code>即可,生成的文件可以顺利的git apply。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git diff HEAD^..HEAD --binary &gt; foobar.patch</span><br></pre></td></tr></table></figure>

<p>2、git apply的空白问题</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git apply foobar.patch</span><br><span class="line">foobar.patch:<span class="number">271</span>: trailing whitespace.</span><br><span class="line">foobar.patch:<span class="number">465</span>: space before tab <span class="keyword">in</span> indent.</span><br><span class="line"> .paging_full_numbers a.paginate_active &#123;</span><br><span class="line">warning: squelched <span class="number">1705</span> whitespace errors</span><br><span class="line">warning: <span class="number">1710</span> lines add whitespace errors.</span><br></pre></td></tr></table></figure>

<p>看看git apply(1)手册上怎么说:</p>
<blockquote>
<ul>
<li>-whitespace=<br>When applying a patch, detect a new or modified line that has whitespace errors. What are considered whitespace errors is controlled by core.whitespace configuration. By default, trailing whitespaces (including lines that solely consist of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors.</li>
</ul>
<p>By default, the command outputs warning messages but applies the patch. When git-apply is used for statistics and not applying a patch, it defaults to nowarn.</p>
<p>You can use different values to control this behavior:</p>
<p>nowarn — turns off the trailing whitespace warning.</p>
<p>warn — outputs warnings for a few such errors, but applies the patch as-is (default).</p>
<p>fix — outputs warnings for a few such errors, and applies the patch after fixing them (strip is a synonym — the tool used to consider only trailing whitespace characters as errors, and the fix involved stripping them, but modern gits do more).</p>
<p>error — outputs warnings for a few such errors, and refuses to apply the patch.</p>
<p>error-all — is similar to error but shows all errors.</p>
</blockquote>
<p>git apply应用补丁时会检测空白错误,默认情况下,尾部空白,包含空白的空行,初始tab缩进之后紧跟的空白字符会被认为是错误。<br>处理这个错误的行为由命令行参数<code>--whitespace</code>或者core.whitespace配置来控制,共有5种可能的动作:</p>
<ul>
<li>  nowarn<br>关闭错误提示</li>
<li>  warn<br>输出部分错误提示,但完整的应用补丁,不会处理错误,这是默认动作。</li>
<li>  fix<br>输出部分错误,修正错误后应用补丁</li>
<li>  error<br>输出部分错误,拒绝应用补丁。</li>
<li>  error-all<br>输出全部的错误,拒绝应用补丁。</li>
</ul>
<p>3、patch命令无法处理含有空白的文件名</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ patch p1 &lt; foobar.patch</span><br><span class="line">can<span class="string">&#x27;t find file to patch at input line 716</span></span><br><span class="line"><span class="string">Perhaps you used the wrong -p or --strip option?</span></span><br><span class="line"><span class="string">The text leading up to this was:</span></span><br><span class="line"><span class="string">--------------------------</span></span><br><span class="line"><span class="string">diff --git a/root/images/Sorting icons.psd b/root/images/Sorting icons.psd</span></span><br><span class="line"><span class="string">new file mode 100644</span></span><br><span class="line"><span class="string">index 0000000..53b2e06</span></span><br><span class="line"><span class="string">Binary files /dev/null and b/root/images/Sorting icons.psd differ</span></span><br><span class="line"><span class="string">--------------------------</span></span><br><span class="line"><span class="string">File to patch: </span></span><br><span class="line"><span class="string">Skip this patch? \[y\] </span></span><br></pre></td></tr></table></figure>

<p>因为diff文件中的文件名含有空格,patch命令无法应用这样的diff补丁。应该避免使用带有特殊字符的文件名。<br>当然patch也无法引用二进制diff补丁,使用普通diff格式生成含有二进制文件的补丁时,patch会应用成功,但生成的二进制文件是空的。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git私有小团队工作流程</title>
    <url>/2014/03/27/git-flow/</url>
    <content><![CDATA[<p>git的工作流程可以多种多样。</p>
<a id="more"></a>
<p>由于git分布式的天性,其工作流程可以灵活的随意变化。根据项目性质和团队大小可以有最适合的工作流程。<br>这里简单记录一下小团队私有项目的多人协作git工作流程,也是最简单的流程。</p>
<p>推荐的分支模型见<a href="https://openwares.net/linux/git_brantch_model.html">git分支策略模型</a></p>
<p>git工作流程:</p>
<ol>
<li><p>克隆仓库</p>
 <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone gitsvr:foobar</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果不在devel分支,则切换到devel分支<br> 开发人员只能向devel分支推送更新,master只有管理员可以推送。</p>
</li>
<li><p>创建以自己名字命名的个人私有分支</p>
 <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git checkout -b myname</span><br></pre></td></tr></table></figure>
</li>
<li><p>在私有分支上工作,做本地提交,当有成果要提交到devel分支时,先从上游拉取devel最新的成果<br> 然后将自己个人私有分支上的成果合并到devel,在解决可能存在的冲突后,将devel分支推送到服务器</p>
 <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git checkout devel</span><br><span class="line">$ git pull</span><br><span class="line">$ git merge --no-ff myname</span><br><span class="line">$ git push</span><br></pre></td></tr></table></figure>
<p> 向devel合并自己分支的成果时要使用<code>--no-ff</code>选项,防止快速前进合并,使devel分支的提交历史保持干净。<br> 如果本地的devel分支已经在tracking远程的devel分支,则git pull/push命令都不用指名分支规范,可以使用下面的命令为本地分支设置跟踪的上游分支:</p>
 <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git branch --set-upstream devel origin/devel</span><br></pre></td></tr></table></figure>
</li>
<li><p> 转到第4步</p>
</li>
</ol>
<p>如果需要代码审核与持续集成,可以参考<a href="https://openwares.net/linux/git_gerrit_gradle_jenkins_integration.html">Git+Gerrit+Gradle+Jenkins持续集成</a></p>
<p>References:<br>[1]<a href="http://git-scm.com/book/zh/%E5%88%86%E5%B8%83%E5%BC%8F-Git-%E4%B8%BA%E9%A1%B9%E7%9B%AE%E4%BD%9C%E8%B4%A1%E7%8C%AE#%E7%A7%81%E6%9C%89%E7%9A%84%E5%B0%8F%E5%9E%8B%E5%9B%A2%E9%98%9F">私有的小型团队</a><br>[2]<a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/0013760174128707b935b0be6fc4fc6ace66c4f15618f8d000">多人协作</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git+Gerrit+Gradle+Jenkins持续集成</title>
    <url>/2014/01/21/git-gerrit-gradle-jenkins-integration/</url>
    <content><![CDATA[<p>Jenkins是开源的CI(Continuous Integration)服务器。</p>
<a id="more"></a>
<p>Jenkins有丰富的插件,可以完成工程的自动构建,自动测试,自动部署等。CI的好处无需多言。</p>
<p>这里选用Git作为版本控制系统,使用Gerrit审核代码,使用Gradle进行系统构建,然后使用Jenkins将这几者集成在一起。</p>
<p>当向Gerrit推送更新时,会触发Jenkins进行编译测试,也就是为Gerrit做代码的verify工作,Jenkins会调用Gradle来编译代码,verify的结果Jenkins会自动反馈到Gerrit服务器。</p>
<p>当代码通过审核合并到代码库后也可以触发Jenkins来编译通过审核的代码,然后将编译结果自动部署到测试服务器进行人工或自动化测试。</p>
<p><strong>安装插件</strong></p>
<p>需要安装的插件有git plugin,gerrit trigger,gradle plugin和Deploy Plugin(Deploy to container Plugin)</p>
<p>Manage Jenkins -&gt; Plugin Manager -&gt; Available,可以通过filter定位到以上插件,点选安装即可。</p>
<p><strong>在gerrit服务器上为jenkins添加账户并授权</strong></p>
<p>当有事件触发时,jenkins要访问gerrit服务器,拉取代码,并反馈构建结果,因此需要为jenkins分配帐号。</p>
<p><em>生成密钥对</em></p>
<p>使用官方源安装的jenkins,用户主目录在/var/lib/jenkins,因此在这个目录下生成jenkins所需的公私密钥对。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># cd /var/lib/jenkins</span><br><span class="line"># mkdir .ssh</span><br><span class="line"># ssh-keygen -b 2048 -t rsa -f .ssh/id_rsa</span><br></pre></td></tr></table></figure>

<p><em>使用gerrit shell为jenkins 添加账户</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh cr gerrit create-account jenkins --ssh-key - &lt; id_rsa.pub</span><br></pre></td></tr></table></figure>

<p>id_rsa.pub是jenkins的公钥。</p>
<p><em>为jenkins用户授权</em></p>
<p>将jenkins添加到Non-Interactive Users组中,在工程权限管理的页签:</p>
<ul>
<li>  新增refs/*引用,将其read权限授予Non-Interactive Users</li>
<li>  新增refs/heads/*应用,将其Label Verified权限授予Non-Interactive Users</li>
<li>  确保Global Capabilities-&gt;Stream Events访问权限授予Non-Interactive Users,gerrit2.8.1默认已经授权,如果没有需要手动添加。</li>
</ul>
<p><strong>在jenkins上添加需要访问的gerrit服务器</strong></p>
<p>Manage Jenkins -&gt; Gerrit Trigger -&gt; Add New Server,填写相关字段,以下字段必填:</p>
<ul>
<li>name<br>给gerrit服务器起个名字</li>
<li>  Hostname<br>gerrit服务器的主机名,比如review.domain.tld</li>
<li>  Frontend URL<br>通过什么URL可以直接访问到gerrit,比如<a href="http://review.domain.tld/">http://review.domain.tld/</a></li>
<li>  SSH Port<br>Gerrit服务器的SSH服务端口,比如29418</li>
<li>  Username<br>Jenkins访问Gerrit服务器使用的账户名,填入在gerrit服务器为jenkins分配的账户名,比如jenkins</li>
<li>  SSH Keyfile<br>访问Gerrit SSH的私钥,默认使用/var/lib/jenkins/.ssh/id_rsa</li>
</ul>
<p>之后点击保存就可以了。</p>
<p><strong>添加为gerrit服务的verify工作</strong></p>
<p>点击jenkins左侧导航栏的New Job,输入job name,然后选择Build a free-style software project。配置如下:</p>
<ul>
<li><p>  Source Code Management<br>选择git<br>Repositories -&gt; Repository URL 输入访问git仓库的ssh路径,比如ssh://jenkins@review.domain.tld:29418/project.git<br>Repositories -&gt; Refspec 点击advance可以看到,这里输入$GERRIT_REFSPEC,这个值来自gerrit trigger的设置。<br>Branches to build -&gt; Branch Specifier (blank for ‘any’) 输入$GERRIT_BRANCH,同样来自gerrit trigger的设置。</p>
</li>
<li><p>  Build Triggers<br>选择Gerrit event</p>
</li>
<li><p>  Gerrit Trigger<br>Choose a server 选择前面步骤配置好的gerrit服务器<br>Trigger on 选择Patchset Created,当提交新的patchset后,jenkins自动为gerrit做verify工作。</p>
</li>
<li><p>  Gerrit Project<br>type选择plain,pattern输入工程名字,后面的branches一栏,type选plain,pattern输入devel(需要拉取的分支)</p>
</li>
<li><p>  Build<br>下拉选择invoke gradle script,然后选择invoke gradle就可以了。</p>
</li>
</ul>
<p>这样一个工作就配置完成了,每次gerrit服务接收到开发人员提交的changes,都会通知jenkins,自动verify就行了,不要开发人员去手工编译工程。</p>
<p>这是个自动触发的任务,手动触发会出现错误,因为手动触发时$GERRIT_REFSPEC变量没有定义:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Started by user anonymous</span><br><span class="line">Building <span class="keyword">in</span> workspace /<span class="keyword">var</span>/lib/jenkins/jobs/xxx_devel/workspace</span><br><span class="line">Fetching changes <span class="keyword">from</span> the remote Git repository</span><br><span class="line">Fetching upstream changes <span class="keyword">from</span> ssh:<span class="comment">//jenkins@review.domain.tld:29418/xxx.git</span></span><br><span class="line">FATAL: Failed to fetch <span class="keyword">from</span> ssh:<span class="comment">//jenkins@review.domain.tld:29418/xxx.git</span></span><br><span class="line">hudson.plugins.git.GitException: Failed to fetch <span class="keyword">from</span> ssh:<span class="comment">//jenkins@review.domain.tld:29418/xxx.git</span></span><br><span class="line">at hudson.plugins.git.GitSCM.fetchFrom(GitSCM.java:<span class="number">625</span>)</span><br><span class="line"> ...</span><br><span class="line">Caused by: hudson.plugins.git.GitException: Command <span class="string">&quot;git fetch --tags --progress </span></span><br><span class="line"><span class="string">ssh://jenkins@review.domain.tld:29418/xxx.git $GERRIT_REFSPEC&quot;</span> returned status code <span class="number">128</span>:</span><br><span class="line">stdout: </span><br><span class="line">stderr: fatal: Couldn<span class="string">&#x27;t find remote ref $GERRIT_REFSPEC</span></span><br></pre></td></tr></table></figure>

<p><strong>自动部署</strong></p>
<p>上面的工程只是测试新的提交能不能通过编译测试,编译结果没必要发布到测试服务器。但是当新的代码被合并到仓库后,可以自动触发jenkins编译,执行单元测试,然后将构建结果自动部署到tomcat应用服务器。</p>
<p><em>设置tomcat管理</em></p>
<p>安装tomcat管理组件</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install tomcat7-admin</span><br></pre></td></tr></table></figure>

<p>/etc/tomcat7/tomcat-users.xml添加:<br>[xml]<br> <role rolename="manager-gui" /><br> <user username="tomcat7" password="tomcat7" roles="manager-gui" /><br>[/xml]<br>重启tomcat7后才能登录管理界面<a href="http://domain.tld/manager/html">http://domain.tld/manager/html</a></p>
<p>如果不安装tomcat管理组件，自动部署时会出现类似的错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Deploying /<span class="keyword">var</span>/lib/jenkins/jobs/dc/workspace/build/libs/reis.war to container Tomcat <span class="number">7.</span>x Remote</span><br><span class="line">ERROR: Build step failed <span class="keyword">with</span> exception</span><br><span class="line">org.codehaus.cargo.container.ContainerException: Failed to redeploy \[<span class="regexp">/var/</span>lib/jenkins/jobs/dc/workspace/build/libs/reis.war\]</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.redeploy(AbstractTomcatManagerDeployer.java:<span class="number">193</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.deploy(CargoContainerAdapter.java:<span class="number">73</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">116</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">991</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">969</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.redeploy(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.plugins.deploy.DeployPublisher.perform(DeployPublisher.java:<span class="number">61</span>)</span><br><span class="line">at hudson.tasks.BuildStepMonitor$3.perform(BuildStepMonitor.java:<span class="number">45</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:<span class="number">779</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:<span class="number">726</span>)</span><br><span class="line">at hudson.model.Build$BuildExecution.post2(Build.java:<span class="number">185</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:<span class="number">671</span>)</span><br><span class="line">at hudson.model.Run.execute(Run.java:<span class="number">1766</span>)</span><br><span class="line">at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:<span class="number">43</span>)</span><br><span class="line">at hudson.model.ResourceController.execute(ResourceController.java:<span class="number">98</span>)</span><br><span class="line">at hudson.model.Executor.run(Executor.java:<span class="number">408</span>)</span><br><span class="line">Caused by: java.io.FileNotFoundException: http:<span class="comment">//192.168.0.8:8080/manager/text/list</span></span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:<span class="number">1835</span>)</span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:<span class="number">1440</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.invoke(TomcatManager.java:<span class="number">544</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.list(TomcatManager.java:<span class="number">686</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.getStatus(TomcatManager.java:<span class="number">699</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.redeploy(AbstractTomcatManagerDeployer.java:<span class="number">174</span>)</span><br><span class="line">... <span class="number">16</span> more</span><br><span class="line">java.io.FileNotFoundException: http:<span class="comment">//192.168.0.8:8080/manager/text/list</span></span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:<span class="number">1835</span>)</span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:<span class="number">1440</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.invoke(TomcatManager.java:<span class="number">544</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.list(TomcatManager.java:<span class="number">686</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.getStatus(TomcatManager.java:<span class="number">699</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.redeploy(AbstractTomcatManagerDeployer.java:<span class="number">174</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.deploy(CargoContainerAdapter.java:<span class="number">73</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">116</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">991</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">969</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.redeploy(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.plugins.deploy.DeployPublisher.perform(DeployPublisher.java:<span class="number">61</span>)</span><br><span class="line">at hudson.tasks.BuildStepMonitor$3.perform(BuildStepMonitor.java:<span class="number">45</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:<span class="number">779</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:<span class="number">726</span>)</span><br><span class="line">at hudson.model.Build$BuildExecution.post2(Build.java:<span class="number">185</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:<span class="number">671</span>)</span><br><span class="line">at hudson.model.Run.execute(Run.java:<span class="number">1766</span>)</span><br><span class="line">at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:<span class="number">43</span>)</span><br><span class="line">at hudson.model.ResourceController.execute(ResourceController.java:<span class="number">98</span>)</span><br><span class="line">at hudson.model.Executor.run(Executor.java:<span class="number">408</span>)</span><br><span class="line">Build step <span class="string">&#x27;Deploy war/ear to a container&#x27;</span> marked build <span class="keyword">as</span> failure</span><br><span class="line">Finished: FAILURE</span><br></pre></td></tr></table></figure>

<p><em>新建job</em></p>
<p>Trigger on选择change merged,Post-build Actions选择Deploy war/ear to a container,具体配置:</p>
<ul>
<li>  WAR/EAR files<br>指定构建后的包路径,相对于工程根路径,对于gradle构建war来说,这个值是build/libs/xxx.war</li>
<li>  Context path<br>应用程序的context路径,以后访问应用程序时需要在主机之后加上context路径,除非部署到ROOT context</li>
<li>  Container<br>选择tomcat 7.x<br>Manager user name 可以管理tomcat的账户名,比如上面设置的tomcat7<br>Manager password 管理账户密码,比如上面设置的tomcat7<br>Tomcat URL 访问tomcat的URL,比如<a href="http://domain.tld/">http://domain.tld/</a></li>
</ul>
<p>其实也可以通过脚本来直接部署war文件到tomcat的主机目录,让jenkins调用部署脚本就可以了。</p>
<p><strong>其他</strong><br>每个job还可以添加e-mail notification。</p>
<p>jenkins有几百个插件,可以做的事情很多很多,比如集成findbugs,checkstyle等,还需要以后慢慢探索。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>GIT忽略已跟踪文件的修改</title>
    <url>/2015/03/26/git-ignore-tracked-files/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>忽略未纳入版本管理的文件或文件夹</strong></p>
<p>我们知道可以通过几种方法来配置git忽略对某些未跟踪文件的跟踪。</p>
<ol>
<li> .gitignore<br>版本库中的每个目录层级都可以有一个.gitignore文件，这个文件每一行保存了一个匹配的规则,如：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># build生成文件</span><br><span class="line">build/</span><br><span class="line">root/WEB-INF/classes/</span><br><span class="line">*.class</span><br><span class="line"></span><br><span class="line"># lib文件和meta文件</span><br><span class="line">#root/WEB-INF/lib/</span><br><span class="line">root/META-INF/</span><br><span class="line"></span><br><span class="line"># vim交换文件</span><br><span class="line">*.swp</span><br><span class="line"></span><br><span class="line"># eclipse工程文件</span><br><span class="line">#.classpath</span><br><span class="line">#.project</span><br><span class="line">#.settings/</span><br><span class="line"></span><br><span class="line"># netbeans工程文件</span><br><span class="line">#build.xml</span><br><span class="line">#nbproject/</span><br><span class="line"></span><br><span class="line">#gradle</span><br><span class="line">.gradle</span><br><span class="line"></span><br><span class="line">#python cache folder</span><br><span class="line">__pycache__</span><br></pre></td></tr></table></figure>
.gitignore文件本身是纳入版本库管理的。</li>
<li> 全局ignore文件<br>可以为自己配置一个全局的ignore文件，位于任何版本库之外：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git config --<span class="built_in">global</span> core.excludesfile ~/.gitignoreglobal</span><br></pre></td></tr></table></figure>
其语法与.gitignore一样</li>
<li> exclude<br>git还提供了另一种exclude方法来排除文件。.gitignore用来保存的是公共的需要排除的文件,<br>而.git/info/exclude文件里设置的则是你自己本地需要排除的文件,他不会影响到其他人,也不会提交到版本库中去。</li>
</ol>
<p><strong>忽略已纳入版本管理的文件或文件夹</strong></p>
<p>以上这些方法对于尚未被git跟踪管理的文件是有效的，如果想忽略已经被git纳入版本库管理的文件的修改，则需要另外的方法。</p>
<p>告诉git忽略对已经纳入版本管理的文件.classpath的修改,git会一直忽略此文件直到重新告诉git可以再次跟踪此文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git update-index --assume-unchanged .classpath</span><br></pre></td></tr></table></figure>

<p>告诉git恢复跟踪.classpath</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git update-index --no-assume-unchanged .classpath</span><br></pre></td></tr></table></figure>

<p>查看当前被忽略的、已经纳入版本库管理的文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git ls-files -v grep -e <span class="string">&quot;^\[hsmrck\]&quot;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://www.cnblogs.com/pylemon/archive/2012/07/16/2593112.html">在 git 中忽略文件 gitignore 与 exclude</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git push.default设置</title>
    <url>/2013/10/31/git-push-default-configuration/</url>
    <content><![CDATA[<p>git push.default设置</p>
<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git --version</span><br><span class="line">git version <span class="number">1.8</span><span class="number">.4</span>.rc3</span><br></pre></td></tr></table></figure>

<p>默认配置下，当使用git push命令而没有明确的指名本地分支和远程参考分支的情况下，会有如下提示：</p>
<p>[html]<br>warning: push.default is unset; its implicit value is changing in<br>Git 2.0 from ‘matching’ to ‘simple’. To squelch this message<br>and maintain the current behavior after the default changes, use:</p>
<p> git config –global push.default matching</p>
<p>To squelch this message and adopt the new behavior now, use:</p>
<p> git config –global push.default simple</p>
<p>See ‘git help config’ and search for ‘push.default’ for further information.<br>(the ‘simple’ mode was introduced in Git 1.7.11. Use the similar mode<br>‘current’ instead of ‘simple’ if you sometimes use older versions of Git)<br>[/html]</p>
<p>git-config(1)有单独的一节讲push.default设置:</p>
<p>如果git push命令没有明确指定引用规格(refspec),也就是没有指定推送的源分支和目标分支，那么git会采用push.default定义的动作。<br>不同的值适用于不同的工作流程模式。</p>
<p>push.default可用的值如下：</p>
<ul>
<li>  nothing<br>不推送任何东西并有错误提示，除非明确指定分支引用规格。强制使用分支引用规格来避免可能潜在的错误。</li>
<li>  current<br>推送当前分支到接收端名字相同的分支。</li>
<li>  upstream<br>推送当前分支到上游@{upstream}。这个模式只适用于推送到与拉取数据相同的仓库，比如中央工作仓库流程模式。</li>
<li>  simple<br>在中央仓库工作流程模式下，拒绝推送到上游与本地分支名字不同的分支。也就是只有本地分支名和上游分支名字一致才可以推送，<br>就算是推送到不是拉取数据的远程仓库，只要名字相同也是可以的。在GIT 2.0中，simple将会是push.default的默认值。<br>simple只会推送本地当前分支。</li>
<li>  matching<br>推送本地仓库和远程仓库所有名字相同的分支。<br>这是git当前版本的缺省值。</li>
</ul>
<p>一般来说simple够了，如果严格一点儿可以用nothing,这样来配置push.default</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git config --<span class="built_in">global</span> push.default simple</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git rebase简介</title>
    <url>/2014/04/24/git-rebase-intro/</url>
    <content><![CDATA[<a id="more"></a>
<p>rebase顾名思义re base,重设基准,也就是重设当前分支的基准,rebase又叫做”衍合”。</p>
<p>git分支都有一个起始点,是从某个commit起始分支出来的。rebase时指定新的分支起始点,git会将当前的分支的所有改变以新的起始点为基准重新计算，计算出相对于新的分支起始点的所有改变之后,将这些改变在新的分支起始点上重放,会生成新的commits,最后将当前分支的头设定到新生成的commits的最后一个上。</p>
<p>实际上就将当前分支嫁接到了新的分支起始点上。rebase可以使提交历史看起来更干净。</p>
<p>rebase还可以用来修改当前分支的历史提交信息，修改历史提交代码，合并或拆分提交，调整提交的历史顺序，甚至删除历史提交，总之这个命令是强大无比。</p>
<p>选定当前分支的一个上游提交,然后使用参数-i进入交互模式Interactive Mode</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git rebase -i &lt;upstream&gt;</span><br></pre></td></tr></table></figure>

<p>然后git会用默认编辑器打开一个调整commit的界面,类似如下:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">pick <span class="number">1517205</span> 测试 </span><br><span class="line">pick 5163c4c 测试</span><br><span class="line">pick <span class="number">3e58114</span> 测试</span><br><span class="line">pick fb07146 测试</span><br><span class="line">pick ebd546c 删除测试</span><br><span class="line">pick bf2466e 添加分支流程服务</span><br><span class="line">pick 84e52d3 添加同步流程分布</span><br><span class="line"></span><br><span class="line"># Rebase ebd5cdd..84e52d3 onto ebd5cdd</span><br><span class="line">#</span><br><span class="line"># Commands:</span><br><span class="line"># p, pick = use commit</span><br><span class="line"># r, reword = use commit, but edit the commit message</span><br><span class="line"># e, edit = use commit, but stop for amending</span><br><span class="line"># s, squash = use commit, but meld into previous commit</span><br><span class="line"># f, fixup = like &quot;squash&quot;, but discard this commit&#x27;s log message</span><br><span class="line"># x, exec = run command (the rest of the line) using shell</span><br><span class="line">#</span><br><span class="line"># These lines can be re-ordered; they are executed from top to bottom.</span><br><span class="line">#</span><br><span class="line"># If you remove a line here THAT COMMIT WILL BE LOST.</span><br><span class="line">#</span><br><span class="line"># However, if you remove everything, the rebase will be aborted.</span><br><span class="line">#</span><br><span class="line"># Note that empty commits are commented out</span><br></pre></td></tr></table></figure>

<p>各个命令的解释:</p>
<ul>
<li>  pick<br>保留这个提交,不做任何修改</li>
<li>  reword<br>修改本条提交的提交信息，其他不做修改</li>
<li>  edit<br>保留这个提交,并修改提交的实际内容</li>
<li>  squash<br>与上一条提交合并,保留本条提交的提交信息</li>
<li>  fixup<br>与squash差不多,除了舍弃本条的提交信息</li>
<li>  exec<br>使用shell执行exec行除exec关键字之后的命令</li>
</ul>
<p>如果想删除某个提交，将pick那行完整删除即可。如果将所有的行全部移除，rebase将会终止。<br>参考[2]图文并茂的展示了git rebase的强大威力。</p>
<p><strong>使用rebase必须遵守的一个规则:</strong></p>
<blockquote>
<p>一旦分支中的提交对象发布到公共仓库，就千万不要对该分支进行衍合(rebase)操作。<br>如果你遵循这条金科玉律，就不会出差错。否则，人民群众会仇恨你，你的朋友和家人也会嘲笑你，唾弃你。</p>
</blockquote>
<p>References:<br>[1]<a href="http://git-scm.com/book/zh/Git-%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E7%9A%84%E8%A1%8D%E5%90%88">分支的衍合</a><br>[2]<a href="http://blog.yorkxin.org/posts/2011/07/29/git-rebase">Git-rebase 小筆記</a><br>[3]<a href="http://blog.imtk.me/programming/2012/git_learning_git_rebase_operation.html">Git 学习笔记：git-rebase 命令</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git操作远程分支和tag</title>
    <url>/2014/04/21/git-remote-branch-tag/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>查看远程分支</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git branch -av</span><br><span class="line">* devel <span class="number">86e9595</span> Merge branch <span class="string">&#x27;guoqiang&#x27;</span> into devel</span><br><span class="line"> lifeng dbd7a71 增加流程图绘制菜单</span><br><span class="line"> remotes/origin/HEAD -&gt; origin/devel</span><br><span class="line"> remotes/origin/devel <span class="number">86e9595</span> Merge branch <span class="string">&#x27;guoqiang&#x27;</span> into devel</span><br><span class="line"> remotes/origin/lifeng dbd7a71 增加流程图绘制菜单</span><br><span class="line"> remotes/origin/master d025ce0 Merge branch <span class="string">&#x27;devel&#x27;</span></span><br><span class="line"> remotes/origin/minli 1fa16ba <span class="string">&#x27;test&#x27;</span></span><br><span class="line"> remotes/origin/zjl 72aa56a test2</span><br></pre></td></tr></table></figure>
<p>远程分支会用红颜色显示</p>
<p><strong>删除远程分支</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git branch -r -d origin/branch-name</span><br></pre></td></tr></table></figure>
<p>或者推送一个空的分支到远程分支</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push origin :branch_to_delete</span><br></pre></td></tr></table></figure>

<p><strong>删除远程tag</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push origin --<span class="keyword">delete</span> tag tag_to_delete</span><br></pre></td></tr></table></figure>
<p>或者用一个空的tag覆盖远程tag</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push origin :refs/tags/tag_to_delete</span><br></pre></td></tr></table></figure>

<p><strong>重命名远程分支</strong><br>先删除远程分支,然后重命名本地分支,然后将重命名后的分支推送到远程。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git branch -m old_name new_name</span><br></pre></td></tr></table></figure>

<p><strong>本地tag推送到远程</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push --tags</span><br></pre></td></tr></table></figure>

<p><strong>获取远程tag</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git fetch origin tag tag_name</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://zengrong.net/post/1746.htm">GIT查看、删除、重命名远程分支和TAG</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git reset与revert</title>
    <url>/2014/04/21/git-reset-revert/</url>
    <content><![CDATA[<a id="more"></a>
<p>reset和revert都可以修改历史提交,但二者的区别是很大的。</p>
<p><strong>reset</strong><br>git reset - Reset current HEAD to the specified state</p>
<p>对于撤销提交,git reset的命令格式如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git reset \[--soft --mixed --hard --merge --keep\] \[-q\] \[&lt;commit&gt;\]</span><br></pre></td></tr></table></figure>

<p>这种形式的reset会将当前分支的头设置到指定的commit，并且根据不同的模式可能会更新索引区域(使用指定commit的目录树)和工作树。如果省略模式参数,则默认为<code>--mixed</code>,模式只能设置为以下值之一:</p>
<ul>
<li>  <code>--soft</code><br>不修改索引区域(staging area)和工作目录(woring tree)，直接将当前分支的头设置为commit。 </li>
<li>  <code>--mixed</code><br>使用commit的目录树重置索引区域,当前工作树保持不变。因此工作树中修改的文件需要重新添加到索引区域才能提交。</li>
<li>  <code>--hard</code><br>使用commit的目录树重设索引区域和工作树。完全丢弃commit之后的所有修改。 </li>
<li>  <code>--merge</code><br>使用commit的目录树重设索引区域,并且更新工作树中在commit和HEAD之间存在差异的文件,但是不更新工作树中索引区域与工作树之间存在差异的文件。<br>如果一个文件在commit和有修改但未将修改更新到索引区域的文件之间存在差异,则撤销会被终止。</li>
<li>  <code>--keep</code><br>使用commit的目录树重设索引区域,并且更新工作树中在commit和HEAD之间存在差异的文件。</li>
</ul>
<p><strong>revert</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git revert &lt;commit&gt;...</span><br></pre></td></tr></table></figure>
<p>git revert用于反转提交,执行evert命令时要求工作树必须是干净的。git revert用一个新提交来消除一个历史提交所做的任何修改。</p>
<p><strong>区别</strong></p>
<p>reset会将历史提交直接撤销掉,不会保留提交历史。而revert会增加一个新的提交来反转指定的历史提交所做的修改,保留完整的提交历史,但被反转的提交相当于没对代码库做任何修改。简单来说,一次提交修改了代码库,revert后另一个提交把对应的修改恢复了原样。</p>
<p>如果comit已经push到远程服务器,要慎用甚至最好不要用reset来撤销修改,除非你真的知道你在做什么。这时候用revert是比较合适的。如果这时候执行git push,会有错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">To gitsvr:xxx</span><br><span class="line"> ! \[rejected\] devel -&gt; devel (non-fast-forward)</span><br><span class="line">error: failed to push some refs to <span class="string">&#x27;gitsvr:xxx&#x27;</span></span><br><span class="line">hint: Updates were rejected because the tip <span class="keyword">of</span> your current branch is behind</span><br><span class="line">hint: its remote counterpart. Integrate the remote changes (e.g.</span><br><span class="line">hint: <span class="string">&#x27;git pull ...&#x27;</span>) before pushing again.</span><br><span class="line">hint: See the <span class="string">&#x27;Note about fast-forwards&#x27;</span> <span class="keyword">in</span> <span class="string">&#x27;git push --help&#x27;</span> <span class="keyword">for</span> details.</span><br></pre></td></tr></table></figure>
<p>如果你确信你push到远程服务器的提交没有别人在引用,比如就你自己在使用代码库,可以强制更新远程代码库:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push -f</span><br></pre></td></tr></table></figure>
<p>如果你的强制撤销会影响到别人，就应该使用git revert了。</p>
<p><strong>git reset后悔药</strong> </p>
<p>git reset后还能恢复吗？只要提交对象还在代码库中存在就可以恢复,因为只不过是HEAD指针被移动了而已,可以重新移动到原来的提交对象。<br>使用git reflog查看操作历史，找到之前 HEAD 的 hash 值，然后<code>git reset --hard</code>到那个hash就可以了。</p>
<p>References:<br>[1]man git</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git恢复删除的文件</title>
    <url>/2013/12/31/git-restore-files/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果在当前工作区删除了文件,又想恢复回来,可以这样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git checkout -- filename</span><br></pre></td></tr></table></figure>
<p>如果删除了一批文件想恢复回来,可以这样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git ls-files --deleted xargs git checkout --</span><br></pre></td></tr></table></figure>
<p>其中git ls-files –deleted是列出所有被删除的文件。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git show-branch输出</title>
    <url>/2013/11/27/git-show-branch-output/</url>
    <content><![CDATA[<a id="more"></a>
<p>为了弄明白git show-branch的输出格式,先做一系列实验，看其输出</p>
<p><strong>初始化一个空的git库</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git init</span><br><span class="line">Initialized empty Git repository <span class="keyword">in</span> /home/$&#123;username&#125;/test/.git/</span><br></pre></td></tr></table></figure>

<p><strong>在master分支上做初始提交</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ touch master</span><br><span class="line">$ git add --all</span><br><span class="line">$ git commit -m <span class="string">&quot;master init commit&quot;</span></span><br><span class="line">\[master (root-commit) d47b60d\] master init commit</span><br><span class="line"> <span class="number">1</span> file changed, <span class="number">0</span> insertions(+), <span class="number">0</span> deletions(-)</span><br><span class="line"> create mode <span class="number">100644</span> master</span><br></pre></td></tr></table></figure>

<p><strong>看看当前分支的情况</strong></p>
<p>$ git branch</p>
<ul>
<li>master</li>
</ul>
<p>$ git show-branch<br>[master] master init commit</p>
<p><strong>新建devel分支</strong></p>
<p>$ git branch devel<br>$ git branch<br>   devel</p>
<ul>
<li>master</li>
</ul>
<p>$ git show-branch<br>!  [devel] master init commit<br>  *  [master] master init commit<br>–<br>+*  [devel] master init commit</p>
<p><strong>切换到devel分支并做新的提交</strong><br>$ git checkout devel<br>Switched to branch ‘devel’<br>$ touch devel<br>$ git add –all<br>$ git commit -m “first commit on devel”<br>$ git branch</p>
<ul>
<li>devel<br>   master</li>
</ul>
<p>$ git show-branch<br>*  [devel] first commit on devel<br>  !   [master] master init commit<br>–<br>*     [devel] first commit on devel<br>*+  [master] master init commit</p>
<p><strong>回到master分支</strong><br>$ git checkout master<br>$ git show-branch<br>!   [devel] first commit on devel<br>   *    [master] master init commit<br>–<br>+      [devel] first commit on devel</p>
<ul>
<li><ul>
<li>  [master] master init commit</li>
</ul>
</li>
</ul>
<p><strong>在devel分支上新建feature分支</strong></p>
<p>$ git checkout devel<br>$ git checkout -b feature<br>$ touch feature<br>$ git add –all<br>$ git commit -m “first commit on feature”<br>$ git show-branch<br><img src="/downloads/show_branch_on_feature.png" alt="show_branch_on_feature"></p>
<p>切换到devel分支<br>$ git checkout devel<br>$ git show-branch<br><img src="/downloads/show_branch_on_devel.png" alt="show_branch_on_devel"></p>
<p>切换到master分支<br>$ git checkout master<br>$ git show-branch<br><img src="/downloads/show_branch_on_master.png" alt="show_branch_on_master"></p>
<p><strong>合并分支feature到devel</strong></p>
<p>$ git checkout devel<br>$ git merge feature<br>$ git show-branch<br><img src="/downloads/show_branch_on_devel_merged_feature.png" alt="show_branch_on_devel_merged_feature"></p>
<p><strong>feature分支多次提交之后</strong><br><img src="/downloads/multiple_commit.png" alt="multiple_commit"></p>
<p><strong>然后再将分支feature合并到devel</strong><br><img src="/downloads/merge.png" alt="merge"></p>
<h5 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h5><ul>
<li>  git show-branch输出<br>输出分为上下两部分，使用短划线”-“分隔。两个分支使用两个短划线”–”，三个分支使用三个短划线”—“，依次类推。<br>上半部分为层次缩进的分支列表，下半部分为commit列表。<br>上半部分的分支列表中，使用<em>标识当前分支，其他分支使用!标识。分支前的标识符</em>或者!一直垂直贯通到下半部分，这一垂直列的符号都是属于这个分支的。<br>下半部分的commit列表中，前导的符号有<em>和+号。</em>表示这一列上的分支(当前分支)有此commit。而+表示这一列上的分支(非当前分支)有此commit。</li>
</ul>
<p>标识符的颜色只是用于容易区分列，一列的颜色是一致的，看起来更清楚。</p>
<ul>
<li>  分支名字和commit标识<br>show-branch输出中，上半部分的分支名字使用[分支名字]标识，下半部分的commit使用[分支名字]标识最后的commit,[分支名字^]标识该分支的上一个提交<br>[分支名字~2]标识该分支的倒数第三个commit。这是commit的快捷标识符，在git命令中可以引用对应的commit，也可以直接使用commit的hash tag,不过比较不直观而已。</li>
<li>  git branch<br>branch只是简单的输出所有的分支，当前分支前使用*表示，当前分支的文字颜色为绿色。</li>
<li>  merge<br>一个commit只输出一次，分支被合并后，被合并分支的commit使用[合并分支]标识，但commit是属于两个分支的，所以commit的前面有两个标识符号*和+。</li>
<li>  分支名字空间<br>git的分支名字空间是扁平的，共享同一个namespace。</li>
</ul>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>一种GIT版本号管理策略</title>
    <url>/2015/11/15/git-version-number-strategy/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>命名格式</strong></p>
<p>版本号的命名格式为:</p>
<p>主版本号.次版本号[-发布进程版本号]-修订版本号-发布分支头SHA1 ID</p>
<p><strong>管理策略</strong></p>
<p>主版本号(Major)和次版本号(Minor)：</p>
<p>主版本号对应大的、全局功能更新，而次版本号对应小的、局部的功能更新。主、次版本号根据实际情况设定。</p>
<p>发布进程版本号(release)：</p>
<p>用于标识发布进程的版本号后缀，使用alpha(内部测试),beta(公共测试)和rc(release candidate,发布候选)加上数字作为次版本号的后缀，比如alpha1,alpha2,beta1,beta2,rc1,rc2等。</p>
<p>修订版本号：</p>
<p>标识自上次标定主次版本号以来的bugfix次数。修订版本号不涉及功能更新。每次重新标定主、次版本号(还可能有发布进程版本号)之后，修订版本号重置，从0开始重新计数。</p>
<p>发布分支头sha1：</p>
<p>标识该版本对应的发布分支头提交的sha1摘要，方便通过版本号回溯git代码库中的commit。</p>
<p><strong>实现</strong></p>
<p>主、次、发布进程版本号，根据项目实际情况确定，确定之后在发布分支上打标签以记录版本号：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git tag -a v1<span class="number">.0</span>-rc1 -m <span class="string">&#x27;version 1.0 release candidate 1&#x27;</span></span><br></pre></td></tr></table></figure>

<p>修订版本号和发布分支头sha1 id通过git命令describe来自动生成：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git describe --tags --long</span><br></pre></td></tr></table></figure>

<p>最后会生成如下格式的版本号:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">v1<span class="number">.0</span>-rc1-<span class="number">10</span>-g742aee8</span><br></pre></td></tr></table></figure>
<p>此版本号的含义为：主版本号为1，次版本号为0，发布进程版本号为rc1,修订版本号为10，也就是主、次、发布进程版本号设定之后又进行了10次bugfix,发布分支头为742a3ee8这个commit对象。</p>
<p><strong>构建</strong></p>
<p>在自动构建脚本中调用git describe命令来自动生成版本号，并自动记录到应用程序中，最后发布的应用程序就有了明确的、易于追溯的版本号。</p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>git查看每行代码的作者</title>
    <url>/2014/12/24/git-view-code-author/</url>
    <content><![CDATA[<a id="more"></a>
<p>git blame 命令用于Show what revision and author last modified each line of a file<br>直接</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git blame filename</span><br></pre></td></tr></table></figure>

<p>或者用git log命令</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git log -p filename</span><br></pre></td></tr></table></figure>
<p>然后搜索一下吧</p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>gitolite v3安装配置</title>
    <url>/2014/03/26/gitolite-v3-install-setup/</url>
    <content><![CDATA[<p>gitolite用于git版本库的权限控制。</p>
<a id="more"></a>
<p>gitolite发端自gitosis,功能早已超越后者,而且gitosis已停止更新好多年！</p>
<p><strong>安装</strong></p>
<p>使用单独的用户git来安装gitolite</p>
<p><em>创建用户</em></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># adduser --shell=/bin/bash git</span><br></pre></td></tr></table></figure>

<p><em>安装gitolite</em><br>先为自己生成一个密钥对</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -b <span class="number">2048</span> -t rsa -f your_name</span><br></pre></td></tr></table></figure>
<p>然后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone git:<span class="comment">//github.com/sitaramc/gitolite</span></span><br><span class="line">$ mkdir -p $HOME/bin</span><br><span class="line">$ $HOME/gitolite/install -to $HOME/bin</span><br><span class="line">$ $HOME/bin/gitolite setup -pk your_name.pub</span><br></pre></td></tr></table></figure>
<p>安装就算完成了。<br>安装之后gitolite会在$HOME/repositories目录下初始化两个git仓库,gitolite-admin.git和testing.git,前者用于管理gitolite,后者是个测试用的仓库。</p>
<p><strong>配置</strong><br>gitolite通过更新gitolite-admin.git仓库来实施管理。所以要先clone这个仓库:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone gitolite:gitolite-admin</span><br></pre></td></tr></table></figure>
<p>这里gitolite是为ssh配置的主机别名。</p>
<p><em>用户管理</em></p>
<p>将git用户的公钥拷贝到进入管理仓库下的子目录keydir,然后提交推送即可。用户的公钥以username.pub的格式命名,username与权限管理时指定的用户名必须是一致的。</p>
<p><em>权限管理</em></p>
<p>权限管理就是配置管理仓库子目录conf下的gitolite.conf文件。配置完毕提交推送权限就会生效。</p>
<p>先列出一个简单的配置:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">@admin = openwares</span><br><span class="line">@staff = minli.wang @admin</span><br><span class="line"></span><br><span class="line">repo gitolite-admin</span><br><span class="line"> RW+ = @admin</span><br><span class="line"></span><br><span class="line">repo testing</span><br><span class="line"> RW+ = @all</span><br><span class="line"></span><br><span class="line">repo foobar</span><br><span class="line"> RW+ = @admin</span><br><span class="line"> - master = @staff</span><br><span class="line"> - refs/tags = @staff</span><br><span class="line"> RW devel = @staff</span><br><span class="line"> RW+ = @staff</span><br></pre></td></tr></table></figure>

<p>gitolite支持按用户或组管理权限。组名以@开头,可以包含多个用户，名字以空格分隔。组还可以嵌套其他组。<br>权限规则行的格式为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;permission&gt; &lt;zero or more refexes&gt; = &lt;one or more users/user groups&gt;</span><br></pre></td></tr></table></figure>
<p>refex的含义见下一节</p>
<p><strong>权限分类和规则</strong></p>
<ul>
<li>  C<br>可以创建新仓库</li>
<li>  R<br>可以读取仓库</li>
<li>  RW<br>可以读取,fast-forward推送,创建分支和标签</li>
<li>  RW+<br>可以进行任何类型的push,包括delete,rewind,overwrite等</li>
<li>  -<br>拒绝任何类型的推送</li>
</ul>
<p>对于clone和fetch操作,只要当前用户具有R,RW或RW+任何一种权限,都可以读取仓库,其实就是存在R权限。<br>对于push操作,gitolite顺序处理权限规则,直到找到一条用户,权限许可和分支模式完全匹配的规则为止，之后的规则不再处理，所以一定要注意权限规则的顺序问题。</p>
<p><em>refex</em><br>refex这玩意儿就类似于regex的叫法,是指ref的匹配模式。有以下匹配规则:</p>
<ul>
<li><p>  空的refex处理为’refs/.*’,也就是匹配任何refs,因为ref默认都存在于refs/目录下</p>
</li>
<li><p>  如果指定的refex没有以refs/开头,则为其添加前缀refs/heads/</p>
</li>
<li><p>refex使用隐式的行首规则,^在规则表达式中为匹配行首,refex默认从行首匹配,但没有$行尾匹配。举个栗子,如果指定refex为master,则下面这几个ref都可以匹配:</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">refs/heads/master</span><br><span class="line">refs/heads/master1</span><br><span class="line">refs/heads/master/full</span><br></pre></td></tr></table></figure>
</li>
<li><p>  最后实际被推送到的ref以经过规则匹配后的结果为准</p>
</li>
</ul>
<p><em>个人分支</em><br>gitolite支持为用户设立个人分支空间,其规则如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RW+ personal/USER/ = alice</span><br></pre></td></tr></table></figure>
<p>personal可以为任何字符,/USER/会被替换成实际的用户名,因此用户alice可以在personal/alice/目录推送任何分支,比如<br>personal/alice/foo和personal/alice/bar,但不能推送到personal/alice。</p>
<p>个人分支空间为每个用户设立一个私人空间,防止公共分支空间的名字污染。开发者可以随意使用自己的个人分支空间,无需关心其权限问题,也不用担心分支名字冲突。</p>
<p><strong>gitolite shell</strong></p>
<p>gitolite提供了一个简单的ssh shell,可以了解远程仓库的一些信息和进行一些管理操作,以下命令可以查看shell的帮助:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh gitolite help</span><br></pre></td></tr></table></figure>

<p>gitolite是远程gitolite的ssh别名。可以在每个支持的命令后面添加-h参数来了解命令的详细用法。比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh gitolite help -h</span><br></pre></td></tr></table></figure>

<p><strong>新建gitolite远程仓库</strong><br>有这么几种方法:</p>
<ul>
<li>  服务器管理员远程登录服务器,直接在$HOME/repositories目录下初始化裸仓库,这和使用git没有任何差别</li>
<li>  修改gitolite-admin/conf/gitolite.conf文件,添加新仓库及其权限,提交推送时,gitolite会自动创建新仓库</li>
<li>具有创建仓库权限的用户,可以本地创建空仓库,然后添加远程仓库引用,推送后gitolite会为用户创建新仓库。比如:  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mkdir somegit</span><br><span class="line">cd somegit</span><br><span class="line">git init</span><br><span class="line">git commit --allow-empty</span><br><span class="line">git remote add origin git@server:Projects/somegit.git</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p><strong>删除gitolite仓库</strong><br>先删除配置文件中仓库的相关配置,然后登录服务器删除仓库,gitolite不会自动删除仓库。</p>
<p>References:<br>[1]github:<a href="https://github.com/sitaramc/gitolite">gitolite</a><br>[2]official:<a href="http://gitolite.com/gitolite/gitolite.html">gitolite</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>gitweb配置(configuration)</title>
    <url>/2009/08/22/gitweb-configuration/</url>
    <content><![CDATA[<p>gitweb是git的web接口，使用单向的http协议来发布git repositories。</p>
<p>通过gitweb可以来浏览任意版本的目录树，查看文件的内容，查看分支的log或shortlog,检视commits,commit信息以及指定commit所做的改变。gitweb可以产生RSS或Atom格式的feeds。可以获取任意指定版本的文件，如果允许，也可以下载指定版本的快照(snapshot)。也可以通过作者、提交者或者包含的某些提交信息来搜索commits。</p>
<p>gitweb的配置比较简单。</p>
<p>Debian默认将gitweb脚本gitweb.cgi安装到/usr/lib/cgi-bin/目录,使用的配置文件为/etc/gitweb.conf。<br>我将gitweb作为一个单独的虚拟主机来配置，gitweb的主目录为/home/${username}/public_html/pcware.cn/git,此处的${username}指代所在主机上的用户名，gitweb的主目录可以依个人喜好设置。</p>
<a id="more"></a>
<p>虚拟主机配置文件内容如下:<br>#gitweb<br>&lt;VirtualHost *:80&gt;<br>    ServerName git.pcware.cn</p>
<p>    ScriptAlias /gitweb/ /usr/lib/cgi-bin/<br>    DirectoryIndex /gitweb/gitweb.cgi</p>
<p>    DocumentRoot “/home/${username}/public_html/pcware.cn/git”</p>
<p>    ErrorLog “/var/log/apache2/git.pcware.cn-error.log”<br>    CustomLog “/var/log/apache2/git.pcware.cn-access.log” combined<br></VirtualHost></p>
<p>首先,把gitweb使用到的资源文件(图片和CSS)符号链接到gitweb主目录<br>sudo ln -sf /usr/share/gitweb/* /home/${username}/public_html/pcware.cn/git</p>
<p>然后,修改gitweb.conf中的$projectroot为”/home/${username}/public_html/pcware.cn/git”</p>
<p>最后将要发布的git repositories拷贝到gitweb主目录下面就可以了,当然也可以初始化一个bare repository,不过一定要作为gitweb主目录的子目录存在。不过要记得把git repositories的post-update hooks打开，这样当你更新repositories的时候post-update里面的命令git-update-server-info得以执行，gitweb才可以正确的更新,chmod +x ${GIT_DIR}/hooks/post-update就可以了。</p>
<p>可以通过修改${GIT_DIR}/description来修改git repositories的文字描述。</p>
<p>这样通过虚拟主机名就可以直接访问到git repositories了，比如<a href="http://git.pcware.cn/">http://git.pcware.cn</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian testing &quot;Error: couldn&#39;t find RGB GLX visual&quot;</title>
    <url>/2011/08/18/glx-visual/</url>
    <content><![CDATA[<p>安装完amd catalyst专有驱动fglrx后,执行fglrx-info查看驱动信息，有如下错误提示</p>
<a id="more"></a>
<p>Error: couldn’t find RGB GLX visual！</p>
<p>这是因为debian没有找到GLX提供者也就是fglrx所致，所以安装这个包fglrx-glx（proprietary libGL for the non-free ATI/AMD RadeonHD display driver）可以解决此问题。</p>
<p>sudo apt-get install fglrx-glx</p>
<p>问题解决。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gnome alacarte崩溃</title>
    <url>/2018/12/22/gnome-alacarte-crash/</url>
    <content><![CDATA[<p>编辑菜单项时，alacarte突然崩溃，应该是因为wine生成的菜单有乱码导致的。</p>
<a id="more"></a>
<p>执行alacarte有如下错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">(alacarte:<span class="number">1985</span>): Gtk-CRITICAL **: gtk_accel_label_set_accel_closure: assertion <span class="string">&#x27;gtk_accel_group_from_accel_closure (accel_closure) != NULL&#x27;</span> failed</span><br><span class="line"></span><br><span class="line">(alacarte:<span class="number">1985</span>): Gtk-CRITICAL **: gtk_accel_label_set_accel_closure: assertion <span class="string">&#x27;gtk_accel_group_from_accel_closure (accel_closure) != NULL&#x27;</span> failed</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">File <span class="string">&quot;/usr/bin/alacarte&quot;</span>, line <span class="number">26</span>, <span class="keyword">in</span> &amp;lt;<span class="built_in">module</span>&amp;gt;</span><br><span class="line">main()</span><br><span class="line">File <span class="string">&quot;/usr/share/alacarte/Alacarte/MainWindow.py&quot;</span>, line <span class="number">464</span>, <span class="keyword">in</span> main</span><br><span class="line">app.setMenuBasename(basename)</span><br><span class="line">File <span class="string">&quot;/usr/share/alacarte/Alacarte/MainWindow.py&quot;</span>, line <span class="number">62</span>, <span class="keyword">in</span> setMenuBasename</span><br><span class="line">self.editor = MenuEditor(menu_basename)</span><br><span class="line">File <span class="string">&quot;/usr/share/alacarte/Alacarte/MenuEditor.py&quot;</span>, line <span class="number">36</span>, <span class="keyword">in</span> __init__</span><br><span class="line">self.load()</span><br><span class="line">File <span class="string">&quot;/usr/share/alacarte/Alacarte/MenuEditor.py&quot;</span>, line <span class="number">49</span>, <span class="keyword">in</span> load</span><br><span class="line"><span class="keyword">if</span> not self.tree.load_sync():</span><br><span class="line">GLib.Error: g-markup-error-quark: <span class="built_in">Error</span> on line <span class="number">1</span> char <span class="number">1</span>: Document was empty or contained only whitespace (<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>是因为~/.config/menus/gnome-applications.menu内容为空导致的，不知道怎么就突然生成了这么一个空白文档，将其删除问题解决。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>gnome main menu alacarte crash</title>
    <url>/2020/09/24/gnome-main-menu-alacarte-crash/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用alacarte删除了几个菜单项后，再也打不开gnome main menu了，终端下运行alacarte出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ alacarte</span><br><span class="line">usr/share/alacarte/Alacarte/MainWindow.py:<span class="number">22</span>: PyGIWarning: GMenu was imported without specifying a version first. Use gi.require_version(<span class="string">&#x27;GMenu&#x27;</span>, <span class="string">&#x27;3.0&#x27;</span>) before <span class="keyword">import</span> to ensure that the right version gets loaded.</span><br><span class="line"> <span class="keyword">from</span> gi.repository <span class="keyword">import</span> Gtk, GdkPixbuf, Gdk, GMenu</span><br><span class="line"></span><br><span class="line">(alacarte:<span class="number">1718</span>): Gtk-CRITICAL **: <span class="number">16</span>:<span class="number">54</span>:<span class="number">24.699</span>: gtk_accel_label_set_accel_closure: assertion <span class="string">&#x27;gtk_accel_group_from_accel_closure (accel_closure) != NULL&#x27;</span> failed</span><br><span class="line"></span><br><span class="line">(alacarte:<span class="number">1718</span>): Gtk-CRITICAL **: <span class="number">16</span>:<span class="number">54</span>:<span class="number">24.699</span>: gtk_accel_label_set_accel_closure: assertion <span class="string">&#x27;gtk_accel_group_from_accel_closure (accel_closure) != NULL&#x27;</span> failed</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"> File <span class="string">&quot;/usr/bin/alacarte&quot;</span>, line <span class="number">26</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> main()</span><br><span class="line"> File <span class="string">&quot;/usr/share/alacarte/Alacarte/MainWindow.py&quot;</span>, line <span class="number">464</span>, <span class="keyword">in</span> main</span><br><span class="line"> app.setMenuBasename(basename)</span><br><span class="line"> File <span class="string">&quot;/usr/share/alacarte/Alacarte/MainWindow.py&quot;</span>, line <span class="number">62</span>, <span class="keyword">in</span> setMenuBasename</span><br><span class="line"> self.editor = MenuEditor(menu_basename)</span><br><span class="line"> File <span class="string">&quot;/usr/share/alacarte/Alacarte/MenuEditor.py&quot;</span>, line <span class="number">36</span>, <span class="keyword">in</span> __init__</span><br><span class="line"> self.load()</span><br><span class="line"> File <span class="string">&quot;/usr/share/alacarte/Alacarte/MenuEditor.py&quot;</span>, line <span class="number">49</span>, <span class="keyword">in</span> load</span><br><span class="line"> <span class="keyword">if</span> not self.tree.load_sync():</span><br><span class="line">gi.repository.GLib.Error: g-markup-error-quark: <span class="built_in">Error</span> on line <span class="number">1</span> char <span class="number">1</span>: Document was empty or contained only whitespace (<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>发现~/.config/menus目录下多了一个空白文件gnome-applications.menu，将其删除问题解决。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gnome移动Desktop目录到其他位置</title>
    <url>/2012/03/18/gnome-nautilus-desktop-folder/</url>
    <content><![CDATA[<p>默认情况下,gnome的“桌面”文件夹位于用户主目录下,根据locale不同,名字也不同</p>
<a id="more"></a>
<p>en_US.utf8环境下,桌面文件夹为~/Desktop,这家伙在这里,不利于用户文件的管理,所以移动到其他位置会比较好</p>
<p>编辑~/.config/user-dirs.dirs文件,如果没有新建一个,增加以下内容</p>
<p>XDG_DESKTOP_DIR=”$HOME/.desktop”</p>
<p>保存退出,然后</p>
<p>$mv Desktop .desktop</p>
<p>桌面文件夹就不会再碍眼了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gnome shell firefox 自带图标无法显示</title>
    <url>/2013/09/12/gnome-shell-firefox-icon-disapper/</url>
    <content><![CDATA[<p>最近手动更新firefox后，无论如何无法设置启动程序图标为firefox自带的图标，使用系统自带图标则没问题。</p>
<a id="more"></a>
<p>debian版本为jessie,firefox版本为23.0.1</p>
<p>将firefox自带图标拷贝到系统图标目录</p>
<h1 id="cp-opt-firefox-browser-icons-mozicon128-png-usr-share-icons-hicolor-128x128-apps"><a href="#cp-opt-firefox-browser-icons-mozicon128-png-usr-share-icons-hicolor-128x128-apps" class="headerlink" title="cp /opt/firefox/browser/icons/mozicon128.png /usr/share/icons/hicolor/128x128/apps/"></a>cp /opt/firefox/browser/icons/mozicon128.png /usr/share/icons/hicolor/128x128/apps/</h1><p>通过更新图标缓存，注册主题图标</p>
<h1 id="gtk-update-icon-cache-usr-share-icons-hicolor"><a href="#gtk-update-icon-cache-usr-share-icons-hicolor" class="headerlink" title="gtk-update-icon-cache /usr/share/icons/hicolor/"></a>gtk-update-icon-cache /usr/share/icons/hicolor/</h1><p>gtk-update-icon-cache: Cache file created successfully.</p>
<p>然后再设置firefox图标为/usr/share/icons/hicolor/128x128/apps/mozicon128.png则可以了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gradle gulp插件</title>
    <url>/2015/11/07/gradle-gulp-plgin/</url>
    <content><![CDATA[<a id="more"></a>
<p>gradle调用gulp任务的插件。</p>
<p><strong>安装</strong></p>
<p>build文件中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">plugins &#123;</span><br><span class="line"> id <span class="string">&quot;com.moowork.gulp&quot;</span> version <span class="string">&quot;0.11&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>调用gulp任务</strong></p>
<p>插件将gulp task_name包装成gulp_task_name的方式从gradle调用。</p>
<p>可以从命令行上调用：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gradle gulp_task_name</span><br></pre></td></tr></table></figure>
<p>这实际上会调用gulp task_name</p>
<p>更重要的，可以在构建文件中把gulp任务作为依赖：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// runs &quot;gulp build&quot; as part of your gradle build</span></span><br><span class="line">build.dependsOn gulp_build</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/srs/gradle-gulp-plugin">gradle-gulp-plugin</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>GNOME环境X应用程序自启动</title>
    <url>/2015/11/22/gnome-x-app-autostart/</url>
    <content><![CDATA[<a id="more"></a>
<p>GNOME环境下的GUI应用程序可以配置在GNOME初始化后自动运行。</p>
<p>配置自启动的位置在：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$HOME/.config/autostart/</span><br></pre></td></tr></table></figure>

<p>简单的将/usr/share/applications目录下的.desktop文件拷贝到此目录下即可：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cp /usr/share/applications/foo.desktop ~<span class="regexp">/.config/</span>autostart/</span><br></pre></td></tr></table></figure>

<p>或者使用GNOME Tweak Tool -&gt; Startup Applications选择一下就可以了。</p>
<p>References:<br>[1]<a href="https://wiki.archlinux.org/index.php/Autostarting">Autostarting</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Gradle安装与简单使用</title>
    <url>/2014/01/18/gradle-intro/</url>
    <content><![CDATA[<p>Gradle是使用Groovy做为DSL的构建工具,十分强大且易用。</p>
<a id="more"></a>
<p><strong>安装</strong></p>
<p>Debian tesing 源里虽然有gradle,但其还依赖于tomcat6的一些库。因此直接从<a href="http://www.gradle.org/downloads">官方下载</a>安装,官方下载的gradle是自包含的,自带了groovy库。<br>当前版本为<a href="http://services.gradle.org/distributions/gradle-1.10-bin.zip">1.10</a>。</p>
<p>安装很简单,只要将gradle的可执行文件bin/gradle加入$PATH环境变量就可以了。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># unzip gradle-1.10-bin.zip -d /opt/</span><br><span class="line"># ln -sf /opt/gradle-1.10 /opt/gradle</span><br><span class="line"># mkdir /opt/bin </span><br><span class="line"># ln -sf /opt/gradle/bin/gradle /opt/bin/gradle</span><br></pre></td></tr></table></figure>

<p>编辑/etc/profile,添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># set PATH so it includes opt bin if it exists</span><br><span class="line"><span class="keyword">if</span> \[ -d <span class="string">&quot;/opt/bin&quot;</span> \] ; then</span><br><span class="line"> PATH=<span class="string">&quot;/opt/bin:$PATH&quot;</span></span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>测试安装:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gradle -v</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">Gradle <span class="number">1.10</span></span><br><span class="line">------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">Build time: <span class="number">2013</span>-<span class="number">12</span>-<span class="number">17</span> <span class="number">09</span>:<span class="number">28</span>:<span class="number">15</span> UTC</span><br><span class="line">Build number: none</span><br><span class="line">Revision: 36ced393628875ff15575fa03d16c1349ffe8bb6</span><br><span class="line"></span><br><span class="line">Groovy: <span class="number">1.8</span><span class="number">.6</span></span><br><span class="line">Ant: Apache Ant(TM) version <span class="number">1.9</span><span class="number">.2</span> compiled on July <span class="number">8</span> <span class="number">2013</span></span><br><span class="line">Ivy: <span class="number">2.2</span><span class="number">.0</span></span><br><span class="line">JVM: <span class="number">1.7</span><span class="number">.0_21</span> (Oracle Corporation <span class="number">23.7</span>-b01)</span><br><span class="line">OS: Linux <span class="number">3.12</span>-<span class="number">1</span>-amd64 amd64</span><br></pre></td></tr></table></figure>
<p><strong>构建java web工程</strong></p>
<p>gradle使用<a href="http://zh.wikipedia.org/wiki/%E7%BA%A6%E5%AE%9A%E4%BC%98%E4%BA%8E%E9%85%8D%E7%BD%AE">约定优于配置</a>(Convention over Configuration)的理念。使用与maven兼容的目录结构布局。完全按照约定的目录结构来布置工程文件,会大大简化build配置文件。</p>
<p>除了常见的src/main/java等目录,默认的web应用程序根目录为src/main/webapp,也就是包含WEB-INF目录的上一级目录。如果工程没有完全依照约定布局,可以通过脚本文件指定相应的路径。</p>
<p>Gradle中有两个最基本的对象：project和task。每个Gradle的构建由一个project对象来表达，它代表着需要被构建的组件或者构建的整个项目。每个project对象由一个或者多个task对象组成。</p>
<p>gradle已经自带了很多pugins,可以满足大部分的常见构建任务。</p>
<p>gradle的默认构建脚本文件为工程根目录下的build.gradle,下面是一个简单的web app构建脚本,脚本虽然简单,但完整的完成了系统的构建和测试,这就是gradle的魅力所在。简约但不简单。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">apply plugin: <span class="string">&#x27;war&#x27;</span></span><br><span class="line"></span><br><span class="line">webAppDirName = <span class="string">&#x27;root&#x27;</span></span><br><span class="line"></span><br><span class="line">dependencies &#123;</span><br><span class="line"> compile fileTree(dir: <span class="string">&#x27;root/WEB-INF/lib&#x27;</span>, <span class="attr">include</span>: <span class="string">&#x27;*.jar&#x27;</span>)</span><br><span class="line"> runtime fileTree(dir: <span class="string">&#x27;root/WEB-INF/lib&#x27;</span>, <span class="attr">include</span>: <span class="string">&#x27;*.jar&#x27;</span>)</span><br><span class="line"> testCompile fileTree(dir: <span class="string">&#x27;root/WEB-INF/lib&#x27;</span>, <span class="attr">include</span>: <span class="string">&#x27;*.jar&#x27;</span>)</span><br><span class="line"> testRuntime fileTree(dir: <span class="string">&#x27;root/WEB-INF/lib&#x27;</span>, <span class="attr">include</span>: <span class="string">&#x27;*.jar&#x27;</span>)</span><br><span class="line"> providedCompile files(<span class="string">&#x27;/usr/share/java/servlet-api-3.0.jar&#x27;</span>)</span><br><span class="line"> providedRuntime files(<span class="string">&#x27;/usr/share/java/servlet-api-3.0.jar&#x27;</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">compileJava &#123; </span><br><span class="line"> options.compilerArgs &lt;&lt; <span class="string">&#x27;-Xlint:unchecked&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>工程根目录下执行构建脚本,下面是脚本中没有添加编译器参数-Xlint:unchecked的输出:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gradle build</span><br><span class="line">:compileJava</span><br><span class="line">Note: Some input files use unchecked or unsafe operations.</span><br><span class="line">Note: Recompile <span class="keyword">with</span> -Xlint:unchecked <span class="keyword">for</span> details.</span><br><span class="line">:processResources UP-TO-DATE</span><br><span class="line">:classes</span><br><span class="line">:war</span><br><span class="line">:assemble</span><br><span class="line">:compileTestJava</span><br><span class="line">:processTestResources UP-TO-DATE</span><br><span class="line">:testClasses</span><br><span class="line">:test</span><br><span class="line">:check</span><br><span class="line">:build</span><br><span class="line"></span><br><span class="line">BUILD SUCCESSFUL</span><br><span class="line"></span><br><span class="line">Total time: <span class="number">9.064</span> secs</span><br></pre></td></tr></table></figure>
<p>即可完成整个编译,测试,打包,输出文件在build目录下,生成的war包在build/libs目录。</p>
<p>这个脚本使用war插件,webAppDirName指定web应用程序的根目录,工程依赖没有使用仓库,设置为本地文件路径。<br>providedCompile指定的依赖只在编译时使用,不会打包到war文件中。providedXxxx与其他依赖的区别就是,<br>其他的依赖会自动拷贝到war包的WEB-INF/lib目录中。</p>
<p>gradle使用groovy作为DSL语言,因此了解一下groovy还是十分有必要的。有一篇<a href="http://blog.csdn.net/kmyhy/article/details/4200563">groovy入门</a>和<a href="http://romejiang.iteye.com/blog/214812">闭包</a>的介绍文章比较不错。<br>gradle更详细的用法参见官方文档[1],其文档十分丰富,直接阅读官方文档即可以解决绝大部分问题。</p>
<p>Gradle真的不错,只是有点点儿慢！</p>
<p>References:<br>[1]<a href="http://www.gradle.org/docs/current/userguide/userguide_single.html">Gradle User Guide</a><br>[2]<a href="http://blog.csdn.net/kmyhy/article/details/4200563">Groovy入门教程</a><br>[3]<a href="http://romejiang.iteye.com/blog/214812">Groovy 闭包深入浅出</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>gradle代理设置</title>
    <url>/2016/05/30/gradle-proxy-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p>众所周知的原因，访问国外的网络不是那么顺畅。gradle下载插件时，几乎无法下载，而使用proxychains也不凑效。<br>可以这样为gradle设置全局socks5代理：</p>
<p>$HOME/.gradle/gradle.properties文件中添加如下行，如没有该文件请自行建立：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">org.gradle.jvmargs=-DsocksProxyHost=<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> -DsocksProxyPort=<span class="number">1080</span></span><br></pre></td></tr></table></figure>

<p>如果不设置代理，也可以使用maven镜像仓库，或者maven本地仓库。</p>
<p>最后，祝狗日的Great Fucking Wall和XXX早日死掉！ </p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Gradle SSH Plugin reject HostKey问题</title>
    <url>/2015/11/04/gradle-ssh-plugin-reject-hostkey/</url>
    <content><![CDATA[<a id="more"></a>
<p>gradle ssh plugin使用的jsch library并不能识别debian系统~/.ssh/known_hosts里面的hostkey格式，从而报reject hostkey错误。</p>
<p>使用如下命令获取主机的hostkey</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-keyscan -t rsa -p port host_ip_or_name</span><br></pre></td></tr></table></figure>
<p>将输出的主机key指纹添加到~/.ssh/known_hosts即可。</p>
<p>References:<br>[1]<a href="http://sbzhouhao.net/2015/01/21/Remote-tomcat-deployment-with-Gradle/">Remote tomcat deployment with Gradle</a><br>[2]<a href="http://anahorny.blogspot.com/2013/05/solution-for-comjcraftjschjschexception.html">Solution for com.jcraft.jsch.JSchException: reject HostKey problem on Ubuntu</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gradle ssh plugin</title>
    <url>/2015/11/07/gradle-ssh-plugin/</url>
    <content><![CDATA[<a id="more"></a>
<p>提供gradle访问ssh执行命令、传输文件的功能。</p>
<p><strong>安装</strong><br>构建脚本中添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">plugins &#123;</span><br><span class="line"> id <span class="string">&#x27;org.hidetake.ssh&#x27;</span> version <span class="string">&#x27;1.1.4&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>使用</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">remotes &#123;</span><br><span class="line"> webServer &#123;</span><br><span class="line"> host = <span class="string">&#x27;192.168.1.101&#x27;</span></span><br><span class="line"> port = <span class="number">2022</span></span><br><span class="line"> user = <span class="string">&#x27;jenkins&#x27;</span></span><br><span class="line"> identity = file(<span class="string">&#x27;id_rsa&#x27;</span>)</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">task deploy &lt;&lt; &#123;</span><br><span class="line"> ssh.run &#123;</span><br><span class="line"> <span class="function"><span class="title">session</span>(<span class="params">remotes.webServer</span>)</span> &#123;</span><br><span class="line"> put <span class="keyword">from</span>: <span class="string">&#x27;example.war&#x27;</span>, <span class="attr">into</span>: <span class="string">&#x27;/webapps&#x27;</span></span><br><span class="line"> execute <span class="string">&#x27;sudo service tomcat restart&#x27;</span></span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以使用此插件通过ssh自动部署应用程序。</p>
<p>tomcat热部署会持续的泄露PermGen内存，因此还是常规的部署更靠谱，不过应用程序会暂时中断。</p>
<p>References:<br>[1]<a href="https://github.com/int128/gradle-ssh-plugin">gradle-ssh-plugin</a><br>[2]<a href="https://gradle-ssh-plugin.github.io/">Deploy your App from Gradle</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>gradle单元测试错误superClassName is empty</title>
    <url>/2015/01/21/gradle-unittest-faile-superclasssname-is-empty/</url>
    <content><![CDATA[<a id="more"></a>
<p>执行gradle build时构建失败,有如下错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">FAILURE: Build failed <span class="keyword">with</span> an exception.</span><br><span class="line"></span><br><span class="line">* What went wrong:</span><br><span class="line">Execution failed <span class="keyword">for</span> task <span class="string">&#x27;:test&#x27;</span>.</span><br><span class="line">&gt; superClassName is empty!</span><br></pre></td></tr></table></figure>
<p>此问题的描述见<a href="https://issues.gradle.org/browse/GRADLE-1682">GRADLE-1682</a>，解决办法为在build.gradle配置文件中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">tasks.withType(Test)&#123;</span><br><span class="line"> scanForTestClasses = <span class="literal">false</span></span><br><span class="line"> include <span class="string">&quot;**/*Test.class&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>grub rescue 模式下引导修复</title>
    <url>/2013/10/19/grub-rescue-unkown-filesystem/</url>
    <content><![CDATA[<p>grub rescue 引导修复</p>
<a id="more"></a>
<p>windows 8.1出来了，升级以后重写了主引导记录，把grub给破坏了。而且开机都进不了BIOS,只能通过windows 8.1的高级启动重新引导才进入BIOS，重新设置Debian EFI引导记录为第一启动顺序。启动时提示：</p>
<p>error:unknown filesystem<br>grub rescue&gt;</p>
<p>所以需要从rescue模式下引导debian,修复grub。rescue模式下只有很少的命令可用。</p>
<p>ls列出硬盘上所有分区<br>grub rescue&gt; ls<br>(hd0) (hd0, gpt8) (hd0, gpt7) (hd0, gpt6) (hd0,gpt5) (hd0,gpt4) (hd0, gpt3) (hd0,gpt2) (hd0,gpt1)</p>
<p>找到grub所在分区<br>grub rescue&gt; ls (hd0, gpt7)/boot/grub</p>
<p>确认grub安装在(hd0,gpt7)分区，然后</p>
<p>grub rescue&gt; set root = (hd0, gpt7)<br>grub rescue&gt; set prefix = (hd0, gpt7)/boot/grub<br>grub rescue&gt; insmod normal.mod</p>
<p>最后输入normal命令进入正常的引导菜单</p>
<p>grub rescue&gt; normal</p>
<p>然后引导进入Debian系统，重新安装grub到硬盘主引导记录</p>
<h1 id="grub-install-dev-sda"><a href="#grub-install-dev-sda" class="headerlink" title="grub-install /dev/sda"></a>grub-install /dev/sda</h1><p>BootCurrent: 0000<br>Timeout: 0 seconds<br>BootOrder: 0002,2001,2002,2003<br>Boot0002* Windows Boot Manager<br>Boot2001* EFI USB Device<br>Boot2002* EFI DVD/CDROM<br>Boot2003* EFI Network<br>BootCurrent: 0000<br>Timeout: 0 seconds<br>BootOrder: 0000,0002,2001,2002,2003<br>Boot0002* Windows Boot Manager<br>Boot2001* EFI USB Device<br>Boot2002* EFI DVD/CDROM<br>Boot2003* EFI Network<br>Boot0000* debian<br>Installation finished. No error reported.</p>
<p>重新启动就可以了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gtk+计算器galculator</title>
    <url>/2011/11/21/gtk-calculator/</url>
    <content><![CDATA[<p>galculator是用gtk+ 2实现的一款计算器，功能不是很复杂，但十分好用。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>CPP博客首篇-兼论GUI轮子</title>
    <url>/2011/04/20/gui-reinvent/</url>
    <content><![CDATA[<p>注:<a href="http://www.cppblog.com/proguru/archive/2008/08/24/59755.html">原文</a>最早发表于cppblog,现转于此处。</p>
<a id="more"></a>
<p>一直以来都是一个C++的坚定支持者和努力实践者，尽管C++面临来自传统语言和动态语言的多方压力，但我仍然坚信C++有自己适用的领域和无可替代的地位。既然是C++的追随者，选择CPPBLOG来写点儿东西也就成了顺利成章的事情了。其实很久以前就考虑过在cppblog开博写点儿啥，但是一来没有文采，二来懒惰成性，这个想法就一直搁置了。最近偶然看到cexer同学的<a href="http://www.cppblog.com/cexer/archive/2008/08/06/58169.html">自己写的一个GUI框架的消息机制</a>,突然就来了兴致，而且兴致颇高，因为我也是一个GUI轮子的制造者。因为一直感觉自己的GUI轮子(暂定名KWinUI)成熟度太低，所以只是自己在用。“重复发明轮子”的论点我是不想反驳的，这个世界不可能只有一个轮子，而且我们需要更好的轮子，更性感的轮子(“性感的轮子”语出cexer,呵呵)，更适合自己的轮子。</p>
<p> GUI Framework的确是个覆盖范围极广的领域，平台依赖性比较强。线程管理、内存管理、消息派发、callback、i18n、图形渲染、组件模型、甚至包括跨平台的考虑等等，而且现在看来一个GUI Framework没有可视化GUI设计器的话，是远不够完美的。界面和逻辑的充分解耦乃是GUI Framework的终极追求之一,用xml来描述界面也许是个不错的主意。</p>
<p> C++的动态特性是比较薄弱的，比如RTTI、对象动态生成、对象序列化等等，而这些对于一个GUI Framework 来讲却是至关重要的，这需要付出更多的努力。尽管如此，C++仍然是最适合开发GUI的语言。</p>
<p> GUI如此之庞杂以至于凭一人之力实在是有所力不从心，简直是在自虐。</p>
<p> 太笨重、丑陋的GUI框架不是我所喜欢的，所以我选择做自己轻量级的框架，虽然简单，却可以全局把握，运用自如。</p>
<p> 还有一个重要的关注点，那就是thread safe，特别在这个多核风行的年代，自始至终都应该高度关注，尽量不要用全局的、static的变量，时刻注意各种competition conditions。</p>
<p> 用C++来包装GUI,thunk是一个很好的trick,甚至是必须的，下一篇就来讲一下thunk。</p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>无GUI安装Virtualbox Guest Additions</title>
    <url>/2019/06/02/guiless-install-virtualbox-guest-additions/</url>
    <content><![CDATA[<a id="more"></a>
<p>没有GUI的debian buster安装virtualbox guest additions</p>
<p>主机端：</p>
<p>启动客户机，点击菜单Devices-&gt;Insert Guest Additons Image…</p>
<p>客户机端：</p>
<p>安装内核模块build依赖:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ apt-get install -y dkms build-essential linux-headers-$(uname -r)</span><br></pre></td></tr></table></figure>

<p>挂载cdrom，安装客户附加组件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mount /dev/cdrom /media/cdrom</span><br><span class="line">$ cd /media/cdrom</span><br><span class="line">$ sudo su</span><br><span class="line"># ./VBoxLinuxAdditions.run </span><br><span class="line">Verifying archive integrity... All good.</span><br><span class="line">Uncompressing VirtualBox <span class="number">6.0</span><span class="number">.8</span> Guest Additions <span class="keyword">for</span> Linux........</span><br><span class="line">VirtualBox Guest Additions installer</span><br><span class="line">Removing installed version <span class="number">6.0</span><span class="number">.8</span> <span class="keyword">of</span> VirtualBox Guest Additions...</span><br><span class="line">Copying additional installer modules ...</span><br><span class="line">Installing additional modules ...</span><br><span class="line">VirtualBox Guest Additions: Starting.</span><br><span class="line">VirtualBox Guest Additions: Building the VirtualBox Guest Additions kernel </span><br><span class="line">modules. This may take a <span class="keyword">while</span>.</span><br><span class="line">VirtualBox Guest Additions: To build modules <span class="keyword">for</span> other installed kernels, run</span><br><span class="line">VirtualBox Guest Additions: <span class="regexp">/sbin/</span>rcvboxadd quicksetup &lt;version&gt;</span><br><span class="line">VirtualBox Guest Additions: or</span><br><span class="line">VirtualBox Guest Additions: <span class="regexp">/sbin/</span>rcvboxadd quicksetup all</span><br><span class="line">VirtualBox Guest Additions: Building the modules <span class="keyword">for</span> kernel <span class="number">4.19</span><span class="number">.0</span>-<span class="number">5</span>-amd64.</span><br><span class="line">update-initramfs: Generating /boot/initrd.img-<span class="number">4.19</span><span class="number">.0</span>-<span class="number">5</span>-amd64</span><br><span class="line">VirtualBox Guest Additions: Running kernel modules will not be replaced until </span><br><span class="line">the system is restarted</span><br></pre></td></tr></table></figure>

<p>reboot客户机</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># reboot</span><br></pre></td></tr></table></figure>

<p>校验安装:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lsmod grep vboxguest</span><br><span class="line">vboxguest <span class="number">348160</span> <span class="number">2</span> vboxsf</span><br></pre></td></tr></table></figure>

<p>安装成功</p>
<p>References:<br>[1]<a href="https://www.techrepublic.com/article/how-to-install-virtualbox-guest-additions-on-a-gui-less-ubuntu-server-host/">How to install VirtualBox Guest Additions on a GUI-less Ubuntu server host</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>gulp 清理文件/文件夹(cleanup)</title>
    <url>/2015/10/29/gulp-cleanup/</url>
    <content><![CDATA[<a id="more"></a>
<p>删除文件或文件夹时，并不会访问文件的内容，因此没有理由非要使用gulp插件处理此事，因为gulp插件主要是用来处理文件流的。</p>
<p>gulp-clean和gulp-rimraf都已经deprecated,使用del和vinyl-paths来做此项工作。</p>
<p><strong>直接删除文件</strong></p>
<p>安装del</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ npm install --save-dev del</span><br></pre></td></tr></table></figure>

<p>定义clean任务:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> del = <span class="built_in">require</span>(<span class="string">&#x27;del&#x27;</span>);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;clean&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"> <span class="keyword">return</span> del(\[<span class="string">&#x27;path1&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;path2&#x27;</span>,</span><br><span class="line"> <span class="string">&#x27;!path3&#x27;</span></span><br><span class="line"> \]);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;default&#x27;</span>, \[<span class="string">&#x27;clean:mobile&#x27;</span>\]);</span><br></pre></td></tr></table></figure>

<p>可以为del传递单个路径，也可以传递一个路径数组，支持globbing。</p>
<p><strong>从pipeline流中删除文件</strong></p>
<p>如果想在流中处理之后删除某些文件，可以使用vinyl-paths来获取流中的文件路径，然后传递给del</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> stripDebug = <span class="built_in">require</span>(<span class="string">&#x27;gulp-strip-debug&#x27;</span>); <span class="comment">// only as an example</span></span><br><span class="line"><span class="keyword">var</span> del = <span class="built_in">require</span>(<span class="string">&#x27;del&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> vinylPaths = <span class="built_in">require</span>(<span class="string">&#x27;vinyl-paths&#x27;</span>);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;clean:tmp&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"> <span class="keyword">return</span> gulp.src(<span class="string">&#x27;tmp/*&#x27;</span>)</span><br><span class="line"> .pipe(vinylPaths(del))</span><br><span class="line"> .pipe(stripDebug())</span><br><span class="line"> .pipe(gulp.dest(<span class="string">&#x27;dist&#x27;</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;default&#x27;</span>, \[<span class="string">&#x27;clean:tmp&#x27;</span>\]);</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/gulpjs/gulp/blob/master/docs/recipes/delete-files-folder.md">Delete files and folders</a><br>[2]<a href="https://github.com/robrich/gulp-rimraf">gulp-rimraf</a><br>[3]<a href="https://github.com/peter-vilja/gulp-clean">gulp-clean</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>gulp debug and log</title>
    <url>/2015/11/04/gulp-debug-and-log/</url>
    <content><![CDATA[<a id="more"></a>
<p>gulp-debug插件可以显示哪些文件经过了gulp的流水线(pipeline)</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ npm install --save-dev gulp-debug</span><br></pre></td></tr></table></figure>

<p><strong>使用</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> debug = <span class="built_in">require</span>(<span class="string">&#x27;gulp-debug&#x27;</span>);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;default&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"> <span class="keyword">return</span> gulp.src(<span class="string">&#x27;foo.js&#x27;</span>)</span><br><span class="line"> .pipe(debug())</span><br><span class="line"> .pipe(gulp.dest(<span class="string">&#x27;dist&#x27;</span>));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>gulp运行时就会输出流中所有处理的文件名:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[<span class="number">22</span>:<span class="number">20</span>:<span class="number">36</span>\] gulp-debug: foo.js</span><br></pre></td></tr></table></figure>

<p><strong>使用gulp-util输出错误</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// minify js</span></span><br><span class="line">gulp.task(<span class="string">&#x27;minifyJs&#x27;</span>, \[<span class="string">&#x27;clean&#x27;</span>\], <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> gulp.src(\[<span class="string">&#x27;**/*.js&#x27;</span>\])</span><br><span class="line"> .pipe(uglify().on(<span class="string">&#x27;error&#x27;</span>, util.log))</span><br><span class="line"> .pipe(debug())</span><br><span class="line"> .pipe(gulp.dest(<span class="string">&#x27;dist&#x27;</span>));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/sindresorhus/gulp-debug">gulp-debug</a><br>[2]<a href="https://github.com/gulpjs/gulp-util">Utilities for gulp plugins</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>gulp usemin</title>
    <url>/2015/11/03/gulp-usemin/</url>
    <content><![CDATA[<a id="more"></a>
<p>一般前端页面上线时，需要进行js,css等资源的合并、压缩，以便提高网络性能，而开发版本的html页面中添加了很多未合并压缩前的js,css资源。gulp插件gulp-usemin可以自动化的完成这一切。</p>
<p>js,css资源的合并、压缩习惯上称做minify，所以替换html文件中js,css的路径顺利成章的就叫做usemin了。</p>
<p><strong>构建标记块build block</strong></p>
<p>html文件中需要使用usemin可以识别的注释格式来标记需要压缩、合并和替换的资源</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;!-- build:&lt;pipelineId&gt;(alternate search path) &lt;path&gt; --&gt;</span><br><span class="line">... HTML Markup, list <span class="keyword">of</span> script / link tags.</span><br><span class="line">&lt;!-- endbuild --&gt;</span><br></pre></td></tr></table></figure>

<p>其中:</p>
<ul>
<li>  piplelineId<br>调用usemin时，可以通过pipelineId来指定此build block,从而为其指定相应的处理动作。如果piplelineId指定为关键词remove,则将在输出的html文件直接删除掉该构件块。</li>
<li>  alternate search path<br>默认的输入文件，比如js或css文件，是相对于当前处理的html文件的，alternate search path可以指定搜索路径。</li>
<li>  path<br>合并、压缩优化之后文件的输出路径。如果不指定path,则将处理之后的输出内联入html文件。</li>
</ul>
<p><strong>usemin选项</strong></p>
<ul>
<li>  assetsDir<br>输出文件的根目录，build block中path指定的路径就是相对于此路径。</li>
<li>  path<br>默认的alternate search path，可以被build block中的alternate search path覆盖。</li>
<li>  pipelineId<br>用于标识build block的标识符</li>
<li>  outputRelativePath<br>压缩合并后的输出文件相对于html文件的路径</li>
<li>  enableHtmlComment<br>保留html注释</li>
</ul>
<p>比如有如下的目录结构:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+- app</span><br><span class="line"> +- index.html</span><br><span class="line"> +- assets</span><br><span class="line"> +- js</span><br><span class="line"> +- foo.js</span><br><span class="line"> +- bar.js</span><br><span class="line"> +- css</span><br><span class="line"> +- clear.css</span><br><span class="line"> +- main.css</span><br><span class="line">+- dist</span><br></pre></td></tr></table></figure>

<p>我们需要将foo.js和bar.js合并压缩为optimized.js，两个css文件合并压缩为style.css<br>index.html文件是这样定义构件块的:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;!-- build:css_whatever style.css --&gt;</span><br><span class="line">&lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;css/clear.css&quot;</span>/&gt;</span><br><span class="line">&lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;css/main.css&quot;</span>/&gt;</span><br><span class="line">&lt;!-- endbuild --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- build:js_whatever js/optimized.js --&gt;</span><br><span class="line">&lt;script src=<span class="string">&quot;assets/js/foo.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script src=<span class="string">&quot;assets/js/bar.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;!-- endbuild --&gt;</span><br></pre></td></tr></table></figure>

<p>输出文件路径为dist,gulpfile.js中定义usemin任务如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> usemin = <span class="built_in">require</span>(<span class="string">&#x27;gulp-usemin&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> uglify = <span class="built_in">require</span>(<span class="string">&#x27;gulp-uglify&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> minifyCss = <span class="built_in">require</span>(<span class="string">&#x27;gulp-minify-css&#x27;</span>);</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;usemin&#x27;</span>, <span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line"> <span class="keyword">return</span> gulp.src(<span class="string">&#x27;./app/index.html&#x27;</span>)</span><br><span class="line"> .pipe(usemin(&#123;</span><br><span class="line"> js_whatever: \[uglify()\],</span><br><span class="line"> css_whatever: \[minifyCSS()\]</span><br><span class="line"> &#125;))</span><br><span class="line"> .pipe(gulp.dest(<span class="string">&#x27;dist/&#x27;</span>));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>将会产生如下的目录结构:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">+- app</span><br><span class="line"> +- index.html</span><br><span class="line"> +- assets</span><br><span class="line"> +- js</span><br><span class="line"> +- foo.js</span><br><span class="line"> +- bar.js</span><br><span class="line">+- dist</span><br><span class="line"> +- index.html</span><br><span class="line"> +- js</span><br><span class="line"> +- optimized.js</span><br><span class="line"> +- style.css</span><br></pre></td></tr></table></figure>

<p>而dist/index.html将会是这个样子的:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;style.css&quot;</span>/&gt;</span><br><span class="line"></span><br><span class="line">&lt;script src=<span class="string">&quot;js/optimized.js&quot;</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/zont/gulp-usemin">gulp-usemin</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>gulp 合并、压缩、重命名js文件</title>
    <url>/2015/11/03/gulp-%E5%90%88%E5%B9%B6%E3%80%81%E5%8E%8B%E7%BC%A9%E3%80%81%E9%87%8D%E5%91%BD%E5%90%8Djs%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> jshint = <span class="built_in">require</span>(<span class="string">&#x27;gulp-jshint&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> concat = <span class="built_in">require</span>(<span class="string">&#x27;gulp-concat&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> rename = <span class="built_in">require</span>(<span class="string">&#x27;gulp-rename&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> uglify = <span class="built_in">require</span>(<span class="string">&#x27;gulp-uglify&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> usemin = <span class="built_in">require</span>(<span class="string">&#x27;gulp-usemin&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> minifyCss = <span class="built_in">require</span>(<span class="string">&#x27;gulp-minify-css&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> minifyHtml = <span class="built_in">require</span>(<span class="string">&#x27;gulp-minify-html&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> rev = <span class="built_in">require</span>(<span class="string">&#x27;gulp-rev&#x27;</span>);</span><br><span class="line"><span class="keyword">var</span> del = <span class="built_in">require</span>(<span class="string">&#x27;del&#x27;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// lint JS,静态检查js语法错误</span></span><br><span class="line">gulp.task(<span class="string">&#x27;lint&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> gulp.src(<span class="string">&#x27;js/**/*.js&#x27;</span>)</span><br><span class="line"> .pipe(jshint())</span><br><span class="line"> .pipe(jshint.reporter(<span class="string">&#x27;default&#x27;</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Concat &amp; Minify JS,合并压缩重命名js</span></span><br><span class="line">gulp.task(<span class="string">&#x27;minify&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"><span class="keyword">return</span> gulp.src(<span class="string">&#x27;js/*.js&#x27;</span>)</span><br><span class="line"> .pipe(concat(<span class="string">&#x27;dwz.js&#x27;</span>))</span><br><span class="line"> .pipe(gulp.dest(<span class="string">&#x27;dist&#x27;</span>))</span><br><span class="line"> .pipe(rename(<span class="string">&#x27;dwz.min.js&#x27;</span>))</span><br><span class="line"> .pipe(uglify())</span><br><span class="line"> .pipe(gulp.dest(<span class="string">&#x27;dist&#x27;</span>));</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// clean,清理输出目录</span></span><br><span class="line">gulp.task(<span class="string">&#x27;clean&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> del(<span class="string">&#x27;dist/*&#x27;</span>);</span><br><span class="line">&#125;);</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>rename插件还可以接收一个函数对重命名进行更复杂的控制:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">.pipe(rename(<span class="function"><span class="keyword">function</span>(<span class="params">path</span>)</span>&#123;</span><br><span class="line"> path.basename += <span class="string">&#x27;.min&#x27;</span>;</span><br><span class="line"> path.extname = <span class="string">&#x27;.js&#x27;</span>; </span><br><span class="line">&#125;))</span><br></pre></td></tr></table></figure>

<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>H3C防火墙端口回流设置</title>
    <url>/2014/03/25/h3c-backward/</url>
    <content><![CDATA[<a id="more"></a>
<p>内网使用域名或公网IP访问同一个子网对外提供服务的服务器时,如不做特殊设置将无法访问,通过在内网接口上配置与公网接口相同的NAT设置可以解决此问题,实际上是对内网的源IP进行了NAT替换,替换成了防火墙内网接口的地址,从而使返回的数据包可以回流到防火墙再替换成正确的源IP,否则因为访问者和服务器在相同的内部网络中,数据包会走内部路由规则直接返回给访问者,由于数据包来源于内网ip而不是公网ip,会被访问者拒绝。但是ICMP不受此影响，如果用ping程序测试，网络看起来是通畅的。</p>
<p>也就是说，<strong>端口回流时，对数据包的源ip和目标ip都做了替换，源ip替换成了防火墙内网接口的ip,而目标ip替换成了内网真正提供服务机器的ip,相应包返回到防火墙内网接口时，根据此前的替换记录，将ip地址再对调回来</strong>就ok了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ telnet x.x.x.x</span><br><span class="line">&lt;fw&gt; system-view</span><br><span class="line">\[fw\] interface xxx</span><br><span class="line">\[fw\] nat server ... </span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>还要在<strong>内网接口</strong>上做相应的<a href="https://openwares.net/misc/h3c_firewall_acl.html">acl规则</a>以允许相应的内网流量从防火墙的内网接口通过。<br>比如内网接口的acl添加如下规则:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rule <span class="number">211</span> permit ip source <span class="number">192.168</span><span class="number">.2</span><span class="number">.0</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.255</span> destination <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span> <span class="number">0</span> </span><br></pre></td></tr></table></figure>
<p>以允许192.168.2.0/24网段的机器可以通过内网接口访问192.168.0.3这台机器。</p>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rule <span class="number">216</span> permit ip destination <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>允许所有的机器可以通过内网接口访问192.168.0.3这台机器。</p>
<p>UPDATE(05/26/2016):<br>但这样设置会造成一个问题，所有的访问流量无论内外网都会被替换源地址，这可能不是你想要的。<br>参见<a href="https://openwares.net/2016/05/26/h3c-secpath-nat-destination-replace/">H3C SecPath防火墙内部服务器NAT访问所有源地址被替换问题</a></p>
<p>对端口回流问题的详述见Reference[1]</p>
<p>H3C还有一种技术叫dns-map,其实这玩意儿的思路和Great Fucking Wall的DNS污染如出一辙,都是将DNS服务器返回的IP地址替换掉,不过一个是替换成错误的,而另一个是替换成更准确的(可以通过内网直接访问的)。</p>
<p>References:<br>[1]<a href="http://melodyyayun.blog.51cto.com/2111476/956326">端口回流与dns-map与域内NAT</a><br>[2]<a href="http://blog.chinaunix.net/uid-27575921-id-3462739.html">华为防火墙域之间inbound和outbound之间的区别！</a><br>[3]<a href="http://virtualadc.blog.51cto.com/3027116/723231">用传统的NAT方式替代H3C的DNS-MAP功能</a><br>[4]<a href="http://blog.163.com/iloveyou10000years@126/blog/static/16332221820137150811151">outbound与inbound的区别——华为</a><br>[5]<a href="http://bluefox.blog.51cto.com/380387/166208">linux 做防火墙端口回流问题</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
  </entry>
  <entry>
    <title>H3C Firewall 添加/删除ACL规则</title>
    <url>/2014/01/08/h3c-firewall-acl/</url>
    <content><![CDATA[<p>自己动手,丰衣足食。</p>
<a id="more"></a>
<p>进入系统视图</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;firewall&gt; system-view</span><br><span class="line">System View: <span class="keyword">return</span> to User View <span class="keyword">with</span> Ctrl+Z.</span><br></pre></td></tr></table></figure>
<p>进入指定的ACL</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[firewall\]acl number <span class="number">3000</span></span><br></pre></td></tr></table></figure>
<p>查看ACL当前的RULE</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[firewall\]display <span class="built_in">this</span></span><br></pre></td></tr></table></figure>

<p>添加规则</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[firewall\]rule <span class="number">36</span> permit ip source <span class="number">192.168</span><span class="number">.1</span><span class="number">.0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>删除规则</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[firewall\]undo rule <span class="number">36</span></span><br></pre></td></tr></table></figure>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>H3C防火墙使用nqa+track结合静态路由实现双链路热备、主备链路自动切换</title>
    <url>/2018/06/20/h3c-nqa-track-static-route-hot-standby/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为种种原因，自备机房联通和移动双物理链路接入互联网访问,联通线路经常挂掉，影响互联网访问，使用NQA(network quality analyzer)+track可以根据物理链路是否有效来自动选择静态默认路由。</p>
<p>两条默认路由的preference是不同的，网通链路优先，当两条链路都有效时，默认路由走联通链路，当联通链路失效时，联通默认路由自动被禁止，从而默认路由走移动链路。</p>
<p><strong>配置步骤</strong><br>启用nqa,默认是启动状态</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">nqa agent enable</span><br></pre></td></tr></table></figure>

<p>１、配置nqa自动侦测两条物理链路<br>网通链路nqa侦测组(test group)：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line">nqa entry admin wangtong #添加nqa侦测项目</span><br><span class="line">type icmp-echo #配置测试例类型为ICMP-echo并进入测试类型视图</span><br><span class="line">　　destination ip 网通网关ip #配置测试操作的目的IP地址,如果网关开启了防ping功能，是ping不通的，必须设置其他一个可以ping通的地址</span><br><span class="line">　　next-hop 网通网关ip #配置IP报文的下一跳IP地址，即网关的ip，若destination设的是网关ip，可以不配置，若destination不是网关ip，则必须配置</span><br><span class="line">　　probe count 3 #配置一次NQA测试中进行探测的次数，默认为1，此处也可以不设置</span><br><span class="line">　　probe timeout 1000 #配置NQA探测超时时间，默认为3000ms,可以不设置，用默认的</span><br><span class="line">　　frequency 1000 #测试频率为1000ms既测试组连续两次测试开始时间的时间间隔为1秒，最好设置下</span><br><span class="line">　　reaction 2 checked-element probe-fail threshold-type consecutive 3 action-type trigger-only #建立联动项2，既如果连续测试3次失败则触发相关动作。每个测试组可以有多条reaction，分别指定不同的编号即可。</span><br></pre></td></tr></table></figure>
<p>移动链路nqa侦测组(test group)：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line">nqa entry admin yidong #添加nqa侦测项目</span><br><span class="line">type icmp-echo #配置测试例类型为ICMP-echo并进入测试类型视图</span><br><span class="line">　　destination ip 移动网关ip #配置测试操作的目的IP地址,如果网关开启了防ping功能，是ping不通的，必须设置其他一个可以ping通的地址</span><br><span class="line">　　next-hop 移动网关ip #配置IP报文的下一跳IP地址，即网关的ip，若destination设的是网关ip，可以不配置，若destination不是网关ip，则必须配置</span><br><span class="line">　　probe count 3 #配置一次NQA测试中进行探测的次数，默认为1，此处也可以不设置</span><br><span class="line">　　probe timeout 1000 #配置NQA探测超时时间，默认为3000ms,可以不设置，用默认的</span><br><span class="line">　　frequency 1000 #测试频率为1000ms既测试组连续两次测试开始时间的时间间隔为1秒，最好设置下</span><br><span class="line">　　reaction 1 checked-element probe-fail threshold-type consecutive 3 action-type trigger-only #建立联动项1，既如果连续测试3次失败则触发相关动作</span><br></pre></td></tr></table></figure>

<p>每个nqa侦测可以绑定多个reaction动作，比如reaction 1, reaction 2, reaction 3,…</p>
<p>2、创建侦测项目中reaction关联的track</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">track <span class="number">1</span> nqa entry admin yidong reaction <span class="number">1</span></span><br><span class="line">track <span class="number">2</span> nqa entry admin wangtong reaction <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>3、启动nqa侦测组</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">nqa schedule admin wangtong start-time now lifetime forever #启动网通链路探测组</span><br><span class="line">nqa schedule admin yidong start-time now lifetime forever #启动移动链路探测组</span><br></pre></td></tr></table></figure>

<p>可以用undo来停止侦测组</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">undo nqa schedule admin wangtong #停止网通链路侦测组</span><br><span class="line">undo nqa schedule admin yidong #停止移动链路侦测组</span><br></pre></td></tr></table></figure>

<p>4、设置track联动的静态默认路由</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">ip route-static 0.0.0.0 0.0.0.0 222.132.*.* track 2 #联通链路,默认preferece为60,低于80，所以优先使用联通链路</span><br><span class="line">ip route-static 0.0.0.0 0.0.0.0 218.201.*.* track 1 preference 80 #移动链路，备份线路</span><br></pre></td></tr></table></figure>

<p><strong>查看状态</strong></p>
<p>查看track</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">display track all #或者查看指定的track: display track 1</span><br><span class="line">Track ID: <span class="number">1</span></span><br><span class="line"> Status: Positive</span><br><span class="line"> Notification delay: Positive <span class="number">0</span>, Negative <span class="number">0</span> (<span class="keyword">in</span> seconds)</span><br><span class="line"> Reference object:</span><br><span class="line"> NQA entry: admin yidong</span><br><span class="line"> Reaction: <span class="number">1</span></span><br><span class="line">Track ID: <span class="number">2</span></span><br><span class="line"> Status: Negative</span><br><span class="line"> Notification delay: Positive <span class="number">0</span>, Negative <span class="number">0</span> (<span class="keyword">in</span> seconds)</span><br><span class="line"> Reference object:</span><br><span class="line"> NQA entry: admin wangtong</span><br><span class="line"> Reaction: <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>可以看到网通链路挂了，移动链路是有效的。</p>
<p>查看nqa统计</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">display nqa statistics</span><br><span class="line">NQA entry(admin admin, tag yidong) test statistics:</span><br><span class="line"> NO. : <span class="number">1</span></span><br><span class="line"> Destination IP address: <span class="number">218.201</span>.*.* </span><br><span class="line"> Start time: <span class="number">2000</span>-<span class="number">10</span>-<span class="number">16</span> <span class="number">15</span>:<span class="number">00</span>:<span class="number">37.9</span> </span><br><span class="line"> Life time: <span class="number">3520</span> </span><br><span class="line"> Send operation times: <span class="number">33633</span> Receive response times: <span class="number">33628</span> </span><br><span class="line"> Min/Max/Average round trip time: <span class="number">1</span>/<span class="number">5</span>/<span class="number">1</span> </span><br><span class="line"> Square-Sum <span class="keyword">of</span> round trip time: <span class="number">33773</span> </span><br><span class="line"> Extended results:</span><br><span class="line"> Packet lost <span class="keyword">in</span> test: <span class="number">0</span>% </span><br><span class="line"> Failures due to timeout: <span class="number">5</span></span><br><span class="line"> Failures due to disconnect: <span class="number">0</span> </span><br><span class="line"> Failures due to no connection: <span class="number">0</span></span><br><span class="line"> Failures due to sequence error: <span class="number">0</span> </span><br><span class="line"> Failures due to internal error: <span class="number">0</span></span><br><span class="line"> Failures due to other errors: <span class="number">0</span></span><br><span class="line"> Packet(s) arrived late: <span class="number">0</span></span><br><span class="line"> NQA entry(admin admin, tag wangtong) test statistics:</span><br><span class="line"> NO. : <span class="number">1</span></span><br><span class="line"> Destination IP address: <span class="number">222.132</span>.*.* </span><br><span class="line"> Start time: <span class="number">2000</span>-<span class="number">10</span>-<span class="number">16</span> <span class="number">15</span>:<span class="number">00</span>:<span class="number">07</span><span class="number">.6</span> </span><br><span class="line"> Life time: <span class="number">3549</span> </span><br><span class="line"> Send operation times: <span class="number">1099</span> Receive response times: <span class="number">0</span> </span><br><span class="line"> Min/Max/Average round trip time: <span class="number">0</span>/<span class="number">0</span>/<span class="number">0</span> </span><br><span class="line"> Square-Sum <span class="keyword">of</span> round trip time: <span class="number">0</span> </span><br><span class="line"> Extended results:</span><br><span class="line"> Packet lost <span class="keyword">in</span> test: <span class="number">100</span>% </span><br><span class="line"> Failures due to timeout: <span class="number">1099</span></span><br><span class="line"> Failures due to disconnect: <span class="number">0</span> </span><br><span class="line"> Failures due to no connection: <span class="number">0</span></span><br><span class="line"> Failures due to sequence error: <span class="number">0</span> </span><br><span class="line"> Failures due to internal error: <span class="number">0</span></span><br><span class="line"> Failures due to other errors: <span class="number">0</span></span><br><span class="line"> Packet(s) arrived late: <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>可以看到网通链路是无效的。</p>
<p>查看当前路由表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">display ip routing-table</span><br><span class="line">Routing Tables: Public</span><br><span class="line"> Destinations : <span class="number">419</span> Routes : <span class="number">419</span></span><br><span class="line"></span><br><span class="line">Destination/Mask Proto Pre Cost NextHop Interface</span><br><span class="line"></span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> Static <span class="number">80</span> <span class="number">0</span> <span class="number">218.201</span>.*.* Vlan200</span><br><span class="line"><span class="number">2.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">8</span> Direct <span class="number">0</span> <span class="number">0</span> <span class="number">2.0</span><span class="number">.0</span><span class="number">.59</span> Vlan300</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>可以看到当前默认路由走的是移动链路。</p>
<p>References:<br>[1]<a href="https://www.iyunv.com/thread-70703-1-1.html">H3C防火墙/路由器通过Track实现双线接入的链路备份</a><br>[2]<a href="http://www.h3c.com.hk/Technical_Support___Documents/Technical_Documents/Security_Products/H3C_SecPath_F1000-E/Configuration/Operation_Manual/H3C_SecPath_High-End_OM(F3169_F3207)-5PW106/05/201109/725892_1285_0.htm">H3C NQA Configuration</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>H3C SecPath防火墙内部服务器NAT访问所有源地址被替换问题</title>
    <url>/2016/05/26/h3c-secpath-nat-destination-replace/</url>
    <content><![CDATA[<a id="more"></a>
<p>设置NAT内部服务器，并且设置了<a href="https://openwares.net/2014/03/25/h3c_backward/">端口回流</a>，内网可以正常通过公网ip访问内部服务。</p>
<p>但是当通过外网访问该服务时，从服务器上观察，TCP连接的源地址也被替换成了防火墙的内网接口地址，不过访问一切正常。</p>
<p>经排查，是因为设置端口回流时，在内网接口的ACL条目中未指定source,类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rule <span class="number">216</span> permit ip destination <span class="number">10.100</span><span class="number">.0</span><span class="number">.31</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>导致防火墙将所有访问NAT服务的源地址全部替换成了防火墙的内网接口地址(内网接口优先级高，且不区分内外网网络地址???)。</p>
<p>通过指定哪些内网段访问NAT服务器时可以通过内网接口，可以只替换这些网段的源地址。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rule <span class="number">226</span> permit ip source <span class="number">192.168</span><span class="number">.1</span><span class="number">.0</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.255</span> destination <span class="number">10.100</span><span class="number">.0</span><span class="number">.31</span> <span class="number">0</span> </span><br><span class="line">rule <span class="number">227</span> permit ip source <span class="number">192.168</span><span class="number">.2</span><span class="number">.0</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.255</span> destination <span class="number">10.100</span><span class="number">.0</span><span class="number">.31</span> <span class="number">0</span> </span><br></pre></td></tr></table></figure>
<p>这样以来，外网访问时，源地址没有被替换，但acl rule未指定的其他内网地址段将不能通过公网ip访问NAT服务。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>硬盘最小安装Ubuntu 10.10(Maverick MeerKat)</title>
    <url>/2010/10/16/harddisk-install-ubuntu-10-10-maverick-meerkat/</url>
    <content><![CDATA[<p>一、下载配置grub4dos<br>下载<a href="http://sourceforge.net/projects/grub4dos/">grub4dos</a>,解压后将grldr文件拷贝到C分区根目录,在c:\boot.ini文件末尾增加一行c:\grldr=”grub4dos”</p>
<a id="more"></a>
<p>在C分区根目录下新建grub4dos配置文件menu.lst,内容如下:</p>
<p>title Ubuntu 10.10<br>find –set-root /ubuntu-10.10-alternate-amd64.iso<br>kernel /vmlinuz noacpi iso-scan/filename=/ubuntu-10.10-alternate-amd64.iso ro quiet splash<br>initrd /initrd.gz</p>
<p>二、下载Ubuntu 10.10硬盘安装映像<br>从官方下载<a href="http://archive.ubuntu.com/ubuntu/dists/maverick/main/installer-amd64/current/images/hd-media/">Maverick的硬盘安装映像</a>vmlinux和initrd.gz,将这两个文件拷贝到C分区根目录</p>
<p>三、下载Ubuntu 10.10并开始安装<br>最小化安装要下载Alternate版本的iso镜像,从官方下载<a href="http://releases.ubuntu.com/maverick/ubuntu-10.10-alternate-amd64.iso.torrent">Ubuntu 10.10 AMD64安装镜像种子</a>文件,下载后将ubuntu-10.10-alternate-amd64.iso放置到C分区根目录下.</p>
<p>重新启动机器,选择启动菜单的grub4dos项即可开始硬盘安装ubuntu,装完基本系统(base system)后不要选择安装其他组件即可完成最小化安装.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>主总线适配器 HBA (host bus adapter)</title>
    <url>/2011/11/01/hba/</url>
    <content><![CDATA[<p>HBA卡即主总线适配器host bus adapter</p>
<a id="more"></a>
<p>HBA卡用于连接外围网络或存储设备到主系统，通常指SCSI,Fibre Channel和eSATA等存储设备与主系统的连接。现在大部分时候,HBA接口卡基本上就是指光线通道接口卡。当然HBA也适用于其他类型的设备，比如HBA网络接口卡,这种网卡与传统Ethernet NICs有一个区别，可以承担TCP的解包卸载，减轻主系统的计算压力。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>oracle文件hc_SID.dat与oradba.exe</title>
    <url>/2011/12/31/hc-sid-dat-oradba-exe-file/</url>
    <content><![CDATA[<p>hc_<ORACLE_SID>.dat文件用于实例的健康检查,oradba.exe用于windows平台创建ORA_DBA用户组</p>
<a id="more"></a>
<p>UNIX/LINUX平台上两文件所在路径为$ORACLE_HOME/dbs/,windows平台两文件所在路径为$ORACLE_HOME/database/</p>
<p>hc_<ORACLE_SID>.dat为实例的健康检查监视而创建,它包含了用于监视实例健康状态的信息,当实例关闭时可以用该文件确定实例因为什么原因而关闭。每次实例启动时重建该文件。如果用一个空白文件替换该文件,会得到ORA-7445错误。</p>
<p>oradba.exe用于windows平台创建ORA_DBA用户组,并将DBA用户加入ORA_DBA用户组。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Headless Server</title>
    <url>/2009/12/23/headless-server/</url>
    <content><![CDATA[<p>无头服务器？很黄很暴力！</p>
<p>Headless Server是指没有物理控制台的服务器，即没有键盘、鼠标和显示器的服务器。BIOS和操作系统必须都支持Headless Mode才可以运行Headless Server。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>Hello Docker</title>
    <url>/2017/10/28/hello-docker/</url>
    <content><![CDATA[<a id="more"></a>
<p>博客正式迁移到docker平台！</p>
]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>hello gulp</title>
    <url>/2015/10/27/hello-gulp/</url>
    <content><![CDATA[<p><a href="https://github.com/gulpjs/gulp">gulp</a>是一个流式构建系统。</p>
<a id="more"></a>
<p>gulp基于nodejs，可用于自动化构建前端工程，或者nodejs工程。</p>
<p><strong>安装</strong></p>
<p>安装node package manager</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install npm</span><br></pre></td></tr></table></figure>

<p>全局安装gulp</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># npm install --global gulp</span><br></pre></td></tr></table></figure>

<p>工程安装gulp,工程根目录下执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ npm install --save-dev gulp</span><br></pre></td></tr></table></figure>

<p>验证安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gulp -v</span><br><span class="line">\[<span class="number">22</span>:<span class="number">30</span>:<span class="number">17</span>\] CLI version <span class="number">3.9</span><span class="number">.0</span></span><br><span class="line">\[<span class="number">22</span>:<span class="number">30</span>:<span class="number">17</span>\] Local version <span class="number">3.9</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>

<p>如果提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/usr/bin/env: node: No such file or directory</span><br></pre></td></tr></table></figure>

<p>请修改/usr/local/bin/gulp文件第一行使用的shell程序为nodejs</p>
<p><strong>hello world</strong></p>
<p>工程根目录(或用户主目录下)新建gulpfile.js</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> gulp = <span class="built_in">require</span>(<span class="string">&#x27;gulp&#x27;</span>)</span><br><span class="line"></span><br><span class="line">gulp.task(<span class="string">&#x27;default&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"> <span class="built_in">console</span>.log(<span class="string">&#x27;Hello World!&#x27;</span>);</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>

<p>然后执行gulp,会自动在用户主目录或工程根目录下查找文件gulpfile.js</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gulp</span><br><span class="line"></span><br><span class="line">\[<span class="number">22</span>:<span class="number">33</span>:<span class="number">59</span>\] Using gulpfile ~/gulpfile.js</span><br><span class="line">\[<span class="number">22</span>:<span class="number">33</span>:<span class="number">59</span>\] Starting <span class="string">&#x27;default&#x27;</span>...</span><br><span class="line">Hello World!</span><br><span class="line">\[<span class="number">22</span>:<span class="number">33</span>:<span class="number">59</span>\] Finished <span class="string">&#x27;default&#x27;</span> after <span class="number">147</span> μs</span><br></pre></td></tr></table></figure>

<p><strong>基础函数</strong><br>gulp命令很简洁，主要有</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">gulp.src</span><br><span class="line">gulp.dest</span><br><span class="line">gulp.task</span><br><span class="line">gulp.watch</span><br></pre></td></tr></table></figure>

<p>掌握了这几个函数，再加上丰富的插件，就可以做很多很多有趣的事情了。</p>
<p><strong>gulp以写javascript代码的方式而不是写配置文件的方式来做所有的一切。</strong></p>
<p>References:<br>[1]<a href="https://github.com/gulpjs/gulp/blob/master/docs/API.md">gulp API docs</a><br>[2]<a href="http://www.cnblogs.com/2050/p/4198792.html">前端构建工具gulpjs的使用介绍及技巧</a><br>[3]<a href="http://zhuanlan.zhihu.com/TLA42/19691575">Gulp —— 另一种自动化流水线</a><br>[4]<a href="http://www.reqianduan.com/1228.html">gulp.js实现非覆盖式发布</a><br>[5]<a href="http://segmentfault.com/a/1190000000435599">“流式”前端构建工具——gulp.js 简介</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello Qt5</title>
    <url>/2016/09/13/hello-qt5/</url>
    <content><![CDATA[<a id="more"></a>
<p>传统上，第一个程序就是hello world, Qt也不例外。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#include &lt;QApplication&gt;</span><br><span class="line">#include &lt;QLabel&gt;</span><br><span class="line"></span><br><span class="line">int <span class="function"><span class="title">main</span>(<span class="params">int argc, char** argv</span>)</span>&#123;</span><br><span class="line"> QApplication app(argc, argv);</span><br><span class="line"></span><br><span class="line"> QLabel lMsg(<span class="string">&quot;Hello QT5!&quot;</span>);</span><br><span class="line"> lMsg.show();</span><br><span class="line"></span><br><span class="line"> <span class="keyword">return</span> app.exec();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>编译</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ qmake -project</span><br><span class="line">$ qmake </span><br><span class="line">$ make</span><br></pre></td></tr></table></figure>

<p>出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">hello.cpp:<span class="number">1</span>:<span class="number">24</span>: fatal error: QApplication: No such file or directory</span><br></pre></td></tr></table></figure>

<p>是因为Qt5将大部分桌面部件移到了Qt Widgets模块中，即QApplication已经从原来的QtGui/QApplication移动到QtWidgets/QApplication了。<br>而qmake默认只连接core和gui下的模块，因此需要修改生成的hello.pro,最后面添加widgets里面的模块：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">QT += widgets</span><br></pre></td></tr></table></figure>

<p>然后重新qmake和make就可以生成动态连接的目标文件hello,执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./hello</span><br></pre></td></tr></table></figure>

<p>一个最简单的Qt5 GUI程序就出现了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>heredoc的分隔标识符</title>
    <url>/2013/11/08/heredoc-delimiting-identifier/</url>
    <content><![CDATA[<p>here文档，又称作heredoc、hereis、here-字串或here-脚本。</p>
<a id="more"></a>
<p>是一种在shell（如sh、csh、ksh、bash、PowerShell和zsh）或程序语言（像Perl、PHP、Python和Ruby）里定义一个字串的方法。它可以保存文字里面的换行或是缩排等空白字符。不bash允许在字串里执行变量替换和命令替换。</p>
<p>here文档最通用的语法是&lt;&lt;紧跟一个标识符，从下一行开始是想要引用的文字，然后再在单独的一行用相同的标识符关闭。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">psql -U role -h localhost -d database &lt;&lt;EOF</span><br><span class="line">INSERT INTO $&#123;mytable&#125; VALUES($&#123;value1&#125;,$&#123;value2&#125;);</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>最常用的分隔符还是EOF，虽然任何成对的普通字符比如END_TEXT都可以作为分隔标识符。<br>重定向表示符&lt;&lt;和分隔标识符(通常为EOF)之间可以有空白也可以没有。但是用于结束的分隔标识符则必须位于单独的一行上，且不能有前导或后继的空白。<br>如果为了美观要缩进结束分隔标识符，则需要在重定向标识符&lt;&lt;加一个-号，然后在结束分隔标识符前输入TAB，而且只能是TAB不能是空格，所有有时候需要用CTRL-v + TAB来输入一个真正的TAB字符。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">psql -U role -h localhost -d database &lt;&lt;-EOF</span><br><span class="line">INSERT INTO $&#123;mytable&#125; VALUES($&#123;value1&#125;,$&#123;value2&#125;);</span><br><span class="line">&lt;TAB&gt;&lt;TAB&gt;EOF</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello Tkinter</title>
    <url>/2015/07/30/hello-tkinter/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/python3</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tkinter</span><br><span class="line"></span><br><span class="line">#<span class="keyword">from</span> tkinter <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">tk = tkinter</span><br><span class="line">root = tk.Tk()</span><br><span class="line">label = tk.Label(root, text=<span class="string">&quot;hello tkinter&quot;</span>)</span><br><span class="line">label.pack()</span><br><span class="line">root.mainloop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>有趣的Homebrew命名逻辑</title>
    <url>/2015/10/08/homebrew-naming-convention/</url>
    <content><![CDATA[<a id="more"></a>
<p>嗯，这篇是转帖的，因为GFW blocked this <a href="http://wildjcrt.pixnet.net/blog/post/29182044-the-naming-logic-from-homebrew">post</a>,又没有再写一篇的必要。</p>
<p><strong>“</strong> Homebrew 是一套在 Mac OS X 下使用的套件管理工具，以往大家會使用 Mac Ports ，但是 port 的套件相依性太深，常常會為了裝個小套件而跟著裝上一堆用不到的相依套件，甚至造成套件版本衝突…… 因此 Homwbrew 甫一推出立刻受到大家的歡迎。</p>
<p>今天早上我剛好重裝 readline 套件，安裝完成後訊息提示我 readline 套件是 「keg-only」。我為了查出「keg-only」到底是指什麼意思，結果解開一連串的謎題，真相終於大白！ Homebrew 的所有命名真的非常有邏輯～～</p>
<p>首先， brew 本身是釀造、釀酒的意思，會用這個字的原因是 homebrew 的安裝方式為下載 source code 回來做編譯，由於是在自己電腦做 local complie 編譯套件，所以這個工具叫做 homebrew 自家釀酒。</p>
<p>釀酒需要有配方 formula ，當你需要安裝套件時，流程就是下 brew 命令去根據配方 formula ，釀造出一桶（keg）酒來。所以 keg 指的是整個編譯完成的套件資料夾。</p>
<p>再來，放置套件的位置在 /usr/local/Cellar ， Cellar 就是地窖，一桶一桶釀好的酒當然要存放在地窖裡囉！所以編譯完成的套件資料夾 keg 預設目錄在 /usr/local/Cellar 。</p>
<p>最後回到「keg-only」這個詞，字面上意思現在就很清楚，表示這個套件只會存放在桶子裡，不會跑出桶子外；實際上的行為是 brew 不會幫你做 symlink 到 /usr/local ，避免你的原生系統內還有一套 readline 而打架，所以訊息提示說 readline 套件是 keg-only 。</p>
<p>至此謎題全部解開啦！ Homebrew 的命名邏輯真是超有趣的～ <strong>”</strong></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>FreeBSD</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>homebrew 卸载formula</title>
    <url>/2015/01/08/homebrew-uninstall-formula/</url>
    <content><![CDATA[<a id="more"></a>
<p>卸载formula的当前版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew remove postgresql</span><br></pre></td></tr></table></figure>

<p>卸载formula全部版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew uninstall --force postgresql</span><br></pre></td></tr></table></figure>

<p>卸载formula指定版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew <span class="keyword">switch</span> postgresql <span class="number">9.3</span><span class="number">.4</span></span><br><span class="line">$ brew remove postgresql</span><br></pre></td></tr></table></figure>

<p>卸载formula全部旧版本,如果不指定formula则清理所有formula的旧版本。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew cleanup postgresql</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>webmail之horde安装配置</title>
    <url>/2014/01/04/horde-webmail/</url>
    <content><![CDATA[<p>因为使用debian源安装horde会默认使用apache,所以改用pear方式安装horde</p>
<a id="more"></a>
<p><strong>安装pear</strong></p>
<h1 id="apt-get-install-php-pear"><a href="#apt-get-install-php-pear" class="headerlink" title="apt-get install php-pear"></a>apt-get install php-pear</h1><p>更新pear包</p>
<h1 id="pear-upgrade-PEAR"><a href="#pear-upgrade-PEAR" class="headerlink" title="pear upgrade PEAR"></a>pear upgrade PEAR</h1><p>如果提示:<br>PHP Warning: PHP Startup: Unable to load dynamic library ‘/usr/lib/php5/20100525/suhosin.so’ - /usr/lib/php5/20100525/suhosin.so: cannot open shared object file: No such file or directory in Unknown on line 0<br>Nothing to upgrade</p>
<p>卸载php5-suhosin就好了</p>
<h1 id="apt-get-remove-php5-suhosin-–purge"><a href="#apt-get-remove-php5-suhosin-–purge" class="headerlink" title="apt-get remove php5-suhosin –purge"></a>apt-get remove php5-suhosin –purge</h1><p>或</p>
<h1 id="aptitude-purge-php5-suhosin"><a href="#aptitude-purge-php5-suhosin" class="headerlink" title="aptitude purge php5-suhosin"></a>aptitude purge php5-suhosin</h1><p><strong>pear配置及horde安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># pear config-show</span><br><span class="line">PEAR directory php_dir /usr/share/php</span><br></pre></td></tr></table></figure>
<p>确保/usr/share/php在/etc/php5/fpm/php.ini文件的include_path字段值中,默认是注释的掉,打开后如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">; UNIX: <span class="string">&quot;/path1:/path2&quot;</span></span><br><span class="line">include_path = <span class="string">&quot;.:/usr/share/php&quot;</span></span><br></pre></td></tr></table></figure>

<p>注册Horde PEAR channel server</p>
<h1 id="pear-channel-discover-pear-horde-org"><a href="#pear-channel-discover-pear-horde-org" class="headerlink" title="pear channel-discover pear.horde.org"></a>pear channel-discover pear.horde.org</h1><p>安装pear install horde/horde_role,horde_role用于定义horde的安装目录,</p>
<h1 id="pear-install-horde-horde-role"><a href="#pear-install-horde-horde-role" class="headerlink" title="pear install horde/horde_role"></a>pear install horde/horde_role</h1><h1 id="pear-run-scripts-horde-horde-role"><a href="#pear-run-scripts-horde-horde-role" class="headerlink" title="pear run-scripts horde/horde_role"></a>pear run-scripts horde/horde_role</h1><p>切记,在第二步运行脚本时提示安装路径,一定不要用带有符号链接的路径,否则horde会傻掉,不会在指定的路径安装任何东西。</p>
<p>安装horde</p>
<h1 id="pear-install-a-horde-horde"><a href="#pear-install-a-horde-horde" class="headerlink" title="pear install -a horde/horde"></a>pear install -a horde/horde</h1><p>安装webmail</p>
<h1 id="pear-install-horde-webmail"><a href="#pear-install-horde-webmail" class="headerlink" title="pear install horde/webmail"></a>pear install horde/webmail</h1><p>拷贝默认horde配置</p>
<h1 id="cd-horde-config"><a href="#cd-horde-config" class="headerlink" title="cd horde/config"></a>cd horde/config</h1><h1 id="cp-conf-php-dist-conf-dist"><a href="#cp-conf-php-dist-conf-dist" class="headerlink" title="cp conf.php.dist conf.dist"></a>cp conf.php.dist conf.dist</h1><p><strong>创建并初始化webmail数据库</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mysql&gt; create database groupware;</span><br><span class="line">mysql&gt; grant all on groupware.* to groupware@localhost identified by <span class="string">&#x27;groupware&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>查看horde bin文件路径</p>
<h1 id="pear-config-get-bin-dir"><a href="#pear-config-get-bin-dir" class="headerlink" title="pear config-get bin_dir"></a>pear config-get bin_dir</h1><p>/usr/bin</p>
<p>初始化webmall</p>
<h1 id="webmail-install"><a href="#webmail-install" class="headerlink" title="webmail-install"></a>webmail-install</h1><p>根据提示输入相关配置信息,最后初始化数据库。如提示如下错误：<br>Fatal Error:<br>The Content_Tagger class could not be found. Make sure the Content application is installed.<br>In /home/${username}/public_html/horde/kronolith/migration/18_kronolith_upgrade_categoriestotags.php on line 25</p>
<p>而确认horde/content已经安装了,可以打开horde/config/registry.php文件,在文件最后添加如下行:<br>[php]<br>$this-&gt;applications[‘content’] = array(<br> ‘fileroot’ =&gt; dirname(<strong>FILE</strong>) . ‘/../content’,<br> ‘webroot’ =&gt; $this-&gt;applications[‘horde’][‘webroot’] . ‘/content’,<br> ‘status’ =&gt; ‘hidden’<br> );<br>[/php]<br>或者将存在的’content’ =&gt; array(行修改为以上内容。</p>
<p><strong>nginx虚拟主机配置</strong><br>新增配置文件<br>/etc/nginx/sites-available/horde.openwares.net.conf,其内容如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"> listen <span class="number">80</span>; </span><br><span class="line"> server_name horde.openwares.net;</span><br><span class="line"> root /home/$&#123;username&#125;/www/horde;</span><br><span class="line"> index index.php;</span><br><span class="line"> access_log /<span class="keyword">var</span>/log/nginx/horde.openwares.net_access.log;</span><br><span class="line"> error_log /<span class="keyword">var</span>/log/nginx/horde.openwares.net_error.log;</span><br><span class="line"></span><br><span class="line"> include php-fpm.conf;</span><br><span class="line"> include errpage.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在/etc/nginx/sites-enable目录下建好符号连接,reload nginx就可以了。</p>
<p><strong>测试horde</strong></p>
<p>编辑horde/conf.php,打开test<br>[php]<br>$conf[‘testdisable’] = false;<br>[/php]</p>
<p>浏览器输入<a href="http://horde.ip/test.php%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E6%B5%8B%E8%AF%95%E4%BF%A1%E6%81%AF%E4%BA%86%E3%80%82">http://horde.ip/test.php就可以看到测试信息了。</a></p>
<p><strong>IMAP设置</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用hp-setup配置HP P1008打印机</title>
    <url>/2014/01/15/hp-setup-p1008/</url>
    <content><![CDATA[<a id="more"></a>
<p><a href="https://openwares.net/linux/debian_printer_1008_setup.html">Debian安装P1008打印机</a>这篇post里使用getweb为P1008下载firmware,打印测试也成功了。但每次重新启动打印机,都无法打印,删除掉重新安装打印机才可以。不知道哪里的原因。</p>
<p><strong>安装配置</strong></p>
<p>只好重新配置,这次使用hplip(HP Linux Imaging and Printing)包里的hp-setup来配置打印机。这是一个图形化的HP打印机配置程序。</p>
<p>首先需要安装hplip-gui,默认是没有安装的,hp-setup需要这个包:</p>
<h1 id="apt-get-install-hplip-gui"><a href="#apt-get-install-hplip-gui" class="headerlink" title="apt-get install hplip-gui"></a>apt-get install hplip-gui</h1><p>将打印机连接,上电,然后启动hp-setup,不要用sudo,直接使用root</p>
<h1 id="hp-setup"><a href="#hp-setup" class="headerlink" title="hp-setup"></a>hp-setup</h1><p>会搜索到打印机,然后需要下载一个专有的plugin程序,但一直下载不成功。可以手动下载执行,然后再重新执行hp-setup</p>
<p><em>下载hp提供的专有plugin</em></p>
<p>根据系统安装的hplip版本选择下载对应的<a href="http://www.openprinting.org/download/printdriver/auxfiles/HP/plugins/">plugin</a>。可以使用dpkg -l hplip查看hplip的版本,比如3.13.11-2,下载3.13.11版本的<a href="http://www.openprinting.org/download/printdriver/auxfiles/HP/plugins/hplip-3.13.11-plugin.run">plugin</a>就行了。</p>
<p><em>然后安装plugin</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># chmod +x hplip-3.13.11-plugin.run</span><br><span class="line"># ./hplip-3.13.11-plugin.run</span><br><span class="line">Verifying archive integrity... All good.</span><br><span class="line">Uncompressing HPLIP <span class="number">3.13</span><span class="number">.11</span> Plugin Self Extracting Archive...............................</span><br><span class="line"></span><br><span class="line">HP Linux Imaging and Printing System (ver. <span class="number">3.13</span><span class="number">.11</span>)</span><br><span class="line">Plugin Installer ver. <span class="number">3.0</span></span><br><span class="line"></span><br><span class="line">Copyright (c) <span class="number">2001</span>-<span class="number">13</span> Hewlett-Packard Development Company, LP</span><br><span class="line">This software comes <span class="keyword">with</span> ABSOLUTELY NO WARRANTY.</span><br><span class="line">This is free software, and you are welcome to distribute it</span><br><span class="line">under certain conditions. See COPYING file <span class="keyword">for</span> more details.</span><br><span class="line"></span><br><span class="line">Plug-<span class="keyword">in</span> version: <span class="number">3.13</span><span class="number">.11</span></span><br><span class="line">Installed HPLIP version: <span class="number">3.13</span><span class="number">.11</span></span><br><span class="line"><span class="built_in">Number</span> <span class="keyword">of</span> files to install: <span class="number">26</span></span><br><span class="line"></span><br><span class="line">Done.</span><br></pre></td></tr></table></figure>

<p>最后重新运行hp-setup就可以完成安装了,这次安装完了貌似没问题了。</p>
<p><strong>共享本地打印机</strong></p>
<p>安装好的本地打印机可以通过网络共享给其他用户使用。</p>
<p><em>本地设置</em><br>通过浏览器访问<a href="http://127.0.0.1:631,进入Administration页签,右侧Server栏下,勾选&quot;Share">http://127.0.0.1:631,进入Administration页签,右侧Server栏下,勾选&quot;Share</a> printers connected to this system”,这样默认是在本地网络上共享打印机,只有同一个网段的主机才能通过网络使用这台打印机。如果同时勾选了”Allow printing from the Internet”,则所有通过网络可以访问这台主机的机器都可以使用这台打印机。</p>
<p><em>客户端连接</em><br>如果使用XP系统通过网络使用这台打印机,在添加打印机向导中,选择”网络打印机-&gt;连接到Internet、家庭或办公网络上的打印机”,URL中输入打印机的地址,如下:</p>
<p><a href="http://192.168.1.88:631/printers/HP_LaserJet_P1008">http://192.168.1.88:631/printers/HP_LaserJet_P1008</a></p>
<p>这段URL除了最后的打印机名称,前面是固定的,打印机名称从打印机管理界面(<a href="http://127.0.0.1:631)的printers页签可以看到。">http://127.0.0.1:631)的printers页签可以看到。</a></p>
<p>然后下一步安装打印机的XP驱动就可以了。最好提前安装打印机的XP驱动。</p>
<p><strong><strong><em>专有的东西就是难用,硬件也应该开源。</em></strong></strong></p>
<p><strong>UPDATE:</strong><br>经过实测,打印机已经完全正常。</p>
<p>参考:<br>[1]<a href="http://hplipopensource.com/node/309">What is the HPLIP Binary Plug-In and How Do I Install It?</a><br>[2]<a href="http://hplipopensource.com/hplip-web/plugin.html">HP Linux Imaging and Printing</a><br>[3]<a href="http://www.openprinting.org/download/printdriver/auxfiles/HP/plugins/">HP plugins</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>HTML自定义标签与标签自定义属性</title>
    <url>/2013/06/16/html-author-defined-tag-and-attributes/</url>
    <content><![CDATA[<p>大部分浏览器支持自定义HTML标签和为标准标签自定义属性，而且很多浏览器对这两种自定义行为的支持都很直接了当。</p>
<a id="more"></a>
<p><strong>自定义HTML标签</strong></p>
<p>在firefox、chrome这种现代浏览器里，自定义标签很简单，就像标准的标签那样写就可以了，而且CSS和JavaScript存取自定义标签和标准标签并无二致。</p>
<p>[javascript]<br><foo id="idFoo" style="color:red" data-bar="bar">foo tag!</foo></p>
<script>
 (function(){
 console.log($("foo").text()); //foo tag!
 console.log($("foo").data("bar")); //bar
 console.log(document.getElementById("idFoo").innerHTML); //foo tag!
 console.log(document.getElementById("idFoo").getAttribute("data-bar")); //bar
 })();
</script>
<p>[/javascript]</p>
<p>firefox 21,chrome 27,IE 10表现都十分正常。IE9没有测试，据说<a href="http://www.qttc.net/201305333.html">也没问题</a>。</p>
<p>不过据说在IE8及之前，自定义标签没那么简单，可以通过添加命名空间或者是document.createElement(“自定义标签名称”)来进行自定义HTML标签，不过如果你想在自定义的标签上使用CSS选择器，则必须使用document.createElement(“自定义标签名称”)，不管有没有定义过XML命名空间。参见<a href="http://freewind.me/blog/20130101/1230.html">这里</a>。</p>
<p>还有人报告一个IE8自定义标签的问题，”<a href="http://www.cnblogs.com/ecma/archive/2012/02/01/2335047.html">事先已document.createElement(‘thetag’)，但后续通过innerHTML的方式添加的该元素，IE8是不认的,createElement + appendChild 则可以</a>“。</p>
<p>新的项目已经决定只支持Firefox,Chrome,IE9+版本，IE6,7,8之类的随它去吧。</p>
<p><strong>标签自定义属性</strong></p>
<p>自定义标签属性经常会用到，但是一直是没有规范来约束如何自定义标签属性，导致一些混乱和移植性问题。现在HTML5增加了一个<a href="http://www.w3.org/TR/html5/dom.html#custom-data-attribute">自定义data属性</a>的特性。</p>
<p>很简单，只要自定义属性以data-开头，后面至少跟随一个字符即可，但是不能包含字符U+0041到U+005A (LATIN CAPITAL LETTER A to LATIN CAPITAL LETTER Z)。每个元素可包含多个自定义属性。</p>
<p>这些data-属性在页面上是不显示的，不会影响页面布局和风格，但它却是可读可写的。</p>
<p>jQuery已经支持通过data方法来读取自定义的data-属性，而且支持json格式的属性值，很方便。</p>
<p>[javascript]<br><foo id="idFoo" style="color:red" data-bar="bar" data-obj='{"key1":"value1"}' >foo tag!</foo></p>
<script>
 (function(){
 console.log($("foo").text()); //foo tag!
 console.log($("foo").data("bar")); //bar
 console.log($("foo").data("obj").key1); //value1
 console.log(document.getElementById("idFoo").innerHTML); //foo tag!
 console.log(document.getElementById("idFoo").innerText); //foo tag!注:firefox 21不支持
 console.log(document.getElementById("idFoo").getAttribute("data-bar")); //bar
 })();
</script>
<p>[/javascript]</p>
<p>上面的代码中，在自定义属性中使用json数据需要注意，一定要在外层使用单引号’，内层使用双引号”,如果反过来,firefox和chrome都会报undefined。</p>
<p>自定义标签的innerText属性，firefox 21不支持，输出”undefined”,chrome 27和IE 10输出正常。</p>
<p>也可以通过data(key,value)方式为自定义data属性赋值。</p>
<p>自定义data属性代码在friefox 21,chrome 27,IE 10测试通过。</p>
<p>UPDATE(05/21/2014):<br><code>The data- attributes are pulled in the first time the data property is accessed and then are no longer accessed or mutated (all data values are then stored internally in jQuery).</code></p>
<p>data-特性(attributes)只在第一次读取时获取其值，并且将其缓存到jQuery内部，之后不再读取或改变data-特性。也就是说第一次读取之后，如果通过.attr()方法修改了特性的值，然后再通过data方法读取时仍然是原来的值。</p>
<p>References:<br>[1]<a href="http://www.ifanybug.com/article/00147.html">HTML 5 的data-× 自定义属性和 jQuery的data（）方法</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>HTML子元素遮盖父元素</title>
    <url>/2015/05/14/html-child-mask-parent/</url>
    <content><![CDATA[<a id="more"></a>
<p>父元素relative定位,然后子元素absolute定位,指定top,left,bottom,right设置为0</p>
<p>[html]<br>#parent {<br> position: relative;<br> height: 100px;<br> width: 100px;<br>}</p>
<p>#child {<br> position: absolute;<br> top:0;<br> left: 0;<br> right: 0;<br> bottom: 0;<br>}<br>[/html]</p>
<p>无需指定z-index</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>HTML各种尺寸</title>
    <url>/2016/12/15/html-dimensions/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="http://blog.csdn.net/xiebaochun/article/details/38382169">offsetLeft,Left,clientLeft详解</a><br>[2]<a href="http://www.cnblogs.com/xiaohuochai/p/5828369.html">深入理解定位父级offsetParent及偏移大小</a><br>[3]<a href="http://www.cnblogs.com/xiaohuochai/p/5830053.html">深入理解可视区尺寸client</a><br>[4]<a href="http://www.cnblogs.com/xiaohuochai/p/5831640.html">深入理解滚动scroll</a><br>[5]<a href="http://www.jacklmoore.com/notes/mouse-position/">Cross-browser mouse positioning</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>判断HTML元素类型</title>
    <url>/2015/05/14/html-element-type/</url>
    <content><![CDATA[<a id="more"></a>
<p>不用jquery</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span>(el.tagName == <span class="string">&#x27;SELECT&#x27;</span>)&#123;</span><br><span class="line"> <span class="comment">//</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>使用jquery</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$el.is(<span class="string">&#x27;select&#x27;</span>)</span><br><span class="line">$el.is(<span class="string">&#x27;SELECT&#x27;</span>)</span><br><span class="line">$el.get(<span class="number">0</span>).tagName == <span class="string">&#x27;SELECT&#x27;</span></span><br></pre></td></tr></table></figure>

<p>使用元素原生属性tagName测试时,类型名要用大写。也就是tagName属性输出的是大写的标签类型名。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>HTML页面中储存自定义信息的几种方式</title>
    <url>/2014/09/24/html-dom-attach-data/</url>
    <content><![CDATA[<a id="more"></a>
<p>HTML页面中储存自定义信息的方式能想到的大概有以下几种:</p>
<ul>
<li>  重用HTML元素的标准属性,比如 id、class、rel 和 title等,这些属性的值根据自己的需要进行解释。DWZ框架使用了这种方式。</li>
<li>  上面的方式毕竟违反了标准的语意，容易造成一些问题。HTML5通过标准化的data-数据属性来支持在DOM元素上附加自定义数据</li>
<li>  使用span或div元素包含自定义信息，通过样式(display: none;)使其不可见。</li>
<li>  使用javascript代码自定义页面DOM元素与Javascript数据结构的关联</li>
<li>  使用JQuery的缓存系统,.data方法向DOM元素附加自定义数据,.removeData移除DOM元素关联的自定义数据。如果dom元素从页面中remove,则JQuery会将其关联的自定义数据一并移除,无需显式调用.removeData。但是如果只是detach元素,则不会清除关联数据。这种方式是JQuery对上一种方式的标准化,其缓存系统十分完善。</li>
</ul>
<p>以上几种方法如无特殊要求，建议使用JQuery的缓存系统。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>HTML原生combobox</title>
    <url>/2015/05/05/html-native-combobox/</url>
    <content><![CDATA[<a id="more"></a>
<p>带有datalist的input即是html原生的combobox,再也无需用select+input来模拟combobox了。</p>
<p>而且每个option还可以有label。</p>
<p>就像下面这样：</p>
<p>源代码：<br>[html]<br><input type="url" list="url_list" name="link" /><br><datalist id="url_list"><br> <option label="W3Schools" value="http://www.w3schools.com" /><br> <option label="Google" value="http://www.google.com" /><br> <option label="Microsoft" value="http://www.microsoft.com" /><br></datalist><br>[/html]</p>
<p>当前主要的浏览器中只有safari还完全不支持datalist,可以使用<a href="https://github.com/aFarkas/webshim/">webshim</a>HTML5垫片程序提供支持。</p>
<p>检测浏览器是否支持datalist<br>[javascript]<br>if (‘options’ in document.createElement(‘datalist’)) {<br> // supported!<br>}<br>[/javascript]</p>
<p>References:<br>[1] <a href="http://diveintohtml5.info/everything.html">THE ALL-IN-ONE ALMOST-ALPHABETICAL GUIDE TO DETECTING EVERYTHING</a><br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>HTML文档中元素ID重复的问题</title>
    <url>/2014/05/22/html-id-not-unique/</url>
    <content><![CDATA[<a id="more"></a>
<p>HTML元素的id属性在一个文档中应该是独一无二的，传统上我们也是这样做的。但是开发SPA单页(Single Page Application)webapp时很容易遇到ID会重复的情况。当SPA多次动态加载同一个模块时，id重复是在所难免了。当前的项目就遇到了这个问题。</p>
<p>ID重复也不是什么大问题，但从语义来讲id(identification)应该是全局唯一的。xml文档严格要求id不能重复,如果html文档中元素有重复的id就无法通过XML校验，不是一个合法的XML文档。id重复虽然现在没有问题，但浏览器并没有保证以后不会出现问题。</p>
<p>当然可以通过动态修改HTML元素的id特性来缓解这个问题。</p>
<p>id重复的元素，通过jQuery或者原生的querySelectorAll方法都可以全部获取到。而且还可以通过指定一个明确的context来选择特定的id。虽然有其他相同id的元素，但只要他们有不同的context,就可以在选择器层面上进行明确的区分。</p>
<p>无论HTML元素的ID如何重复，浏览器生成的DOM对象都是实实在在的不同的。所以ID重复也不是什么大问题，如果实在无法避免重复，那就当class一样来用好了。</p>
<p>但要注意，HTML元素ID重复可能会break一些库或者框架。</p>
<p>References:<br>[1]<a href="http://www.w3schools.com/tags/att_global_id.asp">HTML id Attribute</a><br>[2]<a href="http://www.web-tinker.com/article/20413.html">HTML中的重复ID问题</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>html5 拖拽(drag and drop)</title>
    <url>/2015/07/06/html5-drag-drop/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>属性</strong></p>
<p>在HTML中，除了图片、超链接以及被选中区域，其它元素默认是不可拖拽的。因此如果要其他类型元素可以被拖拽，就需要设置元素的draggable属性为true。</p>
<p>draggble是属性而不是样式，所以并不能用CSS来设置。</p>
<p><strong>事件</strong></p>
<p>一个完整的拖拽，总共会触发七种类型的事件。</p>
<ul>
<li>  dragstart</li>
</ul>
<p>当一个元素开始被拖拽的时候触发。用户拖拽的元素需要附加dragstart事件。在这个事件中，监听器将设置与这次拖拽相关的信息，例如拖动的数据和图像。</p>
<ul>
<li>  dragenter</li>
</ul>
<p>当拖拽中的鼠标第一次进入一个元素的时候触发。这个事件的监听器需要指明是否允许在这个区域释放鼠标。如果没有设置监听器，或者监听器没有进行操作，则默认不允许释放。当你想要通过类似高亮或插入标记等方式来告知用户此处可以释放，你将需要监听这个事件。</p>
<ul>
<li>  dragover</li>
</ul>
<p>当拖拽中的鼠标移动经过一个元素的时候触发。大多数时候，监听过程发生的操作与dragenter事件是一样的。</p>
<ul>
<li>  dragleave</li>
</ul>
<p>当拖拽中的鼠标离开元素时触发。监听器需要将作为可释放反馈的高亮或插入标记去除。</p>
<ul>
<li>  drag</li>
</ul>
<p>这个事件在拖拽源触发。即在拖拽操作中触发dragstart事件的元素。</p>
<ul>
<li>  drop</li>
</ul>
<p>这个事件在拖拽操作结束释放时于释放元素上触发。一个监听器用来响应接收被拖拽的数据并插入到释放之地。这个事件只有在需要时才触发。当用户取消了拖拽操作时将不触发，例如按下了Escape（ESC）按键，或鼠标在非可释放目标上释放了按键。</p>
<ul>
<li>  dragend</li>
</ul>
<p>拖拽源在拖拽操作结束将得到dragend事件对象，不管操作成功与否。</p>
<p>其中在被拖拽对象上触发的事件有：<br>dragstart,drag和dragend</p>
<p>而在目标对象上触发的事件有:<br>dragenter, dragover, dragleave和drop。是不是和mouseenter,mouseover,mouseleave比较像。</p>
<p><strong>对象</strong></p>
<p>拖放操作的核心对象是DataTransfer对象，由拖拽事件的dataTransfer属性来引用，只有在拖拽事件内部，此对象才是有效的。</p>
<p>被拖拽元素和目标元素通过DataTransfer对象来传输数据，一般在被拖拽元素的dragstart事件中，使用dataTransfer.setData来设置要传输的数据，而在目标元素的<br>的drop事件中，使用dataTransfer.getData来获传输的数据。</p>
<p>DataTransfer对象更详细的信息参考[2]</p>
<p><strong>默认操作</strong></p>
<p>浏览器对于拖拽操作，有默认的动作，一般应该取消默认动作。</p>
<p><strong>拖放效果</strong></p>
<p>拖放时，浏览器会自动生成缩略图来指示拖动效果，用户也可以用DataTransfer对象的setDragImage方法来指定自定义的拖动效果。不过此方法并不是所有浏览器都支持。</p>
<p>可以在目标元素的dragenter,dragover,dragleave和drop事件中,为目标元素设置不同的样式来反馈拖放操作。</p>
<p><strong>其他</strong></p>
<p>chrome浏览器,dragenter,dragover,dragleave事件中,event.dataTransfer.getData()函数无法获取数据，一直返回undefined,而firefox是正常的。</p>
<p>References:<br>[1]<a href="https://developer.mozilla.org/zh-CN/docs/DragDrop/Drag_and_Drop">拖放操作</a><br>[2]<a href="https://developer.mozilla.org/en-US/docs/Web/API/DataTransfer">DataTransfer</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>html5表单元素的form属性</title>
    <url>/2014/07/31/html5-input-form-attribute/</url>
    <content><![CDATA[<a id="more"></a>
<p>html5的表单输入元素有一个form属性，用来指定元素所属的form,这样form的表单输入元素就不必囿于form标签之内了。输入元素的form属性值为所属form元素的id。</p>
<p>but,且慢,Internet Explorer直到最新的版本11,版本号11.0.9600.17207都不支持此属性，其他浏览器都是支持的。看来这么好的特性也只能暂时不用了，使用javascript脚本提交form来代替吧。</p>
<p>IE是有多让人痛恨！所有的版本！</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>IBM System X3650 M4 顺利安装 Debian Wheezy</title>
    <url>/2013/03/13/ibm-system-x3650-m4-install-debian-wheezy/</url>
    <content><![CDATA[<p>非图形界面方式安装直接花屏，重启选择图形安装方式则一切正常。</p>
<a id="more"></a>
<p>分区的时候要注意，因为现在的机器基本输入输出系统都是EFI了，因此需要一个EFI boot system 分区，如果不熟悉，可以使用分区向导。</p>
<p>安装过程中会提示缺少non free的固件ql2500_fw.bin，可以从debian官方下载firmware-qlogic包，提取出ql2500_fw.bin，写入usb闪存，将usb闪存插入服务器，安装程序会自动搜索此文件。</p>
<p>系统分区为GPT格式，其他一如既往。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ibus-sunpinyin候选字词翻页快捷键设置</title>
    <url>/2011/11/20/ibus-sunpinyin-setup/</url>
    <content><![CDATA[<p>ibus-sunpinyin默认安装不会使用-/=这个两健来上翻和下翻候选字词</p>
<a id="more"></a>
<p>可以执行ibus-sunpinyin自带的python设置脚本/usr/lib/ibus-sunpinyin/ibus-setup-sunpinyin来全面设置ibus-sunpinyin，如果执行此脚本时提示：</p>
<p>“Traceback (most recent call last):<br> File “/usr/share//ibus-sunpinyin/setup/main.py”, line 41, in<br> import gtk.glade as glade<br>ImportError: No module named glade”</p>
<p>那么需要安装python-glade2包</p>
<p>#apt-get install python-glade2</p>
<p>然后就可以设置ibus-sunpinyin了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>IE版本检测</title>
    <url>/2015/10/11/ie-version-detect/</url>
    <content><![CDATA[<a id="more"></a>
<p>IE版本检测有很多方法，特性检测是比较好的一种方式。</p>
<p>非标准的document.all对象只存在于IE10及以下版本。其实，其他浏览器比如chrome也实现了document.all对象，不过在这些浏览器中以布尔方式判断document.all对象都是返回undefined的。</p>
<p>可以这样测试:<br>[javascript]</p>
<script>
if (!document.all) {
 console.log(typeof(document.all));
 console.log(document.all);
}
</script>
<p>[/javascript]</p>
<p>再佐以其他IE版本相关的特性,详见参考[1],可以有如下的IE版本检测代码:<br>[javascript]<br>var v;</p>
<p>if (document.all) {<br> if (window.atob) {<br> v = ‘10’;<br> }<br> else if (document.addEventListener) {<br> v = ‘9’;<br> }<br> else if (document.querySelector) {<br> v = ‘8’;<br> }<br> else if (window.XMLHttpRequest) {<br> v = ‘7’;<br> }<br> else if (document.compatMode) {<br> v = ‘6’;<br> }<br> else {<br> v = ‘5.5 or older’;<br> }</p>
<p> v = ‘IE’ + v;<br>}<br>else {<br> v = ‘IE11+ or not IE’;<br>}</p>
<p>console.log(‘Your browser is’ + v);</p>
<p>[/javascript]</p>
<p>References:<br>[1]<a href="http://tanalin.com/en/articles/ie-version-js/">Internet Explorer (IE) version detection in JavaScript</a><br>[2]<a href="https://github.com/nioteam/jquery-plugins/issues/12">JavaScript判断IE各版本最完美解决方案</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>IE9及以下版本无法正确处理application/json类型返回</title>
    <url>/2015/12/12/ie9-application-json/</url>
    <content><![CDATA[<a id="more"></a>
<p>IE9及以下版本并不能正确处理application/json返回类型，会提示文件下载，下载之后的文件内容就是返回的json数据串。<br>出现此种症状，只需针对特定版本IE浏览器，将返回类型设置为text/html或者text/plain即可解决此问题。</p>
<p>据说IE10也有此问题，木有测试，也有人说木有问题，可能是早期版本与后期更新版本有不同的表现吧。</p>
<p>References:<br>[1]<a href="http://blog.degree.no/2012/09/jquery-json-ie8ie9-treats-response-as-downloadable-file/">Jquery + JSON: IE8/IE9 treats response as downloadable file</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
  </entry>
  <entry>
    <title>增大tomcat缓存容量</title>
    <url>/2016/10/25/increase-tomcat-cache-size/</url>
    <content><![CDATA[<a id="more"></a>
<p>Tomcat 8.x 启动时有这样的warning:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">25</span>-Oct-<span class="number">2016</span> <span class="number">21</span>:<span class="number">37</span>:<span class="number">42.341</span> WARNING \[tafdc.net-startStop-<span class="number">1</span>\] org.apache.catalina.webresources.Cache.getResource Unable to add the resource at \[<span class="regexp">/WEB-INF/</span>conf/spring-activemq.xml\] to the cache because there was insufficient free space available after evicting expired cache entries - consider increasing the maximum size <span class="keyword">of</span> the cache</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">只需在$CATALINA_BASE/conf/context.xml文件中,`</span>/Context<span class="string">`之前添加如下行，增大默认的缓存容量：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">&lt;Resources</span><br><span class="line"> cachingAllowed=<span class="string">&quot;true&quot;</span></span><br><span class="line"> cacheMaxSize=<span class="string">&quot;102400&quot;</span></span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure>

<p>tomcat 默认的缓存只有10M</p>
<p>References:<br>[1]<a href="http://tomcat.apache.org/tomcat-8.0-doc/config/resources.html">The Resources Component</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>初始化一个单数据中心多节点cassandra集群</title>
    <url>/2015/11/07/init-multinode-single-datacenter-cluster/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>集群信息</strong></p>
<p>集群的名字叫fooCluser,总共有两个节点在同一个数据中心。每个节点位于不同的机架。<br>数据中心的名字叫DC1,两个机架的名字分别为RAC1和RAC2。<br>两个节点的IP分别为192.168.0.100和192.168.0.101。<br>因为只有两个节点，两个节点都作为种子节点。<br>注意：要保证所有的节点安装相同版本的Cassandra</p>
<p><strong>操作步骤</strong></p>
<ol>
<li> 停止节点<br>debian包系统安装的cassandra,安装完成后处于运行状态，而且有默认的集群Test Cluster。<br>停止所有的集群节点<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra stop</span><br></pre></td></tr></table></figure></li>
<li> 清除数据<br>清除默认的集群(Test Cluster)信息<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/cassandra/data/system<span class="comment">/*</span></span><br></pre></td></tr></table></figure></li>
<li> 修改cassandra.yaml配置<br>核心的参数设置如下：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cluster_name: <span class="string">&#x27;fooCluster&#x27;</span></span><br><span class="line">seed_provider:</span><br><span class="line"> - class_name: org.apache.cassandra.locator.SimpleSeedProvider</span><br><span class="line"> parameters:</span><br><span class="line"> - seeds: <span class="string">&quot;192.168.0.100,192.168.0.101&quot;</span></span><br><span class="line"></span><br><span class="line">listen_address: <span class="number">192.168</span><span class="number">.0</span><span class="number">.100</span></span><br><span class="line">endpoint_snitch: GossipingPropertyFileSnitch</span><br><span class="line">auto_bootstrap: <span class="literal">false</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>不同的节点listen_address是不同的。如果需要开启thrift rpc server,还需设置rpc相关参数，对于当前版本的cassandra，rpc并不是必须的，只使用cql是可行的。</p>
<p>当初始化一个没有数据的新集群时，要设置auto_bootstrap参数为false。auto_bootstrap参数在cassandra.yaml中是没有的，其默认值为true,需要手动添加。种子节点是不需要bootstrap的，只有向集群中添加新的节点时，新加入的节点启动时需要bootstrap。<br>4.  机架感应配置<br>因为使用了GossipingPropertyFileSnitch，所以对应的数据中心、机架配置文件为cassandra-rackdc.properties<br>对于192.168.0.100节点，此文件内容设置为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">dc = DC1</span><br><span class="line">rack= RAC1</span><br></pre></td></tr></table></figure>
<p>而对于192.168.0.101节点，则设置为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">dc = DC1</span><br><span class="line">rack= RAC2</span><br></pre></td></tr></table></figure>

<p>注意：cassandra集群内的多个节点是可以放置于同一个机架内的，只不过cassandra认为，同一个机架内的节点容易一起失败，所以要尽量将数据分布到不同机架内的节点上。<br>5.  启动节点<br>先启动种子节点，每次启动一个，顺序启动所有种子节点后，再顺序启动其他节点。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service cassandra start</span><br></pre></td></tr></table></figure>
<ol start="6">
<li> 查看集群状态<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool status</span><br><span class="line">$ nodetool describecluster</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>References:<br>[1]<a href="http://docs.datastax.com/en/cassandra/2.0/cassandra/initialize/initializeSingleDS.html">Initializing a multiple node cluster (single data center)</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>innerHTML动态加载javascript脚本</title>
    <url>/2013/06/03/innerhtml-load-javascript/</url>
    <content><![CDATA[<p>元素对象的属性innerHTML可以用来获取或设置元素的后代节点,但是设置这个属性时，如果包含javascript脚本则有些问题</p>
<a id="more"></a>
<p><strong>脚本加载方式对innerHTML的影响</strong><br>HTML文档加载javascript脚本有三种方式，外部引用方式、内部引用方式和内联引用方式。</p>
<p>外部引用方式<br>[javascript]</p>
<script type="text/javascript" src="/path/to/external.js"></script>
<p>[/javascript]</p>
<p>内部引用方式<br>[javascript]</p>
<script type="text/javascript">
//some javascript code
</script>
<p>[/javascript]</p>
<p>内联引用方式<br>[javascript]<br><input type="button" onclick="someJavascriptCode"> //可以是直接运行的代码，也可以调用其他地方定义的函数<br>[/javascript]</p>
<p>根据 W3C 规范中的描述，SCRIPT 标签内的 “脚本” 只会在”页面加载”时执行一次，或者通过绑定事件实现在页面加载后脚本能够重复地执行。<br>因此使用innetHTML动态加载包含javascript脚本的内容时,外部引用方式和内部引用方式使用的脚本是无法运行的。内联引用方式只有内联javascript是完全自包含的，也就是不调用任何外部的函数时，这些脚本在后来的事件触发调用中是可以正常执行的。</p>
<p><strong>解决方案</strong></p>
<p>一、使用浏览器的特性或者bug</p>
<p><strong>IE浏览器</strong></p>
<p>defer 属性是 SCRIPT 元素的特有属性，这是一个布尔型属性，它通知用户端这段脚本中不会动态生产文档内容（如 “documnet.write” ），所以不必现在立即执行，一般的拥有 defer 属性的 SCRIPT 元素中的脚本会较晚的被执行。在 IE6 IE7 IE8 中，当使用 innerHTML 方法插入脚本时，SCRIPT 元素必须设置 defer 属性才能生效。</p>
<p>因为script是作用域外元素，包含着在页面中看不到该元素的意思，就像看不到style元素或注释一样。在通过innerHTML插入的字符串中，如果一开始就是作用域外元素，IE会把所有作用域外元素都剥离掉。所以通常为了使 innerHTML 插入的脚本能够在 IE 中正常执行，经常会在欲插入的 HTML 代码字符串的最开始增加一个不可见的元素。如：<br>[javascript]<br><span style="display:none;">span</span><script type="text/javascript" defer>someJavascriptCode</script><br>[/javascript]</p>
<p><strong>firefox浏览器</strong><br>在 Firefox 中，先将被插入 HTML 代码的元素从其父元素中移除，然后使用 innerHTML 插入包含 SCRIPT 元素的代码，最后将这个元素恢复至原父元素中，则经过此操作后 SCRIPT 中的脚本可以被执行。</p>
<p>二、通用解决方案</p>
<p>上面提到的方法是不可靠而且不通用的，更一般的方法是解析将要赋予对象innerHTML属性的文本，将其中的javascript做特殊的处理，然后再将其插入对象。大体的方法如下：</p>
<p>对于外部引用javascript脚本，再一次请求src指向的脚本文件，新建script元素，设置其type为text/javascript,将获取的外部脚本的内容插入script元素，然后将script元素插入到head元素下。</p>
<p>对于内部引用脚本，新建script元素，设置其type为text/javascript,将内部引用脚本的内容插入到script元素，然后将script元素插入到head元素下。</p>
<p>javascript脚本中，除函数定义以外，还有一些是函数的调用，应该将这些脚本提取出来，使用eval执行这些脚本。</p>
<p>除脚本以外的html内容，直接用innerHTML插入节点即可。</p>
<p>JQuery的load方法即可以满足这些要求，用innerHTML向元素插入内容时，各种脚本都可以正确的执行。<br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>innerText,textContent和innerHTML</title>
    <url>/2014/08/08/innertext-textcontent-innerhtml/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>textContent</strong></p>
<p>innertText和textContent都是用于获取节点及其后代节点的文本内容。innerText是M$的专有API,不过除firefox外基本上其他浏览器都支持此属性。textContent则是W3C的标准API。</p>
<p>innerText和textContent的主要区别如下:</p>
<ul>
<li>  textContent可以获取所有元素的内容，包括<script>和<style>，但innerText不能获取这两个标签的内容。</li>
<li>  innertText可以感知样式，不会返回隐藏元素的文本内容，但是textContent可以返回</li>
<li>  因为innerText感知样式，因此会触发重排(reflow),而textContent不会</li>
</ul>
<p>新web application应该避免使用innerText等M$专有的API,IE9及以上也支持textContent。</p>
<p><strong>innerHTML</strong></p>
<p>就像名字的含义一样，textContent返回元素及其后代的文本内容,而innerHTML则返回HTML,如果仅仅需要文本就不应该使用innerHTML,textContent不只是更有效率，而且可以避免XSS(Cross-site scripting)攻击。</p>
<p>References:<br>[1]<a href="https://developer.mozilla.org/en-US/docs/Web/API/Node.textContent">Node.textContent</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>install rlt8188cus wireless lan drivers for linux</title>
    <url>/2013/01/16/install-rlt8188cus-drivers-for-linux/</url>
    <content><![CDATA[<p>入手迷你无线网卡一枚,rtl8188cus芯片,真的相当小巧精致,而且信号还不错,记录安装过程以备忘</p>
<a id="more"></a>
<p>1、下载最新官方驱动</p>
<p>光盘自带的linux驱动稍微有些旧了,去realtek官方下载最新的<a href="http://www.realtek.com.tw/downloads/downloadsView.aspx?Langid=3&PNid=48&PFid=48&Level=5&Conn=4&DownTypeID=3&GetDown=false&Downloads=true#2742">linux驱动</a>。官方描述支持到kernel 3.0.8,实测debian wheezy当前的内核3.2.25安装没有问题。</p>
<p>2、编译安装</p>
<p>先安装编译环境<br>#apt-get install build-essential linux-headers-`uname -r`</p>
<p>将下载的zip文件解压得到文件夹RTL8188C_8192C_USB_linux_v3.4.4_4749.20121105,进入此文件夹,最简单的安装方法是执行其下的脚本install.sh</p>
<p>为install.sh添加执行权限<br>$chmod +x install.sh</p>
<p>然后以超级用户身份执行<br>#./install.sh</p>
<p>会自动编译安装内核模块8192cu.ko</p>
<p>3、blacklist老的8192驱动</p>
<p>上一步的安装最后会提示以下字样:<br>insmod: error inserting ‘8192cu.ko’: Device or resource busy</p>
<p>如果<br>#modprobe 8192cu.ko<br>也会有类似的提示<br>这是因为老的驱动rtl8192cu已经加载导致的冲突,所以需要将其加入黑名单<br>#vim /etc/modprobe.d/blacklist.conf<br>写入<br>blacklist rtl8192cu<br>保存退出</p>
<p>然后<br>#rmmod rtl8192cu<br>#modprobe 8192cu<br>或者直接重新启动</p>
<p>再看<br>#ifconfig wlan0<br>就显示正常了</p>
<p>用network-manager连接热点测试,速度还算不错,虽然个头那么小。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>安装shadowsocksr-libdev</title>
    <url>/2018/07/18/install-shadowsocksr-libdev/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone https:<span class="comment">//github.com/shadowsocksrr/shadowsocksr-libev</span></span><br><span class="line">$ cd shadowsocksr-libev</span><br><span class="line">$ sudo apt-get install --no-install-recommends build-essential autoconf libtool libssl-dev \\</span><br><span class="line"> gawk debhelper dh-systemd init-system-helpers pkg-config asciidoc xmlto apg libpcre3-dev</span><br><span class="line">$ dpkg-buildpackage -b -us -uc -i</span><br><span class="line">$ cd ..</span><br><span class="line">$ sudo dpkg -i shadowsocks-libev*.deb</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>Intel Centrino Wireless-N 2200 linux兼容性问题</title>
    <url>/2015/11/28/intel-centrino-wireless-n-2200-linux-compatibility/</url>
    <content><![CDATA[<a id="more"></a>
<p>intel迅驰无线网卡Centrino Wireless-N 2200在debian jessie系统下奇慢无比，连接速度只有1Mb/s,到网关的延迟有时达到1000ms以上。</p>
<p>是因为此无线网卡在802.11n模式下与当前内核存在兼容性问题。所以，要解决此问题，要么关闭无线网卡的802.11n模式，或者更改无线路由器不开启802.11n模式。</p>
<p><strong>关闭网卡的802.11n工作模式</strong></p>
<p> /etc/modprobe.d目录下新建文件11n_disable.conf,添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">options iwlwifi 11n_disable=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>重新启动机器。</p>
<p>References:<br>[1]<a href="http://syntaxionist.rogerhub.com/intel-centrino-wireless-n-2200-ubuntu-1mbps-workaround.html">Intel Centrino Wireless-N 2200 Ubuntu 1Mbps Workaround</a><br>[2]<a href="http://askubuntu.com/questions/119578/how-to-fix-slow-wireless-on-machines-with-intel-wireless-cards">How to fix slow wireless on machines with Intel wireless cards?</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>auto与allow-hotplug的区别</title>
    <url>/2012/09/14/interfaces-auto-allow-hotplug/</url>
    <content><![CDATA[<p>/etc/network/interfaces文件中一般用auto或者allow-hotplug来定义接口的启动行为。</p>
<a id="more"></a>
<p><strong>auto</strong></p>
<p>语法：<br>auto <interface_name><br>含义：<br>在系统启动的时候启动网络接口,无论网络接口有无连接(插入网线),如果该接口配置了DHCP,则无论有无网线,系统都会去执行DHCP,如果没有插入网线,则等该接口超时后才会继续。</p>
<p><strong>allow-hotplug</strong></p>
<p>语法:<br>allow-hotplug <interface_name></p>
<p>含义：<br>只有当内核从该接口检测到热插拔事件后才启动该接口。如果系统开机时该接口没有插入网线,则系统不会启动该接口,系统启动后,如果插入网线,系统会自动启动该接口。也就是将网络接口设置为热插拔模式。</p>
<p><strong>手动重新启动网络</strong></p>
<p>一般修改了网络配置文件后,会用以下命令重新启动网络</p>
<h1 id="etc-init-d-networking-restart"><a href="#etc-init-d-networking-restart" class="headerlink" title="/etc/init.d/networking restart"></a>/etc/init.d/networking restart</h1><p>但从squeeze开始,此命令会有如下提示:</p>
<p>Running /etc/init.d/networking restart is deprecated because it may not enable again some interfaces … (warning).<br>Reconfiguring network interfaces…done.</p>
<p>如果设置接口为auto,虽然会有如此提示,但接口仍然会正确的启动。<br>如果接口设置为allow-hotplug则没有这么走运了,网络接口不会正确启动。这种情况下必须使用如下命令启动网络接口:<br>#ifup <interface_name><br>而命令<br>#ifconfig <interface_name> up<br>也无法正确启动接口</p>
<p>所以allow-hotplug设置的接口最好如下方式重新启动网络接口,当然auto方式的接口也没问题:</p>
<p>#ifdown <interface_name> &amp;&amp; ifup <interface_name></p>
<p>特别是在ssh登录远程主机的情况下,一定要像上面这样在一条命令里执行ifdown和ifup,否则,如果先执行ifdown,则再也没有机会执行ifup了。</p>
<p>看来大多数情形下,网络接口还是用auto方式比较省心。</p>
<p><strong>注(6/3/2019)：如果配置网桥，一定不要用allow-hotplug，要用auto。</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>interfaces文件配置wireless连接</title>
    <url>/2016/03/30/interfaces-config-wireless-conn/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>配置文件访问无线网络</strong></p>
<p>在/etc/network/interfaces文件可以配置要默认访问的无线热点:</p>
<p>动态获取ip:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># wireless</span><br><span class="line">auto wlan0</span><br><span class="line">iface wlan0 inet dhcp</span><br><span class="line"> wpa-ssid ESSID/SSID</span><br><span class="line"> wpa-psk pre-shared-key</span><br></pre></td></tr></table></figure>

<p>配置静态ip:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># wireless</span><br><span class="line">auto wlan0</span><br><span class="line">iface wlan0 inet <span class="keyword">static</span></span><br><span class="line"> address <span class="number">192.168</span><span class="number">.1</span><span class="number">.110</span></span><br><span class="line"> netmask <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span></span><br><span class="line"> network <span class="number">192.168</span><span class="number">.1</span><span class="number">.0</span></span><br><span class="line"> broadcast <span class="number">192.168</span><span class="number">.1</span><span class="number">.255</span></span><br><span class="line"> gateway <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line"> wpa-ssid ESSID/SSID</span><br><span class="line"> wpa-psk pre-shared-key</span><br></pre></td></tr></table></figure>

<p>重新启动网络服务即可连接到默认的热点。</p>
<p><strong>命令行手动扫描并连接到热点</strong></p>
<p>扫描热点：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># iwlist wlan0 scan</span><br><span class="line"># iw dev wlan0 scan</span><br></pre></td></tr></table></figure>

<p>连接到热点：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># wpa_supplicant -i wlan0 -c &lt;(wpa_passphrase ESSID pre-shared-key) -B</span><br></pre></td></tr></table></figure>

<p>动态获取ip:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># dhclient wlan0</span><br></pre></td></tr></table></figure>

<p>设置静态ip:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ip addr add 192.168.1.110/24 dev wlan0</span><br><span class="line"># ip route add default via 192.168.1.1</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>iptables rules 持久化 persistence</title>
    <url>/2013/05/12/iptables-rules-persistence/</url>
    <content><![CDATA[<p>iptables规则即使生效，重启后会丢失，因此需要持久化。</p>
<a id="more"></a>
<p><strong>创建保存iptables规则的文件</strong></p>
<h1 id="touch-etc-iptables-rules"><a href="#touch-etc-iptables-rules" class="headerlink" title="touch /etc/iptables.rules"></a>touch /etc/iptables.rules</h1><p><strong>创建预启动网络脚本</strong></p>
<h1 id="touch-etc-network-if-up-d-iptables"><a href="#touch-etc-network-if-up-d-iptables" class="headerlink" title="touch /etc/network/if-up.d/iptables"></a>touch /etc/network/if-up.d/iptables</h1><h1 id="chmod-x-etc-network-if-up-d-iptables"><a href="#chmod-x-etc-network-if-up-d-iptables" class="headerlink" title="chmod +x /etc/network/if-up.d/iptables"></a>chmod +x /etc/network/if-up.d/iptables</h1><p>编辑此文件，内容如下：<br>#!/bin/sh<br>/sbin/iptables-restore &lt; /etc/iptables.rules</p>
<p><strong>配置并保存iptables规则</strong></p>
<p>配置并测试iptable规则，确认无误后，保存</p>
<h1 id="iptables-save-gt-etc-iptables-rules"><a href="#iptables-save-gt-etc-iptables-rules" class="headerlink" title="iptables-save &gt; /etc/iptables.rules"></a>iptables-save &gt; /etc/iptables.rules</h1>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ip_local_port_range: prefer different parity for start/end values</title>
    <url>/2019/10/15/ip-local-port-range-prefer-different-parity-for-start-end-values/</url>
    <content><![CDATA[<a id="more"></a>
<p>dmesg有提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ip_local_port_range: prefer different parity <span class="keyword">for</span> start/end values</span><br></pre></td></tr></table></figure>

<p>查询本地端口范围</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/sys/net/ipv4/ip_local_port_range</span><br><span class="line"><span class="number">1024</span> <span class="number">65000</span></span><br></pre></td></tr></table></figure>
<p>起始与结束端口都是偶数,打开/etc/sysctl.conf添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">net.ipv4.ip_local_port_range = <span class="number">1024</span> <span class="number">65535</span></span><br></pre></td></tr></table></figure>
<p>开始端口与结束端口奇偶不同就可以了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>jar文件规范</title>
    <url>/2013/05/04/jar-file-specification/</url>
    <content><![CDATA[<p>JAR文件基于流行的ZIP文件格式,用来聚合很多分散的文件到一个档案。</p>
<a id="more"></a>
<p>JAR文件本质上是一个zip文件，包含一个可选的META-INF目录。可以使用<a href="https://openwares.net/lang/java_package_app_jar.html">命令行工具jar创建JAR文件</a>，也可以使用java平台的java.util.jar API来创建。JAR文件的名字没有限制，可以是任何特定平台上允许的文件名字。</p>
<p>多数情况下，JAR文件并不是类文件和/或资源文件的简单聚合档案。他们经常用作应用程序和扩展的构建基础。如果存在的话，META-INF目录用来存储包和扩展的配置数据，包括安全、版本、扩展和服务。</p>
<p><strong>META-INF目录</strong></p>
<p>java 2 平台识别和解释META-INF目录下的文件/目录，用来配置应用程序，扩展，类装载器和服务。</p>
<ul>
<li>  MANIFEST.MF</li>
</ul>
<p>清单文件用来定义扩展和包相关的数据</p>
<ul>
<li>  INDEX.LIST</li>
</ul>
<p>索引文件由jar命令的-i选项产生，其中包含了应用程序或扩展定义的包里面的定位信息。他是JarIndex实现的一部分，类装载器使用索引文件来加速类装载进程。</p>
<ul>
<li>  x.SF</li>
</ul>
<p>JAR包的签名文件(Signature File),x是JAR的基本文件名,也就是JAR文件名的前半部分</p>
<ul>
<li>  x.DSA</li>
</ul>
<p>与签名文件关联的签名块文件，x是与jar包相同的基本文件名，这个文件存储了对应签名文件的数字签名。</p>
<ul>
<li>  services/</li>
</ul>
<p>services目录存储了所有服务提供商的所有文件。</p>
<p>名值对和节</p>
<p>在详述单独的配置文件内容之前，需要先定义一些格式规范。通常，清单文件和签名文件里面的信息由所谓的名：值对来表达，这是受RFC822的启发而来。我们也成为这些名值对为标头或者属性。</p>
<p>一组名值对称之为一个。节之间使用空行来分隔。</p>
<p>任何形式的二进制数据用base64编码来表示，如果二进制数据超过了72字节的行长度，那么就必须续行。二进制数据的例子是摘要和签名。</p>
<p>实现应该支持头值最大到65535字节。</p>
<p>配置文件应遵循的规范<br> section: *header +newline<br> nonempty-section: +header +newline<br> newline: CR LF LF CR (not followed by LF)<br> header: name : value<br> name: alphanum *headerchar<br> value: SPACE *otherchar newline *continuation<br> continuation: SPACE *otherchar newline<br> alphanum: {A-Z} {a-z} {0-9}<br> headerchar: alphanum - _<br> otherchar: any UTF-8 character except NUL, CR and LF</p>
<p>; Also: To prevent mangling of files sent via straight e-mail, no<br>; header will start with the four letters “From”.</p>
<p>注：规范中使用的符号*,+,{},等皆为正则表达式符号</p>
<p>JAR文件规范的其余部分详见<a href="http://docs.oracle.com/javase/7/docs/technotes/guides/jar/jar.html#The_META-INF_directory">JAR File Specification</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java语言编码规范</title>
    <url>/2013/10/22/java-code-convention/</url>
    <content><![CDATA[<p>没有规矩，不成方圆。</p>
<a id="more"></a>
<p>使用Java有不少好处，官方连编码规范都制定出来了，不用费心制定规范了，遵循<a href="http://www.oracle.com/technetwork/java/codeconvtoc-136057.html">官方编码规范</a>文档即可。这里有一篇<a href="http://morningspace.51.net/resource/javacodeconv.html">译文</a>，翻译的挺流畅。</p>
<p>其实编码规范这种东西是见仁见智的事情，并无必须之章法。无非是要做到易于理解代码，易于后期维护而已。</p>
<p>编码规范的流派也不少，比如驼峰命名法(<a href="http://en.wikipedia.org/wiki/CamelCase">CamelCase</a>),蛇行命名法(<a href="http://en.wikipedia.org/wiki/Snake_case">snake_case</a>),匈牙利命名法(<a href="http://en.wikipedia.org/wiki/Hungarian_notation">Hungarian notation</a>),Pascal命名法(<a href="http://c2.com/cgi/wiki?PascalCase">Pascal Case</a>)。</p>
<p>Java基本上遵循CamelCase命名法，linux内核开发则重度使用snake_case命名惯例，匈牙利命名法则主要用于windows平台的开发。这些命名惯用法并无实质性的优劣之分。</p>
<p>项目中最重要的是要使用统一的编码规范，对于JAVA开发，则官方编码规范足以。</p>
<p>注意一点，boolean类型不要以is前缀命名，不然工具生成getter/setter方法时可能会有意想不到的后果。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java jar命令详解</title>
    <url>/2011/03/04/java-jar-intro/</url>
    <content><![CDATA[<p>jar是 Java ARchive的缩写,是JDK内建支持的标准打包工具和方法</p>
<a id="more"></a>
<p>命令行下输入不带任何参数的jar命令将输出jar的用法,也可用man jar来获取帮助资讯</p>
<p>$jar</p>
<p>Usage: jar {ctxui}[vfm0Me] [jar-file] [manifest-file] [entry-point] [-C dir] files …<br>Options:<br>-c  create new archive<br>-t  list table of contents for archive<br>-x  extract named (or all) files from archive<br>-u  update existing archive<br>-v  generate verbose output on standard output<br>-f  specify archive file name<br>-m  include manifest information from specified manifest file<br>-e  specify application entry point for stand-alone application<br>bundled into an executable jar file<br>-0  store only; use no ZIP compression<br>-M  do not create a manifest file for the entries<br>-i  generate index information for the specified jar files<br>-C  change to the specified directory and include the following file<br>If any file is a directory then it is processed recursively.<br>The manifest file name, the archive file name and the entry point name are<br>specified in the same order as the ‘m’, ‘f’ and ‘e’ flags.</p>
<p>Example 1: to archive two class files into an archive called classes.jar:<br>jar cvf classes.jar Foo.class Bar.class<br>Example 2: use an existing manifest file ‘mymanifest’ and archive all the<br>files in the foo/ directory into ‘classes.jar’:<br>jar cvfm classes.jar mymanifest -C foo/ .</p>
<p>下面详细的介绍以下各子命令以及选项的用法</p>
<p>其中ctxui为子命令,每次只能使用一个而不能同时使用,vfm0Me为选项,根据相应的子命令选择适合的选项</p>
<p>-c 创建一个新的jar文件</p>
<p>-t 列出一个jar包的内容列表</p>
<p>-x 从jar包或者标准输入提取指定或者全部文件</p>
<p>-u 更新已经存的jar包,向其添加或删除文件</p>
<p>-v 向标准输出打印详细打包过程资讯</p>
<p>-f 指定jar文件名称,适用于ctxui子命令,指定将要创建的(c)、更新的(u)、提取的(x)、索引的(i)或者查看的(t) jar文件名</p>
<p>-m 指定manifest文件, 生成的jar包中包含指定的manifest文件中的内容，生成的manifest文件为jar包内的META-INF/MANIFEST.MF</p>
<p>-e 指定jar内主类的应用程序入口点,如果使用java标准的main入口点则可以忽略此选项</p>
<p>-0 只存储不压缩,使用zip格式</p>
<p>-M 对于子命令c不产生manifest文件，对于子命令u删除可能存在的manifest文件</p>
<p>-i 对指定的jar文以及其以来的jar文件产生索引信息，将会在jar包内的META-INF子目录下插入一个INDEX.LIST文件</p>
<p>-C dir 更改到指定目录dir并打包其下文件和目录</p>
<p>[jar-file] 指定jar包，适用于子命令ctxu</p>
<p>[manifest-file]  指定需要包含的manifest清单文件,当指定-m选项时适用</p>
<p>[entry-point] 生成的jar包内主类的程序入口点</p>
<p>file… 为需要打包的class及其他资源文件</p>
<p>注意：指定的manifest清单文件名,jar包文件名和程序入口点的顺序必须与选项m,f和e选项的指定顺序一致</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Lint 工具选项</title>
    <url>/2014/10/30/java-lint-options/</url>
    <content><![CDATA[<a id="more"></a>
<p>Rferences:<br>[1]<a href="https://groups.google.com/forum/#!topic/programmercafe/SuRRACj12LI">Java Lint 工具</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Networking and Proxies</title>
    <url>/2020/07/04/java-networking-and-proxies/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="https://docs.oracle.com/javase/8/docs/technotes/guides/net/proxies.html">Java Networking and Proxies</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title>打包Java package包和可执行Java应用程序</title>
    <url>/2011/03/04/java-package-app-jar/</url>
    <content><![CDATA[<p>为了便利的分发和部署Java package(类库)和可执行应用程序,Java提供了jar(Java ARchive)工具,jar在打包的过程中使用zip格式执行文件压缩,加快网络传输速度</p>
<a id="more"></a>
<p><strong>1. 打包Java包(类库)</strong></p>
<p>比如现在有net.openwares.foo这个包,包里面有一个bar类,在硬盘上的目录结构为<br>JavaT/net/openwares/foo/bar.class</p>
<p>Java package依赖于分解package名字为分级目录来定位相应的包,所以打包时必须把相应的目录结构打包进去,这样JVM才能根据CLASSPATH环境变量附加上包的目录结构信息来找到相应的类文件,打成jar包亦不例外,不过这时jar包的全名称必须包含在CLASSPATH环境变量中。</p>
<p>对于package打包,一般用默认生成的manifest文件即可,进入JavaT目录,在该目录下执行以下命令</p>
<p>打包整个目录</p>
<p>$jar cvf bar.jar net</p>
<p>或者更详细指定具体的类名</p>
<p>$jar cvf bar.jar net/openwares/foo/bar.class</p>
<p>之后在JavaT目录下生成bar.jar,将此包拷贝到$JAVA_HOME/jre/lib/ext目录下,即可在其他地方import该包</p>
<p><strong>2. 打包可执行java程序</strong></p>
<p>此处稍有不同,必须指定一个manifest清单文件来指定可执行jar包内的主类,也就是JVM加载时要从此主类开始执行,当然有必要的话还要指定主类的程序入口点</p>
<p>假设现在有两个类foo.class和bar.class,将其打包成foobar.jar,并且foo.class包含程序入口点,目录结构如下</p>
<p>JavaT/foo.class</p>
<p>JavaT/bar.class</p>
<p>在JavaT目录下建立一个文件manifest,其内容如下</p>
<p>Manifest-Version: 1.0<br>Created-By:  openwares.net</p>
<p>Main-Class: foo</p>
<p>最后一行Main-Class即用来指定jar包内的主类,如果此主类属于某一个包,此处要输入类的全限定名字,亦即packagename.foo</p>
<p>然后进入JavaT目录,执行</p>
<p>$jar cvfm foobar.jar manifest foo.class bar.class</p>
<p>生成foobar.jar,拷贝此文件至任意目录,通过以下命令即可执行此jar包</p>
<p>$java -jar foobar.jar</p>
<p>如果可执行java程序在一个命名的包内,也就是不使用默认包,那么其打包方式与package基本一样，除了需要增加一个manifest文件来指定完整的主类名。</p>
<p><strong>3. 其他打包方式</strong></p>
<p>因为jar是一个标准的zip格式文件,所以只要组织好文件的目录结构,增加必要的元文件,比如META-INF/MANIFEST.MF等,用支持zip格式压缩的工具比如7zip等将完整的目录结构压缩成一个zip格式扩展名为.jar的文件即可</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java package与C++ namespace的异同</title>
    <url>/2011/01/24/java-package-cpp-namespace/</url>
    <content><![CDATA[<p>Java的包与C++的名字空间基本上是一个类型的东西。</p>
<a id="more"></a>
<p>其相同点为划分作用域, 解决名字冲突的问题,方便项目的协作、集成。</p>
<p>其不同点有三：</p>
<p>其一，C++的名字空间可以修饰所有的标识符,类、结构、联合、枚举、变量等皆可,而Java的包只能修饰Java类。</p>
<p>其二，C++的名字空间可以嵌套,Java的包不支持嵌套。</p>
<p>其三，C++内层空间可以看到外层空间的各种标识符，相反则不可，如果有同名标识符，则内层空间自动屏蔽外层空间的同名标识符。而Java包内的类默认为package访问权限,同一个包内的类默认可以相互访问,而只有public修饰的类才可以被包外面的代码访问。</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Java异常与Spring MVC异常统一处理</title>
    <url>/2013/10/23/java-spring-mvc-exception/</url>
    <content><![CDATA[<p>Java异常与Spring MVC异常统一处理</p>
<a id="more"></a>
<p><strong>Java异常</strong></p>
<p>异常是程序运行过程中出现错误。</p>
<p>其实CPU也有异常的概念，有相应的异常中断处理器，当CPU遇到某些错误，会陷入异常处理器。</p>
<p>Java的所有异常都继承自java.lang.Throwable,其有两个直接的子类java.lang.Error和java.lang.Exeption。</p>
<p><em>错误</em><br>java.lang.Error是无需程序处理的，有些程序也是处理不了的，比如JVM资源耗尽，抛出java.lang.OutOfMemoryError异常。</p>
<p><em>异常</em><br>java.lang.Exeption则是程序可以处理的异常，又分为两大类unchecked异常和checked异常。<br>java.lang.Exeption有个直接子类java.lang.RuntimeExeption,所有派生自java.lang.Error和java.lang.RuntimeExeption的异常都是unchecked异常，<br>其他的异常为checked异常</p>
<p><em>unchecked异常</em><br>unchecked异常用户程序可以不用捕捉处理，程序编译不会有问题。运行时抛出此类异常会有JVM来负责处理。</p>
<p><em>checked异常</em><br>checked异常用户程序必须要处理，如果一个方法抛出checked异常，还要在方法声明里添加异常规格声明，否则编译无法通过。<br>一个方法调用一个抛出checked异常的方法，有两个选择：要么处理或转换掉这个异常，要么在本方法上添加异常规格说明，直接重新抛出这个异常。</p>
<p><strong>Spring MVC异常统一处理</strong></p>
<p>当程序出现异常或错误时，最好不要将容器默认的错误页面直接返回给最终用户，这样是不友好的，会让用户手足无措。<br>最好对所有出现的错误，异常等进行统一处理包装，给用户友好的提示。</p>
<p>tomcat可以设置自定义的错误页面，web.xml中添加：<br>[xml]<br> <!-- error page --><br> <error-page><br> <location>/error</location><br> </error-page><br>[/xml]</p>
<p>在Servlet 3之前，声明一个错误页，必须指定错误码status-code或者异常类型exception-type。从Servlet 3之后，可以设定一个统一的错误页面。</p>
<p>错误页面可以指向一个jsp,html页面,也可以指向一个控制器可以处理的URL。所以可以用一个controller来统一处理。</p>
<p>[java]<br>@Controller<br>public class ErrorController {</p>
<p> @RequestMapping(value=”/error”, produces=”application/json”)<br> @ResponseBody<br> public Map&lt;String, Object&gt; handle(HttpServletRequest request) {</p>
<p> Map&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();<br> map.put(“status”, request.getAttribute(“javax.servlet.error.status_code”));<br> map.put(“reason”, request.getAttribute(“javax.servlet.error.message”));<br> map.put(“exception”, request.getAttribute(“javax.servlet.error.exception”));<br> map.put(“exception_type”, request.getAttribute(“javax.servlet.error.exception_type”));<br> map.put(“request_uri”, request.getAttribute(“javax.servlet.error.request_uri”));<br> map.put(“servlet_name”, request.getAttribute(“javax.servlet.error.servlet_name”));</p>
<p> return map;<br> }</p>
<p>}<br>[/java]</p>
<p>这只是个简单的示例，返回json格式的响应信息。可以在控制器里通过X-Requested-With和Accept请求头来综合判断请求来自Ajax请求还是普通的页面请求，然后以不同的格式给出不用的响应内容。</p>
<p>一般ajax请求会设置X-Requested-With请求头为XMLHttpRequest，但不是所有的ajax请求都会设置这个头，或者设置的不一定一致。<br>Accept头则指明了客户可以接受的mime类型。可以综合这二者进行判断。可以针对json请求返回json应答，其他返回html应答。</p>
<p>Servlet 3.0 规范在10.9 Error Handling有如下规定：</p>
<p>如果在部署描述文件中指定的错误页为一个Servlet或者JSP页面，则容器实现应该满足以下要求：</p>
<ul>
<li>  由容器创建的、原始未包装的请求和响应对象必须传递给Servlet或JSP页面</li>
<li>  如果对错误处理页面执行了RequestDispatcher.forward，则应设置请求路径和相关属性</li>
<li>  以下请求属性必须设置<br>[html]<br>请求属性 类型</li>
</ul>
<hr>
<p>javax.servlet.error.status_code java.lang.Integer<br>javax.servlet.error.exception_type java.lang.Class<br>javax.servlet.error.message java.lang.String<br>javax.servlet.error.exception java.lang.Throwable<br>javax.servlet.error.request_uri java.lang.String<br>javax.servlet.error.servlet_name java.lang.String<br>[/html]</p>
<p>所以在我们的错误控制器可以获取到这些错误相关的信息。<br>自从Servlet 2.3引入请求属性exception对象以后，异常类型属性exception_type和错误消息属性message就成多余无用的属性了，保留它们只是为了向后兼容。</p>
<p>特别是在处理ajax的请求错误时，可以通过错误页面返回详细的错误信息，客户端收到响应后，除给客户一个友好的错误提示以外，还可以将对应客户端请求的context和服务器返回的错误信息进行打包，给开发人员提交一个feedback，方便分析定位解决问题。</p>
<p>只要出现异常(不是错误),那一般说明程序存在问题(难以预料、非应用程序导致的IO异常除外)，完全可以通过完善程序来解决。<br>所以客户自定义的异常可以设计成unchecked异常，程序发现问题时直接携带详细错误信息抛出异常，不用捕捉处理，<br>事后通过分析定位解决问题来避免以后发生异常。</p>
<p>很多时候就算处理了异常，程序也无法回到正常的执行路径。</p>
<p>References:<br>[1]<a href="http://download.oracle.com/otndocs/jcp/servlet-3.0-fr-eval-oth-JSpec/">Java Servlet 3.0 Specification</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java文档注释规范</title>
    <url>/2013/10/22/javadoc-convention/</url>
    <content><![CDATA[<p>把文档和代码写在一起是个不错的主意。</p>
<a id="more"></a>
<p>开发人员总是不愿意写文档，别说文档，连注释都懒的写。修改代码后，再去其他的地方更新文档，估计没几个人会乐意这么做，能写写注释已经仁至义尽了。<br>把文档和代码写在一起可以最大限度的保持代码和文档的一致性。</p>
<p>所以有了<a href="http://www.stack.nl/~dimitri/doxygen/index.html">Doxygen</a>,<a href="http://www.oracle.com/technetwork/java/javase/documentation/index-137868.html">Javadoc</a>等等。</p>
<p>Doxygen是C++文档注释的事实标准，当然也支持很多其他语言，比如C, Objective-C, C#, PHP, Java, Python, IDL (Corba, Microsoft, and UNO/OpenOffice flavors), Fortran, VHDL, Tcl等等。</p>
<p>Doxygen基本上兼容Javadoc的语法，除此之外还支持其他的文档注释标记，可以输出成HTML、以及CHM、RTF、PDF、LaTeX、PostScript或man pages。</p>
<p>据说TODO在Doxygen和Javadoc之间有些不同，见<a href="http://www.douban.com/note/52331471/">doxygen、javadoc通用的TODO标记</a></p>
<p><strong>Javadoc标记</strong></p>
<p>标签 &amp; 参数</p>
<p>说明</p>
<p>示例</p>
<p>@author <em>name-text</em></p>
<p>标明作者</p>
<p>@author openwares.net</p>
<p>@deprecated <em>deprecated-text</em></p>
<p>过期的API</p>
<p>[html]<br>/**</p>
<ul>
<li>@deprecated As of JDK 1.1, </li>
<li>replaced by {@link #setBounds(int,int,int,int)}</li>
<li>/<br>[/html]</li>
</ul>
<p>{@code <em>text</em>}</p>
<p>text里面的特殊符号不会被解释为HTML或Javadoc标签，<br>这样就可以不用费劲的使用HTML转义实体了<br>(左右尖括号转义字符序列)</p>
<p>{@code A&lt; B&gt;C}会被直接显示为A&lt; B&gt;C</p>
<p>{@docRoot}</p>
<p>指定当前文档的根目录路径</p>
<p>[html]<br>/**</p>
<ul>
<li>See the <a href="{@docRoot}/copyright.html">Copyright</a>.</li>
<li>/[/html]</li>
</ul>
<p>@exception <em>class-name description</em></p>
<p>方法抛出的异常</p>
<p>[html]<br>/**</p>
<ul>
<li>@exception IOException If an input or output </li>
<li>exception occurred</li>
<li>/<br>[/html]</li>
</ul>
<p>{@inheritDoc}</p>
<p>从父类继承的注释</p>
<p>{@link <em>package.class#member label</em>}</p>
<p>到另一个注释文档的链接</p>
<p>Use the {@link #getComponentAt(int, int) getComponentAt} method</p>
<p>{@linkplain <em>package.class#member label</em>}</p>
<p>与@link一样，除了链接文字显示为普通文本</p>
<p>Refer to {@linkplain add() the overridden method}</p>
<p>{@literal <em>text</em>}</p>
<p>与@code相同</p>
<p>@param <em>parameter-name description</em></p>
<p>方法的参数</p>
<p>[java]<br> /**</p>
<ul>
<li>@param string the string to be converted</li>
<li>@param type the type to convert the string to</li>
<li>@param <T> the type of the element</li>
<li>@param <V> the value of the element</li>
<li>/<br>&lt;T, V extends T&gt; V convert(String string, Class<T> type) {<br>}<br>[/java]</li>
</ul>
<p>@return <em>description</em></p>
<p>方法返回值</p>
<p>@see <em>reference</em></p>
<p>到另一个主题的链接</p>
<p>[html]<br>格式:@see “string”,示例:@see “The Java Programming Language”<br>格式:@see <a href="URL#value">label</a>,<br>示例: @see <a href="spec.html#section">Java Spec</a><br>格式:@see <em>package.class#member label</em>,<br>示例:<br>/**</p>
<ul>
<li>@see String#equals(Object) equals</li>
<li>/<br>[/html]</li>
</ul>
<p>@serial <em>field-description include exclude</em></p>
<p>@serialField <em>field-name field-type field-description</em></p>
<p>@serialData <em>data-description</em></p>
<p>@since <em>since-text</em></p>
<p>新的改变从时候时候开始</p>
<p>@since 1.5</p>
<p>@throws</p>
<p>同@exception</p>
<p>{@value <em>package.class#field</em>}</p>
<p>显示指定的常量值</p>
<p>[html]<br>/**</p>
<ul>
<li><p>The value of this constant is {@value}.</p>
</li>
<li><p>/<br>public static final String SCRIPT_START = “<script>"</p>
<p>/**</p>
</li>
<li><p>Evaluates the script starting with {@value #SCRIPT_START}.</p>
</li>
<li><p>/<br>public String evalScript(String script) {<br>}<br>[/html]</p>
</li>
</ul>
<p>@version <em>version-text</em></p>
<p>标明版本</p>
<p>参考：<br><a href="http://docs.oracle.com/javase/1.5.0/docs/tooldocs/windows/javadoc.html">javadoc - The Java API Documentation Generator</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Javascript \&quot;类\&quot;数组对象</title>
    <url>/2014/08/07/javascript-array-like-object/</url>
    <content><![CDATA[<a id="more"></a>
<p>“类”数组对象,这名字实在太让人迷惑了,不过看看其英文的含义就一目了然了,array like objects。嚓！原来如此！</p>
<p>类数组对象中的“类”不是class的意思，而是like，类似的意思。JavaScript中有一些看起来像却又不是数组的对象，叫作”类”数组对象。</p>
<p>类数组对象拥有数组索引下标以及length属性,但不具有数组所拥有的其他方法。比如每个函数都具有的arguments对象就是一个类数组对象。</p>
<p>Javascript是如此的灵活，类数组对象可以借用Array对象所拥有的方法,只要调用数组函数的call方法将类数组对象绑定为this即可。比如可以将arguments类数组对象转换为真正的数组:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> args = <span class="built_in">Array</span>.prototype.slice.call(<span class="built_in">arguments</span>);</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript变量声明提升(hoisting)</title>
    <url>/2013/06/11/javascript-declaration-hoisting/</url>
    <content><![CDATA[<p>javascript的变量声明具有hoisting机制，JavaScript引擎在执行的时候，会把所有变量的声明都提升到<strong>当前作用域</strong>的最前面。</p>
<a id="more"></a>
<p>先看一段代码<br>[javascript]<br>var v = “hello”;<br>(function(){<br> console.log(v);<br> var v = “world”;<br>})();<br>[/javascript]</p>
<p>这段代码运行的结果是什么呢？<br>答案是：undefined<br>这段代码说明了两个问题，<br>第一，function作用域里的变量v遮盖了上层作用域变量v。代码做少些变动<br>[javascript]<br>var v = “hello”;<br>if(true){<br> console.log(v);<br> var v = “world”;<br>}<br>[/javascript]<br>输出结果为”hello”,说明<strong>javascript是没有块级作用域的</strong>。<strong>函数是JavaScript中唯一拥有自身作用域的结构。</strong></p>
<p>第二，在function作用域内，变量v的声明被提升了。所以最初的代码相当于：<br>[javascript]<br>var v = “hello”;<br>(function(){<br> var v; //declaration hoisting<br> console.log(v);<br> v = “world”;<br>})();<br>[/javascript]</p>
<p><strong>声明、定义与初始化</strong></p>
<p>声明宣称一个名字的存在，定义则为这个名字分配存储空间，而初始化则是为名字分配的存储空间赋初值。<br>用C++来表述这三个概念<br>[cpp]<br>extern int i;//这是声明，表明名字i在某处已经存在了<br>int i;//这是声明并定义名字i,为i分配存储空间<br>i = 0;//这是初始化名字i,为其赋初值为0<br>[/cpp]</p>
<p>javascript中则是这样<br>[javascript]<br>var v;//声明变量v<br>v = “hello”;//(定义并)初始化变量v<br>[/javascript]<br>因为javascript为动态语言，其变量并没有固定的类型，其存储空间大小会随初始化与赋值而变化，所以其变量的“定义”就不像传统的静态语言一样了，其定义显得无关紧要。</p>
<p><strong>声明提升</strong></p>
<p>当前作用域内的声明都会提升到作用域的最前面，包括变量和函数的声明<br>[javascript]<br>(function(){<br> var a = “1”;<br> var f = function(){};<br> var b = “2”;<br> var c = “3”;<br>})();<br>[/javascript]<br>变量a,f,b,c的声明会被提升到函数作用域的最前面，类似如下：<br>[javascript]<br>(function(){<br> var a,f,b,c;<br> a = “1”;<br> f = function(){};<br> b = “2”;<br> c = “3”;<br>})();<br>[/javascript]<br>请注意函数表达式并没有被提升，这也是函数表达式与函数声明的区别。进一步看二者的区别：<br>[javascript]<br>(function(){<br> //var f1,function f2(){}; //hoisting,被隐式提升的声明</p>
<p> f1(); //ReferenceError: f1 is not defined<br> f2();</p>
<p> var f1 = function(){};<br> function f2(){}<br>})();<br>[/javascript]<br>上面代码中函数声明f2被提升，所以在前面调用f2是没问题的。虽然变量f1也被提升，但f1提升后的值为undefined,其真正的初始值是在执行到函数表达式处被赋予的。所以只有声明是被提升的。</p>
<p><strong>名字解析顺序</strong></p>
<p>javascript中一个名字(name)以四种方式进入作用域(scope)，其优先级顺序如下：<br>1、语言内置：所有的作用域中都有 this 和 arguments 关键字<br>2、形式参数：函数的参数在函数作用域中都是有效的<br>3、函数声明：形如function foo() {}<br>4、变量声明：形如var bar;</p>
<p>名字声明的优先级如上所示，也就是说如果一个变量的名字与函数的名字相同，那么函数的名字会覆盖变量的名字，无论其在代码中的顺序如何。但名字的初始化却是按其在代码中书写的顺序进行的，不受以上优先级的影响。看代码：<br>[javascript]<br>(function(){<br> var foo;<br> console.log(typeof foo); //function</p>
<p> function foo(){}</p>
<p> foo = “foo”;<br> console.log(typeof foo); //string<br>})();<br>[/javascript]</p>
<p>如果形式参数中有多个同名变量，那么最后一个同名参数会覆盖其他同名参数，即使最后一个同名参数并没有定义。</p>
<p>以上的名字解析优先级存在例外，比如可以覆盖语言内置的名字arguments。</p>
<p><strong>命名函数表达式</strong></p>
<p>可以像函数声明一样为函数表达式指定一个名字，但这并不会使函数表达式成为函数声明。命名函数表达式的名字不会进入名字空间，也不会被提升。<br>[javascript]<br>f();//TypeError: f is not a function<br>foo();//ReferenceError: foo is not defined<br>var f = function foo(){console.log(typeof foo);};<br>f();//function<br>foo();//ReferenceError: foo is not defined<br>[/javascript]<br>命名函数表达式的名字只在该函数的作用域内部有效。<br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript检测显示PPI</title>
    <url>/2014/07/17/javascript-detect-ppi/</url>
    <content><![CDATA[<a id="more"></a>
<p>添加一个尺寸为1英寸物理div,然后获取其尺寸的逻辑单位值就可以了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;div id=<span class="string">&quot;ppitest&quot;</span> style=<span class="string">&quot;width:1in;height:1in;visible:hidden;&quot;</span>&gt;&lt;/div&gt;</span><br><span class="line">&lt;script&gt;</span><br><span class="line"> <span class="keyword">var</span> ppi_x = <span class="built_in">document</span>.getElementById(<span class="string">&#x27;ppitest&#x27;</span>).offsetWidth;</span><br><span class="line"> <span class="keyword">var</span> ppi_y = <span class="built_in">document</span>.getElementById(<span class="string">&#x27;ppitest&#x27;</span>).offsetHeight;</span><br><span class="line"> alert(<span class="string">&#x27;ppi_x=&#x27;</span>+ppi_x+<span class="string">&#x27;; ppi_y=&#x27;</span>+ppi_y);</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript执行环境栈(Execute Context Stack)与作用域链(Scope Chain)</title>
    <url>/2014/05/06/javascript-execute-context-scope/</url>
    <content><![CDATA[<a id="more"></a>
<p>1、函数对象创建时会继承当前执行环境的作用域链。也就是当前执行环境会将其创建的函数对象的[[scope]]属性设置为当前作用域链的头，也就是指向当前执行环境的活动对象(Active Object),其实就是一个可变对象(Variable Object),不过因为它是当前激活的VO,所以又叫AO。</p>
<p>References:<br>[1]<a href="http://www.cn-cuckoo.com/main/wp-content/uploads/2007/08/JavaScriptClosures.html">Javascript 闭包</a><br>[2]<a href="http://www.360weboy.com/front/page1/execution-context.html">深入理解javascript之执行上下文(execution context)</a><br>[3]<a href="http://octsky.com/post/63/">JavaScript中的 变量、作用域链、执行上下文</a><br>[4]<a href="http://www.yeebing.com/webdesign/998.html">理解js作用域链及闭包</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript函数声明、函数表达式和函数构造器</title>
    <url>/2013/11/17/javascript-function/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>函数声明</strong><br><em>命名函数声明</em><br>[javascript]<br>// 函数声明会被提升，所以可以提前调用<br>// 这里只是普通的函数调用,此时this指向Window对象,会为Window对象添加属性b<br>// result的值和类型依赖于Func()函数的返回值,没有return语句默认返回undefined<br>var result = Func(); //Window{…}<br>console.log(result); //undefined<br>console.log(typeof result); //undefined</p>
<p>// 函数声明<br>function Func(){<br> //局域临时变量，函数执行完即被丢弃，无论是作为普通函数还是构造器调用<br> var a = “a”;</p>
<p> // 无论是普通函数调用还是作为函数构造器<br> // this指向哪个对象，则为那个对象添加属性b,<br> // 如果作为构造器调用，this指向新创建的对象<br> this.b = “b”;</p>
<p> // 因为没有使用var声明c,所以c属于全局变量，无论什么时候函数被调用，都会为全局对象添加属性c<br> c=”c”;</p>
<p> console.log(this);<br>}</p>
<p>//用户自定义函数的构造器为Function(),所以Func函数的原型链(<strong>proto</strong>)指向Function.prototype<br>console.log(Func); //function Func(){//临时变量…}<br>console.log(typeof Func); //function<br>console.log(Func.<strong>proto</strong>); //function Empty(){}<br>console.log(Func.<strong>proto</strong>===Function.prototype); //true<br>console.log(Func.prototype); //Func{}<br>console.log(Func.prototype.constructor); //function Func(){//临时变量…}<br>console.log(Func.prototype.<strong>proto</strong>===Object.prototype); //true</p>
<p>// 当对函数施加new运算符时,函数才叫做构造器,new运算符的结果总是一个对象<br>// 函数自身返回对象的优先级高，new运算符新构造对象的优先级低。<br>// new运算符无论如何都会执行构造器函数,如果函数也返回一个对象的话,new运算符新构造的对象会被丢弃。<br>var obj = new Func(); //Func{b: “b”}<br>console.log(obj); // Func{b: “b”}<br>console.log(typeof obj); // object<br>console.log(obj.<strong>proto</strong>); // Func{}<br>console.log(obj.<strong>proto</strong>===Func.prototype); // true<br>console.log(obj.prototype); //undefined</p>
<p>// 这里只是为Func换了个别名func而已,func和Func都引用同一个命名函数对象Func()<br>// 二者是同一个东西，排名不分先后<br>var func = Func;<br>console.log(func); //function Func(){//临时变量…}<br>console.log(typeof func); //function<br>console.log(func.<strong>proto</strong>); //function Empty(){}<br>console.log(func.prototype); //Func{}<br>[/javascript]</p>
<p><em>匿名函数声明</em><br>匿名函数不立即执行是没有什么用处的，因为声明之后根本无法引用它，但仍然可以这样声明<br>[javascript]<br>//匿名函数<br>console.log(function(){var a=”a”;this.b=”b”;console.log(this);}) //function (){var a=”a”…}<br>//直接执行,第一次是console.log(this)输出,为Window{…}<br>// 第二次输出为函数返回值输出undefined<br>console.log((function(){var a=”a”;this.b=”b”;console.log(this);})()) //Window{…}; undefined<br>//当作函数构造器执行,第一次是构造函数输出，console.log(this)<br>//第二次是返回的新对象的输出,都是Onject{b: “b”}<br>console.log(new function(){var a=”a”;this.b=”b”;console.log(this);}) //Object{b: “b”}; Object{b: “b”}<br>console.log(function(){var a=”a”;this.b=”b”;console.log(this);}.<strong>proto</strong>) //function Empty(){}<br>// 匿名函数的匿名原型对象<br>console.log(function(){var a=”a”;this.b=”b”;console.log(this);}.prototype) //Object{}<br>console.log(function(){var a=”a”;this.b=”b”;console.log(this);}.prototype==Object.prototype) //false<br>console.log(function(){var a=”a”;this.b=”b”;console.log(this);}.prototype.<strong>proto</strong>===Object.prototype) //true<br>[/javascript]<br><strong>函数表达式</strong></p>
<p><em>命名函数表达式</em></p>
<p>[javascript]<br>// 函数表达式中的Func名字只在函数内部可见，不会进入外部名字空间<br>//var result1 = Func(); //Func is not defined</p>
<p>// 函数表达式不会被提升，所以不能提前调用<br>//var result2 = func(); //func is not a function<br>console.log(func); //undefined</p>
<p>// 函数表达式,func和Func都指向同一个命名函数对象Func()<br>// 二者是同一个东西，但是Func名字只在函数内部可见<br>var func = function Func(){<br> //临时变量，函数执行完即被丢弃，无论是作为普通函数还是构造器调用<br> var a = “a”;</p>
<p> // 无论是普通函数调用还是作为函数构造器<br> // this指向哪个对象，则为那个对象添加属性b,<br> this.b = “b”;<br> console.log(this);<br>}</p>
<p>// 函数表达式不会被提升，所以只能在函数定义之后调用<br>// 普通函数调用,this指向Window对象<br>var result3 = func(); //Window{…}</p>
<p>//用户自定义函数的构造器为Function(),所以func函数的原型链(<strong>proto</strong>)指向Function.prototype<br>console.log(func); //function Func(){//临时变量…}<br>console.log(typeof func); //function<br>console.log(func.<strong>proto</strong>); //function Empty(){}<br>console.log(func.<strong>proto</strong>===Function.prototype); //true<br>console.log(func.prototype); //Func{}<br>console.log(func.prototype.<strong>proto</strong>===Object.prototype); //true</p>
<p>// 当对函数施加new运算符时,函数才叫做构造器,new运算符的结果总是一个对象<br>// 函数自身返回对象的优先级高，new运算符新构造对象的优先级低。<br>// new运算符无论如何都会执行构造器函数,如果函数也返回一个对象的话,new运算符新构造的对象会被丢弃。<br>var obj = new func(); //Func{b: “b”}<br>console.log(obj); // Func{b: “b”}<br>console.log(typeof obj); // object<br>console.log(obj.<strong>proto</strong>); // Func{}<br>console.log(obj.<strong>proto</strong>===func.prototype); // true<br>console.log(obj.prototype); //undefined<br>[/javascript]</p>
<p><em>匿名函数表达式</em></p>
<p>匿名函数表达式和命名函数表达式的唯一区别是，其prototype属性对象是个匿名对象，而命名函数表达式的prototype属性对象为一个具名对象，比如上个例子中的Func()</p>
<p>[javascript]<br>// 函数表达式不会被提升，所以不能提前调用<br>//var result2 = func(); //func is not a function<br>console.log(func); //undefined</p>
<p>// 函数表达式,引擎为其分配了一个不具名的对象作为其原型对象(prototype属性指向的对象)<br>// 其本质上与上个示例中的具名对象Func()是一样的,原型链的上层都是Object<br>// func指向一个匿名函数对象function(){//临时变量…}<br>var func = function(){<br> //临时变量，函数执行完即被丢弃，无论是作为普通函数还是构造器调用<br> var a = “a”;</p>
<p> // 无论是普通函数调用还是作为函数构造器<br> // this指向哪个对象，则为那个对象添加属性b,<br> this.b = “b”;<br> console.log(this);<br>}</p>
<p>// 函数表达式不会被提升，所以只能在函数定义之后调用<br>// 普通函数调用,this指向Window对象<br>var result3 = func(); //Window{…}</p>
<p>//用户自定义函数的构造器为Function(),所以func函数的原型链(<strong>proto</strong>)指向Function.prototype<br>console.log(func); //function(){//临时变量…}<br>console.log(typeof func); //function<br>console.log(func.<strong>proto</strong>); //function Empty(){}<br>console.log(func.<strong>proto</strong>===Function.prototype); //true<br>//func.prototype是一个不具名的对象,其与上个例子中的具名对象Func()是一样的东西<br>//其原型链的上一个对象都是Object.prototype<br>console.log(func.prototype.constructor); // function(){//临时变量…}<br>console.log(func.prototype); // Object{}<br>console.log(Object.prototype); // Object{}<br>//不要被输出迷惑了,这个不具名对象与Object.prototype是不同的对象<br>console.log(func.prototype==Object.prototype); // false<br>//这个不具名对象原型自Object<br>console.log(func.prototype.<strong>proto</strong>===Object.prototype); // true</p>
<p>// 当对函数施加new运算符时,函数才叫做构造器,new运算符的结果总是一个对象<br>// 函数自身返回对象的优先级高，new运算符新构造对象的优先级低。<br>// new运算符无论如何都会执行构造器函数,如果函数也返回一个对象的话,new运算符新构造的对象会被丢弃。<br>var obj = new func(); //func{b: “b”}<br>console.log(obj); // func{b: “b”}<br>console.log(typeof obj); // object<br>console.log(obj.<strong>proto</strong>); // Object{}<br>console.log(obj.<strong>proto</strong>===func.prototype); // true<br>console.log(obj.prototype); //undefined<br>[/javascript]</p>
<p><strong>函数构造器</strong></p>
<p>当对函数施加new运算符时，函数才叫做构造器(constrcutor)，否则就是普通的函数调用。普通的函数调用中，函数返回的对象直接返回给调用者。</p>
<p><strong>但是当使用new操作符作为构造器调用时，new操作符会构造一个函数构造器(constrcutor)原型对象(constructor.prototype)类型的空对象(是object，不是function)，新对象的__proto__属性指向函数构造器的原型(constructor.prototype),从而新对象从函数构造器原型(constructor.prototype)继承属性。<br>新对象的constructor属性值被赋予原型对象的constructor值(prototype.constructor)，也就是函数构造器(constrcutor)自身。new运算符使用新对象作为this调用函数构造器(constrcutor)。</strong></p>
<p>返不返回新对象还要视函数的返回值而定。如果函数自身使用return语句明确的返回一个object或function,则直接返回函数的返回值，新<br>创建的对象被丢弃。否则会返回新创建的对象。</p>
<p>无论返不返回新创建的对象函数构造器(constrcutor)都会被调用。无论如何构造器(使用new操作符)都会返回一个对象，而不是基本类型。</p>
<p>new操作符创建的新对象只可能是object，不会是其他类型，不会是function。</p>
<p>new操作符新创建的对象未添加其他属性之前，所有的本地属性都来自于构造函数中使用this添加的属性。</p>
<p>不同的函数构造器(constrcutor)创建不同的对象。</p>
<p>到底new运算符做了什么事情，参见MDN文章<a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/new">new</a>。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>Javascript获取图片实际尺寸</title>
    <url>/2014/09/20/javascript-get-image-real-dimensions/</url>
    <content><![CDATA[<a id="more"></a>
<p>img元素的width和height属性只会取出图像当前的宽度和高度,这宽度和高度可能不是图像原始的尺寸,因为img元素可以指定width和height属性。</p>
<p>现代浏览器为img元素添加了两个属性naturalWidth和naturalHeight可以获取图像的原始尺寸。这两个属性是只读的。<br>jquery没有对应的属性或方法，可以通过获取原始的dom对象来读取这两个属性。</p>
<p>对于不支持这个两个属性的浏览器,可以通过生成一个不设定width和height的内存图像来获取原始尺寸。</p>
<p>代码如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> image = <span class="built_in">document</span>.getElementById(<span class="string">&quot;img_id&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(<span class="keyword">typeof</span> image.naturalWidth == <span class="string">&quot;undefined&quot;</span>) &#123;</span><br><span class="line"> <span class="comment">// legacy browsers</span></span><br><span class="line"> <span class="keyword">var</span> tmp_img = <span class="keyword">new</span> Image();</span><br><span class="line"> tmp_img.addEventListener(<span class="string">&#x27;load&#x27;</span>, <span class="function"><span class="keyword">function</span>(<span class="params">e</span>)</span>&#123;</span><br><span class="line"> <span class="keyword">var</span> rw = tmp_img.width;</span><br><span class="line"> <span class="keyword">var</span> rh = tmp_img.height;</span><br><span class="line"> &#125;);</span><br><span class="line"> tmp_img.src = image.src;</span><br><span class="line">&#125;<span class="keyword">else</span>&#123;</span><br><span class="line"> <span class="comment">// modern browsers</span></span><br><span class="line"> <span class="keyword">var</span> rw = image.naturalWidth;</span><br><span class="line"> <span class="keyword">var</span> rh = image.naturalHeight;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript继承模型</title>
    <url>/2013/06/05/javascript-instance-class-prototype/</url>
    <content><![CDATA[<p>javascript中并没有类的概念，这里的类指代用new操作符产生出其他对象的对象。</p>
<a id="more"></a>
<p>这里说的属性也包括方法，因为方法只不过是值为函数的属性。</p>
<p>javascript是基于原型的，没有类的概念，但是借鉴了new操作符来通过原型对象(constructor.prototype)生成实例对象，new运算符作用于一个函数构造器(constructor)之上。先看一个简单的函数构造器(constructor)<br>[javascript]<br>function F(){}<br>[/javascript]</p>
<p>F看起来平淡无奇，但其背后隐藏了很多看不到的奥秘。首先F是一个函数F()，其次函数本身还是一个对象F，再次函数F()背后还有一个由javascript引擎安排的一个函数构造器原型(constructor.prototype)对象F{}。这个构造器原型对象F{}是F对象的属性，而不是F()函数的,由F对象的prototype属性引用，也就是F.prototype=F{}</p>
<p>从机器域来说，函数F()就是一段可执行代码，所以底层实现还是需要一个数据区来存储函数对象F的属性。在机器层面上这与C++的类模型并无本质的不同。</p>
<p>这里有必要区分下F()函数和F对象。先来看段C++代码：<br>[cpp]<br>class F{<br>public:<br> F(){<br> this.m_a=’a’;<br> }<br>private:<br> char m_a;<br>}</p>
<p>F* f = new F();<br>[/cpp]<br>是不是有一个F类还有一个F构造函数。F类的构造函数就是F(),生成f实例对象时new会在内部调用F()构造函数。new先申请一块类对象大小的内存块，然后初始化一些内部的变量如vptr等，最后会以此内存区域的首地址为this指针的值来调用构造函数F(),最后将实例对象的地址赋予实例对象指针f。</p>
<p>javascript的原型继承与其有相似之处，只是实现方式不同。再回到最初的javascript函数构造器，F()就是构造函数，F对象就是类，F.prototype引用的原型对象F{}就是父类，原型对象F{}有一个字段constructor指向构造函数F()。</p>
<p>var f = new F();</p>
<p>构造函数为新创建对象添加用this修饰的属性，因为this此时指向新创建的对象，并返回给f,这是显式的。并且新创建的对象动态的继承原型对象F{}(F.prototype)中的所有属性。但是对象f并不从F对象继承任何属性，这与C++等是不同的。new做的具体操作参考<a href="https://openwares.net/js/javascript_prototype_chain.html">JavaScript原型链浅析</a></p>
<p>看一段测试代码<br>[javascript]<br>function F(){<br> var a = “a”; //a不过是函数F()的局部变量，离开F()，变量a就不存在了<br> this.b = “b”; //b也是函数F()作用域内部的变量，离开F()就不存在了，<br> //但b却添加到新对象上，因为执行构造函数F()之时，this指向新构造的对象<br> this.instanceF = function(){ //与b相同，所有this修饰的属性都会添加到新对象之上<br> console.log(“this=”+this);<br> console.log(“this.a=”+this.a);<br> console.log(“this.b=”+this.b);<br> console.log(“this.c=”+this.c);<br> };<br>};</p>
<p>F.c = “c”; //这里c其实是添加到F对象之上<br>F.staticF = function(){ //与c相同,添加F对象之上<br> console.log(“this=”+this);<br> console.log(“this.a=”+this.a);<br> console.log(“this.b=”+this.b);<br> console.log(“this.c=”+this.c);<br>};</p>
<p>//static</p>
<p>console.log(F.a); //undefined<br>console.log(F.b); //undefined<br>console.log(F.c); //c<br>//F.instanceF(); //TypeError: F.instanceF is not a function<br>F.staticF(); //依次输出(可以看出staticF()函数的this就是F对象，也就是function F(){…}):<br> //this=function F(){<br> // var a = “a”; //a不过是函数F()的局部变量，离开F()，变量a就不存在了<br> // this.b = “b”; //b也是函数F()作用域内部的变量，离开F()就不存在了，<br> // //但b却添加到新对象上，因为执行构造函数F()之时，this指向新构造的对象<br> // this.instanceF = function(){ //与b相同，所有this修饰的属性都会添加到新对象之上<br> // console.log(“this=”+this);<br> // console.log(“this.a=”+this.a);<br> // console.log(“this.b=”+this.b);<br> // console.log(“this.c=”+this.c);<br> // };<br> //}<br> //this.a=undefined<br> //this.b=undefined<br> //this.c=c</p>
<p>//函数对象F是由Function(){}构造的<br>console.log(F.constructor); //function Function() { [native code] }<br>console.log(F.constructor===F.<strong>proto</strong>.constructor); //true<br>//new instance<br>var f = new F();</p>
<p>console.log(f.a); //undefined<br>console.log(f.b); //b<br>console.log(f.c); //undefined<br>f.instanceF(); //依次输出:<br> //this=[object object]<br> //this.a=undefined<br> //this.b=b<br> //this.c=undefined<br>//f.staticF(); //TypeError: f.staticF is not a function<br>[/javascript]</p>
<p>对象实例f，拥有构造函数F()为其添加的属性、自己添加的属性，并可以访问原型链F.prototype上的属性，但不能访问F对象上的属性。从构造函数F()添加的属性每个实例都有一个单独的拷贝，不会相互影响，但F.prototype上的属性则是由所有的实例共享的，修改F.prototype的属性会影响所有的实例。</p>
<p>由此可见，<strong>F.prototype其有属性constructor指向构造函数F(),并且new出来的实例对象从F.prototype继承属性，并可沿原型链上溯。相对而言F对象则看起来可有可无了。因为纯粹的构造函数F()是不能持有属性的，所以就有了F对象来持有F的prototype属性，难道这就是生成F对象的唯一原因吗？</strong></p>
<p>F对象的方法很像其他语言里的类静态方法，无需实例化对象即可直接访问，其实就是一种全局函数，不过就是加上了类型的名字空间而已。</p>
<p>那么，最终可以与C++,java等语言做一个类比，当然并没有很多的可比性，差别还是很大的：<br>new生成的f对象是F类的实例，而F类的功能则是由F()和F共同提供，F()提供实例属性，F提供类静态属性，F{}(F.prototype)则是F类的父类，大体是这么个对应关系。但是实例对象f并不能访问F对象的静态属性。</p>
<p>也就是说：<strong>函数构造器是构造函数，其背后隐式的对象为类，构造器的prototype是父类，而通过构造器new出来的则是对象。</strong><br>一个字，真绕！</p>
<p><strong>P.S.</strong> 这篇文章<a href="http://blog.vjeux.com/2011/javascript/how-prototypal-inheritance-really-works.html">Javascript – How Prototypal Inheritance really works</a>对javascript原型继承讲述的十分清晰。<br>这里还有一篇大牛Douglas Crockford的文章<a href="http://javascript.crockford.com/prototypal.html">Prototypal Inheritance in JavaScript</a></p>
<p><strong>UPDATE（05/03/2014)：</strong>如果非要与传统的OOP类比的话,应该是<strong>构造函数</strong>和其<strong>原型对象</strong>一起构成了继承链中的<strong>父类</strong>。<br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript使新创建对象继承函数构造器对象的属性</title>
    <url>/2013/11/18/javascript-new-prototype/</url>
    <content><![CDATA[<a id="more"></a>
<p>默认情况下，使用new运算符创建的对象是从函数构造器(constructor)的原型对象(constructor.prototype)继承属性的，新对象不会继承函数构造器(constructor)自身的属性。<br>[javascript]<br>(function(){<br> function Func(){<br> this.a=”a”<br> }</p>
<p> Func.b=”b”<br> Func.prototype.c=”c”;</p>
<p> var obj=new Func();<br> console.log(obj.a); //a<br> console.log(obj.b); //undefined<br> console.log(obj.c); //c</p>
<p> console.log(obj.<strong>proto</strong>); //F{c: “c”}<br> console.log(obj.prototype); //undefined<br>})();<br>[/javascript]</p>
<p>可以看到obj有本地属性a,没有属性b，还有继承自constructor.prototype的属性c。</p>
<p>那么要让obj继承函数构造器(constructor)的属性也十分简单<br>[javascript]<br> function Func(){<br> this.a=”a”<br> }</p>
<p> Func.b=”b”<br> Func.prototype.c=”c”;<br> Func.prototype=Func; </p>
<p> var obj=new Func();<br> console.log(obj.a); //a<br> console.log(obj.b); //b<br> console.log(obj.c); //undefined</p>
<p> console.log(obj.<strong>proto</strong>); //function Func(){this.a=”a”}<br> console.log(obj.prototype); //function Func(){this.a=”a”}<br>})();<br>[/javascript]</p>
<p>只要将函数构造器(constructor)的原型对象(constructor.prototype)指定为其自身即可。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript 局部打印(print area)</title>
    <url>/2015/10/09/javascript-print-area/</url>
    <content><![CDATA[<a id="more"></a>
<p>非标准、非通用的二进制插件打印方式此处不叙。</p>
<p><strong>打印命令</strong></p>
<ul>
<li><p>  标准的打印方法为调用window.print(),所有的现代浏览器都支持该方法。</p>
</li>
<li><p>还可以使用Print命令调用Document.execCommand(),也就是:</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">document</span>.execCommand(<span class="string">&#x27;Print&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>  虽然所有的桌面浏览器都支持，但这个方法是非标准的。</p>
<p>  execCommand的接口规格:</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">bool = <span class="built_in">document</span>.execCommand(aCommandName, aShowDefaultUI, aValueArgument)</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p><strong>局部打印方法</strong></p>
<p>Javascript局部打印大约有一下这几种方法：</p>
<ul>
<li>  print css方式</li>
</ul>
<p>html支持print css,这是专用于打印设备的，而通常的css用于显示设备</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;link rel=<span class="string">&quot;stylesheet&quot;</span> href=<span class="string">&quot;print.css&quot;</span> media=<span class="string">&quot;print&quot;</span> /&gt;</span><br></pre></td></tr></table></figure>
<p>可以使用print css将无需打印的区域隐藏掉,而需要打印的区域重新设置适合打印的样式，打印时直接调用window.print()即可。</p>
<p>这种打印方式页面不会看到变化，但是样式的调整可能会比较繁琐。</p>
<ul>
<li>  screen css方式</li>
</ul>
<p>使用通常的CSS,在打印之前将无需打印的部分从页面上隐藏，需要打印的区域冲洗设置适合打印的样式。打印完成后再恢复样式。打印时会看到页面的变化。</p>
<ul>
<li>  body replace方式</li>
</ul>
<p>打印之前将页面的body内容替换为需要打印的区域，打印完毕后再恢复body的内容。打印时会看到页面的变化。<br>这种方式与上种方法虽然做法不同，但其实质是相同的，即讲当前页面显示的内容设置要打印的内容，打印完毕后再恢复页面。</p>
<ul>
<li>  iframe方式</li>
</ul>
<p>打印时生成一个iframe嵌入到主页面中,iframe的内容即为需要打印的内容，然后调用iframe的print()方法就可以了。iframe其实就是一个window。<br>用iframe的好处是不用弹出新窗口。</p>
<p>但是需要<strong>注意</strong>:<br>chrome从45.0开始，默认阻止iframe的print方法,除非iframe的沙箱属性有allow-modal值，并且设置了modal标志。</p>
<p>Starting with Chrome 45.0 print method is blocked inside an iframe unless its sandbox attribute has the value allow-modal and the modal flag is enabled.</p>
<ul>
<li>  popup new window方式</li>
</ul>
<p>new window方式其实与iframe方式基本一样，唯一的区别是需要弹出新窗口。很多浏览器对于弹出新窗口都有严格的管制策略，因此新窗口方式用户体验不佳。</p>
<p>总的来说,iframe的方式比较简单，用户体验也较佳。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript原型链浅析</title>
    <url>/2013/05/29/javascript-prototype-chain/</url>
    <content><![CDATA[<p>JavaScript prototype chain 探索</p>
<a id="more"></a>
<p>先来看图<br><img src="/downloads/js_obj_layout.png" alt="javascript object layout"><br>这图有点儿复杂，不过画的很好。这是<a href="http://www.mollypages.org/misc/js.mp">原图</a>，我对其做了些微修改，以便看起来更清楚一些。</p>
<p><strong>1、对象的prototype和__proto__属性</strong><br>确切的说，__proto__不是一个标准的属性，是部分浏览器的特定实现。不过除了IE浏览器之外，其他的浏览器都使用这个名字来实现javascript标准文档里所讲的[[prototype]]隐藏属性。这个属性是隐藏的，只应该有解释器来使用，客户代码不应该依赖于此属性。最新的标准提供了Object.getPrototypeOf函数来获取对象的[[prototype]]属性。</p>
<p>prototype是一个显式的属性，客户可以存取，prototype属性引用对象“关联”的原型对象，而__proto__属性引用“构造”该对象的原型对象。javascript查找对象的属性时是使用__proto__引用的原型对象链向上查找的。</p>
<p>所有的对象都有__proto__属性，但只有可以作为构造器的函数对象才有prototype属性，当然所有的函数都可以作为构造器，也就是只有函数才有prototype属性。普通的非函数对象实例是没有的，因为这样的对象并不能用来构造新的对象。而这个prototype属性所引用的原型对象正是构造器函数构造对象时使用的原型，一会儿讲new运算符会讲到。</p>
<p>[javascript]<br>function F(){};<br>var f = new F();<br>console.log(f.<strong>proto</strong> == F.prototype); //true<br>console.log(f.prototype);//undefined<br>[/javascript]</p>
<p><strong>2、函数对象的prototype从哪里来，由谁负责构造</strong><br>内置函数对象的prototype属性及其引用的原型对象由javascript引擎提供。用户在自定义函数时，js引擎会背地里同时为该函数生成一个原型对象，其为一个与用户定义函数同名的对象，看代码</p>
<p>[javascript]<br>function f(){this.test=””;}<br>console.log(f.prototype); //f{}<br>console.log(typeof f.prototype); //object<br>[/javascript]<br>请注意，f.prototype的类型为object,而不是Object。Object其实是一个函数对象，而object表明f.prototype是一个地地道道的纯粹对象。<br>其实构造器函数的prototype就是为其派生对象存储公共属性的一个容器，不然这些派生对象从原型继承来的属性放到哪里呢？当然prototype还有其他用来管理的属性，比如其constructor属性就指回到函数构造器。当一个对象用构造器构造完成后，构造器的使命就完成了，派生对象从此之后只与其prototype有关系，而与构造器彻底无关了。</p>
<p><strong>再看看内置对象的prototype属性及其类型</strong><br>[javascript]<br>console.log(Object.prototype); //Object{}<br>console.log(typeof Object.prototype); //object<br>console.log(Function.prototype); //function()<br>console.log(typeof Function.prototype); //function<br>console.log(Array.prototype); //[]<br>console.log(typeof Array.prototype); //object<br>[/javascript]<br>可以看到，除了Function的原型对象为function类型外，其他内置函数对象的原型对象皆为object类型，纯粹的对象，注意不要与Object混淆。</p>
<p>Function比较特殊，其prototype属性和__proto__属性皆引用同一个原型对象，且其原型对象的类型为function(),而不是对象。因为javascript中的所有函数功能皆来自于Function.prototype原型对象,包括Function自身，所以如果Function.prototype也是一个对象而不是函数的话，那函数的功能从哪里来呢？所以其为函数类型，由js引擎来实现。<br>也就是说，Function对象的原型对象就是其自身Function(),Function对象是由其自身构造的。bootstrap?！但请注意Function.prototype是由Object().prototype构造的。</p>
<p><strong>前面只是说原型对象(prototype属性所引用的对象)由javascript引擎生成的，但其构造器是什么呢？</strong></p>
<p>除了Object()之外的所有函数构造器，包括自定义构造器，他们”关联”的原型对象(prototype属性所引用)都是由Object()构造器构造而来，也就是他们“关联”的原型对象(prototype属性所引用)的原型对象(由__proto__属性所引用)是Object.prototype。那么Object()构造器关联的原型对象Object.prototype(prototype属性所引用)是由谁负责构造的呢？答案就是，Object.prototype是原型链的顶端，是有javascript引擎构造出来的，它没有构造器，它的__proto__属性为null。</p>
<p><strong>3、对象的__proto__属性指向哪里？</strong><br><strong>首先看用户对象</strong><br>对于用户自定义的对象，其<strong>proto__属性都指向使用的构造器的prototype对象<br>[javascript]<br>function f(){this.test=””;}<br>var f1 = new f();<br>console.log(f.prototype); //f{}<br>console.log(f1.prototype); //undefined<br>console.log(f1.__proto</strong>); //f{}<br>console.log(f1.constructor);//function f(){this.test=””;}<br>[/javascript]</p>
<p>对于对象直接量，其实内部是调用Object函数构造器来构造对象的，所以其<strong>proto__指向Object原型对象。Object其实是一个函数，是由Fucntion对象构造的。<br>[javascript]<br>var o={first:1,last:2};<br>console.log(o.prototype); //undefined<br>console.log(o.__proto</strong>); //Object{}<br>console.log(o.constructor);//Object() 或输出function Object() { [native code] }<br>[/javascript]</p>
<p>对于数组对象直接量,则是由内部调用Array函数构造器来构造的。<br>[javascript]<br>var arr = [];<br>console.log(arr.prototype); //undefined<br>console.log(arr.<strong>proto</strong>);//[]<br>console.log(o.constructor);//function Array() { [native code] }<br>[/javascript]</p>
<p>其他内置对象大抵如是。</p>
<p><strong>再看用户自定义函数</strong><br>用户自定义函数都是由Function()构造器构造的,其<strong>proto__属性都指向Function.prototype<br>[javascript]<br>function f(){this.test=””;}<br>console.log(f.__proto</strong>); //function()<br>console.log(Function.prototype); //function()<br>console.log(f.<strong>proto</strong>=== Function.prototype); //true<br>[/javascript]</p>
<p><strong>最后看内置对象</strong><br>内置函数对象其<strong>proto__属性都指向Function.prototype,因为这些对象都是函数原型派生而来，具有函数的公共方法，比如call,apply,bind等。<br>[javascript]<br>console.log(Object.__proto</strong>); //function()<br>console.log(Function.<strong>proto</strong>); //function()<br>console.log(Arrar.<strong>proto</strong>);//function()<br>[/javascript]</p>
<p><strong>4、函数构造器与变量</strong><br>为什么构造器里用var声明的变量，派生对象无法访问，而用this限定的变量派生对象可以访问到呢？这是因为new操作符。</p>
<p>new主要做了三件事，这里大大简化了：<br>第一，创建一个空object,注意不是Object()<br>第二，将空对象的constructor属性初始化为基对象prototype对象的constructor属性的值，将空对象的__proto__属性初始化成基对象的prototype属性引用的原型对象<br>第三，将空对象绑定到构造器上来调用构造器，类似constructor.call(obj,parameters)，也就是构造器里的this即指向新创建的对象。</p>
<p>所以从第三步可以看出，使用this限定的构造器变量，在这一步执行时，实际上就为派生对象添加了对应的属性，所以派生对象可以访问到这个变量，因为这已经成了派生对象的内置属性。而用var修饰的局部变量则与派生对象毫无关系，构造器执行完毕后，这些局部变量就被销毁了。<br>所以说，<strong>实例对象从其构造器静态获取属性，而从其原型对象(__proto__引用的对象)动态获取属性</strong>。阮一峰在<a href="http://www.ruanyifeng.com/blog/2011/06/designing_ideas_of_inheritance_mechanism_in_javascript.html">Javascript继承机制的设计思想</a>说,”<strong>实例对象的属性和方法，分成两种，一种是本地的，另一种是引用的</strong>“,既是此意。</p>
<p><strong>5、Object.prototype</strong></p>
<p>Object.prototype的__proto__属性指向哪里？答：指向null。<br>这已经是javascript对象原型链的顶点了。</p>
<p><strong>6、函数构造器“关联”的原型对象有prototype吗？</strong><br>没有，但他们有__proto__属性指向其原型对象。因为他们都是普通的对象，Function有点儿例外，但Function的原型对象也只是个普通的函数，而不是函数对象。再次证明，只有函数构造器对象才有prototype属性。</p>
<p><strong>7、函数构造器从其prototype指向的原型对象继承属性吗？</strong><br>答案是：Nope。函数构造器prototype属性“关联”的原型对象是为从这个构造器派生的对象提供原型服务的，构造器自身从其__proto__也就是[[prototype]]属性指向的原型对象（亦即其自身的构造器）继承属性。</p>
<p><strong>8、Object()构造器与Function()构造器</strong><br>Object()是由Function()构造的(Object.<strong>proto</strong> = Function.prototype),而Function()是由其自身构造的(Function.<strong>proto</strong> = Function.prototype)。而Function.prototype是由Object()构造的(Function.prototype.<strong>proto</strong>=Object.prototype)。<br>有此可知，Object()是Function()的直接实例，而Function()是Object()的间接实例，所以Object()与Function()互为实例<br>[javascript]<br>console.log(Object instanceof Function); //true<br>console.log(Function instanceof Object); //true<br>console.log(Object.<strong>proto</strong> == Function.prototype); //true<br>console.log(Function.<strong>proto</strong>.<strong>proto</strong> == Object.prototype); //true<br>[/javascript]</p>
<p><strong>9、如果忘了new会怎样?</strong></p>
<p>如果忘了在构造器上使用new操作符,那么构造器会退化成一个普通的函数调用<br>[javascript]<br>function F(){this.test=””;}<br>var f = F();<br>console.log(typeof f); //undefined<br>console.log(f); //undefined<br>[/javascript]</p>
<p>没有new就不会生成一个新的对象，而且函数如果没有return语句，默认返回undefined。如果函数有显式的return语句，则f为return返回结果的引用。</p>
<p><strong>10、如果构造器返回一个对象</strong></p>
<p>构造器函数也是函数，它可以返回它想返回的任何类型，虽然通常情况下构造器函数没有return语句，不会显式的返回值，但却会隐式的返回undefined。构造器也可以有显式的return语句，返回简单数据类型或对象。比如：<br>[javascript]<br>return 0; //number<br>return “”; //string<br>return true; //boolean<br>return; //undefined<br>return {}; //object<br>return [1,2]; //object<br>return function(){}; //function<br>[/javascript]</p>
<p>new操作符的行为正与构造器的返回类型有关。上面有一点儿没有提到，new操作符创建了一个新对象，但具体返回什么还要看构造器函数的返回值类型。<br>如果构造器函数返回undefined,number,string,boolean等简单数据类型,那么new操作符会返回新构造的对象覆盖构造器函数的返回。但是如果构造器函数返回了object或function等对象类型，那么new操作符会抛弃新构造的对象而直接返回构造器函数的返回值。<br>简单来说，如果构造器返回的是对象new操作符就直接返回这个对象，否则new操作符返回新构造的对象，也就是new操作符总是返回一个对象而不会返回简单数据类型。</p>
<p>如果不在构造器函数上施加new运算符，则构造器函数就是一个普通的函数，直接返回其返回值，隐式的或显式的。</p>
<p>当函数构造器返回一个对象或函数(也是对象)时，用不用new运算符，结果都是一样的。</p>
<p>[javascript]<br> function Bar() {<br> return 0;<br> //return “”;<br> //return true;<br> //return;<br> //return [1,2];<br> //return {};<br> //return function(){};<br> }</p>
<p> Bar.prototype = {<br> foo: function() {}<br> };</p>
<p> var bar1 = new Bar();<br> var bar2 = Bar();</p>
<p> console.log(typeof bar1); //object</p>
<p> //返回的是Bar对象，所以其有foo属性，会从Bar.prototype继承属性<br> console.log(bar1.<strong>proto</strong>); //Object {foo: function}</p>
<p> console.log(typeof bar2); //number<br> console.log(bar2.<strong>proto</strong>); //Number {}<br>[/javascript]</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript this关键字</title>
    <url>/2013/06/10/javascript-this/</url>
    <content><![CDATA[<p>与传统的静态语言不同，javascript的函数和对象是完全动态绑定的，而且全局函数和成员函数的界限十分模糊，或者说二者没有区别，完全依赖于执行上下文(execution context)而定,因此this指针到底指向哪个对象呢？哦，对了，javascript没有指针，this是一个引用。</p>
<a id="more"></a>
<p>javascript是一种函数式编程语言，函数是第一类的对象。函数本身为一种特殊对象，属于顶层对象，不依赖于任何其他的对象而存在，因此可以将函数作为输入输出参数，可以存储在变量中，以及一切其他对象可以做的事情,因为函数自身就是对象。</p>
<p><strong>javascript中无论函数是如何定义的，无论通过函数声明还是函数表达式，无论是全局函数，内部函数，匿名函数还是从函数内部返回的函数，除了其作用域链不同之外，其他并无不同，他们在javascript中的地位是相同的。</strong></p>
<p>this的取值依赖于执行上下文，并且在严格模式(strict mode)和非严格模式下(non-strict mode)也有不同。</p>
<p><strong>全局上下文</strong></p>
<p>在任何函数之外，无论处于严格模式还是非严格模式，this都指向全局对象,浏览器环境下，这个全局对象就是window</p>
<p>[javascript]<br>console.log(this === window); // true<br>[/javascript]</p>
<p><strong>函数上下文</strong></p>
<p>函数内部的this指针依赖于函数是如何被调用的。</p>
<p>1、作为全局函数调用</p>
<p>[javascript]<br>function f1(){<br> return this;<br>}<br>console.log(f1() === window); //true<br>[/javascript]</p>
<p>这种情况下，this被初始化为全局window对象，但在严格模式下则有不同</p>
<p>[javascript]<br>function f1(){<br> “use strict”;<br> return this;<br>}<br>console.log(f1() === undefined); //true<br>[/javascript]</p>
<p>此时，this是未定义的。</p>
<p>2、作为对象的方法被调用</p>
<p>[javascript]<br>var o = {<br> prop: 37,<br> f: function() {<br> return this.prop;<br> }<br>};</p>
<p>console.log(o.f()); //37<br>[/javascript]</p>
<p>这种情况下，this绑定到对象o。无论对象的方法是如何定义的，是在对象内部定义的，还是在对象外部定义的，这条规则都是适用的。</p>
<p>[javascript]<br>var o = {prop: 37};</p>
<p>function independent() {<br> return this.prop;<br>}</p>
<p>o.f = independent;</p>
<p>console.log(o.f()); //37<br>[/javascript]</p>
<p>但是，如果将对象的方法赋予一个变量，然后使用这边变量调用对象的方法，就会不同了，比如这样：</p>
<p>[javascript]<br>var test = someObject.methodTest;<br>test();<br>[/javascript]<br>此时test像一个全局函数一样被调用，而不是作为对象的方法调用，因此this不再指向someObject，而指向全局对象window</p>
<p>3、作为层级对象的方法调用<br>作为多级对象的方法被调用时，this绑定为距离方法最近的对象，或者说最内层的对象。延续上面的例子。</p>
<p>[javascript]<br>o.b = {g: independent, prop: 42};<br>console.log(o.b.g()); //42<br>[/javascript]</p>
<p>这里this绑定的是o.b对象而不是o</p>
<p>4、对象原型链上的方法调用</p>
<p>对对象原型链上的方法而不是本地方法调用时，this指针像本地方法调用一样绑定到对象上。</p>
<p>5、作为构造函数调用</p>
<p>this绑定到新建立的对象上</p>
<p>[javascript]<br>function C(){<br> this.a = 37;<br>}</p>
<p>var o = new C();<br>console.log(o.a); //37<br>[/javascript]</p>
<p>6、内部函数的this<br>先看代码</p>
<p>[javascript]<br>var o = { a:”1”,<br> F:function(){<br> console.log(this === o); //true<br> (function(){<br> console.log(this === window); //true<br> })();<br> }<br> };<br>o.F();<br>[/javascript]</p>
<p><strong>内部函数的this指向全局对象window</strong>,这多少有点儿令人意外，不是我们想要的结果。如果要在内部函数中存取外部函数的this,可以在外部函数声明一个变量that,内部函数使用这个that变量即可。that是一个随便起的变量名字，不过是个惯用法而已。</p>
<p>[javascript]<br>var o ={a:”1”,F:function(){<br> console.log(this === o); //true<br> var that = this;<br> (function(){<br> console.log(this === window); //true<br> console.log(that === o); //true<br> })();<br>}};<br>o.F();<br>[/javascript]</p>
<p><strong>函数作为DOM的事件处理器</strong></p>
<p>首先声明一个事件处理函数logThis()</p>
<p>[javascript]<br>function logThis() {<br> console.log(this);<br>}<br>[/javascript]</p>
<p>当以不同的方式注册到DOM元素作为其事件处理器时，this指向也有不同。</p>
<p>[javascript]<br>element.onclick = logThis; //使用脚本设置，this指向触发事件的DOM元素<br>element.addEventListener(‘click’,logThis,false);//使用脚本设置，this指向触发事件的DOM元素<br>element.onclick = function () {console.log(this);};//使用脚本设置，this指向触发事件的DOM元素<br><element onclick="console.log(this);">//内联事件处理器，this指向触发事件的DOM元素<br>[/javascript]</p>
<p>通过以上这几种方式设置事件处理器，事件处理程序内的this指向触发事件的DOM元素，但是下面的却不是这样</p>
<p>[javascript highlight=”1,2,4,5,7”]<br>element.onclick = function () {logThis()};//使用脚本设置，this指向全局对象window<br>element.onclick = function () {(function(){console.log(this)})();};//使用脚本设置，this指向全局对象window<br>element.attachEvent(‘onclick’,logThis);//使用脚本设置，this指向全局对象window<br><element onclick="logThis()"> //内联事件处理器，this指向全局对象window。<br> //可以通过传递this来弥补此问题，如onclick=”logThis(this)”,logThis函数内部就可以正确的<br> //访问到触发事件的dom元素了<br><element onclick="(function(){console.log(this);})();"> //内联事件处理器，this指向全局对象window<br>[/javascript]</p>
<p>这几种情况下，this皆指向全局对象window。<br>attachEvent是IE自己的事件注册方法，其他浏览器使用标准的addEventListener来注册事件，从IE9开始也支持addEventListener。<br>attachEvent一个最大的问题就是绑定到事件处理程序的this指向全局window对象。</p>
<p>使用<element onclick="logThis()">这种方法时，element元素的onclick方法属性只是简单的调用logThis函数，而不是把logThis函数赋予onclick属性,类似如下</p>
<p>[javascript]<br>function onclick(){<br> logThis();<br>}<br>[/javascript]</p>
<p>估计attachEvent也是这样实现的，logThis成了onclick的内部嵌套函数，导致this指向全局对象window，失误。<br>其实上面高亮的第1,2,4,5,7行的本质都是真正的事件处理函数成了onclick函数的内部嵌套函数，而不是将事件处理函数自身赋予元素的onclick属性，所以内部嵌套函数的this指向全局对象window也就一点儿也不奇怪了。内联事件处理程序是不推荐使用的，破坏了结构和行为的分离原则。</p>
<p><strong>call,apply和bind</strong></p>
<p>通过call和apply函数调用，可以为函数绑定一个指定的对象作为其this。call和apply都继承自Function.prototype原型，二者唯一的不同在于传递参数的方式，apply使用数组来包裹参数。<br>[javascript]<br>function add(c, d){<br> return this.a + this.b + c + d;<br>}</p>
<p>var o = {a:1, b:3};</p>
<p>//将o作为add函数的this<br>add.call(o, 5, 7); // 1 + 3 + 5 + 7 = 16</p>
<p>//将o作为add函数的this<br>add.apply(o, [10, 20]); // 1 + 3 + 10 + 20 = 34<br>[/javascript]</p>
<p>而Function.prototype.bind函数则生成一个新的函数，将一个对象永久的绑定到新函数的this,无论如何调用这个新函数，this都指向绑定的那个对象。</p>
<p>[javascript]<br>function f(){<br> return this.a;<br>}</p>
<p>var g = f.bind({a:”azerty”});<br>console.log(g()); // azerty</p>
<p>var o = {a:37, f:f, g:g};<br>console.log(o.f(), o.g()); // 37, azerty<br>[/javascript]</p>
<p>最后推荐一篇好文<a href="http://bonsaiden.github.io/JavaScript-Garden/zh/">JavaScript 秘密花园</a><br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>浏览器里的javascript运行环境</title>
    <url>/2013/05/22/javascripts-in-browser/</url>
    <content><![CDATA[<p>浏览器是javascript脚本语言最主要的宿主环境</p>
<a id="more"></a>
<p>javasctipt现在已经成为一种通用的脚本语言，除了最常见的在浏览器端运行，javascript还可以在服务器端运行，比如<a href="http://nodejs.org/">Node.js</a>,还有一些独立的第三方应用程序使用了javascript作为他们的脚本语言，比如Adode Acrobat,photoshop等。</p>
<p>browser为javascript的运行准备了一套对象体系，此对象体系的根就是window对象。window对象表达浏览器里的一个窗口或frame,在支持tab的浏览器里，每一个tab页都是一个window对象。window对象有两个引用自身的属性window和self,可以使用这两个属性引用这个全局window对象，当然默认情况下，所有的全局变量都在window对象的作用域范围内，都是window对象的属性。</p>
<p>浏览器为javascript准备了全局对象window，并将其作为全局的执行上下文，所有其他的对象，包括DOM对象，浏览器内置对象(BOM)以及javascript语言内置的对象，都在window对象的上下文内执行。如下图：<br><img src="/downloads/browser_object.png" alt="browser object hierachy"></p>
<p>window对象之下的所有其他对象大体分为三组</p>
<p><strong>DOM对象</strong><br>这就是我们最熟悉的DOM对象了，最主要的一个对象就是document,用来表达浏览器窗口里的一个文档</p>
<p><strong>BOM对象</strong><br>这是浏览器相关的对象，比如navigator,location,history,XMLHttpRequest对象，alert,prompt,confirm也属于此类。</p>
<p><strong>javascript对象</strong><br>这是<a href="https://developer.mozilla.org/en-US/docs/JavaScript/Reference/Global_Objects">javascript语言内置的全局对象</a>，比如Math,Date等，他们被置于window对象之下。</p>
<p>因此javascript脚本里所有函数和对象作用域之外的变量即所谓的全局变量被自动的置于window对象之下，成为window对象的属性。如果声明变量时不使用var修饰,则该变量自动成为一个全局变量。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>linux平台jboss as 7安装配置</title>
    <url>/2013/05/12/jboss-as-7-install-setup/</url>
    <content><![CDATA[<p>jboss是redhat开源java应用服务器、中间件服务器、ejb容器,内嵌tomcat提供jsp/servlet容器,最新版本为7</p>
<a id="more"></a>
<p>操作系统为debian wheezy</p>
<p><strong>安装openjdk</strong></p>
<h1 id="apt-get-install-openjdk-7-jdk"><a href="#apt-get-install-openjdk-7-jdk" class="headerlink" title="apt-get install openjdk-7-jdk"></a>apt-get install openjdk-7-jdk</h1><p>无须配置JAVA_HOME等环境变量,因为debian已经通过alternatives为java做好了配置</p>
<p><strong>安装jboss as 7</strong></p>
<h1 id="wget-http-download-jboss-org-jbossas-7-1-jboss-as-7-1-1-Final-jboss-as-7-1-1-Final-tar-gz"><a href="#wget-http-download-jboss-org-jbossas-7-1-jboss-as-7-1-1-Final-jboss-as-7-1-1-Final-tar-gz" class="headerlink" title="wget http://download.jboss.org/jbossas/7.1/jboss-as-7.1.1.Final/jboss-as-7.1.1.Final.tar.gz"></a>wget <a href="http://download.jboss.org/jbossas/7.1/jboss-as-7.1.1.Final/jboss-as-7.1.1.Final.tar.gz">http://download.jboss.org/jbossas/7.1/jboss-as-7.1.1.Final/jboss-as-7.1.1.Final.tar.gz</a></h1><h1 id="tar-jxvf-jboss-as-7-1-1-Final-tar-gz-C-opt"><a href="#tar-jxvf-jboss-as-7-1-1-Final-tar-gz-C-opt" class="headerlink" title="tar jxvf jboss-as-7.1.1.Final.tar.gz -C /opt/"></a>tar jxvf jboss-as-7.1.1.Final.tar.gz -C /opt/</h1><p>将jboss as 7解压缩到/opt目录即完成安装,无需设置JBOSS_HOME目录，jboss启动脚本会自动设置该环境变量。</p>
<p><strong>启动和停止jboss</strong><br>有两种启动模式,单独启动模式和域模式。变量JBOSS_HOME的值为JBOSS安装目录/opt/jboss</p>
<p>standalone启动<br>$ ${JBOSS_HOME}/bin/standalone.sh</p>
<p>关闭</p>
<p>如果是前台运行,直接CTRL+C即可，如果是后台运行，运行以下命令</p>
<p><code>js$ $&#123;JBOSS_HOME&#125;/bin/jboss-cli.sh --connect --command=:shutdown</code></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>jboss as 7配置绑定端口和地址</title>
    <url>/2013/05/12/jboss-binding-port-address/</url>
    <content><![CDATA[<p>jboss的http访问默认绑定到本地loopback接口的8080端口</p>
<a id="more"></a>
<p>jboss standalone配置文件为${JBOSS_HOME}/standalone/configuration/standalone.xml</p>
<p><strong>接口配置</strong></p>
<p>接口绑定语句<br>[xml highlight=”5,6”]<br> <interfaces><br> <interface name="management"><br> <inet-address value="${jboss.bind.address.management:127.0.0.1}"/><br> </interface><br> <interface name="public"><br> <inet-address value="${jboss.bind.address:127.0.0.1}"/><br> </interface><br> <interface name="unsecure"><br> <inet-address value="${jboss.bind.address.unsecure:127.0.0.1}"/><br> </interface><br> </interfaces><br>[/xml]</p>
<p>public访问接口绑定到了127.0.0.1，也就是localhost,从外部是无法访问到的。要从外部访问，必须绑定到其他非本地回环接口，或者直接绑定到本地所有接口，如<br>[xml]<br><interface name="public"><br> <any-address/><br></interface><br>[/xml]</p>
<p><strong>端口配置</strong></p>
<p>[xml highlight=”6”]<br> <socket-binding-group name="standard-sockets" default-interface="public" port-offset="${jboss.socket.binding.port-offset:0}"><br> <socket-binding name="management-native" interface="management" port="${jboss.management.native.port:9999}"/><br> <socket-binding name="management-http" interface="management" port="${jboss.management.http.port:9990}"/><br> <socket-binding name="management-https" interface="management" port="${jboss.management.https.port:9443}"/><br> <socket-binding name="ajp" port="8009"/><br> <socket-binding name="http" port="8080"/><br> <socket-binding name="https" port="8443"/><br> <socket-binding name="osgi-http" interface="management" port="8090"/><br> <socket-binding name="remoting" port="4447"/><br> <socket-binding name="txn-recovery-environment" port="4712"/><br> <socket-binding name="txn-status-manager" port="4713"/><br> <outbound-socket-binding name="mail-smtp"><br> <remote-destination host="localhost" port="25"/><br> </outbound-socket-binding><br> </socket-binding-group><br>[/xml]</p>
<p>可见默认访问端口为8080,访问应用时必须添加端口号。因为传统的web服务器比如apache,nginx,iis都默认绑定到80端口，一般联合使用来提供服务，apache等提供静态资源访问，而jboss等提供动态内容。如果只使用jboss,那么可以将默认绑定端口更改为80，有两种方式。</p>
<p>1、直接更改端口为80</p>
<p>linux系统下，只有特权用户root才能绑定1024以下的端口，所以如果更改为80端口，则必须以root用户来启动jboss,存在安全隐患，不推荐。apache是先通过特权用户绑定80端口，然后降低到普通用户的权限来提供服务。</p>
<p>2、端口重定向</p>
<p>创建iptables规则，将对端口80的访问重定向到8080端口</p>
<p><code>js# iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080</code></p>
<p>针对本地loopback接口的规则<br><code>js# iptables -t nat -A OUTPUT -d localhost -p tcp --dport 80 -j REDIRECT --to-ports 8080</code></p>
<p>然后就可以通过80端口来访问jboss应用了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>jConsole远程监控tomcat8</title>
    <url>/2015/06/13/jconsole-remote-monitor-tomcat8/</url>
    <content><![CDATA[<p>jConsole是JDK自带的性能监控工具。</p>
<a id="more"></a>
<p>使用jConsole监控远程tomcat8时，需要为远程tomcat8打开jmx远程管理功能。<br>在/etc/default/tomcat8文件中添加如下选项:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">&quot;$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=8090 -Dcom.sun.management.jmxremote.ssl=false&quot;</span></span><br><span class="line">JAVA_OPTS=<span class="string">&quot;$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.authenticate=false&quot;</span></span><br></pre></td></tr></table></figure>

<p>打开jmxremote,设置其访问端口为8090,不使用ssl安全连接，不启用认证。</p>
<p>这样，直接在jConsole的Remote Access中填入：ip:8090,无需输入用户名和密码直接连接即可。</p>
<p><strong>用户认证</strong><br>如需开启用户认证，从jdk目录拷贝两个文件到tomcat8配置目录</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ cd /etc/tomcat8</span><br><span class="line"># cp $&#123;JAVA_HOME&#125;/jre/lib/management/jmxremote.access .</span><br><span class="line"># cp $&#123;JAVA_HOME&#125;/jre/lib/management/jmxremote.password.template jmxremote.password</span><br></pre></td></tr></table></figure>
<p>编辑jmxremote.password文件，去掉monitorRole行前的#号, 开启monitorRole用户，并为其设置新的密码，这是个只读的用户。<br>安全起见不要启用controlRole用户。</p>
<p>设置jmxremote.password的属主和存取权限：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># chown tomcat8:tomcat8 jmxremote.password</span><br><span class="line"># chmod 600 jmxremote.password</span><br></pre></td></tr></table></figure>

<p>最后在/etc/default/tomcat8中添加如下选项:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">&quot;$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.authenticate=true&quot;</span></span><br><span class="line">JAVA_OPTS=<span class="string">&quot;$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.access.file=$&#123;CATALINA_BASE&#125;/conf/jmxremote.access&quot;</span></span><br><span class="line">JAVA_OPTS=<span class="string">&quot;$&#123;JAVA_OPTS&#125; -Dcom.sun.management.jmxremote.password.file=$&#123;CATALINA_BASE&#125;/conf/jmxremote.password&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>jmxremote.authenticate由false更改为true,或者删除掉此语句，因为默认是要用户认证的。</li>
</ul>
<p>重新启动tomcat8后，jconsole连接时提供对应的用户名和密码即可。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>内存溢出导致jenkins自动部署到tomcat失败</title>
    <url>/2014/11/05/jenkens-deploy-to-tomcat-error-of-outofmemoryerror/</url>
    <content><![CDATA[<a id="more"></a>
<p>jenkins自动部署war到tomcat 7应用服务器时很不稳定,经常出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR: Publisher hudson.plugins.deploy.DeployPublisher aborted due to exception</span><br><span class="line">org.codehaus.cargo.container.ContainerException: Failed to deploy \[<span class="regexp">/var/</span>lib/jenkins/jobs/devel_auto_build_deploy/workspace/build/libs/reis.war\]</span><br><span class="line">...</span><br><span class="line">Caused by: org.codehaus.cargo.container.tomcat.internal.TomcatManagerException: FAIL - Encountered exception javax.management.RuntimeErrorException: <span class="built_in">Error</span> invoking method check</span><br><span class="line">...</span><br><span class="line">org.codehaus.cargo.container.tomcat.internal.TomcatManagerException: FAIL - Encountered exception javax.management.RuntimeErrorException: <span class="built_in">Error</span> invoking method check</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>tomcat日志可以看到如下异常:<br>堆空间内存不足</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">java.lang.OutOfMemoryError: Java heap space</span><br></pre></td></tr></table></figure>

<p>永久代内存不足</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SEVERE: Exception invoking method check</span><br><span class="line">java.lang.OutOfMemoryError: PermGen space</span><br><span class="line">...</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;http-bio-8080-exec-38&quot;</span> java.lang.OutOfMemoryError: PermGen space</span><br><span class="line">OpenJDK <span class="number">64</span>-Bit Server VM warning: Exception java.lang.OutOfMemoryError occurred dispatching signal SIGTERM to handler- the VM may need to be forcibly terminated</span><br></pre></td></tr></table></figure>

<p>出现此问题的原因是tomcat默认配置的堆和非堆内存都太小了，需要调整如下JVM内存配置参数:</p>
<ul>
<li>  -Xms<br>初始堆内存大小</li>
<li>  -Xmx<br>最大堆内存大,一般设置-Xms与-Xmx一样大小,根据应用类型和物理内存大小来决定二者的大小</li>
<li>  -Xmn或者-XX:NewSize<br>堆内存中年轻代的大小</li>
<li>  -XX:PermSize<br>永久代内存的初始大小</li>
<li>  -XX:MaxPermSize<br>永久代内存的最大值</li>
</ul>
<p>一般设置这几个参数也就够了,debian系统上tomcat 7 设置JVM的内存参数要在配置文件/etc/default/tomcat7中的JAVA_OPTS参数中设置。</p>
<p>一个web app,服务器物理内存16G,其设置如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">&quot;-Djava.awt.headless=true -Xmx5120m -Xms5120m -Xmn1024m -XX:PermSize=1024m -XX:MaxPermSize=1024m -XX:+UseConcMarkSweepGC&quot;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://www.cnblogs.com/redcreen/archive/2011/05/04/2036387.html">JVM系列一：JVM内存组成及分配</a><br>[2]<a href="http://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html">JVM系列三:JVM参数设置、分析</a><br>[3]<a href="https://plumbr.eu/outofmemoryerror/permgen-space">java.lang.OutOfMemoryError: Permgen space</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins自动部署war到tomcat根context</title>
    <url>/2015/06/05/jenkins-deploy-to-root/</url>
    <content><![CDATA[<a id="more"></a>
<p>自动部署war包到ROOT路径，也就是网站的根目录时，deploy插件的”Context path”要填写：”/“,而不是”ROOT”或者”/ROOT”,不然自动部署会失败，有类似以下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Build step <span class="string">&#x27;Invoke Gradle script&#x27;</span> changed build result to SUCCESS</span><br><span class="line">Deploying /<span class="keyword">var</span>/lib/jenkins/jobs/devel_auto_build_deploy/workspace/build/libs/reis.war to container Tomcat <span class="number">7.</span>x Remote</span><br><span class="line"> \[<span class="regexp">/var/</span>lib/jenkins/jobs/devel_auto_build_deploy/workspace/build/libs/reis.war\] is not deployed. Doing a fresh deployment.</span><br><span class="line"> Deploying \[<span class="regexp">/var/</span>lib/jenkins/jobs/devel_auto_build_deploy/workspace/build/libs/reis.war\]</span><br><span class="line">ERROR: Build step failed <span class="keyword">with</span> exception</span><br><span class="line">org.codehaus.cargo.container.ContainerException: Failed to deploy \[<span class="regexp">/var/</span>lib/jenkins/jobs/devel_auto_build_deploy/workspace/build/libs/reis.war\]</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.deploy(AbstractTomcatManagerDeployer.java:<span class="number">111</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.redeploy(AbstractTomcatManagerDeployer.java:<span class="number">185</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.deploy(CargoContainerAdapter.java:<span class="number">73</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">116</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">991</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">969</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.redeploy(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.plugins.deploy.DeployPublisher.perform(DeployPublisher.java:<span class="number">61</span>)</span><br><span class="line">at hudson.tasks.BuildStepMonitor$3.perform(BuildStepMonitor.java:<span class="number">45</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:<span class="number">779</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:<span class="number">726</span>)</span><br><span class="line">at hudson.model.Build$BuildExecution.post2(Build.java:<span class="number">185</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:<span class="number">671</span>)</span><br><span class="line">at hudson.model.Run.execute(Run.java:<span class="number">1769</span>)</span><br><span class="line">at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:<span class="number">43</span>)</span><br><span class="line">at hudson.model.ResourceController.execute(ResourceController.java:<span class="number">98</span>)</span><br><span class="line">at hudson.model.Executor.run(Executor.java:<span class="number">374</span>)</span><br><span class="line">Caused by: java.io.IOException: <span class="built_in">Error</span> writing request body to server</span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.checkError(HttpURLConnection.java:<span class="number">3478</span>)</span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.write(HttpURLConnection.java:<span class="number">3461</span>)</span><br><span class="line">at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:<span class="number">82</span>)</span><br><span class="line">at java.io.BufferedOutputStream.write(BufferedOutputStream.java:<span class="number">126</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.pipe(TomcatManager.java:<span class="number">647</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.invoke(TomcatManager.java:<span class="number">538</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.deployImpl(TomcatManager.java:<span class="number">611</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.deploy(TomcatManager.java:<span class="number">291</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.deploy(AbstractTomcatManagerDeployer.java:<span class="number">102</span>)</span><br><span class="line">... <span class="number">17</span> more</span><br><span class="line">java.io.IOException: <span class="built_in">Error</span> writing request body to server</span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.checkError(HttpURLConnection.java:<span class="number">3478</span>)</span><br><span class="line">at sun.net.www.protocol.http.HttpURLConnection$StreamingOutputStream.write(HttpURLConnection.java:<span class="number">3461</span>)</span><br><span class="line">at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:<span class="number">82</span>)</span><br><span class="line">at java.io.BufferedOutputStream.write(BufferedOutputStream.java:<span class="number">126</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.pipe(TomcatManager.java:<span class="number">647</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.invoke(TomcatManager.java:<span class="number">538</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.deployImpl(TomcatManager.java:<span class="number">611</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.TomcatManager.deploy(TomcatManager.java:<span class="number">291</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.deploy(AbstractTomcatManagerDeployer.java:<span class="number">102</span>)</span><br><span class="line">at org.codehaus.cargo.container.tomcat.internal.AbstractTomcatManagerDeployer.redeploy(AbstractTomcatManagerDeployer.java:<span class="number">185</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.deploy(CargoContainerAdapter.java:<span class="number">73</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">116</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter$1.invoke(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">991</span>)</span><br><span class="line">at hudson.FilePath.act(FilePath.java:<span class="number">969</span>)</span><br><span class="line">at hudson.plugins.deploy.CargoContainerAdapter.redeploy(CargoContainerAdapter.java:<span class="number">103</span>)</span><br><span class="line">at hudson.plugins.deploy.DeployPublisher.perform(DeployPublisher.java:<span class="number">61</span>)</span><br><span class="line">at hudson.tasks.BuildStepMonitor$3.perform(BuildStepMonitor.java:<span class="number">45</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.perform(AbstractBuild.java:<span class="number">779</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.performAllBuildSteps(AbstractBuild.java:<span class="number">726</span>)</span><br><span class="line">at hudson.model.Build$BuildExecution.post2(Build.java:<span class="number">185</span>)</span><br><span class="line">at hudson.model.AbstractBuild$AbstractBuildExecution.post(AbstractBuild.java:<span class="number">671</span>)</span><br><span class="line">at hudson.model.Run.execute(Run.java:<span class="number">1769</span>)</span><br><span class="line">at hudson.model.FreeStyleBuild.run(FreeStyleBuild.java:<span class="number">43</span>)</span><br><span class="line">at hudson.model.ResourceController.execute(ResourceController.java:<span class="number">98</span>)</span><br><span class="line">at hudson.model.Executor.run(Executor.java:<span class="number">374</span>)</span><br><span class="line">Build step <span class="string">&#x27;Deploy war/ear to a container&#x27;</span> marked build <span class="keyword">as</span> failure</span><br><span class="line">Finished: FAILURE</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>jenkins集成gitolite提交自动构建发布</title>
    <url>/2014/07/18/jenkins-gitolite-push-auto-build/</url>
    <content><![CDATA[<a id="more"></a>
<p>jenkins可以集成gitolite,这样代码推到仓库后,jenkins可以立即构建工程，并可以自动发布。</p>
<p><strong>1、配置gitolite用户</strong></p>
<p>jenkins要执行构建任务,必须可以从gitolite仓库获取代码，因此需要为jenkins配置访问gitolite的用户。可以参考”<a href="https://openwares.net/linux/gitolite_v3_install_setup.html">gitolite v3安装配置</a>“。只要记住jenkins的用户主目录在/var/lib/jenkins就可以了，与普通用户的配置并无二致。同样可以在用户主目录下的.ssh目录下添加config来访问gitolite,注意known_hosts中要添加gitolite主机的fingerprint。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Host gitsvr</span><br><span class="line"> Hostname *.*.*.*</span><br><span class="line"> User git </span><br><span class="line"> Port <span class="number">2022</span></span><br><span class="line"> IdentityFile /<span class="keyword">var</span>/lib/jenkins/.ssh/id_rsa</span><br></pre></td></tr></table></figure>
<p>这里配置的gitolie访问别名为gitsvr,然后jenkins使用如gitsvr:project就可以访问到gitolite管理的仓库project了。</p>
<p><strong>2、配置gitolite hook</strong> </p>
<p>jenkins的git插件目前只支持定时poll，虽然设置一个较短时间的轮询间隔也能满足要求，但总觉不太爽利。幸好git和<br>gitolite都支持hook，而且jenkins的git插件提供了一个url接收通知来进行构建。所以使用gitolite的post-receive<br>钩子通知jenkins构建就可以了。</p>
<p>gitolite用户的~/.gitolite/hooks/common/post-receive添加如下脚本:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">JENKINS_URL=http:<span class="comment">//*.*.*.*:8082</span></span><br><span class="line">GIT_URL=gitsvr</span><br><span class="line">echo -n <span class="string">&quot;Notifying Jenkins...&quot;</span></span><br><span class="line">wget -q $JENKINS_URL/git/notifyCommit\\?url=$GIT_URL:$GL_REPO -O /dev/<span class="literal">null</span></span><br><span class="line">echo <span class="string">&quot;done.&quot;</span></span><br></pre></td></tr></table></figure>

<p>gitolite自动设置了一个环境变量GL_REPO,这个变量的值是当前操作的仓库的名字。为post-receive脚本添加执行权限，然后执行gitolite setup就可以了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ chmod +x post-receive</span><br><span class="line">$ gitolite setup</span><br></pre></td></tr></table></figure>

<p><strong>3、配置jenkins job</strong></p>
<p>现在就可以添加jenkins job了</p>
<p>几个关键的地方:</p>
<p>源代码管理选择git后,设置Repository URL为配置好的别名加仓库名就可以，比如gitsvr:project</p>
<p>构建触发器(build trigger)要选择poll SCM，但不要输入任何值，保持空白即可。</p>
<p>这里采用gradle进行构建，选择Invoke Gradle,如果构建文件名字采用默认的build.gradle，则除了tasks那里填写build,其他字段空着使用默认值即可。</p>
<p>构建后在自动发布到tomcat7,因此这里选择”Deploy war/ear to a container”,然后选择tomcat7。WAR/EAR files填写相对于当前job的workspace目录的需要部署的文件的名字，比如build/libs/project.war。Context path输入自己想使用的访问路径，比如输入foo,则需要这样访问应用程序<a href="http://domain.tld/foo%E3%80%82%E5%85%B6%E4%BB%96%E5%AD%97%E6%AE%B5%E4%B8%BAtomcat7%E7%9A%84%E7%AE%A1%E7%90%86%E7%94%A8%E6%88%B7%E8%B4%A6%E5%8F%B7%E5%92%8C%E8%AE%BF%E9%97%AEtomcat7%E7%9A%84URL%E3%80%82">http://domain.tld/foo。其他字段为tomcat7的管理用户账号和访问tomcat7的URL。</a></p>
<p>如果想将应用程序部署到root context,只需在Context path里输入”/“即可,这样访问应用程序时就更简单了，<a href="http://domain.tld/%E5%B0%B1%E6%98%AF%E8%AE%BF%E9%97%AE%E7%9A%84root">http://domain.tld/就是访问的root</a> context。</p>
<p>这样jenkins就算配置完了，可以通过手动构建进行测试。</p>
<p><strong>4、其他问题</strong></p>
<ul>
<li><p>由于项目使用了myBatis,因此有一些xml资源文件分散在dao接口目录中,所以需要在build.gradle脚本中添加资源目录，否则这些xml文件不会被打包，从而出现错误:</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sourceSets &#123;</span><br><span class="line"> main &#123;</span><br><span class="line"> resources.srcDirs = \[<span class="string">&#x27;src/main/java&#x27;</span>\]</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  如果不指定资源目录，则需要将资源放入src/main/resources目录。</p>
</li>
<li><p>gradle war插件默认生成的war包名字格式为:<br>  ${baseName}-${appendix}-${version}-${classifier}.${extension}<br>  也就是war.archiveName变量的默认值。</p>
<p>  gradle自动构建时生成的war包名字可能不是你想要的，因此可以明确的指定war包名字，比如在build.gradle文件中添加如下行：<br>  war.archiveName = ‘project.war’</p>
</li>
<li><p>用于tomcat7自动部署的管理用户必须具有manager-script角色,manager-gui角色是不够的，不然会有错误出现：<br>  The username you provided is not allowed to use the text-based Tomcat Manager (error 403)</p>
<p>  在/etc/tomcat7/tomcat-users.xml文件中为管理用户添加manager-script角色即可。</p>
</li>
</ul>
<p>References:<br>[1]<a href="http://meschbach.com/kb/gitolite-jenkins-hook.html">Gitolite to Jenkins Post Commit Kick</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins安装配置</title>
    <url>/2014/01/21/jenkins-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>安装</strong></p>
<p>编辑文件 /etc/apt/sources.list.d/jenkins.list,其内容如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb http:<span class="comment">//pkg.jenkins-ci.org/debian binary/</span></span><br></pre></td></tr></table></figure>
<p>然后执行以下命令:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget -q -O - http:<span class="comment">//pkg.jenkins-ci.org/debian/jenkins-ci.org.key sudo apt-key add -</span></span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install jenkins</span><br></pre></td></tr></table></figure>

<p><strong>配置</strong></p>
<p><em>端口</em></p>
<p>Jenkins默认监听8080端口,如果与其他应用程序端口冲突,修改/etc/default/jenkins文件:</p>
<p>HTTP_PORT=8082</p>
<p>然后</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># /etc/init.d/jenkins restart</span><br></pre></td></tr></table></figure>
<p>就可以了</p>
<p><em>访问控制</em></p>
<p>Jenkins默认安装是没有启用访问控制的,也就是可以随便匿名访问,要启用安全控制,访问Jenkins web界面,从”系统管理-&gt;安全设置”中配置即可。</p>
<p><em>邮件通知</em></p>
<p>打开Manage Jenkins -&gt; Configure System:</p>
<p>Jenkins Location -&gt; System Admin e-mail address 设置管理员邮箱地址<br>E-mail Notification -&gt; SMTP server 输入stmp服务器地址<br>Default user e-mail suffix 用户邮箱后缀,比如@openwares.net<br>Advanced -&gt; Use SMTP Authentication 输入smtp认证需要的User Name和password<br>Use SSL 如果服务器使用SSL则勾选,如果使用TLS/STARTTLS则不要勾选<br>SMTP Port 指定端口,默认25</p>
<p>如果smtp服务器使用TLS,则需要在jenkins配置文件/etc/default/jenkins中添加JAVA选项:<br>JAVA_ARGS=”-Dmail.smtp.starttls.enable=true” # enable STARTTLS<br>否则测试邮件发送会有异常:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Failed to send out e-mail</span><br><span class="line"></span><br><span class="line">javax.mail.MessagingException: Could not connect to SMTP host: mail.openwares.net, <span class="attr">port</span>: <span class="number">25</span>; </span><br><span class="line"> nested exception is: </span><br><span class="line"> javax.net.ssl.SSLException: Unrecognized SSL message, plaintext connection?</span><br><span class="line"> at com.sun.mail.smtp.SMTPTransport.openServer(SMTPTransport.java:<span class="number">1934</span>)</span><br><span class="line"> at com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:<span class="number">638</span>)</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>
<p>然后重新启动jenkins。</p>
<p>但是如果启用STARTSSL时服务器的SSL证书是自签的,又会抛出异常:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Failed to send out e-mail</span><br><span class="line"></span><br><span class="line">javax.mail.MessagingException: Could not convert socket to TLS;</span><br><span class="line"> nested exception is:</span><br><span class="line">javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target</span><br><span class="line">at com.sun.mail.smtp.SMTPTransport.startTLS(SMTPTransport.java:<span class="number">1880</span>)</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>
<p>因为证书是不受信任的:-(。</p>
<p>那么还需要在jenkins配置文件/etc/default/jenkins中添加一个JAVA选项:<br>JAVA_ARGS=”-Dcom.sun.net.ssl.checkRevocation=false” #disable cert verify</p>
<p>这样就可以正常发送邮件了。</p>
<p>References:<br>[1]<a href="http://pkg.jenkins-ci.org/debian/">Jenkins Debian packages</a><br>[2]<a href="https://wiki.jenkins-ci.org/display/JENKINS/Installing+Jenkins+on+Ubuntu">Installing Jenkins on Ubuntu</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>$().prop和$().attr</title>
    <url>/2015/05/15/jq-prop-attr/</url>
    <content><![CDATA[<a id="more"></a>
<p>JQuery早期版本只有.attr方法而没有提供.prop方法,导致一些混乱。1.9之后的版本,设置元素的property要用$().prop(‘property’, val),设置元素的attribute要用$().attr(‘attribute’, val)。</p>
<p>设置表单元素的值,可以$().val(val),也可以使用$().prop(‘value’, val)。</p>
<p>checked/selected之流,虽然attribute和property都有，但二者的类型是不同的。对于property,他们的值是true或者false,是布尔类型,而对于attribute，他们的值是字符类型的，有值”checked”/“selected”表示元素是选中的，而没有值，表示元素没有被选中。property与attribute之间有一个同步的问题。</p>
<p>一般使用$().prop即可，除非真的要更改HTML元素的attribute。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>JQuery metadata插件</title>
    <url>/2014/02/26/jquery-metadata/</url>
    <content><![CDATA[<p>jquery.metadata.js已经合并到jquery核心</p>
<a id="more"></a>
<p><a href="https://github.com/jquery-orphans/jquery-metadata">jquery.metadata.js</a>用于从元素的class,任意的属性或者子元素中提取元数据(metadata),支持以下三种形式的元数据:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;li <span class="class"><span class="keyword">class</span></span>=<span class="string">&quot;someclass &#123;some: &#x27;data&#x27;&#125; anotherclass&quot;</span>&gt;...&lt;/li&gt;</span><br><span class="line"></span><br><span class="line">&lt;li data=<span class="string">&quot;&#123;some:&#x27;random&#x27;, json: &#x27;data&#x27;&#125;&quot;</span>&gt;...&lt;/li&gt;</span><br><span class="line"></span><br><span class="line">&lt;li&gt;<span class="xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;data&quot;</span>&gt;</span><span class="javascript">&#123;<span class="attr">some</span>:<span class="string">&quot;json&quot;</span>,<span class="attr">data</span>:<span class="literal">true</span>&#125;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span> ...&lt;/li&gt;</span><br></pre></td></tr></table></figure>

<p>大括号{}对内的数据即为元数据,可以使用元数据在元素中存储额外的信息。</p>
<p>现在只要使用.data函数存取元数据就可以了,而且.data函数支持<a href="https://openwares.net/js/html_author_defined_tag_and_attributes.html">HTML5 data-*自定义属性</a>。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>jQuery插件jReject</title>
    <url>/2013/06/11/jquery-plugin-jreject/</url>
    <content><![CDATA[<p><a href="http://jreject.turnwheel.com/">jReject</a>提供一种优雅通用的方式来拒绝特定的浏览器版本，有丰富的自定义选项</p>
<a id="more"></a>
<p>界面也十分美观，可以用它来拒绝那些不想兼容的浏览器平台，比如IE6-8等，以后会用得到。<br>其用法极其简单，主页上写的很明白。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>jQuery使用POST方法以JSON字符串方式发送普通对象</title>
    <url>/2014/06/17/jquery-post-send-object-to-json/</url>
    <content><![CDATA[<a id="more"></a>
<p>调用$.ajax函数时，即使设置contentType为’application/json; charset=utf-8’,如果给data属性传递的是一个的对象，这时候jQuery也不会将其自动转换为JSON字符串。jQuery默认会将给data赋予的对象(除字符串之外的任何东西)处理为适用于”application/x-www-form-urlencoded”的请求字符串。</p>
<p>有一个选项processData来控制默认的自动转换，设置其为false,jQuery就不会自动转换对象。</p>
<p>所以如果要向服务器传送JSON字符串就只能自力更生了。如果自己能完全控制.ajax请求就简单了，只要使用JSON.stringify将对象转换为JSON字符串再传递给data就好了。</p>
<p>如果使用第三方库又不想直接修改源代码，可以通过$.ajaxSetup来动态修改传递的数据，看代码：</p>
<p>[javascript]<br> $.ajaxSetup({<br> processData:false,<br> beforeSend: function(jqXHR, settings){<br> if((settings.contentType.indexOf(‘application/json’) != -1)<br> &amp;&amp; (typeof settings.data != ‘string’)){<br> settings.data = JSON.stringify(settings.data);<br> }<br> }<br> });<br>[/javascript]<br>不过这是修改jQuery ajax请求的全局配置一定要格外小心，比如processData设置为false后，其他ajax请求也不会自动转换请求数据了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>jQuery 1.x 升级</title>
    <url>/2014/05/20/jquery-upgrade/</url>
    <content><![CDATA[<a id="more"></a>
<p>jQuery 1.9 删除了一些过时的API,修改了一些API的行为。比如jQuery.browser()已经移除了，推荐使用<a href="http://modernizr.com/">Modernizr</a>特性检测库，而不是检测特定的浏览器。<br>从jQuery 2+起,不再支持IE6/7/8。</p>
<p>jQuery提供了迁移插件<a href="https://github.com/jquery/jquery-migrate/">jquery-migrate</a>来辅助用户平滑升级。<br>jquery-migrate插件恢复了被删除或变化的API,但会在console给出警告(注意:只有开发版才会给出警告)。<br>jquery-migrate插件可以用于jQuery 2.x版本，但这只是个过渡，现有产品应该尽快将源代码迁移到jQuery 2.x上来。</p>
<p>这样使用jquery-migrate插件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;script src=<span class="string">&quot;js/jquery-2.1.1.js&quot;</span>&gt;&lt;/script&gt;</span><br><span class="line">&lt;script src=<span class="string">&quot;js/jquery-migrate-1.2.1.js&quot;</span>&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure>

<p>抛弃低版本IE浏览器是大势所趋。IE浏览器从版本11开始才真正算是一个现代浏览器。</p>
<p>也可以使用<a href="http://www.quirksmode.org/css/condcom.html">条件注释</a>语句为低版本IE使用低版本的jQuery。</p>
<p>References:<br>[1]<a href="http://jquery.com/upgrade-guide/1.9/">jQuery Core 1.9 Upgrade Guide</a><br>[2]<a href="http://www.css88.com/archives/4564">jQuery 1.9升级指南</a><br>[3]<a href="http://www.fwolf.com/blog/post/35">jQuery 1.9 移除了 $.browser 的替代方法</a><br>[4]<a href="http://www.quirksmode.org/css/condcom.html">Conditional comments</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>条件跳转指令Jcc(Jump condition code)</title>
    <url>/2009/07/03/jump-condition-code/</url>
    <content><![CDATA[<p>关于条件跳转指令，特别是用于有符号数比较的Jcc指令，网上的文章多有讹误，这次彻底的厘清一下，以备忘。</p>
<p>在介绍条件跳转指令之前，介绍一下EFLAGS寄存器中的状态标志(Status Flag)是有必要的，Jcc中的cc(condition code)即表示需要测试的状态标志或状态标志组合。EFLAGS寄存器的低16位在8086时代叫做FLAGS寄存器，又称作程序状态字PSW(Program Status Word)。</p>
<a id="more"></a>
<p>这些状态标志指示了算术运算指令的运算结果，分别介绍如下：</p>
<ul>
<li>  CF(bit 0) 进位标志 - 当运算结果的最高有效位发生进位或借位的时候该标志位置位，否则复位。这个标志指示了无符号数运算的溢出条件。它同样用于多精度算术运算。</li>
<li>  PF(bit 2) 奇偶标志 - 运算结果的最低有效字节如果包含偶数个1，那么该标志置位，否则复位。请注意是最低有效字节而不是整个运算结果。</li>
<li>  AF(bit) 调整标志 - 如果运算结果的位3发生进位或借位，则该标志位置位，否则复位。这个标志位使用在BCD(binary-coded decimal)码的算术运算中。</li>
<li>  ZF(bit 6) 零标志 - 如果运算结果是零则置位，否则复位。</li>
<li>  SF(bit 7) 符号标志 - 与运算结果的最高有效位相同。</li>
<li>  OF(bit 11) 溢出标志 - 如果运算结果对于一个正数来说太大或者对于一个负数来说太小而不能用与目标操作数等位宽的数来表示的时候,也就是超出了n位(目的操作数的位数)有符号数表示的范围则置位，否则复位。这个标志指示了有符号数算术运算的溢出条件。</li>
</ul>
<p>这些状态标志允许仅使用一个算术运算操作为三种不同的数据类型产生结果，这三种数据类型为无符号整数，有符号整数和BCD编码的整数。如果将运算结果看做一个无符号数，那么CF标志指示运算超出范围，有进位或借位发生。如果将运算结果看做一个有符号数，那么OF标志指示有进位或借位发生。如果将运算结果看做一个BCD数，那么AF标志指示有进位或借位发生。也就是说，对于整数运算来说，CPU才不管操作数是什么类型的，操作数是什么类型由你说了算,只要测试不同的标志位就可以了。</p>
<p>下面三张表详细列出了各种Jcc指令</p>
<p>指令</p>
<p>描述</p>
<p>条件</p>
<p>JC rel8/16/32</p>
<p>如果进位标志置位则短/近/近跳转</p>
<p>CF=1</p>
<p>JNC rel8/16/32</p>
<p>如果进位标志复位则短/近/近跳转</p>
<p>CF=0</p>
<p>JP/JPE rel8/16/32</p>
<p>如果奇偶标志置位则短/近/近跳转</p>
<p>PF=1</p>
<p>JNP,JPO rel8/16/32</p>
<p>如果奇偶标志复位则短/近/近跳转</p>
<p>PF=0</p>
<p>JZ rel8/16/32</p>
<p>如果零标志置位则短/近/近跳转</p>
<p>ZF=1</p>
<p>JNZ rel8/16/32</p>
<p>如果零标志复位则短/近/近跳转</p>
<p>ZF=0</p>
<p>JS rel8/16/32</p>
<p>如果符号标志置位则短/近/近跳转</p>
<p>SF=1</p>
<p>JNS rel8/16/32</p>
<p>如果符号标志复位则短/近/近跳转</p>
<p>SF=0</p>
<p>JO rel8/16/32</p>
<p>如果零溢出志置位则短/近/近跳转</p>
<p>OF=1</p>
<p>JNO rel8/16/32</p>
<p>如果零溢出志复位则短/近/近跳转</p>
<p>OF=0</p>
<p>指令</p>
<p>描述</p>
<p>条件</p>
<p>JA/JNBE rel8/16/32</p>
<p>如果高于/不低于或等于则短/近/近跳转</p>
<p>CF=0 and ZF=0</p>
<p>JAE/JNB rel8/16/32</p>
<p>如果高于或等于/不低于则短/近/近跳转</p>
<p>CF=0</p>
<p>JB/JNAE rel8/16/32</p>
<p>如果低于/不高于或等于则短/近/近跳转</p>
<p>CF=1</p>
<p>JBE/JNA rel8/16/32</p>
<p>如果低于或等于/不高于则短/近/近跳转</p>
<p>CF=1 or ZF=1</p>
<p>JE rel8/16/32</p>
<p>如果等于则短/近/近跳转</p>
<p>ZF=1</p>
<p>JNE rel8/16/32</p>
<p>如果不等于则短/近/近跳转</p>
<p>ZF=0</p>
<p>指令</p>
<p>描述</p>
<p>条件</p>
<p>JG/JNLE rel8/16/32</p>
<p>如果大于/不小于或等于则短/近/近跳转</p>
<p>ZF=0 and SF=OF</p>
<p>JGE/JNL rel8/16/32</p>
<p>如果大于或等于/不小于则短/近/近跳转</p>
<p>SF=OF</p>
<p>JL/JNGE rel8/16/32</p>
<p>如果小于/不大于或等于则短/近/近跳转</p>
<p>SF!=OF</p>
<p>JLE/JNG rel8/16/32</p>
<p>如果小于或等于/不大于则短/近/近跳转</p>
<p>ZF=1 or SF!=OF</p>
<p>JE rel8/16/32</p>
<p>如果等于则短/近/近跳转</p>
<p>ZF=1</p>
<p>JNE rel8/16/32</p>
<p>如果不等于则短/近/近跳转</p>
<p>ZF=0</p>
<p>表注释:</p>
<ol>
<li> 64位模式下，不支持所有Jcc rel16格式的近跳转指令。</li>
<li> 对于有符号数的比较使用术语小于”less”和大于”greater”，而对于无符号数的比较使用术语低于”below”和高于”above”</li>
</ol>
<p>前两张表记载的指令比较直白、简单，不做过多介绍。下面重点介绍一下有符号数比较的Jcc指令。只要解释清楚了JG和JL，其他就很简单了。</p>
<p>n位二进制数来表示有符号数，可以表示的范围为<br>-2^(n-1) =&lt; X Y OF==SF </p>
<p>再考虑一个负数减一个正数的情况，这种情况下结果肯定是一个负数，如果结果超出了n位有符号数可以标示的范围，则溢出OF=1,而一个负数太小了，则发生了反绕，变成了正数，也就是SF=0<br>如果结果没有溢出，则OF=0,因为结果是一个负数，所以SF=1<br>那么<br>X&lt;Y OF!=SF</p>
<p>如果两个数同号，那么不会溢出OF=0，如果X&gt;Y则结果是正的SF=0,如果X&lt;Y则结果是负的,SF=1<br>那么<br>X&gt;Y OF==SF<br>X&lt;Y OF!=SF</p>
<p>所以两个有符号数XY相减X-Y，最后总结如下：<br>X&gt;Y也就是JG成立的条件为OF==SF<br>X&lt;Y也就是JL成立的条件为OF!=SF</p>
<p>其他指令不过是再加上对ZF的判断而已，比较简单。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>JTA开源实现atomikos日志和锁文件路径权限问题</title>
    <url>/2015/08/21/jta-atomikos-log-lock-file-path/</url>
    <content><![CDATA[<a id="more"></a>
<p>应用程序启动时有如下错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR \[localhost-startStop-<span class="number">1</span>\] - Context initialization failed</span><br><span class="line">org.springframework.beans.factory.BeanCreationException: <span class="built_in">Error</span> creating bean <span class="keyword">with</span> name <span class="string">&#x27;atomikosUserTransaction&#x27;</span> defined <span class="keyword">in</span> ServletContext resource \[<span class="regexp">/WEB-INF/</span>conf/spring-servlet.xml.bak\]: <span class="built_in">Error</span> setting property values; nested exception is org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (<span class="number">1</span>) are:</span><br><span class="line">PropertyAccessException <span class="number">1</span>: org.springframework.beans.MethodInvocationException: Property <span class="string">&#x27;transactionTimeout&#x27;</span> threw exception; nested exception is com.atomikos.icatch.SysException: <span class="built_in">Error</span> <span class="keyword">in</span> init(): <span class="regexp">/var/</span>lib/tomcat8/./tm.out.lck</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java: <span class="number">1506</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:<span class="number">1214</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:<span class="number">537</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:<span class="number">476</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:<span class="number">303</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:<span class="number">230</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:<span class="number">299</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:<span class="number">194</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:<span class="number">762</span>)</span><br><span class="line"> at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:<span class="number">757</span>)</span><br><span class="line"> at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:<span class="number">480</span>)</span><br><span class="line"> at org.springframework.web.servlet.FrameworkServlet.configureAndRefreshWebApplicationContext(FrameworkServlet.java:<span class="number">663</span>)</span><br><span class="line"> at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:<span class="number">629</span>)</span><br><span class="line"> at org.springframework.web.servlet.FrameworkServlet.createWebApplicationContext(FrameworkServlet.java:<span class="number">677</span>)</span><br><span class="line"> at org.springframework.web.servlet.FrameworkServlet.initWebApplicationContext(FrameworkServlet.java:<span class="number">548</span>)</span><br><span class="line"> at org.springframework.web.servlet.FrameworkServlet.initServletBean(FrameworkServlet.java:<span class="number">489</span>)</span><br><span class="line"> at org.springframework.web.servlet.HttpServletBean.init(HttpServletBean.java:<span class="number">136</span>)</span><br><span class="line"> at javax.servlet.GenericServlet.init(GenericServlet.java:<span class="number">158</span>)</span><br><span class="line"> at org.apache.catalina.core.StandardWrapper.initServlet(StandardWrapper.java:<span class="number">1241</span>)</span><br><span class="line"> at org.apache.catalina.core.StandardWrapper.loadServlet(StandardWrapper.java:<span class="number">1154</span>)</span><br><span class="line"> at org.apache.catalina.core.StandardWrapper.load(StandardWrapper.java:<span class="number">1041</span>)</span><br><span class="line"> at org.apache.catalina.core.StandardContext.loadOnStartup(StandardContext.java:<span class="number">4969</span>)</span><br><span class="line"> at org.apache.catalina.core.StandardContext.startInternal(StandardContext.java:<span class="number">5255</span>)</span><br><span class="line"> at org.apache.catalina.util.LifecycleBase.start(LifecycleBase.java:<span class="number">150</span>)</span><br><span class="line"> at org.apache.catalina.core.ContainerBase.addChildInternal(ContainerBase.java:<span class="number">724</span>)</span><br><span class="line"> at org.apache.catalina.core.ContainerBase.addChild(ContainerBase.java:<span class="number">700</span>)</span><br><span class="line"> at org.apache.catalina.core.StandardHost.addChild(StandardHost.java:<span class="number">714</span>)</span><br><span class="line"> at org.apache.catalina.startup.HostConfig.deployWAR(HostConfig.java:<span class="number">919</span>)</span><br><span class="line"> at org.apache.catalina.startup.HostConfig$DeployWar.run(HostConfig.java:<span class="number">1703</span>)</span><br><span class="line"> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">511</span>)</span><br><span class="line"> at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">266</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1142</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">617</span>)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line">Caused by: org.springframework.beans.PropertyBatchUpdateException; nested PropertyAccessExceptions (<span class="number">1</span>) are:</span><br><span class="line">PropertyAccessException <span class="number">1</span>: org.springframework.beans.MethodInvocationException: Property <span class="string">&#x27;transactionTimeout&#x27;</span> threw exception; nested exception is com.atomikos.icatch.SysException: <span class="built_in">Error</span> <span class="keyword">in</span> init(): <span class="regexp">/var/</span>lib/tomcat8/./tm.out.lck</span><br><span class="line"> at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:<span class="number">121</span>)</span><br><span class="line"> at org.springframework.beans.AbstractPropertyAccessor.setPropertyValues(AbstractPropertyAccessor.java:<span class="number">75</span>)</span><br><span class="line"> at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java: <span class="number">1502</span>)</span><br><span class="line"> ... <span class="number">33</span> more</span><br></pre></td></tr></table></figure>

<p>这是因为默认情况下,atomikos要在/var/lib/tomcat8目录下生成其日志和锁文件，而/var/lib/tomcat8文件夹的所有者和组都是root,无法写入，所以初始化失败。</p>
<p>解决方法有二，最简单粗暴的就是将/var/lib/tomcat8目录的所有者和组都更改为tomcat8.</p>
<p>另一个方法是classpath中添加atomikos配置文件，将其输出文件目录配置到tomcat8有权限写入的目录中，比如/var/log/tomcat8</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">com.atomikos.icatch.service=com.atomikos.icatch.standalone.UserTransactionServiceFactory</span><br><span class="line">com.atomikos.icatch.log_base_name = jdbc</span><br><span class="line">com.atomikos.icatch.log_base_dir = /var/log/tomcat8 # 日志文件输出目录</span><br><span class="line">com.atomikos.icatch.output_dir = /var/log/tomcat8 # 文件输出目录</span><br><span class="line">com.atomikos.icatch.tm_unique_name = com.atomikos.spring.jdbc.tm</span><br><span class="line">com.atomikos.icatch.serializable_logging=<span class="literal">false</span></span><br><span class="line">com.atomikos.icatch.max_timeout=<span class="number">2000000</span></span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>查看JVM相关信息的命令与工具</title>
    <url>/2014/11/05/jvm-commands-and-tools/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>jps</strong><br>JVM版的ps命令,主要参数有:</p>
<ul>
<li>-l<br>输出完整的包名或者应用程序jar文件的全路径名</li>
<li>-m<br>输出传给main方法的参数</li>
<li>-v<br>输出传给JVM的参数</li>
</ul>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo jps -lmv grep -v Jps</span><br><span class="line"><span class="number">738</span> org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=<span class="regexp">/var/</span>lib/tomcat8/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.awt.headless=<span class="literal">true</span> -Xmx128m -XX:+UseConcMarkSweepGC -Djava.endorsed.dirs=<span class="regexp">/usr/</span>share/tomcat8/endorsed -Dcatalina.base=<span class="regexp">/var/</span>lib/tomcat8 -Dcatalina.home=<span class="regexp">/usr/</span>share/tomcat8 -Djava.io.tmpdir=<span class="regexp">/tmp/</span>tomcat8-tomcat8-tmpJVM版的ps命令</span><br></pre></td></tr></table></figure>

<p>jps命令的输出格式为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">lvmid \[ \[ classname JARfilename <span class="string">&quot;Unknown&quot;</span>\] \[ arg* \] \[ jvmarg* \] \]</span><br></pre></td></tr></table></figure>

<p>第一个列的lvmid是本地JVM标识符,同时也就是JVM进程的进程号。</p>
<p>jps命令只会输出当前执行命令的用户有权限访问的JVM进程信息。所以就是root也不一定能读取JVM进程信息，比如访问tomcat8的JVM信息要这样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u tomcat8 jps -lvm</span><br><span class="line"><span class="number">25768</span> sun.tools.jps.Jps -lvm -Dapplication.home=<span class="regexp">/usr/</span>lib/jvm/jdk-<span class="number">8</span>-oracle-x64 -Xms8m</span><br><span class="line"><span class="number">25151</span> org.apache.catalina.startup.Bootstrap start -Djava.util.logging.config.file=<span class="regexp">/var/</span>lib/tomcat8/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djava.awt.headless=<span class="literal">true</span> -Xmx3072m -Xms3072m -Xmn2048m -XX:PermSize=2048m -XX:MaxPermSize=3072m -XX:+UseConcMarkSweepGC -Djava.endor</span><br></pre></td></tr></table></figure>

<p>用root用户也看不到详细信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo jps -lvm</span><br><span class="line"><span class="number">25809</span> sun.tools.jps.Jps -lvm -Dapplication.home=<span class="regexp">/usr/</span>lib/jvm/jdk-<span class="number">8</span>-oracle-x64 -Xms8m</span><br><span class="line"><span class="number">11806</span> -- process information unavailable</span><br><span class="line"><span class="number">9998</span> -- process information unavailable</span><br><span class="line"><span class="number">25151</span> -- process information unavailable</span><br></pre></td></tr></table></figure>

<p>因为临时文件/tmp/hsperfdata_{user}/目录下的文件只有{user}才有存取权限。</p>
<p><strong>jinfo</strong><br>查看JVM的所有配置信息和命令行标志,还可以动态设置JVM的命令行标志参数。详细用法见jinfo(1)。<br>如果出现：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">pid: well-known file is not secure </span><br></pre></td></tr></table></figure>
<p>说明当前用户没有相应的权限，情使用与JVM进程相同的用户或者root用户再次尝试命令</p>
<p>如果出现:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.io.IOException: Command failed <span class="keyword">in</span> target VM</span><br><span class="line"> at sun.tools.attach.LinuxVirtualMachine.execute(LinuxVirtualMachine.java:<span class="number">224</span>)</span><br><span class="line"> at sun.tools.attach.HotSpotVirtualMachine.executeCommand(HotSpotVirtualMachine.java:<span class="number">217</span>)</span><br><span class="line"> at sun.tools.attach.HotSpotVirtualMachine.setFlag(HotSpotVirtualMachine.java:<span class="number">190</span>)</span><br><span class="line"> at sun.tools.jinfo.JInfo.flag(JInfo.java:<span class="number">129</span>)</span><br><span class="line"> at sun.tools.jinfo.JInfo.main(JInfo.java:<span class="number">76</span>)</span><br></pre></td></tr></table></figure>
<p>说明不支持配置此参数。</p>
<p><strong>jstat</strong><br>JVM版的vmstat命令，JVM内存使用统计监控工具,可以监控各类内存使用量，也可以按时间间隔连续输出进行监控。详细用法参见jstat(1)和参考[1]</p>
<p>列如,查看VM内存中三代（young,old,perm）对象的使用和占用大小</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo jstat -gccapacity lvmid</span><br><span class="line">NGCMN NGCMX NGC S0C S1C EC OGCMN OGCMX OGC OC PGCMN PGCMX PGC PC YGC FGC </span><br><span class="line"> <span class="number">20672.0</span> <span class="number">43648.0</span> <span class="number">43648.0</span> <span class="number">4352.0</span> <span class="number">4352.0</span> <span class="number">34944.0</span> <span class="number">41408.0</span> <span class="number">87424.0</span> <span class="number">87424.0</span> <span class="number">87424.0</span> <span class="number">21248.0</span> <span class="number">169984.0</span> <span class="number">90476.0</span> <span class="number">90476.0</span> <span class="number">271</span> <span class="number">24</span></span><br></pre></td></tr></table></figure>

<p><strong>jmap</strong><br>查看JVM中所有对象使用内存资源的详细情况,详细用法见jmap(1)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">jmap \[ option \] lvmid</span><br></pre></td></tr></table></figure>

<p>查看JVM堆使用情况</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u tomcat8 jmap -heap <span class="number">4891</span></span><br><span class="line">Attaching to process ID <span class="number">4891</span>, please wait...</span><br><span class="line">Debugger attached successfully.</span><br><span class="line">Server compiler detected.</span><br><span class="line">JVM version is <span class="number">24.65</span>-b04</span><br><span class="line"></span><br><span class="line">using parallel threads <span class="keyword">in</span> the <span class="keyword">new</span> generation.</span><br><span class="line">using thread-local object allocation.</span><br><span class="line">Concurrent Mark-Sweep GC</span><br><span class="line"></span><br><span class="line">Heap Configuration:</span><br><span class="line"> MinHeapFreeRatio = <span class="number">40</span></span><br><span class="line"> MaxHeapFreeRatio = <span class="number">70</span></span><br><span class="line"> MaxHeapSize = <span class="number">134217728</span> (<span class="number">128.</span>0MB)</span><br><span class="line"> NewSize = <span class="number">1310720</span> (<span class="number">1.</span>25MB)</span><br><span class="line"> MaxNewSize = <span class="number">44695552</span> (<span class="number">42.</span>625MB)</span><br><span class="line"> OldSize = <span class="number">5439488</span> (<span class="number">5.</span>1875MB)</span><br><span class="line"> NewRatio = <span class="number">2</span></span><br><span class="line"> SurvivorRatio = <span class="number">8</span></span><br><span class="line"> PermSize = <span class="number">21757952</span> (<span class="number">20.</span>75MB)</span><br><span class="line"> MaxPermSize = <span class="number">174063616</span> (<span class="number">166.</span>0MB)</span><br><span class="line"> G1HeapRegionSize = <span class="number">0</span> (<span class="number">0.</span>0MB)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p><strong>jstack</strong><br>Java 栈追踪,用法详见jstack(1)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">jstack \[ option \] pid</span><br></pre></td></tr></table></figure>

<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u tomcat8 jstack <span class="number">4891</span></span><br><span class="line"><span class="number">2014</span>-<span class="number">11</span>-<span class="number">06</span> <span class="number">10</span>:<span class="number">30</span>:<span class="number">21</span></span><br><span class="line">Full thread dump OpenJDK <span class="number">64</span>-Bit Server VM (<span class="number">24.65</span>-b04 mixed mode):</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;Attach Listener&quot;</span> daemon prio=<span class="number">10</span> tid=<span class="number">0x00007f2174001000</span> nid=<span class="number">0x165f</span> waiting on condition \[<span class="number">0x0000000000000000</span>\]</span><br><span class="line"> java.lang.Thread.State: RUNNABLE</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;http-nio-80-exec-10&quot;</span> daemon prio=<span class="number">10</span> tid=<span class="number">0x00007f213800a800</span> nid=<span class="number">0x135a</span> waiting on condition \[<span class="number">0x00007f2161e16000</span>\]</span><br><span class="line"> java.lang.Thread.State: WAITING (parking)</span><br><span class="line"> at sun.misc.Unsafe.park(Native Method)</span><br><span class="line"> - parking to wait <span class="keyword">for</span> &lt;<span class="number">0x00000000f06fe518</span>&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)</span><br><span class="line"> at java.util.concurrent.locks.LockSupport.park(LockSupport.java:<span class="number">186</span>)</span><br><span class="line"> at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:<span class="number">2043</span>)</span><br><span class="line"> at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:<span class="number">442</span>)</span><br><span class="line"> at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:<span class="number">103</span>)</span><br><span class="line"> at org.apache.tomcat.util.threads.TaskQueue.take(TaskQueue.java:<span class="number">31</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:<span class="number">1068</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1130</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line"> at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:<span class="number">61</span>)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p><strong>jconsole</strong><br>jconsole是JMX兼容的java监视和管理控制台。可以查看JVM上运行程序的性能和资源占用情况。<br>当使用jconsole监视本地程序时，jconsole与本地程序必须使用相同的用户运行，或者使用root,比如要监视tomcat运行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u tomcat7 jconsole &lt;lvmid_for_tomcat&gt;</span><br></pre></td></tr></table></figure>
<p>如果出现如下错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">No protocol specified</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.lang.InternalError: Can<span class="string">&#x27;t connect to X11 window server using &#x27;</span>:<span class="number">0</span><span class="string">&#x27; as the value of the DISPLAY variable.</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment.initDisplay(Native Method)</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment.access$200(X11GraphicsEnvironment.java:65)</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment$1.run(X11GraphicsEnvironment.java:110)</span></span><br><span class="line"><span class="string"> at java.security.AccessController.doPrivileged(Native Method)</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment.&lt;clinit&gt;(X11GraphicsEnvironment.java:74)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName0(Native Method)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName(Class.java:191)</span></span><br><span class="line"><span class="string"> at java.awt.GraphicsEnvironment.createGE(GraphicsEnvironment.java:102)</span></span><br><span class="line"><span class="string"> at java.awt.GraphicsEnvironment.getLocalGraphicsEnvironment(GraphicsEnvironment.java:81)</span></span><br><span class="line"><span class="string"> at sun.awt.X11.XToolkit.&lt;clinit&gt;(XToolkit.java:120)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName0(Native Method)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName(Class.java:191)</span></span><br><span class="line"><span class="string"> at java.awt.Toolkit$2.run(Toolkit.java:869)</span></span><br><span class="line"><span class="string"> at java.security.AccessController.doPrivileged(Native Method)</span></span><br><span class="line"><span class="string"> at java.awt.Toolkit.getDefaultToolkit(Toolkit.java:861)</span></span><br><span class="line"><span class="string"> at javax.swing.UIManager.getSystemLookAndFeelClassName(UIManager.java:608)</span></span><br><span class="line"><span class="string"> at sun.tools.jconsole.JConsole.&lt;clinit&gt;(JConsole.java:60)</span></span><br></pre></td></tr></table></figure>
<p>这是因为用户tomcat7没有被授权访问本地显示服务器造成的，执行以下命令然后重新运行jconsole即可：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xhost +local:all</span><br><span class="line">non-network local connections being added to access control list</span><br></pre></td></tr></table></figure>

<p>如果出现以下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u tomcat8 jconsole &lt;lvmid_for_tomcat&gt;</span><br><span class="line">X11 connection rejected because <span class="keyword">of</span> wrong authentication.</span><br><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.awt.AWTError: Can<span class="string">&#x27;t connect to X11 window server using &#x27;</span>localhost:<span class="number">0.0</span><span class="string">&#x27; as the value of the DISPLAY variable.</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment.initDisplay(Native Method)</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment.access$200(X11GraphicsEnvironment.java:65)</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment$1.run(X11GraphicsEnvironment.java:115)</span></span><br><span class="line"><span class="string"> at java.security.AccessController.doPrivileged(Native Method)</span></span><br><span class="line"><span class="string"> at sun.awt.X11GraphicsEnvironment.&lt;clinit&gt;(X11GraphicsEnvironment.java:74)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName0(Native Method)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName(Class.java:264)</span></span><br><span class="line"><span class="string"> at java.awt.GraphicsEnvironment.createGE(GraphicsEnvironment.java:103)</span></span><br><span class="line"><span class="string"> at java.awt.GraphicsEnvironment.getLocalGraphicsEnvironment(GraphicsEnvironment.java:82)</span></span><br><span class="line"><span class="string"> at sun.awt.X11.XToolkit.&lt;clinit&gt;(XToolkit.java:126)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName0(Native Method)</span></span><br><span class="line"><span class="string"> at java.lang.Class.forName(Class.java:264)</span></span><br><span class="line"><span class="string"> at java.awt.Toolkit$2.run(Toolkit.java:860)</span></span><br><span class="line"><span class="string"> at java.awt.Toolkit$2.run(Toolkit.java:855)</span></span><br><span class="line"><span class="string"> at java.security.AccessController.doPrivileged(Native Method)</span></span><br><span class="line"><span class="string"> at java.awt.Toolkit.getDefaultToolkit(Toolkit.java:854)</span></span><br><span class="line"><span class="string"> at javax.swing.UIManager.getSystemLookAndFeelClassName(UIManager.java:611)</span></span><br><span class="line"><span class="string"> at sun.tools.jconsole.JConsole.&lt;clinit&gt;(JConsole.java:60)</span></span><br></pre></td></tr></table></figure>
<p>是因为xauth授权的问题，因为tomcat8用户的主目录在/usr/share/tomcat8，但其主目录下并没有xauth授权文件.Xauthority文件，可以从登录用户的主目录下拷贝.Xauthority到tomcat8主目录，记得修改文件的属主和组为tomcat8，然后在重新执行命令就可以了。<br><strong>注意：</strong>.Xauthority文件中的凭证会过期，每次登录其凭证都会更新。所以拷贝的办法只能临时用用，不能解决根本性的问题。</p>
<p><strong>VisualVM</strong></p>
<p><a href="https://visualvm.github.io/">VisualVM</a>是java的东家出品的、自由的性能分析和调优工具，基本上涵盖了以上几个命令行工具的功能。debian官方源里有对应的包VisualVM,也可以官网直接下载最新的zip包，解压缩后直接运行visualvm/bin/visualvm命令即可。这个工具更直观易用。</p>
<p>visualvm支持jmx和jstatd两种方式连接到远程jvm，jmx需要每jvm实例单独设置，而jstatd则可以连接系统范围内的所有jvm实例，无需单独设置。</p>
<p><strong>jstatd配置</strong><br>openjdk11内置jstatd，只要提供一个安全策略文件就可以直接运行，下面是一个可以运行的安全策略文件jstatd.all.policy</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">grant codebase <span class="string">&quot;jrt:/jdk.jstatd&quot;</span> &#123; </span><br><span class="line"> permission java.security.AllPermission; </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">grant codebase <span class="string">&quot;jrt:/jdk.internal.jvmstat&quot;</span> &#123; </span><br><span class="line"> permission java.security.AllPermission; </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>运行jstatd，如果需要连接到所有的jvm实例，则需要使用特权用户运行，如果只需要连接到特定用户的jvm实例，可以用对应的用户来运行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo jstatd -J-Djava.security.policy=jstatd.all.policy -J-Djava.rmi.server.hostname=&lt;ip_of_host&gt; -J-Djava.rmi.server.logCalls=<span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>默认监听在1099端口，默认创建的RMI名字为JStatRemoteHost，最后一个选项为启用调用日志，可以不要。<br>jstatd连接并不支持cpu监视，所以如果需要cpu监视的话可以使用jmx远程连接或者本地连接(可以通过ssh X11Forward在jvm所在机器本地运行VisualVM)。</p>
<p>References:<br>[1]<a href="http://blog.csdn.net/michaelfeng726/article/details/8597921">jstat用法详解</a><br>[2]<a href="https://manpages.debian.org/testing/openjdk-11-jdk-headless/jstatd.1.en.html">jstatd(1)</a><br>[3]<a href="https://stackoverflow.com/questions/51032095/starting-jstatd-in-java-9">Starting jstatd in Java 9+</a><br>[4]<a href="https://stackoverflow.com/questions/32515727/jvisualvm-connect-to-remote-jstatd-not-showing-applications">jvisualvm connect to remote jstatd not showing applications</a><br>[5]<a href="https://stackoverflow.com/questions/55142971/visualvm-shows-not-supported-for-this-jvm">VisualVM shows “Not supported for this JVM”</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>为联想K860i添加google服务套件gapps</title>
    <url>/2013/01/03/k860i-add-gapps/</url>
    <content><![CDATA[<p>国产android机器以及非国产android机的国行版都遵照上谕阉割了google服务套件。其实国产和国行机连android系统都不应该用,这种即当婊子又立牌坊的行为让人不齿。</p>
<a id="more"></a>
<p>如果android机没有google套件是难以想象的,特别是对于google的深度用户来说。</p>
<p>lenovo k860i刚上市不久,说好的4.1.2系统在2012年的最后一天发布了,OTA升级很顺利。升到4.1就可以放心的收拾机器了,4.0.4时没收拾,怕OTA时麻烦,要耍来刷去。</p>
<p><strong>获取根权限</strong></p>
<p>k860i使用了三爽的Exynos 4412 CPU,最近爆出了漏洞,XDA上的大牛开发了利用此漏洞root机器的程序,获取根权限只要安装一个apk,点击一下就可以了。</p>
<p>此程序叫<a href="http://forum.xda-developers.com/showthread.php?t=2050297">ExynosAbuse</a>,使用最新版本1.40顺利获得根权限。</p>
<p><strong>添加gapps</strong></p>
<p>去goo.im下载对应4.1.2的gapps套件<a href="http://goo.im/gapps/gapps-jb-20121011-signed.zip">gapps-jb-20121011-signed.zip</a>,下载完了记得校验下MD5。</p>
<p>按说直接用recovery刷入机器就可以了,但是k860i提示刷入成功,但实际上什么东西都没有刷进去,可能需要安装第三方recovery才行。关机状态下,按住音量增加按钮再按开机键,选择recovery进去恢复模式。</p>
<p>既然已经root机器了,那用root explorer将gapps写入也是一样,顺便还可以精简以下gapps。</p>
<p><strong>精简gapps</strong></p>
<p>将gapps-jb-20121011-signed.zip解包。</p>
<p>optional文件夹用来安装面部解锁功能和为没有NEON技术的CPU添加软件实现,860i的CPU硬件支持NEON技术,所以optional文件夹和install-optional.sh文件删除掉即可。</p>
<p>参考META-INF/com/google/android/updater-script可以了解gapps-jb-20121011-signed.zip刷机包都对机器做了哪些修改。</p>
<p>META-INF文件可以安全的删除掉。</p>
<p>system文件夹才是gapps核心所在。</p>
<p>system/addon.d文件夹下只有一个文件70-gapps.sh,用于在刷新机器时自动备份/恢复gapps,可以编辑此文件只保留精简后的gapps,此处直接将addon.d文件夹删除掉。</p>
<p>system/tts和system/usr文件夹用于TTS(text to speech)技术,直接删除。</p>
<p>system/app文件夹内删除以下apk文件:<br>ChromeBookmarksSyncAdapter.apk - chrome书签同步适配器<br>GoogleFeedback.apk - 反馈<br>Microbes.apk - 动态壁纸<br>Talk.apk - gtalk<br>GenieWidget.apk - 天气widget<br>Talkback.apk - 为视觉障碍人士提供的语音辅助程序<br>GooglePartnerSetup.apk - 合作伙伴设置<br>Thinkfree.apk -GoogleCalendarSyncAdapter.apk office程序<br>GoogleCalendarSyncAdapter.apk - 日历同步适配器<br>VoiceSearchStub.apk - 语音搜索基本程序<br>GoogleTTS.apk - TTS服务<br>QuickSearchBox.apk - 快速搜索框widget<br>GoogleEars.apk - 语音输入<br>MediaUploader.apk - 媒体上载器</p>
<p>system/lib文件下删除以下库文件,大部分都是语音相关的库：<br>libfilterpack_facedetect.so<br>libgoogle_recognizer_jni.so<br>libspeexwrapper.so<br>libflint_engine_jni_api.so<br>libmicrobes_jni.so<br>libfrsdk.so<br>libpatts_engine_jni_api.so<br>libpicowrapper.so<br>libvoicesearch.so</p>
<p><strong>安装gapp</strong></p>
<p>将精简后的gapps,system文件夹拷贝到k860i的/temp文件下,使用terminal修改文件的owner和group为root,然后修为所有文件夹的权限为0755,文件的权限为0644。修改前需要执行下su命令以成为超级用户。</p>
<p>最后使用root explorer将/temp/system下的文件夹拷贝到/system文件夹下</p>
<p>重启手机,会提示”android系统升级,优化应用程序”云云,进入桌面后gapps即算安装完成了。</p>
<p>经验证google套件安装成功。</p>
<p>精简后的<a href="/downloads/gapps-4-1-2.tar.bz2">gapps 4.1.2</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>K860i viberom 1351获取root以及安装google服务</title>
    <url>/2013/12/26/k860i-vibe-root-google/</url>
    <content><![CDATA[<p>总的来说vibe还算凑合,但是不提供root权限,不提供google服务,这样的rom和垃圾有什么两样！</p>
<a id="more"></a>
<p><strong>获取root权限</strong></p>
<p>目前还必须通过卡刷来提权,先刷第三方recovery。安装<a href="http://bbs.lephone.cc/k860/t524604/">CWM</a>即可。</p>
<p>下载zip格式<a href="http://forum.xda-developers.com/showthread.php?t=1538053">SuperSu卡刷包</a>放置到sdcard根目录。<br>之后音量加键+电源键进CWM recovery,将Supersu zip包刷进系统就可以获得root权限了。</p>
<p><strong>安装google服务框架和gapps</strong></p>
<p>下载4.2.1版本的<a href="http://goo.im/devs/UniqueDroid/gapps/gapps-4.2.1">gapps-jb-4.2.1-20121129-signed.zip</a>,放置到sdcard根目录,<br>进入CWM recovery将gapps zip刷入系统即可。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>keepalived实现PostgreSQL流复制故障自动迁移HA</title>
    <url>/2015/12/14/keepalived-postgresql-streaming-replication-auto-failover/</url>
    <content><![CDATA[<a id="more"></a>
<p>keepalived是一个路由软件，主要用于linux系统上的负载均衡(load balancing)和高可用(high availability)。<br>keepalived基于IPVS(IP Virtual Server)提供四层负载均衡功能，Keepalived提供一组checker根据服务器的健康状况来动态维护负载均衡资源池。</p>
<p>另一方面，keepalived基于VRRP协议提供高可用功能。可以由多台服务器组成一个热备组,一个热备组使用一个或一组虚拟ip对外提供服务。一个组内只有一台服务器接管虚拟ip对外提供服务，成为master,其余服务器为backup服务器。当master出现问题时，会执行一次选举(election)选出一台新的master服务器来接管虚拟ip对外提供服务。master服务器负责对虚拟ip请求的相应，并定时发出VRRP通告,backup服务器则待时而动。</p>
<p>keepalived的配置文件中由vrrp_sync_group和vrrp_instance提供高可用配置，由virtual_server_group和virtual_server提供负载均衡配置。</p>
<p>负载均衡配置提供HTTP_GET，SSL_GET，TCP_CHECK，SMTP_CHECK，MISC_CHECK,ICMP_CHECK等检查器，其中ICMP_CHECK工作在三层，TCP_CHECK工作在四层，而HTTP_GET则工作在七层。</p>
<p>高可用配置时，keepalive可以检测网络故障和自身运行状态，还可以设定用户脚本来检测服务器状态，从而当master出现故障时，可以通过重新选举来进行主备切换。</p>
<p><strong>高可用配置</strong></p>
<p>此处主要讲述高可用配置，下面是由两个服务器组成一个热备组用于PostgreSQL数据库高可用服务的配置:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"> notification_email &#123;</span><br><span class="line"> admin@domain.tld # 接收通知的email</span><br><span class="line"> &#125;</span><br><span class="line"> notification_email_from admin@domain.tld # 发送通知的email地址</span><br><span class="line"> smtp_server <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> </span><br><span class="line"> smtp_connect_timeout <span class="number">30</span></span><br><span class="line"> router_id vmin # 标识机器,可以使用机器名,主备不能相同</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_pgsql &#123;</span><br><span class="line"> # script &quot;/path/script.sh&quot;</span><br><span class="line"> script <span class="string">&quot;sudo -u postgres psql -c &#x27;select 1&#x27;&quot;</span></span><br><span class="line"> interval 2 # 2秒检查一次</span><br><span class="line"> weight -2 # 检查失败(返回值非0)时,优先级加-2,其他情况优先级保持不变.默认值为2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"> state BACKUP # 初始状态,主备可都设置为BACKUP,启动后会自动选举优先级高者为master</span><br><span class="line">　　＃　如果高优先级的服务器设置为MASTER,就算设置了nopreempt,当重新启动keepalived实例时，仍然会抢占vip</span><br><span class="line"> interface br0 # vrrp绑定接口</span><br><span class="line"> #use_vmac # 使用虚拟MAC地址,地址格式为00-00-5E-00-01-&lt;virtual_router_id&gt;,主备设置相同</span><br><span class="line"> #vmac_xmit_base # 不使用虚拟接口收发VRRP报文</span><br><span class="line"> virtual_router_id 50 # 虚拟路由id,主备必须使用相同的配置</span><br><span class="line"> track_interface &#123;</span><br><span class="line"> br0 # 监测的网络接口，当此接口不可用时会引起主备切换,可有多个被监测的接口</span><br><span class="line"> &#125;</span><br><span class="line"> nopreempt # 非抢占模式,master设置为nopreempt,backup不要设置，</span><br><span class="line"> # 当高优先级的master重新恢复上线时，不会抢占当前低优先级的backup</span><br><span class="line"> priority 100 # 初始优先级,取值范围为0-255, master可设置为100, backup设置为99</span><br><span class="line"> advert_int 1 # VRRP 通告时间间隔</span><br><span class="line"> virtual_ipaddress &#123;</span><br><span class="line"> 192.168.0.200 # 对外提供服务器的虚拟地址,主备设置相同</span><br><span class="line"> &#125;</span><br><span class="line"> authentication &#123;</span><br><span class="line"> auth_type PASS # 认证类型,master与backup必须一致</span><br><span class="line"> auth_pass 1234 # 认证密码,只使用前8个字符,master与backup必须一致</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> # 如果使用参数调用的脚本,将脚本及参数用引号包围</span><br><span class="line"> notify_master &quot;/usr/local/bin/notify.sh master&quot; # 状态转移为master时执行的脚本</span><br><span class="line"> notify_backup &quot;/usr/local/bin/notify.sh backup&quot; # 状态转移为backup时执行的脚本</span><br><span class="line"> notify_fault &quot;/usr/local/bin/nofity.sh fault&quot; # 状态转移为故障时执行的脚本</span><br><span class="line"></span><br><span class="line"> # 当发生任何的状态变化时,在nofity_*脚本之后被调用,调用时会提供三个参数:</span><br><span class="line"> # $1 = &quot;GROUP&quot;&quot;INSTANCE&quot;</span><br><span class="line"> # $2 = 组或实例的名字</span><br><span class="line"> # $3 = 变化的目标状态</span><br><span class="line"> # (&quot;MASTER&quot;&quot;BACKUP&quot;&quot;FAULT&quot;)</span><br><span class="line"> nofity <span class="string">&quot;/usr/local/bin/notify.sh&quot;</span></span><br><span class="line"></span><br><span class="line"> # 发送邮件通知,使用global_defs中的定义</span><br><span class="line"> # smtp_alert </span><br><span class="line"></span><br><span class="line"> track_script &#123;</span><br><span class="line"> chk_pgsql # 使用检查脚本</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>MASTER和BACKUP节点的优先级如何调整？</strong></p>
<p>首先，每个节点有一个初始优先级，由配置文件中的priority配置项指定，MASTER节点的priority应比BAKCUP高。运行过程中keepalived根据vrrp_script的weight设定，增加或减小节点优先级。</p>
<p>规则如下：</p>
<ol>
<li>当weight &gt; 0时，vrrp_script script脚本执行返回0(成功)时优先级为priority + weight, 否则为priority。当BACKUP发现自己的优先级大于MASTER通告的优先级时，进行主从切换。</li>
<li>当weight &lt; 0时，vrrp_script script脚本执行返回非0(失败)时优先级为priority + weight, 否则为priority。当BACKUP发现自己的优先级大于MASTER通告的优先级时，进行主从切换。 </li>
<li>当两个节点的优先级相同时，以节点发送VRRP通告的IP作为比较对象，IP较大者为MASTER。</li>
<li>　优先级并不会不断的提高或降低，只会根据脚本返回结果计算一次。</li>
</ol>
<p><strong>什么时候会发生主从切换？</strong></p>
<p>当监测的网络接口发生故障、keepalived实例关闭或者主备优先级发生变化时，会重新选择新的master服务器来接管服务。</p>
<p><strong>防止脑裂(brain split)</strong></p>
<p>将主备服务器都设置为BACKUP状态，并且将master服务器(初始优先级高的服务器)配置为nopreempt,当master因为各种可能原因下线，然后重新恢复上线时，虽然恢复上线的master优先级高于当前master的优先级，但不会去抢夺控制权。</p>
<p>这样会造成一个问题，除非当前的master网络故障或keepalived实例停止，其优先级就算降低后低于原来的master服务器，因为设置了nopreempt，也不会切换到原来的master。所以原master恢复上线之前，应该降低其优先级，并且要低于当前master的优先级，然后去掉nopreempt,而当前master添加nopreempt。</p>
<p>如果没有设置nopreempt,当master因为网络原因短暂下线后，backup服务器接管vip,并且PostgreSQL备库升级为主库。当原来的master网络恢复，重新上线时，会重新成为master,而此时就有了两个主库，发生了分裂。</p>
<p><strong>通知脚本</strong><br>可以在通知脚本中处理PostgeSQL备库提升，主库停止，发送通知等各种事务。</p>
<p><strong>查看VRRP通告</strong><br>可以使用tcpdump命令监测VRRP通告,可以看到当前的master服务器为192.168.0.3</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo tcpdump -vvv -n -i eth0 host <span class="number">224.0</span><span class="number">.0</span><span class="number">.18</span></span><br><span class="line">tcpdump: listening on eth0, link-type EN10MB (Ethernet), capture size <span class="number">262144</span> bytes</span><br><span class="line"><span class="number">23</span>:<span class="number">06</span>:<span class="number">49.974761</span> IP (tos <span class="number">0xc0</span>, ttl <span class="number">255</span>, id <span class="number">373</span>, offset <span class="number">0</span>, flags \[none\], proto VRRP (<span class="number">112</span>), length <span class="number">40</span>)</span><br><span class="line"> <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span> &gt; <span class="number">224.0</span><span class="number">.0</span><span class="number">.18</span>: vrrp <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span> &gt; <span class="number">224.0</span><span class="number">.0</span><span class="number">.18</span>: VRRPv2, Advertisement, vrid <span class="number">50</span>, prio <span class="number">98</span>, authtype simple, intvl 1s, length <span class="number">20</span>, <span class="attr">addrs</span>: <span class="number">192.168</span><span class="number">.0</span><span class="number">.200</span> auth <span class="string">&quot;1234^@^@^@^@&quot;</span></span><br><span class="line"><span class="number">23</span>:<span class="number">06</span>:<span class="number">50.975113</span> IP (tos <span class="number">0xc0</span>, ttl <span class="number">255</span>, id <span class="number">374</span>, offset <span class="number">0</span>, flags \[none\], proto VRRP (<span class="number">112</span>), length <span class="number">40</span>)</span><br><span class="line"> <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span> &gt; <span class="number">224.0</span><span class="number">.0</span><span class="number">.18</span>: vrrp <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span> &gt; <span class="number">224.0</span><span class="number">.0</span><span class="number">.18</span>: VRRPv2, Advertisement, vrid <span class="number">50</span>, prio <span class="number">98</span>, authtype simple, intvl 1s, length <span class="number">20</span>, <span class="attr">addrs</span>: <span class="number">192.168</span><span class="number">.0</span><span class="number">.200</span> auth <span class="string">&quot;1234^@^@^@^@&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>如果热备组内的服务器跨越子网，则交换路由设备必须开启VRRP多播报文转发。</p>
<p>References:<br>[1]man keepalived.conf<br>[2]<a href="http://www.yangfannie.com/26.html">Keepalived在PostgreSQL高可用中的运用</a><br>[3]<a href="http://blog.csdn.net/zzban/article/details/8483902">Linux集群实现–Keepalived-1.2.7</a><br>[4]<a href="http://www.cnblogs.com/songyuejie/p/4561089.html">PostgreSQL+pgpooll+Keepalived双机HA方案</a><br>[5]<a href="http://fengchj.com/?p=2156">keepalived vip漂移基本原理及选举算法</a><br>[6]<a href="http://fossies.org/linux/keepalived/doc/NOTE_vrrp_vmac.txt">Note on using VRRP with Virtual MAC address</a><br>[7]<a href="http://blog.jobbole.com/94675/">Keepalived 集群软件高级使用(工作原理和状态通知)</a><br>[8]<a href="http://www.keepalived.org/">keepalived</a><br>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>kpartx为多路径块设备分区增加设备映射</title>
    <url>/2013/09/08/kpartx-device-map/</url>
    <content><![CDATA[<p>kpartx命令用来为块设备上的分区增加设备映射</p>
<a id="more"></a>
<p>一直以来，multipath-tools会自动的为多路径设备自动映射分区设备文件，但最近升级到wheezy最新版本后，/dev/mapper/目录下只有整个块设备data(dm-0)，而没有为分区准备的映射文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ls -l /dev/mapper</span><br><span class="line">total <span class="number">0</span></span><br><span class="line">crw------T <span class="number">1</span> root root <span class="number">10</span>, <span class="number">236</span> Sep <span class="number">8</span> <span class="number">19</span>:<span class="number">52</span> control</span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">7</span> Sep <span class="number">8</span> <span class="number">19</span>:<span class="number">53</span> data -&gt; ../dm-<span class="number">0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># fdisk /dev/mapper/data</span><br><span class="line"><span class="string">``</span><span class="string">`js</span></span><br><span class="line"><span class="string">是可以看到多路径设备data下的分区data1的</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">Device Boot Start End Blocks Id System</span><br><span class="line">/dev/mapper/data1 <span class="number">2048</span> <span class="number">2924441599</span> <span class="number">1462219776</span> <span class="number">83</span> Linux</span><br></pre></td></tr></table></figure>
<p>看来需要手动映射一下</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># kpartx -a /dev/mapper/data</span><br></pre></td></tr></table></figure>
<p>再看设备文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ls -l /dev/mapper</span><br><span class="line">total <span class="number">0</span></span><br><span class="line">crw------T <span class="number">1</span> root root <span class="number">10</span>, <span class="number">236</span> Sep <span class="number">8</span> <span class="number">19</span>:<span class="number">52</span> control</span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">7</span> Sep <span class="number">8</span> <span class="number">19</span>:<span class="number">53</span> data -&gt; ../dm-<span class="number">0</span></span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">7</span> Sep <span class="number">8</span> <span class="number">20</span>:<span class="number">21</span> data1 -&gt; ../dm-<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这样就可以看到分区data1(dm-1),并且可以正常的挂装。</p>
<p>kaprtx的完整选项：</p>
<p>-a 增加分区映射 add<br>-r 分区映射为只读状态 readonly<br>-d 删除分区映射 delete<br>-u 更新分区映射 update<br>-l 列出用选项-a会映射的分区 list<br>-p 设置设备名-分区号之间的分隔符号，默认为空<br>-f 强制创建分区映射，忽略’no_partitions’特性，force<br>-g 强制GUID分区表,GUID<br>-v 冗余输出，verbose<br>-s 同步模式，知道分区表建立才返回,sync</p>
<p>kpartx可以挂载含有分区的映像文件，比如</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># kpartx -av disk.img</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Squeeze KVM虚拟机安装笔记(2):客户机安装</title>
    <url>/2011/05/13/kvm-client-install/</url>
    <content><![CDATA[<p>KVM主机端设置完毕后,开始安装客户机,这里介绍两个客户机的安装,Debian Squeeze AMD64和Windows 2003 x64</p>
<a id="more"></a>
<p>当然主机系统是64位平台,必须的。</p>
<p><strong>准备</strong></p>
<p>因为要使用半虚拟化(Paravirtualized)驱动virtio,但是当前的Debian Stable版本也就是squeeze发行版的kvm并不支持从virtio驱动器启动,所以需要更新一下seabios,从Debian官方sid源下载<a href="http://ftp.us.debian.org/debian/pool/main/s/seabios/seabios_0.6.1.2-2_all.deb">seabios 0.6.1.2</a>,然后手动安装该包 seabios_0.6.1.2-2_all.deb</p>
<p>$sudo dpkg -i seabios_0.6.1.2-2_all.deb</p>
<p>主机系统只安装了debian基本系统(base system),没有X,因此使用VNC来远程安装客户机，如果使用windows系统,请自行下载TightVNC Viewer。</p>
<p><strong>KVM核心参数</strong></p>
<p>这是只简单介绍几个主要的参数,详细的文档请见man kvm。</p>
<p>-bios file<br>指定虚拟机使用的BIOS,file指定BIOS文件路径</p>
<p>-smp n[,cores=cores][,threads=threads][,sockets=sockets][,maxcpus=maxcpus]<br>模拟一个有n个cpu的smp系统,可以简单的指定n为一个数值,或者分别指定socket数,core数/socket,线程数/core</p>
<p>-m megs<br>指定虚拟机使用的内存数量,可以使用M或G后缀</p>
<p>-rtc [base=utclocaltimedate][,clock=hostvm][,driftfix=noneslew]<br>指定虚拟机使用的时间,linux客户机使用-rtc base=utc,clock=host,windows客户机使用-rtc base=localtime,clock=host</p>
<p>-net nic,model=virtio,macaddr=52-54-00-12-34-01 -net tap,ifname=tap0<br>桥接网络，客户机网络接口通过tap接口桥接到主机网络，使用的tap接口名为tap0，由/etc/kvm/kvm-ifup来动态配置tap0接口。model=virtio指定虚拟机网卡使用半虚拟化驱动,如果有多个虚拟客户机同时运行则必须指定macaddr为一个独一无二的值,否则会出现mac地址冲突。如果通过主机的/etc/network/interfaces来静态配置tap接口,则此处应在-net tap接口处附加两个另外的参数script=no,downscript=no</p>
<p>-drive file=debian.img,if=virtio,index=0,media=disk,format=qcow2,cache=writeback<br>指定客户机使用的硬盘驱动器,if=virtio指定使用半虚拟化驱动,index=0指定该硬盘为接口的第一个驱动器,media=disk指定为硬盘驱动器,如果是光盘则为media=cdrom。旧式指定第一个硬盘驱动器的参数为-hda debian.img,已经不再推荐使用。</p>
<p>-drive file=debian.iso,index=2,media=cdrom或者-hdc debian.iso<br>指定光盘驱动器,debian.iso为使用的光驱映像文件</p>
<p>-fda file<br>指定软盘驱动器,file为软磁盘镜像 </p>
<p>-no-fd-bootchk<br>客户机启动时不检查软盘驱动器,加速客户机启动</p>
<p>-boot order=c<br>指定引导顺序,c为第一个硬盘驱动器,d为第一个光盘驱动器</p>
<p>-vnc :0<br>将虚拟机的视频输出重定向到vnc端口,通过vnc viewer可以连接到虚拟机的视频输出</p>
<p>-nographic<br>禁止kvm虚拟机的视频输出</p>
<p>-daemonize<br>后台运行虚拟机</p>
<p><strong>安装Debian Squeeze AMD64客户机</strong></p>
<p>使用一下脚本开始安装debian客户机</p>
<p>1 #!/bin/bash<br>2<br>3 sudo kvm -bios /usr/share/seabios/bios.bin -smp 16 -m 4G -rtc base=utc,clock=host       <strong>\</strong><br>4     -net nic,model=virtio,macaddr=52-54-00-12-34-01 -net tap,ifname=tap0                <strong>\</strong><br>5     -boot order=c -no-fd-bootchk                                                        <strong>\</strong><br>6     -drive file=debian.img,if=virtio,index=0,media=disk,format=qcow2,cache=writeback    <strong>\</strong><br>7     -drive file=debian.iso,index=2,media=cdrom                                          <strong>\</strong><br>8     -vnc :0  </p>
<p>这里指定虚拟机使用的BIOS,这样安装完成后才能从virtio磁盘启动客户机,debian.iso为客户机安装光盘镜像,远程通过vnc viewer连接到主机开始安装客户机,Debian Squeeze内置支持virtio设备支持,因此正常安装即可。</p>
<p>安装完毕开启sshd后,将-vnc :0参数更换为-nographic -daemonize,以后通过ssh登录即可。</p>
<p><strong>安装windows 2003 R2 x64客户机</strong></p>
<p>首先从Fedora下载<a href="http://alt.fedoraproject.org/pub/alt/virtio-win/latest/images/bin/">virtio for windows驱动</a>,使用如下脚本启动虚拟安装<br>1 #!/bin/bash<br>2<br>3 sudo kvm -bios /usr/share/seabios/bios.bin -smp 16 -m 2G -rtc base=localtime,clock=host     <strong>\</strong><br>4     -boot order=d                                                                           <strong>\</strong><br>5     -net nic,model=virtio,macaddr=52-54-00-12-34-02 -net tap,ifname=tap1                    <strong>\</strong><br>6     -drive file=win2k3_dns.qcow2,if=virtio,index=0,media=disk,format=qcow2,cache=writeback  <strong>\</strong><br>7     -drive file=windows_2003_r2_x64_cd1.iso,index=2,media=cdrom                             <strong>\</strong><br>8     -fda virtio-win-1.1.16.vfd                                                              <strong>\</strong><br>9     -vnc :0   </p>
<p>使用vnc viewer连接到主机开始安装,按F6从<a href="/downloads/virtio-win-1.1.16.vfd">virtio软磁盘镜像</a>加载virto驱动,否则会找不到硬盘驱动器,系统安装完成后将光驱换上virtio-win-1.1.16.iso安装virtio网卡驱动,打开远程桌面后将-vnc :0替换成-nographic -daemonize,然后用远程桌面管理虚拟机即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>kvm客户机共享主机目录</title>
    <url>/2016/04/25/kvm-guest-access-host-dir/</url>
    <content><![CDATA[<a id="more"></a>
<p>主机通过virtio上的9p文件系统以及文件系统设备，可以将主机上的文件系统导出给客户机来挂载使用</p>
<p>v9fs是plan 9 9p远程文件系统协议的实现</p>
<p><strong>主机配置</strong></p>
<p>在客户机启动命令上新添加fsdev和device选项</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-fsdev local,security_model=passthrough,id=fsdev0,path=<span class="regexp">/mnt/</span>share </span><br><span class="line">-device virtio-9p-pci,id=fs0,fsdev=fsdev0,mount_tag=hostshare</span><br></pre></td></tr></table></figure>
<p>这样导出了主机的/mnt/share目录供客户机来存取</p>
<p><strong>客户机配置</strong></p>
<p>客户机需要在内核中开启9P文件系统相关选项，可以这样查看:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /boot/config-$(uname -r) grep 9P</span><br><span class="line">CONFIG_NET_9P=m</span><br><span class="line">CONFIG_NET_9P_VIRTIO=m</span><br><span class="line">CONFIG_NET_9P_RDMA=m</span><br><span class="line"># CONFIG_NET_9P_DEBUG is not set</span><br><span class="line">CONFIG_9P_FS=m</span><br><span class="line">CONFIG_9P_FSCACHE=y</span><br><span class="line">CONFIG_9P_FS_POSIX_ACL=y</span><br><span class="line">CONFIG_9P_FS_SECURITY=y</span><br></pre></td></tr></table></figure>

<p>可以看到9P配置成了内核模块的形式，然后就可以挂载主机的目录来使用了：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mount -t 9p -o trans=virtio\[,version=9p2000.L\] hostshare /mnt/point</span><br></pre></td></tr></table></figure>

<p>hostshare就是主机导出的挂载点的名称，此处将其挂载到客户机的/mnt/point。<br>version选项是可选的。</p>
<p>References:<br>[1]<a href="http://www.linux-kvm.org/page/9p_virtio">Example Sharing Host files with the Guest</a><br>[2]<a href="http://wiki.qemu.org/Documentation/9psetup">Documentation/9psetup</a><br>[3]<a href="https://www.kernel.org/doc/Documentation/filesystems/9p.txt">v9fs: Plan 9 Resource Sharing for Linux</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>KVM虚拟化环境高可用方案探讨</title>
    <url>/2012/04/27/kvm-high-availability/</url>
    <content><![CDATA[<p>KVM是成熟的开源虚拟化解决方案,将其部署于企业生产环境,其高可用性也是必须要仔细考虑的问题。</p>
<a id="more"></a>
<p>高可用性(High Availability)是指系统提供不间断服务的能力,也就是尽可能的减少系统停止服务的时间。KVM虚拟化环境也存在HA的问题,KVM主机软硬件或外部环境都有可能出现问题甚至是灾难,这就必须要考虑一些高可用方案。</p>
<p>KVM高可用方案无非就是如何能最大限度的让客户机保持正常运行。目前想到的HA方案有如下几个。</p>
<p><strong>1、DRBD</strong></p>
<p>DRDB(Distributed Replicated Block Device),可以直译为”分布式复制块设备”,其工作方式为通过网络来镜像块设备,可以称其为网络RAID1(Network RAID1)。 DRDB在本地接受IO请求,除了将数据写入本地硬盘外,还会通过网络发送给另一主机,另一主机将其写入自己的本地硬盘,从而保持两台主机的块设备实时同步。</p>
<p>从kernel 2.6.33开始DRDB已经进入mainline。DRBD 9.0之前只能将数据复制到一个节点,9.0之后将提供复制到多个节点的能力。</p>
<p>通过与heartbeat结合可以做到自动的failover,从而达到高可用性。</p>
<p>DRBD是一种通用解决方案,KVM虚拟化环境完全可以使用这一高可用技术。</p>
<p><strong>2、Sheepdog</strong></p>
<p>Sheepdog是专为QEMU/KVM开发的分布式块存储系统。它可以提供QEMU/KVM可以直接挂接使用的高可用块级存储卷。Sheepdog可以扩大到上百个节点,并且支持高级卷管理特性,比如快照、克隆、thin provisioning等。它是针对KVM的专用集群存储方案。</p>
<p>这玩意儿听起来真像那么一回事儿,但目前版本为0.3.0,成熟度貌似还很不够。不过很看好这项目。</p>
<p><strong>3、双机</strong></p>
<p>双机共享存储,但这种方式仍然存在单一故障点,那就是存储,所以这种方式并不是一种很好的方式,虽然存储的可靠性比主机要高的多。</p>
<p>目前正在采用这种方式,两台服务器分别通过多路径连接到共享的磁盘阵列,但同一时刻只能有一台服务器挂载磁盘阵列。因为磁盘阵列使用的是ext4文件系统,这种单机文件系统是不支持两台主机同时访问的,会造成数据混乱,甚至文件系统崩溃。</p>
<p>KVM客户机客户机磁盘镜像文件和启动KVM客户机的命令脚本都放在共享存储上面,当正在使用磁盘阵列的主机出现故障时,可以使用备机挂载磁盘阵列来运行KVM客户机。因为有了共享存储,也可以通过NFS来做客户机的动态迁移,即V2V热迁移,客户机可以在几乎没有任何中断的情况下从一台主机迁移到另一台主机。</p>
<p>因为存储是单一故障点,所以有必要经常备份KVM客户机。但目前KVM客户机还不能热备份,也就是要想完整备份客户机,只能将客户机停掉,然后拷贝其磁盘镜像文件。显然这样太麻烦了。</p>
<p>热备份的问题可以通过文件系统快照来间接实现。ext4不支持snapshot,ZFS是更好的选择。<a href="http://zfsonlinux.org/">ZFS on linux</a>是ZFS到linux的原生移植,以内核模块的方式来绕过license限制。通过ZFS给文件系统做快照,然后将快照传输到远程主机,来间接的实现KVM虚拟机的热备份。</p>
<p>近期会测试这种方式,ZFS on linux 现在的版本为0.6.0-rc8,不知道稳定性如何！</p>
<p>当然还有一种备份方式,现在的磁盘阵列大部分提供一种功能叫做远程卷镜像RVM(remote volume mirroring)的特性,但这种方式有许多缺点,比如硬件投资高,灵活性差,而且RVM会忠实的镜像一切数据,包括错误,一旦原卷数据损坏,可能远程镜像卷也会无法使用,如果RVM能提供事务支持就更好了,当然也有阵列提供snapshot功能。但是能用软件方案解决的问题还是尽量不要用硬件解决方案。</p>
<p><strong>总结</strong></p>
<p>总的来说,使用DRBD或Sheepdog是更好的解决方案,Sheepdog还不太成熟,也许DRDB是目前一个很好的选择。双机热备这种古老的技术其实并不灵活也不十分可靠,集群才是高可用和高性能的方向。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>KVM的-nographic与-display选项</title>
    <url>/2014/03/10/kvm-nographic-display/</url>
    <content><![CDATA[<a id="more"></a>
<p>KVM客户机正常运行时是不需要在主机上显示图形界面的,以前都是使用-nographic和-daemoniz选项来使客户机后台运行。<br>但是从qemu-kvm 1.4开始,这招不灵了，会有这样的错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-nographic can not be used <span class="keyword">with</span> -daemonize</span><br></pre></td></tr></table></figure>

<p>这提示过于简单的,新版本的kvm不再允许-nographic和-daemonize一起使用了,应该使用-display none参数来代替-nographic,这样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">kvm ...</span><br><span class="line">-display none</span><br><span class="line">-daemonize</span><br></pre></td></tr></table></figure>

<p>-display参数用于替代老风格的显示类型选项,如-sdl,-curses,-vnc，其语法如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-display \[sdl curses vnc=&lt;display&gt;\]</span><br></pre></td></tr></table></figure>

<p>其中,vnc=<display>中的display与显示环境变量$DISPLAY的含义一致,格式为hostname: displaynumber.screennumber(X服务器主机名/地址:显示号.屏幕号)。一般设置为vnc=:0即可,如果有多台虚拟机在同一台主机上需要同时使用VNC,则每台客户机的显示号顺延就可,比如:1,:2,:3等,而通过vnc客户端连接客户机的端口号则分别为5900,5901,5902,5903。5900是默认的vnc端口,对应显示设备:0。 </p>
<p>使用-display none选项时,客户机仍然会看到模拟的显卡，但是其显示不会输出给用户。<br>-display none与-nographic的区别是,-display none仅仅影响显示输出,而-nographic同时还会影响串行口和并行口的输出。</p>
<p>-nographic和-daemonize组合一直以来存在一个小问题,kvm客户机启动后,主机虚拟终端后续的命令回显会被关闭,但命令的输出会显示，只能退出重新登录终端才会恢复正常，这是个很明显的bug,却很久都没有修复。改用-display none参数后就没有此问题了。</p>
<p>kvm更详细的用法,请自行 man qemu</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>基于KVM的P2V迁移</title>
    <url>/2012/04/19/kvm-p2v/</url>
    <content><![CDATA[<p>物理机迁移到虚拟机称之为P2V迁移即Phisycal to Virtual migration</p>
<a id="more"></a>
<p>虚拟化迁移技术按迁移方向分为P2V,V2V(Virtual to Virtual),V2P(Virtual to Phisycal)这三种类型，按迁移方式又有静态迁移和动态迁移之分。动态迁移的好处是可以基本保证物理机或虚拟机提供的服务在迁移过程中不会中断或极短时间中断,适用于那些十分关键的服务。当然动态迁移要求也会很高,相对来说静态迁移要简单的多,而且静态迁移相对来说更能保证数据的完整性。</p>
<p>最近共享存储的KVM虚拟化环境已经正常运行了一段时间,所以考虑将一些非关键的物理机迁移到KVM平台。</p>
<p><strong>P2V on KVM</strong></p>
<p>因为物理机提供的服务在某些时间段是可以中断的,所以选择相对简单的静态迁移。</p>
<p>P2V的主要工作是将物理机的磁盘设备制作成KVM可以使用的虚拟机磁盘镜像。常见的方法有使用dd命令或者使用磁盘/分区克隆工具。比如使用systemrescuecd引导物理机,然后使用dd制作磁盘/分区的镜像,并将其保存到移动设备或者网络。但是dd制作镜像会将磁盘完整复制,包括未使用的区域,镜像文件大,浪费时间和空间。这里使用linux克隆工具clonezilla来制作磁盘镜像，clonezilla只克隆使用到的数据区。</p>
<p>物理机操作系统为windows 2003 r2 sp2 x86版本。</p>
<p><strong>P2V迁移主要步骤：</strong></p>
<ol>
<li><p> 下载<a href="http://clonezilla.org/">clonezilla</a> live cd镜像并刻录CD或制作usb引导设备</p>
</li>
<li><p> 为源物理主机打开IDE设备支持。IDE设备是windows和linux沟通的最好桥梁,IDE十分成熟,而对于SCSI设备两个系统的支持则存在很多问题。所以KVM的虚拟机磁盘要设置为IDE接口才能顺利完成迁移。物理机使用SCSI接口的RAID磁盘设备,这种情况下,windows 2003默认并未提供IDE设备的支持,因此需要在物理机打开对IDE设备的支持。否则会遇到BSOD错误STOP: 0x0000007B。参考M$文章<a href="http://support.microsoft.com/kb/314082/en-us">Article ID: 314082</a>,导入注册表设置Mergeide.reg,然后将Atapi.sys, Intelide.sys, Pciide.sys和Pciidex.sys四个驱动文件拷贝到%SystemRoot%\System32\Drivers目录下。Intelide.sys在windows\Driver Cache\I386\sp2.cab文件中,其他三个文件在windows\Driver Cache\I386\driver.cab文件中。</p>
</li>
<li><p> 用clonezilla引导物理机,因为使用device-device模式未成功,所以使用device-image模式,选择ssh_server通过ssh将存储设备的镜像文件保存到ssh服务器,按clonezilla的向导一步步操作即可</p>
</li>
<li><p> 在KVM主机上分配虚拟机,虚拟机的硬盘容量要比物理机硬盘容量稍微大一些,加1G够了。虚拟机磁盘接口设置为IDE,将clonezilla镜像文件挂载为虚拟机的CDROM设备并从CDROM启动虚拟机,然后通过ssh_server模式从ssh服务器将物理机生成的镜像恢复到虚拟机，完成之后关机。</p>
</li>
<li><p> 对于P2V迁移,问题最大的是块存储设备和网络设备,块存储设备通过IDE这个桥梁来解决。而虚拟机添加的网络设备则需要重新安装驱动程序,物理机原来的网络设备和驱动就都废弃了。virtio是KVM的半虚拟化驱动,大大提高了虚拟机的IO性能。所以网卡使用virtio接口。下载<a href="http://alt.fedoraproject.org/pub/alt/virtio-win/latest/images/bin/">virtio驱动iso镜像</a>,将其挂载为虚拟机的CDROM设备,然后从硬盘启动虚拟机。windows客户机启动后会自动安装变化了的设备的驱动程序,同时也要安装网卡的virtio驱动</p>
</li>
<li><p>如果物理机的网络接口使用静态IP,将其迁移到虚拟机后,使用了新的虚拟网络接口,这时如果给虚拟机赋予相同的静态IP,则windows会有提示有隐藏设备使用了相同的IP。此时可以打开隐藏的不存在的设备,然后找到物理机原来的网络接口将其删除,再为虚拟网络设备设置IP地址即可。如果在克隆物理机磁盘之前,将物理机的网络配置为自动获取IP,则此问题就不会存在了。</p>
<p>如果想看到并删除原物理机的网卡,执行以下步骤<br>打开一个控制台窗口,输入<br>set devmgr_show_nonpresent_devices = 1<br>然后在同一个控制台窗口输入<br>start devmgmt.msc<br>最后在打开的设备管理器窗口“显示隐藏的设备”,就可以看到原物理网卡了,将他们删除即可。</p>
</li>
</ol>
<p>这样P2V迁移算是完成了,但是现在虚拟机使用的是IDE磁盘设备,为了提高磁盘IO性能,有必要将其转换到半虚拟化的virtio磁盘设备。</p>
<p><strong>虚拟机磁盘从IDE转换到virtio步骤：</strong></p>
<ol>
<li><p> 停止虚拟机，创建一个新的磁盘映像并以virtio接口将其挂载为虚拟机的第二块硬盘,将virtio驱动iso镜像挂载为虚拟机的CDROM设备</p>
</li>
<li><p> 启动虚拟机,系统会提示安装virtio设备的驱动程序,按提示从CDROM安装驱动即可</p>
</li>
<li><p> 关闭虚拟机,去掉新添加的第二块磁盘,将原来磁盘的接口从IDE更改为virtio,启动虚拟机即完成磁盘设备的接口转换</p>
</li>
</ol>
<p>至此完整的将物理机迁移到支持半虚拟化IO的虚拟机,完成P2V迁移。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>KVM性能优化</title>
    <url>/2012/04/28/kvm-performance-tuning/</url>
    <content><![CDATA[<p>KVM虚拟环境性能优化的几个措施</p>
<a id="more"></a>
<p>KVM本来性能已经很不错了,但还有一些微调措施来进一步提高KVM性能。</p>
<p><strong>1、virtio</strong></p>
<p>virtio是KVM的半虚拟化机制,用以提高IO性能,使用virtio可以显著提高KVM性能。virtio具体使用方法参见<a href="https://openwares.net/linux/debian_kvm.html">1</a>,<a href="https://openwares.net/linux/kvm_client_install.html">2</a>。</p>
<p><strong>2、使用writeback缓存选项</strong></p>
<p>针对客户机块设备的缓存,drive有一个子选项cache来设置缓存模式。两个主要的选项为writeback和writethrough,man手册是这样说的</p>
<p>By default, writethrough caching is used for all block device. This means that the host page cache will be used to read and write data but write notification will be sent to the guest only when the data has been reported as written by the storage subsystem.</p>
<p>Writeback caching will report data writes as completed as soon as the data is present in the host page cache. This is safe as long as you trust your host. If your host crashes or loses power, then the guest may experience data corruption.</p>
<p>writethrough写操作时不使用主机的缓存,只有当主机接受到存储子系统写操作完成的通知后,主机才通知客户机写操作完成,也就是说这是同步的。而writeback则是异步的,它使用主机的缓存,当客户机写入主机缓存后立刻会被通知写操作完成,而此时主机尚未将数据真正写入存储系统,之后待合适的时机主机会真正的将数据写入存储。显然writeback会更快,但是可能风险稍大一些,如果主机突然掉电,就会丢失一部分客户机数据。</p>
<p>这样使用writeback选项</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-drive file=debian.img,<span class="keyword">if</span>=virtio,index=<span class="number">0</span>,media=disk,format=qcow2,cache=writeback </span><br></pre></td></tr></table></figure>
<p>CDROM设备也可以使用writeback选项</p>
<p><strong>3、客户机的磁盘IO调度策略</strong></p>
<p>磁盘IO要经过调度才可以写入磁盘,这种调度又称作电梯算法。对于客户机对磁盘的IO操作实际上要经过三次IO调度才能真正访问到物理磁盘,客户机对虚拟磁盘执行一次IO调度,KVM主机对所有上层的IO执行一次调度,当KVM主机将IO提交给磁盘阵列时,磁盘阵列也会对IO进行调度,最后才会真正读写物理磁盘。</p>
<p>客户机看到的磁盘只不过是主机的一个文件,所以其IO调度并无太大意义,反而会影响IO效率,所以可以通过将客户机的IO调度策略设置为NOOP来提高性能。NOOP就是一个FIFO队列,不做IO调度。</p>
<p>linux客户机使用grub2引导时,可以通过给内核传递一个参数来使用NOOP调度策略</p>
<p>编辑文件/etc/default/grub</p>
<p>行GRUB_CMDLINE_LINUX_DEFAULT=”quiet splash”后添加elevator=noop,变成为</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=<span class="string">&quot;quiet splash elevator=noop&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo update-grub</span><br></pre></td></tr></table></figure>

<p><strong>4、打开KSM(Kernel Samepage Merging)</strong></p>
<p>页共享早已有之,linux中称之为COW(copy on write)。内核2.6.32之后又引入了KSM。KSM特性可以让内核查找内存中完全相同的内存页然后将他们合并,并将合并后的内存页打上COW标记。KSM对KVM环境有很重要的意义,当KVM上运行许多相同系统的客户机时,客户机之间将有许多内存页是完全相同的,特别是只读的内核代码页完全可以在客户机之间共享,从而减少客户机占用的内存资源,从而可以同时运行更多的客户机。</p>
<p>查看内核是否支持KSM特性:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ grep KSM /boot/config-\<span class="string">`uname -r\`</span></span><br><span class="line"><span class="string">CONFIG_KSM=y</span></span><br></pre></td></tr></table></figure>

<p>Debian系统中KSM默认是关闭的,通过以下命令来开启KSM</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># echo 1 &gt; /sys/kernel/mm/ksm/run</span><br></pre></td></tr></table></figure>
<p>关闭KSM</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># echo 0 &gt; /sys/kernel/mm/ksm/run</span><br></pre></td></tr></table></figure>
<p>这样设置后,重新启动系统KSM会恢复到默认状态,尚未找个哪个内核参数可以设置在/etc/sysctl.conf中让KSM持久运行。</p>
<p>可以在/etc/rc.local中添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">echo <span class="number">1</span> &gt; <span class="regexp">/sys/</span>kernel/mm/ksm/run</span><br></pre></td></tr></table></figure>
<p>让KSM开机自动运行</p>
<p>有个哥们不喜欢rc.local,为ksm写了<a href="http://dnaeon.github.io/enable-ksm-during-boot-time-on-linux/">个debian风格的system V init脚本</a>,很简洁。</p>
<p>通过/sys/kernel/mm/ksm目录下的文件来查看内存页共享的情况,pages_shared文件中记录了KSM已经共享的页面数。</p>
<p>国人对KSM做了进一步优化,这就是<a href="http://kerneldedup.org/">UKSM</a>(Ultra KSM)项目,据说比KSM扫描更全面,页面速度更快,而且CPU占用率更低,希望此项目能尽快进入内核mainline。</p>
<p>KSM会稍微的影响系统性能,以效率换空间,如果系统的内存很宽裕,则无须开启KSM,如果想尽可能多的并行运行KVM客户机,则可以打开KSM。</p>
<p><strong>5、KVM Huge Page Backed Memory</strong> </p>
<p>通过为客户机提供巨页后端内存,减少客户机消耗的内存并提高TLB命中率,从而提升KVM性能。x86 CPU通常使用4K内存页,但也有能力使用更大的内存页,x86_32可以使用4MB内存页，x86_64和x86_32 PAE可以使用2MB内存页。x86使用多级页表结构,一般有三级,页目录表-&gt;页表-&gt;页,所以通过使用巨页,可以减少页目录表和也表对内存的消耗。当然x86有缺页机制,并不是所有代码、数据页面都会驻留在内存中。</p>
<p>首先挂装hugetlbfs文件系统</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mkdir /hugepages</span><br><span class="line">#mount -t hugetlbfs hugetlbfs /hugepages</span><br></pre></td></tr></table></figure>
<p>然后指定巨页需要的内存页面数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#sysctl vm.nr_hugepages=xxx</span><br></pre></td></tr></table></figure>
<p>最后指定KVM客户机使用巨页来分配内存</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">kvm -mem-path /hugepages</span><br></pre></td></tr></table></figure>
<p>也可以让系统开机自动挂载hugetlbfs文件系统,在/etc/fstab中添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">hugetlbfs /hugepages hugetlbfs defaults <span class="number">0</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>在/etc/sysctl.conf中添加如下参数来持久设定巨页文件系统需要的内存页面数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">vm.nr_hugepages=xxx</span><br></pre></td></tr></table></figure>
<p>巨页文件系统需要的页面数可以由客户机需要的内存除以页面大小也就是2M来大体估算。</p>
<p>References:<br>[1]<a href="http://dnaeon.github.io/enable-ksm-during-boot-time-on-linux/">Enable KSM during boot-time on Linux</a><br>[2]<a href="https://github.com/dnaeon/ksm-init.d-debian">KSM init.d script for Debian GNU/Linux</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>KVM客户机使用主机USB设备</title>
    <url>/2011/06/02/kvm-usb/</url>
    <content><![CDATA[<p>有些时候KVM客户机还是要使用USB设备,比如USB密钥等</p>
<a id="more"></a>
<p><strong>KVM命令行参数</strong></p>
<p>-usb 打开usb驱动程序,启动客户机usb支持<br>-usbdevice devname 为客户机增加usb设备,devname有多种形式,详见man kvm,这里只涉及一种形式host:vendor_id:product_id,也就是-usbdevce vendor_id:product_id</p>
<p><strong>获取USB设备参数</strong></p>
<p>将usb设备插入主机之前</p>
<p>$lsusb &gt; usb.old</p>
<p>usb设备插入主机之后</p>
<p>$lsusb &gt; usb.new</p>
<p>然后</p>
<p>vimdiff usb.old usb.new</p>
<p>找到新增加的那一行，类似下面这行</p>
<p>Bus 002 Device 004: ID 13fd:1040 Initio Corporation</p>
<p>ID后面的两个字段分别是vendor_id和product_id</p>
<p><strong>映射usb设备</strong><br>客户机命令行添加这两个参数<br>sudo kvm -usb -usbdevice host:13fd:1040 … </p>
<p>这样客户机就可以看到映射的USB设备了</p>
<p><strong>小问题</strong></p>
<p>把移动硬盘映射到客户机做测试,虚拟客户机竟然无法启动了，从远程vnc看一直停留在Booting from Hard Disk…,搜索了下下也无结果,后来灵光一闪，是不是因为移动硬盘成了启动磁盘？果然如此,修改引导参数如下</p>
<p>-boot order=c,menu=on</p>
<p>这里增加了menu=on,这样启动的时候按F12可以选择从哪个驱动器启动,重新启动，果然看到移动硬盘成了第一个启动设备，选择本地硬盘正常启动系统，从客户机里也可以看到移动硬盘。</p>
<p>据了解，现在KVM还没有命令行参数可以设置从第二块硬盘启动，也有人在提这个事情，建议order=e从第二块硬盘启动，依次类推。</p>
<p><strong>update:</strong><br>参数-usbdevice devname映射普通的USB设备有两种格式,devname可以指定为<br>host:bus.addr<br>host:vendor_id:product_id<br>上面-usbdevice host:13fd:1040指定的是host:vendor_id:product_id这种格式，对于例子中显示的USB设备，也可以以host:bus.addr格式设定参数<br>host:2.4<br>其中2为总线号,4为设备在总线上的地址Bus 002 Device 004,但是使用host:bus.addr这种格式有一个缺点，如果USB设备换一个插口，其总线和设备号会发生变化，而host:vendor_id:product_id这种格式则不受影响,即便客户机换到另一台主机上跑也是一样。</p>
<p><strong>update again(09/19/2012):</strong></p>
<p>KVM主机上插了两个同类型的usb设备,这个两个usb设备的verdor_id和product_id竟然完全一样,那只能通过host:bus.addr这种方式为客户机指定usb设备了,不然kvm主机会不知所措吧。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>轻量级开源C++ GUI开发框架KWinUI发布</title>
    <url>/2009/06/05/kwinui-0-1-0-release/</url>
    <content><![CDATA[<p>windows平台上的GUI框架已经有很多了，为什么还会有KWinUI?<br>答案就是轻量，高效，线程安全，并且可以完全掌控。</p>
<p>比较各种GUI Framework的优劣是没有太多意义的，存在的东西都有它存在的合理性和适用的范围。从来没有能满足所有需求的东西，C++亦如是，虽然它是如此的强大。KWinUI来源自开发实践，是做一个项目过程中产生的。对于一个界面并不算复杂的小项目来说，那些重量级的framework太过沉重了,而每次用SDK来写界面，显然又过于繁琐了，所以有了KWinUI。KWinUI使用C++来包装windows SDK,并没有使用太复杂的技术，太复杂的我也不会:)，主要使用了<a href="https://openwares.net/it/kwinui/gui_wndproc_thunk.html">thunk技术</a>和C++模板的静多态特性，并且仔细考虑了线程安全，毕竟在这个多核的时代，如果不是线程安全的就显得不那么in。</p>
<p>跨平台不是KWinUI的诉求，现在不是、将来也不是，现在就有很多十分优秀的跨平台GUI开发框架，比如<a href="http://vcf-online.org/">VCF</a>,wxWidget,<a href="http://www.gtk.org/">gtk+</a>,QT等。KWinUI更像是一个自娱自乐的产物，只是觉得它可能对其他一些人也有用处，所有采用lgpl协议将它公布于众，如果能对其他人有些微的帮助，那么开放它的目的就达到了。采用lgpl的好处就是你可以放心的使用KWinUI,就是在商业程序中使用也没有问题。但是如果你对KWinUI做了更好的修改，最好公布一下修改的代码，以便给其他人以帮助。就算KWinUI真的没啥价值，这样发布应该也不会对别人造成什么伤害，权当娱乐一回吧，呵呵。</p>
<p>KWinUI的主要特性如下：<br>轻量、高效、资源占用少、线程安全、使用简单，差不多就这些了。</p>
<p>KWinUI因为使用了模板技术，所以就是一堆头文件和几个cpp文件，使用起来相当简单，后面我会继续发几个简单的sample来演示如何使用KWinUI。</p>
<p>如果非要有一个版本号的话，那么就定为 0.1.0吧，因为KWinUI实在是挺稚嫩的。</p>
<p>如果有人对KWinUI有兴趣，欢迎对它进行进一步的修改。</p>
<p>KWinUI的全部源程序<a href="/downloads/kwinui/kwinui-0.1.0.zip">从此</a>下载，很小的，我保证你瞬间就能下载下来:)</p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>关于KWinUI的一些说明</title>
    <url>/2009/06/06/kwinui-explain/</url>
    <content><![CDATA[<p>在KWinUI发布的文章中有些事情没有说清楚，现在补充一下。</p>
<p>首先是KWinUI的开发和测试环境。在开发KWinUI的最初是用的Visual C++ 2005 Express和windows platform sdk,sdk的版本记不清楚了。对于开发工具，我是有新的不用旧的。后来换到了Visual C++ 2008 Express,sdk更新到了windows sdk 6.0。为什么要用Express版本，自然是因为它是免费的，而且相当的好用，运行速度飞快。VC的编辑器我是不用的，我还是习惯用vim，所以其实主要用到的还是它的Debugger，编译、链接的话用命令行也是一样的方便。KWinUI还特别考虑到了C++ Builder系列的兼容性，因为我早年用过一段时间C++ Builder，相当不错的工具。不过我只在Turbo C++ Explore下面做过测试，除了它生成的程序体积比VC大一些以外，其他都还正常。甚至KWinUI可以与VCL混合编程，我试过。所以使用VC 2005/2008 Express加上最新的windows sdk或者Turbo C++ Explore以上版本的C++ Builder,来使用KWinUI应该都是没有问题的。</p>
<p>其次是关于界面设计。KWinUI是没有可视化界面设计器的，不过对于Dialog Based应用来说，这也不是很大的问题，我习惯用<a href="http://www.resedit.net/">ResEdit</a>来设计界面，也是很方便的，ResEdit是一个很不错的资源编辑器，现在完全支持UNICODE，使用很简单。后面会放出几个这样的samples。后面的samples会尽量带上截图，可以更直观的看到用KWinUI做出来的程序长啥样子:)，其实不过就是标准的windows程序界面。KWinUI的程序支持系统的视觉样式也是很简单的，增加个manifest资源就可以了，关于这个网上介绍的不少。我也基于KWinUI做了一个支持程序换肤的库，不过还不太成熟，有机会可以展示一下。</p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>KWinUI sample 1: Hello World</title>
    <url>/2009/06/05/kwinui-first-sample/</url>
    <content><![CDATA[<p>可能没有比Hello World更适合做第一个sample了。</p>
<p>下面就是KWinUI的Hello World程序。</p>
<a id="more"></a>
<p> 1 #include “kwin.h”<br> 2 #include “kapp.h”<br> 3<br> 4 <strong>using</strong> <strong>namespace</strong> kwinui;<br> 5<br> 6 <strong>class</strong> KMainWindow : <strong>public</strong> KWindowBase<KMainWindow>{<br> 7 <strong>public</strong>:<br> 8     KMainWindow():KWindowBase<KMainWindow>(_T(“MyClassName”)){}<br> 9<br>10     BEGIN_MSG_MAP<br>11         MSG_HANDLER(WM_PAINT,OnPaint)<br>12     END_MSG_MAP(KWindowBase<KMainWindow>)<br>13<br>14     LRESULT OnPaint(UINT uMsg,WPARAM wParam,LPARAM lParam,<strong>bool</strong>&amp; bHandled){<br>15         PAINTSTRUCT ps;<br>16         HDC hDC;<br>17<br>18         RECT rect;<br>19         ::GetClientRect(m_hWnd,&amp;rect);<br>20         <br>21         hDC=::BeginPaint(m_hWnd,&amp;ps);<br>22         ::SetBkMode(hDC,TRANSPARENT);<br>23         ::DrawText(hDC,_T(“Hell World!”),-1,&amp;rect,DT_SINGLELINEDT_CENTERDT_VCENTER);<br>24         ::EndPaint(m_hWnd,&amp;ps);<br>25<br>26         <strong>return</strong> 0;<br>27     }<br>28 };<br>29<br>30 <strong>class</strong> KUIThreadApp : <strong>public</strong> KWinApp<KUIThreadApp>{<br>31 <strong>public</strong>:<br>32     <strong>bool</strong> InitInstance(){<br>33         m_pMainWindow=<strong>new</strong> KMainWindow();<br>34         m_pMainWindow-&gt;CreateOverlappedWindow(_T(“Hello World!”));<br>35         m_pMainWindow-&gt;ShowWindow(m_nCmdShow);<br>36         m_pMainWindow-&gt;UpdateWindow();<br>37<br>38         <strong>return</strong> true;<br>39     }<br>40     <strong>void</strong> ExitInstance(){<br>41         SAFE_DEL_PTR(m_pMainWindow);<br>42     }<br>43     <br>44 <strong>private</strong>:<br>45     KMainWindow* m_pMainWindow;<br>46 };<br>47<br>48 KUIThreadApp theApp;  </p>
<p><a href="/downloads/kwinui/samples/hello.cpp">代码下载</a><br>用Visual C++ 2008 Express win32 project默认设置静态链接Release版本生成的程序大小为54KB。<br>截图：<a href="/images/2009/06/hello.png"><img src="/images/2009/06/hello-300x173.png" alt="hello" title="hello"></a></p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>KWinUI Sample:圆形滑动条(round slider)</title>
    <url>/2009/07/14/kwinui-round-slider/</url>
    <content><![CDATA[<p>这是早先发表于cppblog.com的一篇文章，现在稍作整理，迁移到此处。<a href="http://www.cppblog.com/proguru/archive/2008/08/25/59932.html">原文在此</a>。<br>此sample主要是展示一个圆形的滑动条(Slider)组件，可以做播放器的音量按钮等此类的东西,还算比较酷。使用到的KRoundSlider类已经包含在KWinUI源代码中。</p>
<a id="more"></a>
<p>代码如下：<br> 1 #include “kcstcmnctrls.h”<br> 2 #include “kapp.h”<br> 3 #include “resource.h”<br> 4<br> 5 <strong>using</strong> <strong>namespace</strong> kwinui;<br> 6<br> 7 <strong>class</strong> KRndSliderDemoDlg : <strong>public</strong> KDialogBase<KRndSliderDemoDlg>{<br> 8 <strong>public</strong>:<br> 9     BEGIN_MSG_MAP<br>10         MSG_HANDLER(WM_INITDIALOG,OnInitDialog)<br>11         COMMAND_ID_HANDLER(IDOK,OnOK)<br>12         COMMAND_ID_HANDLER(IDCANCEL,OnOK)<br>13     END_MSG_MAP(KDialogBase<KRndSliderDemoDlg>)<br>14<br>15     <strong>enum</strong>{IDD=IDD_DLG_ROUND_SLIDER};<br>16     <br>17     LRESULT OnInitDialog(UINT uMsg,WPARAM wParam,LPARAM lParam,<strong>bool</strong>&amp; bHandled){<br>18         m_rscSlider1.SubclassDlgItem(IDC_SLIDER1,<strong><em>this**);<br>19         m_rscSlider2.SubclassDlgItem(IDC_SLIDER2,</em></strong>this**);<br>20<br>21         m_rscSlider1.SetRange(-179, 180, FALSE);<br>22         m_rscSlider1.SetPos(42);<br>23         m_rscSlider1.SetZero(90);<br>24         m_rscSlider1.SetInverted();<br>25<br>26         m_rscSlider1.SetDialColor(RGB(255, 255, 0));<br>27         m_rscSlider1.SetKnobColor(RGB(0, 0, 255));<br>28<br>29         m_rscSlider2.SetRange(875, 1080, FALSE);<br>30         m_rscSlider2.SetPos(948);<br>31         m_rscSlider2.SetZero(180);<br>32         m_rscSlider2.SetRadioButtonStyle();<br>33<br>34<br>35         m_rscSlider2.SetFontName(_T(“Comic Sans MS”));<br>36         m_rscSlider2.SetFontSize(14);<br>37         m_rscSlider2.SetFontItalic();<br>38         m_rscSlider2.SetTextColor(RGB(0, 0, 255));<br>39<br>40         CentralizeWindow();<br>41         <strong>return</strong> TRUE;<br>42     }<br>43     LRESULT OnOK(WORD wID,WORD wNotifyCode,HWND hWndCtrl,<strong>bool</strong>&amp; bHandled){<br>44         EndDialog(wID);<br>45         <strong>return</strong> 0;<br>46     }<br>47 <strong>private</strong>:<br>48     KRoundSlider    m_rscSlider1,m_rscSlider2;<br>49 };<br>50<br>51 <strong>class</strong> KRndSliderDemo : <strong>public</strong> KWinApp<KRndSliderDemo>{<br>52 <strong>public</strong>:<br>53     <strong>bool</strong> InitInstance(){<br>54         KRndSliderDemoDlg dlg;<br>55         dlg.DoModal();<br>56         <strong>return</strong> false;<br>57     }<br>58 };<br>59<br>60 KRndSliderDemo theApp;  </p>
<p>程序主要是使用KRoundSlider类来子类化(subclass)两个标准的滑动条控制(slider control),其实这个类接管了WM_PAINT,WM_ERASEBKGROUND等绘制消息,所以两个标准控制只不过是充当占位符(placehold)而已,换成其他的标准控制也是一样。<br>此程序编译需要用到kdc.cpp,kmisc.cpp和ktypes.cpp源文件。<br>再次推荐ResEdit，很好的资源编辑器。<br>Visual C++ 2008 Express sp1 win32 project默认设置静态链接Release版本生成的程序大小为108KB。<br>截图：<a href="/images/2009/07/round_slider.png"><img src="/images/2009/07/round_slider-300x209.png" alt="round_slider" title="round_slider"></a><br><a href="/downloads/kwinui/samples/round_slider.zip">代码下载</a></p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>KWinUI sample 2: Dialog based应用程序</title>
    <url>/2009/06/08/kwinui-sample-2-dialog-based-application/</url>
    <content><![CDATA[<p>KWinUI配合ResEdit来开发Dialog Based Application还是比较轻松的。</p>
<p>启动ResEdit添加一个简单的dialog资源，ResEdit为你生成两个文件，一个是资源文件，一个包含资源ID的头文件resource.h。我这里简单的把这两个文件的内容贴出来。</p>
<a id="more"></a>
<p>resource.h<br>1 #ifndef IDC_STATIC<br>2 #define IDC_STATIC (-1)<br>3 #endif<br>4<br>5 #define IDD_DLG_MAIN 100  </p>
<p>dlgmain.rc<br> 1 // Generated by ResEdit 1.4.4.19<br> 2 // Copyright (C) 2006-2008<br> 3 // <a href="http://www.resedit.net/">http://www.resedit.net</a><br> 4<br> 5 #include “resource.h”<br> 6 #include &lt;windows.h&gt;<br> 7 #include &lt;commctrl.h&gt;<br> 8 #include &lt;richedit.h&gt;<br> 9<br>10<br>11 //<br>12 // Dialog resources<br>13 //<br>14 IDD_DLG_MAIN DIALOG 0, 0, 186, 95<br>15 STYLE DS_3DLOOK  DS_CENTER  DS_MODALFRAME  DS_SHELLFONT WS_VISIBLE  WS_BORDER  WS_CAPTION  WS_DLGFRAME  WS_POPUP  WS_SYSMENU<br>16 CAPTION “Dialog”<br>17 FONT 8, “Ms Shell Dlg 2”<br>18 {<br>19     DEFPUSHBUTTON   “OK”, IDOK, 129, 7, 50, 14, BS_DEFPUSHBUTTON<br>20     PUSHBUTTON      “Cancel”, <strong>IDCANCEL</strong>, 129, 24, 50, 14, BS_PUSHBUTTON<br>21 }  </p>
<p>然后就是我们的KWinUI主程序了，内容如下：<br> 1 #include “resource.h”<br> 2 #include “kapp.h”<br> 3 #include “kwin.h”<br> 4<br> 5 <strong>using</strong> <strong>namespace</strong> kwinui;<br> 6<br> 7 <strong>class</strong> KDlgMain : <strong>public</strong> KDialogBase<KDlgMain>{<br> 8 <strong>public</strong>:<br> 9     <strong>typedef</strong> KDialogBase<KDlgMain> __base;<br>10     <strong>enum</strong>{IDD=IDD_DLG_MAIN};<br>11<br>12     BEGIN_MSG_MAP<br>13         COMMAND_ID_HANDLER(IDOK,OnOK)<br>14         COMMAND_ID_HANDLER(IDCANCEL,OnCancel)<br>15     END_MSG_MAP(__base)<br>16<br>17     LRESULT OnOK(WORD wID,WORD wNotifyCode,HWND hWndCtrl,<strong>bool</strong>&amp; bHandled){<br>18         ShowMessage(_T(“KWinUI dialog based program sample!”));<br>19         <strong>return</strong> TRUE;<br>20     }<br>21<br>22     LRESULT OnCancel(WORD wID,WORD wNotifyCode,HWND hWndCtrl,<strong>bool</strong>&amp; bHandled){<br>23         EndDialog(wID);<br>24         ::PostQuitMessage(0);<br>25         <strong>return</strong> TRUE;<br>26     }<br>27 };<br>28<br>29 <strong>class</strong> KDlgApp : <strong>public</strong> KWinApp<KDlgApp>{<br>30 <strong>public</strong>:<br>31     <strong>bool</strong> InitInstance(){<br>32         m_pMainWindow=<strong>new</strong> KDlgMain();<br>33         m_pMainWindow-&gt;Create(NULL);<br>34         <strong>return</strong> true;<br>35     }<br>36 <strong>private</strong>:<br>37     KDlgMain* m_pMainWindow;<br>38 };<br>39<br>40 KDlgApp theApp;  </p>
<p>当然，我这里创建的是一个无模式对话框，使用了KWinUI的消息循环，你也可以把第33、34行改为<br>m_pMainWindow-&gt;DoModal();<br>return false;<br>这样的话会创建一个模式对话框，使用对话框自己提供的消息循环。<br>使用模式对话框时，可以将程序的第24行注释掉，但是对于无模式对话框，此行代码必须存在才能正确的结束程序。</p>
<p>实际上KWinUI程序的风格和WTL是很相似的，有WTL开发经历的童鞋看到这段代码应该感觉比较亲切。<br>用Visual C++ 2008 Express win32 project默认设置静态链接Release版本生成的程序大小为47KB。<br><a href="/downloads/kwinui/samples/dialog_based.zip">代码下载</a><br>截图：<a href="/images/2009/06/dialog.png"><img src="/images/2009/06/dialog.png" alt="dialog" title="dialog"></a></p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>KWinUI sample:工作线程(work thread)中的UI窗口</title>
    <url>/2009/07/13/kwinui-work-thread-ui/</url>
    <content><![CDATA[<p>在一个多线程应用程序中，进程创建的第一个线程我们称之为主线程(main thread),而从主线程中通过系统调用派生的其他线程称之为工作线程(work thread)。虽然习惯上这么称呼，而在实际上这两种线程并没有本质的差别，他们的能力是完全一样的，唯一的区别就在于派生的先后顺序而已。</p>
<a id="more"></a>
<p>下面来演示一下KWinUI中如何使工作线程拥有窗口，代码如下：<br> 1 #include “kwin.h”<br> 2 #include “kctrls.h”<br> 3 #include “kapp.h”<br> 4<br> 5 <strong>using</strong> <strong>namespace</strong> kwinui;<br> 6<br> 7 <strong>class</strong> KMainWindow : <strong>public</strong> KWindowBase<KMainWindow>{<br> 8 <strong>public</strong>:<br> 9     KMainWindow():KWindowBase<KMainWindow>(_T(“MyClassName”)){}<br>10     BEGIN_MSG_MAP<br>11         MSG_HANDLER(WM_CREATE,OnCreate)<br>12         COMMAND_ID_HANDLER(1000,OnExit)<br>13     END_MSG_MAP(KWindowBase<KMainWindow>)<br>14<br>15     LRESULT OnCreate(UINT uMsg,WPARAM wParam,LPARAM lParam,<strong>bool</strong>&amp; bHandled){<br>16         RECT rect1={30,30,90,60};<br>17         m_btnExit.Create(<strong><em>this**,_T(“exit”),WS_CHILDWS_VISIBLEWS_TABSTOP,rect1,1000);<br>18         <strong>return</strong> 0;<br>19     }<br>20     LRESULT OnExit(WORD wID,WORD wNotifyCode,HWND hWndCtrl,<strong>bool</strong>&amp; bHandled){<br>21         m_nRetCode=wID;<br>22         SendMessage(WM_CLOSE);<br>23         <strong>return</strong> 0;<br>24     }<br>25 <strong>private</strong>:<br>26     <strong>int</strong>     m_nRetCode;<br>27     KButton m_btnExit;<br>28 };<br>29<br>30 <strong>class</strong> KWorkThread : <strong>public</strong> KThreadImpl<KWorkThread>{<br>31 <strong>public</strong>:<br>32     KWorkThread():KThreadImpl<KWorkThread>(CREATE_SUSPENDED){}<br>33     <strong>bool</strong> InitInstance(){<br>34         m_pMainWindow=<strong>new</strong> KMainWindow();<br>35         m_pMainWindow-&gt;CreateOverlappedWindow(_T(“work thread’s main window”));<br>36         <strong>return</strong> true;<br>37     }<br>38     <strong>void</strong> ExitInstance(){<br>39         SAFE_DEL_PTR(m_pMainWindow);<br>40     }<br>41 <strong>public</strong>:<br>42     KMainWindow</em> m_pMainWindow;<br>43 };<br>44<br>45 **class</strong> KThreadUIApp : <strong>public</strong> KWinApp<KThreadUIApp>{<br>46 <strong>public</strong>:<br>47     KThreadUIApp():m_pMainWindow(0),m_pWorkThread(0){}<br>48     <strong>bool</strong> InitInstance(){<br>49         m_pWorkThread=<strong>new</strong> KWorkThread();<br>50         m_pWorkThread-&gt;ResumeThread();<br>51<br>52         m_pMainWindow=<strong>new</strong> KMainWindow();<br>53         m_pMainWindow-&gt;CreateOverlappedWindow(_T(“main thread’s main window”));<br>54<br>55         <strong>return</strong> true;<br>56     }<br>57     <strong>void</strong> ExitInstance(){<br>58         SAFE_DEL_PTR(m_pMainWindow);<br>59         SAFE_DEL_PTR(m_pWorkThread);<br>60     }<br>61     <br>62 <strong>private</strong>:<br>63     KMainWindow*    m_pMainWindow;<br>64     KWorkThread*    m_pWorkThread;<br>65 };<br>66<br>67 KThreadUIApp theApp;  </p>
<p>我们可以很清楚的看到，工作线程拥有UI窗口的方式与主线程是完全一样的，不过主线程多了一项简单的工作，创建工作线程而已。</p>
<p>我们甚至可以让主线程提前结束，而由工作线程继续显示窗口来与用户交互，这就更可以证明这两种线程是完全一样的。</p>
<p>用Visual C++ 2008 Express win32 project默认设置静态链接Release版本生成的程序大小为57KB。<br>截图：<a href="/images/2009/07/threadui.png"><img src="/images/2009/07/threadui-300x188.png" alt="threadui" title="threadui"></a><br><a href="/downloads/kwinui/samples/thread_ui.cpp">代码下载</a></p>
<p>预告：近期会推出KWinUI换肤框架的Demo，敬请期待…</p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>debian系统L2TP/IPSec VPN客户端配置</title>
    <url>/2012/10/19/l2tp-ipsec-client-setup/</url>
    <content><![CDATA[<p>客户端大部分参数与服务器端是一致的</p>
<a id="more"></a>
<p><strong>安装配置IPSec</strong></p>
<h1 id="apt-get-install-openswan"><a href="#apt-get-install-openswan" class="headerlink" title="apt-get install openswan"></a>apt-get install openswan</h1><p>编辑/etc/ipsec.conf文件</p>
<p> 1 version 2.0<br> 2<br> 3 config setup<br> 4     dumpdir=/var/run/pluto/<br> 5     nat_traversal=yes<br> 6     virtual_private=%v4:10.0.0.0/8,%v4:192.168.0.0/16,%v4:172.16.0.0/12,%v4:25.0.0.0/8,%v6:fd00::/8,%v6:fe80::/10<br> 7     oe=off<br> 8     protostack=netkey<br> 9<br>10 conn L2TP-PSK<br>11        authby=secret<br>12        pfs=no<br>13        auto=add<br>14        keyingtries=3<br>15        rekey=no<br>16        ikelifetime=8h<br>17        keylife=8h<br>18        type=transport<br>19        left=your_local_ip<br>20        leftprotoport=UDP/1701<br>21        right=your_vpn_server_ip<br>22        rightprotoport=UDP/1701 </p>
<p>编辑 /etc/ipsec.secrets添加PSK</p>
<p>your_local_ip your_vpn_server_ip: PSK “yourpsk”</p>
<p><strong>修改内核参数</strong></p>
<p>root账户运行以下命令<br>for each in /proc/sys/net/ipv4/conf/*<br>do<br>echo 0 &gt; $each/accept_redirects<br>echo 0 &gt; $each/send_redirects<br>done</p>
<p><strong>校验IPSec是否正常</strong></p>
<p>先安装lsof</p>
<h1 id="apt-get-install-lsof"><a href="#apt-get-install-lsof" class="headerlink" title="apt-get install lsof"></a>apt-get install lsof</h1><p>校验</p>
<h1 id="ipsec-verify"><a href="#ipsec-verify" class="headerlink" title="ipsec verify"></a>ipsec verify</h1><p><strong>安装配置L2TP</strong></p>
<p>#apt-get install xl2tpd</p>
<p>编辑/etc/xl2tpd.conf</p>
<p> 1 [global]        <br> 2 ipsec saref=yes<br> 3<br> 4 [lac myvpn]             # L2tp Access Concentrator 访问集中器配置,名字随意<br> 5 lns=your_vpn_server_ip  # L2TP Network Server<br> 6 ppp debug=yes<br> 7 pppoptfile=/etc/ppp/options.xl2tpd.client<br> 8 length bit=yes<br> 9 require authentication = yes<br>10 refuse pap = yes        <br>11 refuse chap = yes </p>
<p><strong>安装配置ppp</strong></p>
<p>#apt-get install ppp<br>编辑/etc/ppp/options.xl2tpd.client<br> 1 require-mschap-v2   #使用M$的CHAP v2认证协议<br> 2 ipcp-accept-local   #IPCP(IP Control Protocol)协议相关<br> 3 ipcp-accept-remote<br> 4 refuse-eap          #拒绝EAP认证<br> 5 noccp               #禁止压缩控制协议协商(Compress Control Protocol)<br> 6 noauth              <br> 7 idle 1800       <br> 8 mtu 1410            #最大传输单元Maximum Transmit Unit<br> 9 mru 1410            #最大接受单元Maximum Receive Unit<br>10 defaultroute        #IPCP协商成功后在系统路由表里增加默认路由记录,使用ppp对端作为网关<br>11 usepeerdns          #使用对端提供的DNS服务器地址<br>12 debug<br>13 lock<br>14 connect-delay 5000<br>15 name username          #VPN用户名<br>16 password password      #密码 </p>
<p><strong>VPN拨号</strong></p>
<p>连接到VPN服务器connect to myvpn</p>
<h1 id="echo-“c-myvpn”-gt-var-run-xl2tpd-xl2tpd-control"><a href="#echo-“c-myvpn”-gt-var-run-xl2tpd-xl2tpd-control" class="headerlink" title="echo “c myvpn” &gt; /var/run/xl2tpd/xl2tpd-control"></a>echo “c myvpn” &gt; /var/run/xl2tpd/xl2tpd-control</h1><p>从VPN服务器断开disconnect from myvpn</p>
<h1 id="echo-“d-myvpn”-gt-var-run-xl2tpd-xl2tpd-control"><a href="#echo-“d-myvpn”-gt-var-run-xl2tpd-xl2tpd-control" class="headerlink" title="echo “d myvpn” &gt; /var/run/xl2tpd/xl2tpd-control"></a>echo “d myvpn” &gt; /var/run/xl2tpd/xl2tpd-control</h1>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>延迟中断请求级(lazy IRQL)</title>
    <url>/2009/08/25/lazy-irql/</url>
    <content><![CDATA[<p>因为访问可编程中断控制器(PIC)是相对较慢的操作,需要访问I/O总线来改变中断请求级(IRQL)的硬件抽象层(HAL)，比如为了访问中断控制器(PIC)和32位高级配置电源接口(ACPI)系统，实现了一个性能优化 ,谓之延迟中断请求级(lazy IRQL),来尽量避免可编程中断控制器(PIC)访问。当中断请求级(IRQL)上升以后，硬件抽象层(HAL)在内部记录该中断请求级(IRQL)而不是来改变中断屏蔽(interrupt mask)。如果一个低优先级的中断随之而来，硬件抽象层(HAL)为前面的中断设置合适的中断屏蔽(interrupt mask)，也就是实实在在的提升中断请求级(IRQL)，从而延迟这个低优先级的中断直到中断请求级(IRQL)降低。这样以来，当中断请求级(IRQL)升高时如果没有低优先级的中断发生，硬件抽象层(HAL)并不真正的去修改可编程中断控制器(PIC)。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>申请Let’s Encrypt统配SSL证书</title>
    <url>/2018/06/02/lets-encrypt-wildcard-ssl-cert/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>安装certbot</strong></p>
<p>stretch源里的版本太低，因此需要配置stretch backports源，然后用以下命令安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install certbot -t stretch-backports</span><br></pre></td></tr></table></figure>

<p>或者直接去官方下载安装使用：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//dl.eff.org/certbot-auto</span></span><br><span class="line">$ chmod a+x ./certbot-auto</span><br><span class="line">$ ./certbot-auto --help</span><br></pre></td></tr></table></figure>

<p><strong>申请统配证书</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo certbot certonly \\</span><br><span class="line">--server https:<span class="comment">//acme-v02.api.letsencrypt.org/directory \\</span></span><br><span class="line">--manual --preferred-challenges dns \\</span><br><span class="line">-d *.openwares.net</span><br></pre></td></tr></table></figure>
<p>或者如果手工安装certbot的话请用certbot-auto命令<br>这里只是申请证书，并不会自动安装，需要手工配置应用服务器，那些自动部署证书的插件并不是很好用。</p>
<p>要申请wildcard子域统配证书，certbot必须为0.22.0或以上版本，而且要使用ACMEv2服务器申请证书。</p>
<p>然后会有一通问题，看清楚回答即可，后面会要求为申请证书的域名配置TXT记录，类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Please deploy a DNS TXT record under the name</span><br><span class="line">_acme-challenge.openwares.net <span class="keyword">with</span> the following value:</span><br><span class="line"></span><br><span class="line">ZvjRBkEYcMVZSEslsuj*******************</span><br><span class="line"></span><br><span class="line">Before continuing, verify the record is deployed.</span><br></pre></td></tr></table></figure>
<p>按照要求配置域名TXT记录，确认TXT记录生效</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ host -t TXT _acme-challenge.openwares.net</span><br><span class="line">_acme-challenge.openwares.net descriptive text <span class="string">&quot;ZvjRBkEYcMVZSEslsu************&quot;</span></span><br></pre></td></tr></table></figure>
<p>TXT记录生效可能稍微会需要一些时间，确认生效后继续,如果通过验证则会生成证书</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Waiting <span class="keyword">for</span> verification...</span><br><span class="line">Cleaning up challenges</span><br><span class="line"></span><br><span class="line">IMPORTANT NOTES:</span><br><span class="line"> - Congratulations! Your certificate and chain have been saved at:</span><br><span class="line"> /etc/letsencrypt/live/openwares.net/fullchain.pem</span><br><span class="line"> Your key file has been saved at:</span><br><span class="line"> /etc/letsencrypt/live/openwares.net/privkey.pem</span><br><span class="line"> Your cert will expire on <span class="number">2018</span>-<span class="number">08</span>-<span class="number">31.</span> To obtain a <span class="keyword">new</span> or tweaked</span><br><span class="line"> version <span class="keyword">of</span> <span class="built_in">this</span> certificate <span class="keyword">in</span> the future, simply run certbot</span><br><span class="line"> again. To non-interactively renew *all* <span class="keyword">of</span> your certificates, run</span><br><span class="line"> <span class="string">&quot;certbot renew&quot;</span></span><br><span class="line"> - If you like Certbot, please consider supporting our work by:</span><br><span class="line"></span><br><span class="line"> Donating to ISRG / Let<span class="string">&#x27;s Encrypt: https://letsencrypt.org/donate</span></span><br><span class="line"><span class="string"> Donating to EFF: https://eff.org/donate-le</span></span><br></pre></td></tr></table></figure>

<p>现在已经有了wildcard证书了，将证书配置到你的web服务器中就ok了。</p>
<p>证书的有效期只有三个月，距离失效期30日内，可以简单的执行以下命令来更新证书：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo certbot renew</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>Libreoffice gnome整合</title>
    <url>/2012/06/14/libreoffice-gnome/</url>
    <content><![CDATA[<p>libreoffice原生界面的菜单栏外观太差了,而且与系统输入法整合的很不好</p>
<a id="more"></a>
<p>通过安装包libreoffice-gnome可以使libreoffice与gnome的外观保持一致,与系统输入法兼容性更好,还可以安装与GTK+3整合的包libreoffice-gtk3</p>
<p>这样libreoffice就好用多了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>likely,unlikely宏与GCC内建函数__builtin_expect()</title>
    <url>/2009/06/04/likely-unlikely/</url>
    <content><![CDATA[<p>先罗嗦几句</p>
<p>最近在读linux 2.6 内核,虽然以前已经看了很多相关的知识,&lt;&lt;linux内核完全注释(0.11)&gt;&gt;也看了2,3遍,但读2.6内核仍然感到很吃力。面对2.6如此庞大的内核，信心真的不是很足，而且好像也没有很好的、有帮助的论坛来一起探讨，哎！现在正在边看&lt;&lt;情景分析&gt;&gt;，边看最新的内核，自&lt;&lt;情景分析&gt;&gt;出版以来，内核已经有了很多的变化，好难读啊！如果这样读下去算不算“皓首穷经”呢，不得而知了！</p>
<a id="more"></a>
<p>言归正传</p>
<p>在读linux/kernel/fork.c的时候遇到了unlikely宏定义，一路追踪，最后找到了GCC内建函数__builtin_expect(),查阅GCC手册，发现其定义如下：</p>
<p>long __builtin_expect (long exp, long c) [Built-in Function]<br>You may use __builtin_expect to provide the compiler with branch prediction<br>information. In general, you should prefer to use actual profile feedback for this<br>(‘-fprofile-arcs’), as programmers are notoriously bad at predicting how their<br>programs actually perform. However, there are applications in which this data is<br>hard to collect.<br>The return value is the value of exp, which should be an integral expression. The<br>value of c must be a compile-time constant. The semantics of the built-in are that it<br>is expected that exp == c. For example:<br>if (__builtin_expect (x, 0))<br>foo ();<br>would indicate that we do not expect to call foo, since we expect x to be zero. Since<br>you are limited to integral expressions for exp, you should use constructions such as<br>if (__builtin_expect (ptr != NULL, 1))<br>error ();<br>when testing pointer or floating-point values.</p>
<p>大致是说，由于大部分程序员在分支预测方面做得很糟糕，所以GCC提供了这个内建函数来帮助程序员处理分支预测，优化程序。其第一个参数exp为一个整型表达式，这个内建函数的返回值也是这个exp,而c为一个编译期常量，这个函数的语义是：你期望exp表达式的值等于常量c，从而GCC为你优化程序，将符合这个条件的分支放在合适的地方。</p>
<p>因为这个程序只提供了整型表达式，所以如果你要优化其他类型的表达式，可以采用指针的形式。</p>
<p>unlikely的定义如下：</p>
<p>#define unlikely(x) __builtin_expect(!!(x), 0)</p>
<p>也就是说我们期望表达式x的值为0，从而如果我们用</p>
<p>…….</p>
<p>if(unlikely(x)){<br>    bar();<br>}<br>来测试条件的话，我们就不期望bar()函数执行，所以该宏的名字用unlikely也就是不太可能来表示。<br>likely宏与此类似.</p>
<p>说到底__builtin_expect函数就是为了优化可能性大的分支程序。</p>
<p>PS:<a href="http://blog.csdn.net/mopyman/archive/2006/02/09/595302.aspx">此文</a>最早发表于CSDN。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>linode最新内核docker服务无法启动</title>
    <url>/2018/11/25/linode-latest-kernel-docker-service-faile/</url>
    <content><![CDATA[<a id="more"></a>
<p>升级完linode发现docker服务无法启动了，containerd服务报找不到overlay模块</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">modprobe: FATAL: Module overlay not found</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>linode内核早就启用overlay模块了，这是docker bug导致的。</p>
<p>执行以下命令来解决此问题：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ su -</span><br><span class="line">$ mkdir -p /etc/systemd/system/containerd.service.d/</span><br><span class="line"></span><br><span class="line">$ cat &lt;&lt; EOF &gt; <span class="regexp">/etc/</span>systemd/system/containerd.service.d/override.conf</span><br><span class="line">\[Service\]</span><br><span class="line">ExecStartPre=</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">$ systemctl daemon-reload</span><br><span class="line"></span><br><span class="line">$ systemctl start docker</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://www.linode.com/community/questions/17114/docker-wont-start-using-the-latest-linode-kernel#answer-67343">Docker won’t start using the latest Linode kernel</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>linux系统添加windows共享打印机</title>
    <url>/2012/05/14/linux-add-smb-printer/</url>
    <content><![CDATA[<p>Debian AMD64 testing添加windows共享打印机简单步骤</p>
<a id="more"></a>
<p>1、安装cups(Common UNIX Printing System)<br>#apt-get install cups</p>
<p>2、打开cups web管理界面</p>
<p>浏览器输入网址<a href="http://127.0.0.1:631打开cups管理界面">http://127.0.0.1:631打开cups管理界面</a></p>
<p>3、添加共享windows共享打印机</p>
<p>进入Administration页面,点击”Add Printer”,选择”Windows Printer via SAMBA”,点击continue。然后在”Connection:”输入框内输入共享打印机的地址,</p>
<p>smb://ip/HPLaserJ</p>
<p>ip是共享打印机所在windows机器的ip,HPLaserJ是打印机的网络共享名。</p>
<p>如果需要密码来访问共享打印机,则需要添加用户名和密码,如下<br>smb://username:passwd@ip/printer_share_name</p>
<p>点击continue继续,为共享打印机提供一个本地名字name,Description与Location字段选填，如果不从本机对外继续共享此网络打印机,不要勾选”Share This Printer”,默认未勾选。</p>
<p>点击continue继续,Make栏选择打印机厂商,这里选择HP,点击continue继续,选择打印机型号Model,这是选择的是”HP LaserJet P1008 Foomatic/foo2xqx (recommended)(en)”,然后点击add printer添加网络打印机完成。</p>
<p>4、打印测试页</p>
<p>从CUPS管理界面进入printer页面，点击刚添加的共享打印机,这里是P1008,然后从maintence下拉框选择Print Test Page即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux amd64 memory mapping</title>
    <url>/2019/02/16/linux-amd64-memory-mapping/</url>
    <content><![CDATA[<a id="more"></a>
<p>amd64架构linux kernel使用四级页表映射结构，但是存在两套terminology来描述这个事情</p>
<p>其一：</p>
<p>PML4(Page Map Leve4)(Level 4) -&gt; PDP(Page Directory Pointer) (Level 3) -&gt; PD(Page Directory) (Level 2) -&gt; PTE(Page Table Entry)(Level 1)</p>
<p>另一：</p>
<p>PGD(Page Global Directory)(Level 4) -&gt; PUD(Page Upper Directory)(Level 3) -&gt; PMD(Page Middle Directory)(Level 2) -&gt; PTE(Page Table Entry) (Level 1)</p>
<p>这两套术语其实表达的都是一样的东西,CR3寄存器保存Level 4表的物理地址，Level 4只有一页，4K大小，总共512个表项，每个表项可以寻址512GB内存，总共可以寻址256TB内存。<br>当前amd64处理器只是用了64位中的48位来寻址，因此使用四级页表时，虚拟地址的低48位为9+9+9+9+12映射结构，每个物理页框(Page Frame)为4K，4K地址对齐。<br>当使用2M的大页/巨页时，使用三级页表映射，虚拟地址的低48位为9+9+9+21映射结构，每个物理页框为2M,2M地址对齐。</p>
<p>参见下面两图：</p>
<p>4K页面地址转换<br><img src="https://www.ibm.com/developerworks/cn/linux/l-lvm64/images/image004.gif" alt="4K页面地址转换"></p>
<p>2M 页面地址转换<br><img src="https://www.ibm.com/developerworks/cn/linux/l-lvm64/images/image006.gif" alt="2M 页面地址转换"></p>
<p>为了支持更大的线性地址空间，以后的CPU会扩展到57位虚拟地址寻址。linux目前已经提供5级页表映射，如果启用5级页表，会在PGD和PUD之间插入新的一级页表，叫做P4D(Page 4 Directory)，这样PGD会成为第五级页表,参见[1]。</p>
<p>References:<br>[1]<a href="https://lwn.net/Articles/717293/">Five-level page tables</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>linux查看cpu型号,物理cpu个数,逻辑cpu个数,cpu核心数</title>
    <url>/2014/10/23/linux-cpuinfo/</url>
    <content><![CDATA[<a id="more"></a>
<p>无需第三方工具,proc文件系统里面的/proc/cpuinfo提供了丰富的cpu信息。<br>其输出类似如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">processor : <span class="number">0</span></span><br><span class="line">vendor_id : AuthenticAMD</span><br><span class="line">cpu family : <span class="number">16</span></span><br><span class="line">model : <span class="number">4</span></span><br><span class="line">model name : Quad-Core AMD Opteron(tm) Processor <span class="number">8382</span></span><br><span class="line">stepping : <span class="number">2</span></span><br><span class="line">microcode : <span class="number">0x1000086</span></span><br><span class="line">cpu MHz : <span class="number">2611.977</span></span><br><span class="line">cache size : <span class="number">512</span> KB</span><br><span class="line">physical id : <span class="number">0</span></span><br><span class="line">siblings : <span class="number">4</span></span><br><span class="line">core id : <span class="number">0</span></span><br><span class="line">cpu cores : <span class="number">4</span></span><br><span class="line">apicid : <span class="number">4</span></span><br><span class="line">initial apicid : <span class="number">0</span></span><br><span class="line">fpu : yes</span><br><span class="line">fpu_exception : yes</span><br><span class="line">cpuid level : <span class="number">5</span></span><br><span class="line">wp : yes</span><br><span class="line">flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm 3dnowext 3dnow constant_tsc rep_good nopl nonstop_tsc extd_apicid pni monitor cx16 popcnt lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt hw_pstate npt lbrv svm_lock nrip_save</span><br><span class="line">bogomips : <span class="number">5223.95</span></span><br><span class="line">TLB size : <span class="number">1024</span> 4K pages</span><br><span class="line">clflush size : <span class="number">64</span></span><br><span class="line">cache_alignment : <span class="number">64</span></span><br><span class="line">address sizes : <span class="number">48</span> bits physical, <span class="number">48</span> bits virtual</span><br><span class="line">power management: ts ttp tm stc 100mhzsteps hwpstate</span><br></pre></td></tr></table></figure>

<p><strong>型号和逻辑CPU个数</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/cpuinfo grep <span class="string">&#x27;model name&#x27;</span> cut -f2 -d: uniq -c</span><br><span class="line"><span class="number">32</span> Quad-Core AMD Opteron(tm) Processor <span class="number">8382</span></span><br></pre></td></tr></table></figure>
<p>可以看到有32个逻辑CPU，后面是型号</p>
<p><strong>物理CPU个数</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/cpuinfo grep <span class="string">&#x27;physical id&#x27;</span> uniq -d</span><br><span class="line">physical id : <span class="number">0</span></span><br><span class="line">physical id : <span class="number">1</span></span><br><span class="line">physical id : <span class="number">2</span></span><br><span class="line">physical id : <span class="number">3</span></span><br><span class="line">physical id : <span class="number">4</span></span><br><span class="line">physical id : <span class="number">5</span></span><br><span class="line">physical id : <span class="number">6</span></span><br><span class="line">physical id : <span class="number">7</span></span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/cpuinfo grep <span class="string">&#x27;physical id&#x27;</span> uniq -d cut -f1 -d: uniq -c</span><br><span class="line"><span class="number">8</span> physical id</span><br></pre></td></tr></table></figure>
<p>可以看到有8颗物理CPU</p>
<p><strong>每颗CPU核心数</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/cpuinfo grep <span class="string">&#x27;cpu cores&#x27;</span> uniq</span><br><span class="line">cpu cores : <span class="number">4</span></span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/cpuinfo grep <span class="string">&#x27;core id&#x27;</span> sort uniq</span><br><span class="line">core id : <span class="number">0</span></span><br><span class="line">core id : <span class="number">1</span></span><br><span class="line">core id : <span class="number">2</span></span><br><span class="line">core id : <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>8*4刚好是32颗逻辑CPU,如果有超线程技术则不是简单的相乘就可以，还要乘以每个核心的线程数。</p>
<p>还有一个命令lscpu,可以总览系统cpu概况：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lscpu</span><br><span class="line">Architecture: x86_64</span><br><span class="line">CPU op-mode(s): <span class="number">32</span>-bit, <span class="number">64</span>-bit</span><br><span class="line">Byte Order: Little Endian</span><br><span class="line">CPU(s): <span class="number">32</span></span><br><span class="line">On-line CPU(s) list: <span class="number">0</span>-<span class="number">31</span></span><br><span class="line">Thread(s) per core: <span class="number">1</span></span><br><span class="line">Core(s) per socket: <span class="number">4</span></span><br><span class="line">Socket(s): <span class="number">8</span></span><br><span class="line">NUMA node(s): <span class="number">4</span></span><br><span class="line">Vendor ID: AuthenticAMD</span><br><span class="line">CPU family: <span class="number">16</span></span><br><span class="line">Model: <span class="number">4</span></span><br><span class="line">Stepping: <span class="number">2</span></span><br><span class="line">CPU MHz: <span class="number">2611.977</span></span><br><span class="line">BogoMIPS: <span class="number">5224.55</span></span><br><span class="line">Virtualization: AMD-V</span><br><span class="line">L1d cache: 64K</span><br><span class="line">L1i cache: 64K</span><br><span class="line">L2 cache: 512K</span><br><span class="line">L3 cache: 6144K</span><br><span class="line">NUMA node0 CPU(s): <span class="number">0</span>-<span class="number">3</span></span><br><span class="line">NUMA node1 CPU(s): <span class="number">4</span>-<span class="number">7</span></span><br><span class="line">NUMA node2 CPU(s): <span class="number">8</span>-<span class="number">11</span></span><br><span class="line">NUMA node3 CPU(s): <span class="number">12</span>-<span class="number">31</span></span><br></pre></td></tr></table></figure>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux基于cron的rman自动增量备份脚本及设置</title>
    <url>/2012/03/22/linux-cron-rman-incremental-bakcup/</url>
    <content><![CDATA[<p>rman及catalog运行于linux,target数据库运行于windows,oracle版本一致,而且都是64位平台。</p>
<a id="more"></a>
<p>历史原因数据库运行于windows,但显然linux更适合于系统管理,因此此处rman暂时运行于混合环境。</p>
<p><strong>备份策略</strong></p>
<p>数据库用于OLTP系统,容量中等,全库接近400G,但有大约200G的数据是不变化只用于查询的,将其表空间置于read only模式,备份时可以忽略这些数据。其他200G左右的数据每天都在发生变化,如果系统需要回复,要尽可能的恢复到最新的数据。已经做了<a href="https://openwares.net/database/oracle_10g_windows_x64_dataguard.html">dataguard灾备</a>。</p>
<p>基于以上情况制定备份策略，每周日凌晨做0级备份，周一到周六做1级备份。</p>
<p>target数据库要打开<a href="https://openwares.net/database/oracle_10g_incremental_backup.html">块变化追踪机制</a>,然后<a href="https://openwares.net/database/rman_catalog_database.html">建立恢复目录</a>。</p>
<p><strong>备份脚本</strong></p>
<p> 1 #!/bin/bash<br> 2<br> 3 <strong>set</strong> -e<br> 4<br> 5 #############################################################<br> 6 # sunday incremental level 0<br> 7 # other day incremental level 1<br> 8 #<br> 9 # rman and catalog on oracle 10.2.0.4 64bits for debian amd64<br>10 # target on oracle 10.2.0.4 64bits for windows 2003 r2 sp2 x64<br>11 #############################################################<br>12<br>13 <strong>export</strong> ORACLE_HOME=/u01/app/oracle/product/10.2.0/db_1<br>14 rman_bin=$ORACLE_HOME/bin/rman<br>15<br>16 weekday=`date +%a`<br>17 <strong>case</strong> <strong>“</strong>${weekday}<strong>“</strong> <strong>in</strong><br>18<br>19     <strong>“**Sun</strong>“<strong>**)</strong><br>20         inc_level=0<br>21         <strong>;;</strong><br>22     *<strong>)</strong><br>23         inc_level=1<br>24         <strong>;;</strong><br>25 <strong>esac</strong><br>26<br>27 rman_user=rman_usr<br>28 rman_passwd=rman_usr<br>29 catalog_inst_name=catalogd<br>30<br>31 target_sys_passwd=oracle<br>32 target_inst_name=db_test<br>33<br>34 log_file=/var/log/rman/`date +%F`<em>${inc_level}.log<br>35 bak_file=<strong>‘**d:\rman_bak\bak_%U</strong>‘**<br>36 arc_file=**’**d:\rman_bak\arc</em>%U**’**<br>37 ctl_file=<strong>‘**d:\rman_bak\ctl_%F</strong>‘**<br>38<br>39 $rman_bin log ${log_file} <strong>&gt;&gt;</strong> /dev/null 2<strong>&gt;&amp;1</strong> <strong>&lt;&lt;EOF</strong><br>40<br>41 connect catalog ${rman_user}/${rman_passwd}@${catalog_inst_name};<br>42 connect target sys/${target_sys_passwd}@${target_inst_name};<br>43<br>44 run {<br>45  configure backup optimization on;<br>46  configure archivelog deletion policy to applied on standby;<br>47  configure retention policy to redundancy 3;<br>48  configure controlfile autobackup on;<br>49  configure controlfile autobackup format for device type disk to ‘${ctl_file}’;<br>50<br>51  allocate channel ch1 device type disk;<br>52  backup incremental level ${inc_level} cumulative database format ‘${bak_file}’ skip readonly plus archivelog format ‘${arc_file}’;<br>53<br>54  release channel ch1;<br>55 }<br>56<br>57 crosscheck backup;<br>58 delete noprompt obsolete;<br>59<br>60 delete noprompt archivelog all completed before ‘sysdate - 14’;<br>61<br>62 exit;<br>63 <strong>EOF</strong><br>64<br>65 <strong>exit</strong> 0 </p>
<p>rman操作日志记录于/var/log/rman目录下,需要在/var/log目录先新建rman子目录,不然rman会报错无法打开log文件。脚本很简单,就不解释了。</p>
<p><strong>自动运行</strong></p>
<p>打开/etc/crontab,编辑cron.daily所在的那行，将其第一个字段m(minute)改为0或其他小于60的数值,第二个字段h(hour)改为0,这样以来cron守护程序每天的0点稍后自动运行/etc/cron.daily目录下的脚本。然后将备份脚本拷贝到/etc/cron.daily目录下,注意为备份脚本添加可执行权限。</p>
<p>*<em>特别注意：crond或者直接说run-parts不会执行带有.sh扩展名的脚本,也就说/etc/cron.</em>/目录下的脚本不要带任何扩展名。**</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>linux查看设备usb版本号</title>
    <url>/2014/10/31/linux-device-usb-version/</url>
    <content><![CDATA[<a id="more"></a>
<p>usb规范目前有3个主要的版本,1.0,1.1,2.0,3.0和3.1,在linux系统下可以这样查看设备的usb版本:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lsusb -s <span class="number">001</span>:<span class="number">004</span> -v grep bcdUSB</span><br><span class="line">bcdUSB <span class="number">2.00</span></span><br></pre></td></tr></table></figure>

<p>lsusb的-s选项指定总线编号和设备在总线上的编号,可以事先用lsusb得到这些编号</p>
<p>bcdUSB域包含该描述符遵循的USB规范的版本号（以BCD编码）。现在，设备可以使用值0x0100或0x0110来指出它所遵循的是1.0版本还是1.1版本的USB规范。</p>
<p>版本对应:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">bcdUSB <span class="number">1.00</span> <span class="comment">// usb version 1.0</span></span><br><span class="line">bcdUSB <span class="number">1.10</span> <span class="comment">// usb version 1.1</span></span><br><span class="line">bcdUSB <span class="number">2.00</span> <span class="comment">// usb version 2.0</span></span><br><span class="line">bcdUSB <span class="number">3.00</span> <span class="comment">// usb version 3.0</span></span><br><span class="line">bcdUSB <span class="number">3.10</span> <span class="comment">// usb version 3.1</span></span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>查看linux版本信息相关命令</title>
    <url>/2011/03/16/linux-dist-version/</url>
    <content><![CDATA[<p>查看linux distribution版本信息的命令有以下几个</p>
<a id="more"></a>
<p>系统信息<br>1 $uname -a<br>2 Linux debian 2.6.32-5-686 #1 SMP Wed Jan 12 04:01:41 UTC 2011 i686 GNU/Linux  </p>
<p>详细版本<br>1 $cat /proc/version<br>2 Linux version 2.6.32-5-686 (Debian 2.6.32-30) (<a href="mailto:&#x62;&#x65;&#x6e;&#x40;&#100;&#x65;&#99;&#x61;&#100;&#101;&#x6e;&#116;&#46;&#111;&#114;&#103;&#x2e;&#x75;&#x6b;">&#x62;&#x65;&#x6e;&#x40;&#100;&#x65;&#99;&#x61;&#100;&#101;&#x6e;&#116;&#46;&#111;&#114;&#103;&#x2e;&#x75;&#x6b;</a>) (gcc version 4.3.5 (Debian 4.3.5-4) ) #1 SMP Wed Jan 12 04:01:41 UTC 2011  </p>
<p>发行版版本信息<br>1 $lsb_release -a<br>2 No LSB modules are available.<br>3 Distributor ID: Debian<br>4 Description:    Debian GNU/Linux 6.0 (squeeze)<br>5 Release:        6.0<br>6 Codename:       squeeze  </p>
<p><strong>UPDATE(09/19/2013):</strong><br>还有一个配置文件有发行版本信息<br>$ cat /etc/issue<br>Debian GNU/Linux jessie/sid \n \l</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux通用open命令</title>
    <url>/2015/09/08/linux-general-open-command/</url>
    <content><![CDATA[<a id="more"></a>
<p>我们知道，mac os x 终端下有一个命令open,可以打开任意类型的文件，当然是以系统内对应文件类型默认关联的应用程序来打开文件，如果系统本身没有该类型文件的处理程序，那么open命令一样无能为力。open命令还可以打开目录，默认用finder打开。</p>
<p>比如用finder打开当前目录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ open .</span><br></pre></td></tr></table></figure>

<p>其实linux平台上也有类似的命令，与mac open命令最接近的应该是xdg-open。xdg-open是桌面环境无关的默认应用程序处理器，在不同的桌面环境下，会调用桌面环境自己的默认程序处理器，比如gnome环境下会调用gnome-open。gnome-open以与nautilus相同的规则来打开各种类型的文件以及目录。</p>
<p>当没有桌面环境，或者桌面环境不支持默认程序处理时, xdg-open会使用自己的配置文件，自己来处理各种类型文件的默认应用程序。</p>
<p>比如,gnome环境下，执行以下命令，会用nautilus打开当前目录:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xdg-open .</span><br></pre></td></tr></table></figure>

<p>XDG是X Desktop Group的缩写,freedesktop.org以前就叫这个名字，所以freedesktop所做的工作，很多冠以xdg开头。</p>
<p>Debian系统内也有一个open命令，这个命令是openvt的符号链接，用于在一个新的虚拟终端中运行应用程序。</p>
<p>可以在bashrc文件中用别名覆盖掉默认的open，这样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias open=<span class="string">&#x27;xdg-open 2&gt;/dev/null&#x27;</span> </span><br></pre></td></tr></table></figure>

<p>这样终端下就可以直接open各种文档了。</p>
<p>References:<br>[1]<a href="https://wiki.archlinux.org/index.php/Xdg-open">xdg-open</a><br>[2]<a href="http://www.worldhello.net/2011/04/12/2437.html">Linux下的通用打开命令</a><br>[3]<a href="http://wiki.devl.cz/Default%20programs">Debian alternatives system</a><br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux环境通过interfaces文件配置无线网卡</title>
    <url>/2010/10/19/linux-interfaces-wireless/</url>
    <content><![CDATA[<p>linux下通过/etc/network/interfaces配置无线网卡很简单,<a href="https://openwares.net/linux/ubuntu_ad_hoc_network.html">adhoc模式的设置</a>已经写过了,再写一下访问无线AP的设置.</p>
<a id="more"></a>
<p>下面是DHCP方式访问wap2-psk加密的无线AP的设置<br>auto wlan0<br>iface wlan0 inet dhcp #static<br>#address 192.168.1.3<br>#netmask 255.255.255.0<br>#gateway 192.168.1.1</p>
<p>wpa-essid ssid_name<br>wpa-psk xxxxxxxxx #wap2访问密码</p>
<p>如果是wep方式访问无线AP,则最后两行改为<br>wireless-essid ssid_name<br>wireless-key xxxxxx #wep访问密码</p>
<p>这样开机就可以自动连入无线网络了</p>
<p>**UPDATE:**一定要确保安装了wpasupplicant包，这是WPA和WPA2的客户端支持组件，通过以下命令安装<br>$sudo apt-get install wpasupplicant</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux内核开启TCP BBR拥塞控制算法</title>
    <url>/2017/10/30/linux-kernel-enable-tcp-bbr-congestion/</url>
    <content><![CDATA[<a id="more"></a>
<p>内核要求4.9及以上。</p>
<p>修改内核配置文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># cat &gt;&gt; /etc/sysctl.conf &lt;&lt; EOF</span><br><span class="line">net.core.default_qdisc=fq</span><br><span class="line">net.ipv4.tcp_congestion_control=bbr</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>或sudo vim /etc/sysctl.d/10-custom-kernel-bbr.conf添加以上两行</p>
<p>使配置生效：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># sysctl -p </span><br><span class="line">net.core.default_qdisc = fq</span><br><span class="line">net.ipv4.tcp_congestion_control = bbr</span><br></pre></td></tr></table></figure>

<p>sysctl -p不指定文件默认加载/etc/sysctl.conf<br>或</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$sudo sysctl --system</span><br><span class="line">* Applying /etc/sysctl.d/<span class="number">10</span>-custom-kernel-bbr.conf ...</span><br><span class="line">net.core.default_qdisc = fq</span><br><span class="line">net.ipv4.tcp_congestion_control = bbr</span><br><span class="line">* Applying /etc/sysctl.d/<span class="number">60</span>-gce-network-security.conf ...</span><br><span class="line">net.ipv4.tcp_syncookies = <span class="number">1</span></span><br><span class="line">net.ipv4.conf.all.accept_source_route = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.default.accept_source_route = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.all.accept_redirects = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.default.accept_redirects = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.all.secure_redirects = <span class="number">1</span></span><br><span class="line">net.ipv4.conf.default.secure_redirects = <span class="number">1</span></span><br><span class="line">net.ipv4.ip_forward = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.all.send_redirects = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.default.send_redirects = <span class="number">0</span></span><br><span class="line">net.ipv4.conf.all.rp_filter = <span class="number">1</span></span><br><span class="line">net.ipv4.conf.default.rp_filter = <span class="number">1</span></span><br><span class="line">net.ipv4.icmp_echo_ignore_broadcasts = <span class="number">1</span></span><br><span class="line">net.ipv4.icmp_ignore_bogus_error_responses = <span class="number">1</span></span><br><span class="line">net.ipv4.conf.all.log_martians = <span class="number">1</span></span><br><span class="line">net.ipv4.conf.default.log_martians = <span class="number">1</span></span><br><span class="line">kernel.randomize_va_space = <span class="number">2</span></span><br><span class="line">kernel.panic = <span class="number">10</span></span><br><span class="line">* Applying /etc/sysctl.d/<span class="number">99</span>-sysctl.conf ...</span><br><span class="line">* Applying /etc/sysctl.d/protect-links.conf ...</span><br><span class="line">fs.protected_hardlinks = <span class="number">1</span></span><br><span class="line">fs.protected_symlinks = <span class="number">1</span></span><br><span class="line">* Applying /etc/sysctl.conf ...</span><br></pre></td></tr></table></figure>
<p>会加载所有的系统级配置文件</p>
<p>确认是否生效：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># sysctl net.core.default_qdisc</span><br><span class="line">net.core.default_qdisc = fq</span><br><span class="line"># sysctl net.ipv4.tcp_available_congestion_control</span><br><span class="line">net.ipv4.tcp_available_congestion_control = bbr cubic reno</span><br><span class="line"></span><br><span class="line">$ lsmod grep bbr</span><br><span class="line">tcp_bbr <span class="number">20480</span> <span class="number">14</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://sb.sb/debian-ubuntu-tcp-bbr/">Debian / Ubuntu 更新内核并开启 TCP BBR 拥塞控制算法</a><br>[2]<a href="http://www.zphj1987.com/2017/01/24/Linux-kernel-TCP-BBR-better/">Linux 升级内核开启 TCP BBR 有多大好处</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>linux SCSI多路径(multipath)IO设备设置</title>
    <url>/2012/04/12/linux-multipath-config/</url>
    <content><![CDATA[<p>通过多条路径访问同一个块设备,可以有效提高存储系统的可靠性。</p>
<a id="more"></a>
<p>linux kernel已经内置对<a href="https://openwares.net/2011/03/18/multipath_io/">multipath I/O</a>的支持,可以支持绝大多数常见存储设备。</p>
<p>系统环境：debian wheezy(testing) amd64,kernel 3.2.0-2-amd64</p>
<p>安装multipath用户空间工具multipath-tools</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#apt-get install multipath-tools</span><br></pre></td></tr></table></figure>
<p>通常,multipath-tools已经按默认参数设置好了multipath设备</p>
<p>先查看默认的多路径拓扑信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#multipath -ll</span><br><span class="line"></span><br><span class="line">360080e500018a38a0000027c4dc9d637 dm-<span class="number">0</span> LSI,INF-<span class="number">01</span>-<span class="number">00</span></span><br><span class="line">size=<span class="number">1.</span>4T features=<span class="string">&#x27;3 queue_if_no_path pg_init_retries 50&#x27;</span> hwhandler=<span class="string">&#x27;1 rdac&#x27;</span> wp=rw</span><br><span class="line">-+- policy=<span class="string">&#x27;round-robin 0&#x27;</span> prio=<span class="number">6</span> status=active</span><br><span class="line"> \<span class="string">`- 4:0:0:0 sdc 8:32 active ready running</span></span><br><span class="line"><span class="string">\`-+- policy=&#x27;round-robin 0&#x27; prio=1 status=enabled</span></span><br><span class="line"><span class="string"> \`- 1:0:0:0 sdb 8:16 active ghost running</span></span><br></pre></td></tr></table></figure>
<p>查看map设备</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#ls -l /dev/mapper</span><br><span class="line"></span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">7</span> Apr <span class="number">12</span> <span class="number">01</span>:<span class="number">06</span> 360080e500018a38a0000027c4dc9d637 -&gt; ../dm-<span class="number">0</span></span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">7</span> Apr <span class="number">12</span> <span class="number">01</span>:<span class="number">06</span> 360080e500018a38a0000027c4dc9d637-part1 -&gt; ../dm-<span class="number">1</span></span><br><span class="line">crw------T <span class="number">1</span> root root <span class="number">10</span>, <span class="number">236</span> Apr <span class="number">12</span> <span class="number">01</span>:<span class="number">06</span> control</span><br></pre></td></tr></table></figure>
<p>可以看到默认的多路径映射已经有了,<br>360080e500018a38a0000027c4dc9d637-part1设备是360080e500018a38a0000027c4dc9d637设备的分区,<br>control应该是SCSI控制器本身。dm-0就是真正的多路径设备。</p>
<p>默认的多路径设置是按照默认的参数配置的,最好根据设备特性稍微调整一下,以及为设备设定一个别名以方便使用,还有就是屏蔽掉非多路径设备,一般就是本地硬盘。</p>
<p>multipath的配置文件为/etc/multipath.conf,multipath-tools安装默认没有建立此文件,拷贝一个样本配置文件即可</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#cp /usr/share/doc/multipath-tools/examples/multipath.conf.synthetic /etc/multipath.conf</span><br></pre></td></tr></table></figure>
<p>在编辑/etc/multipath.conf文件前,查看一下所有的路径及设备信息以准确了解多路径拓扑信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#multipath -v3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loading /lib/multipath/libcheckdirectio.so checker</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loading /lib/multipath/libprioconst.so prioritizer</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: not found <span class="keyword">in</span> pathvec</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: mask = <span class="number">0x1f</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: dev_t = <span class="number">8</span>:<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: size = <span class="number">1167966208</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: vendor = LSI</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: product = MegaRAID 8708EM2</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: rev = <span class="number">1.40</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: h:b:t:l = <span class="number">1</span>:<span class="number">2</span>:<span class="number">0</span>:<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: path state = running</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: <span class="number">7166</span> cyl, <span class="number">255</span> heads, <span class="number">63</span> sectors/track, start at <span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: serial = 006736d00dd3092615001bc402b00506</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: get_state</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: path checker = directio (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: checker timeout = <span class="number">90000</span> ms (sysfs setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> directio: starting <span class="keyword">new</span> request</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> directio: io finished <span class="number">4096</span>/<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: state = up</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: getuid = <span class="regexp">/lib/u</span>dev/scsi_id --whitelisted --replace-whitespace --device=<span class="regexp">/dev/</span>%n (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: uid = 3600605b002c41b00152609d30dd03667 (callout)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: prio = <span class="keyword">const</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: prio = (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: <span class="keyword">const</span> prio = <span class="number">1</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sr0: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop0: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop1: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop2: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop3: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop4: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop5: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop6: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loop7: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: not found <span class="keyword">in</span> pathvec</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: mask = <span class="number">0x1f</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: dev_t = <span class="number">8</span>:<span class="number">16</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: size = <span class="number">2924441600</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: vendor = LSI</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: product = INF-<span class="number">01</span>-<span class="number">00</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: rev = <span class="number">0760</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: h:b:t:l = <span class="number">4</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: tgt_node_name = <span class="number">0x20040080e518a38a</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: path state = running</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: <span class="number">50966</span> cyl, <span class="number">255</span> heads, <span class="number">63</span> sectors/track, start at <span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: serial = SQ04600676</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: get_state</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loading /lib/multipath/libcheckrdac.so checker</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: path checker = rdac (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: checker timeout = <span class="number">30000</span> ms (sysfs setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: state = up</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: getuid = <span class="regexp">/lib/u</span>dev/scsi_id --whitelisted --replace-whitespace --device=<span class="regexp">/dev/</span>%n (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: uid = 360080e500018a38a0000027c4dc9d637 (callout)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> loading /lib/multipath/libpriordac.so prioritizer</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: prio = rdac (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: prio args = (<span class="literal">null</span>) (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdb: rdac prio = <span class="number">6</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> dm-<span class="number">0</span>: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> dm-<span class="number">1</span>: device node name blacklisted</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: not found <span class="keyword">in</span> pathvec</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: mask = <span class="number">0x1f</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: dev_t = <span class="number">8</span>:<span class="number">32</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: size = <span class="number">2924441600</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: vendor = LSI</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: product = INF-<span class="number">01</span>-<span class="number">00</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: rev = <span class="number">0760</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: h:b:t:l = <span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: tgt_node_name = <span class="number">0x20040080e518a38a</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: path state = running</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: <span class="number">51694</span> cyl, <span class="number">64</span> heads, <span class="number">32</span> sectors/track, start at <span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: serial = SQ04600187</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: get_state</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: path checker = rdac (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: checker timeout = <span class="number">30000</span> ms (sysfs setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: state = ghost</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: getuid = <span class="regexp">/lib/u</span>dev/scsi_id --whitelisted --replace-whitespace --device=<span class="regexp">/dev/</span>%n (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: uid = 360080e500018a38a0000027c4dc9d637 (callout)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: prio = rdac (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: prio args = (<span class="literal">null</span>) (controller setting)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sdc: rdac prio = <span class="number">1</span></span><br><span class="line">===== paths list =====</span><br><span class="line">uuid hcil dev dev_t pri dm_st chk_st vend/prod</span><br><span class="line">3600605b002c41b00152609d30dd03667 <span class="number">1</span>:<span class="number">2</span>:<span class="number">0</span>:<span class="number">0</span> sda <span class="number">8</span>:<span class="number">0</span> <span class="number">1</span> undef ready LSI,MegaR</span><br><span class="line">360080e500018a38a0000027c4dc9d637 <span class="number">4</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span> sdb <span class="number">8</span>:<span class="number">16</span> <span class="number">6</span> undef ready LSI,INF-<span class="number">0</span></span><br><span class="line">360080e500018a38a0000027c4dc9d637 <span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span> sdc <span class="number">8</span>:<span class="number">32</span> <span class="number">1</span> undef ghost LSI,INF-<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> params = <span class="number">3</span> queue_if_no_path pg_init_retries <span class="number">50</span> <span class="number">1</span> rdac <span class="number">2</span> <span class="number">1</span> round-robin <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">8</span>:<span class="number">16</span> <span class="number">1000</span> round-robin <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">8</span>:<span class="number">32</span> <span class="number">1000</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> status = <span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> A <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">8</span>:<span class="number">16</span> A <span class="number">0</span> E <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">8</span>:<span class="number">32</span> A <span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 360080e500018a38a0000027c4dc9d637: disassemble map \[<span class="number">3</span> queue_if_no_path pg_init_retries <span class="number">50</span> <span class="number">1</span> rdac <span class="number">2</span> <span class="number">1</span> round-robin <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">8</span>:<span class="number">16</span> <span class="number">1000</span> round-robin <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">8</span>:<span class="number">32</span> <span class="number">1000</span> \]</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 360080e500018a38a0000027c4dc9d637: disassemble status \[<span class="number">2</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">2</span> <span class="number">1</span> A <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">8</span>:<span class="number">16</span> A <span class="number">0</span> E <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">8</span>:<span class="number">32</span> A <span class="number">0</span> \]</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: ownership set to 3600605b002c41b00152609d30dd03667</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: not found <span class="keyword">in</span> pathvec</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: mask = <span class="number">0xc</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: path state = running</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: get_state</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> directio: starting <span class="keyword">new</span> request</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> directio: io finished <span class="number">4096</span>/<span class="number">0</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: state = up</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> sda: <span class="keyword">const</span> prio = <span class="number">1</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: features = <span class="number">0</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: no_path_retry = <span class="number">0</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: pgfailover = -<span class="number">1</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: pgpolicy = failover (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: selector = round-robin <span class="number">0</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: features = <span class="number">0</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: hwhandler = <span class="number">0</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: rr_weight = <span class="number">1</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: minio = <span class="number">1</span> rq (config file <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: no_path_retry = <span class="number">0</span> (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: pg_timeout = NONE (internal <span class="keyword">default</span>)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: remove queue_if_no_path <span class="keyword">from</span> <span class="string">&#x27;0&#x27;</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: assembled map \[<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> round-robin <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">8</span>:<span class="number">0</span> <span class="number">1</span>\]</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: set ACT_CREATE (map does not exist)</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> 3600605b002c41b00152609d30dd03667: domap (<span class="number">0</span>) failure <span class="keyword">for</span> create/reload map</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> directio checker refcount <span class="number">1</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> rdac checker refcount <span class="number">2</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> rdac checker refcount <span class="number">1</span></span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> unloading rdac prioritizer</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> unloading <span class="keyword">const</span> prioritizer</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> unloading rdac checker</span><br><span class="line">Apr <span class="number">11</span> <span class="number">21</span>:<span class="number">05</span>:<span class="number">13</span> unloading directio checker</span><br></pre></td></tr></table></figure>


<p>可以看出本地非多路径设备sda并没有被排除,下面列出/etc/multipath.conf的内容：</p>
<p> 1 blacklist {<br> 2    devnode “^sda”<br> 3 }<br> 4<br> 5 multipaths {<br> 6    multipath {<br> 7        wwid            360080e500018a38a0000027c4dc9d637<br> 8        alias           data<br> 9    }<br>10 }<br>11<br>12 devices {<br>13     device {<br>14         vendor              “LSI”<br>15         product             “INF-01-00”<br>16         hardware_handler    “1 rdac”<br>17     }<br>18 }</p>
<p>首先从多路径配置中去掉sda。<br>wwid就是上面查看路径信息时提示的uuid,不过一定要分清楚多路径设备与非多路径设备。为多路径设备提供一个别名data。设备的vendor,product都可以从multipath -v3的输出中找到,hardware_handler此处设置为”1 rdac”,因为使用的是LSI的设备。<br>其他参数使用默认值即可。</p>
<p>然后</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#/etc/init.d/multipath-tools reload</span><br></pre></td></tr></table></figure>
<p>使新的配置生效,然后再查看多路径拓扑信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#multipath -ll</span><br><span class="line"></span><br><span class="line">data (360080e500018a38a0000027c4dc9d637) dm-<span class="number">0</span> LSI,INF-<span class="number">01</span>-<span class="number">00</span></span><br><span class="line">size=<span class="number">1.</span>4T features=<span class="string">&#x27;3 queue_if_no_path pg_init_retries 50&#x27;</span> hwhandler=<span class="string">&#x27;1 rdac&#x27;</span> wp=rw</span><br><span class="line">-+- policy=<span class="string">&#x27;round-robin 0&#x27;</span> prio=<span class="number">6</span> status=active</span><br><span class="line"> \<span class="string">`- 4:0:0:0 sdc 8:32 active ready running</span></span><br><span class="line"><span class="string">\`-+- policy=&#x27;round-robin 0&#x27; prio=1 status=enabled</span></span><br><span class="line"><span class="string"> \`- 1:0:0:0 sdb 8:16 active ghost running</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#ls -l /dev/mapper</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">crw------T 1 root root 10, 236 Apr 12 13:06 control</span></span><br><span class="line"><span class="string">lrwxrwxrwx 1 root root 7 Apr 12 14:06 data -&gt; ../dm-0</span></span><br><span class="line"><span class="string">lrwxrwxrwx 1 root root 7 Apr 12 14:06 data-part1 -&gt; ../dm-1</span></span><br></pre></td></tr></table></figure>
<p>可以看到新的设置已经生效,data即是真正的多路径设备,而data-part1设备是data设备的分区。以后把/dev/mapper/data和/dev/mapper/data-part1当作常规的块设备来使用就可以了。也可以通过blkid查看块设备的uuid。</p>
<p>还有一个问题,如果系统启动时没有提前加载scsi_dh_rdac模块,则在启动时会有大量的I/O错误,启动会很慢,错误信息类似如下：</p>
<p>[ 7.093679] sd 1:0:0:0: [sdb] Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>[ 7.093683] sd 1:0:0:0: [sdb] Sense Key : Illegal Request [current]<br>[ 7.093687] sd 1:0:0:0: [sdb] &lt;&gt; ASC=0x94 ASCQ=0x1ASC=0x94 ASCQ=0x1<br>[ 7.093698] sd 1:0:0:0: [sdb] CDB: Read(10): 28 00 00 00 00 00 00 00 08 00<br>[ 7.093705] end_request: I/O error, dev sdb, sector 0<br>[ 7.093751] Buffer I/O error on device sdb, logical block 0<br>[ 7.610368] sd 1:0:0:0: [sdb] Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>[ 7.610372] sd 1:0:0:0: [sdb] Sense Key : Illegal Request [current]<br>[ 7.610375] sd 1:0:0:0: [sdb] &lt;&gt; ASC=0x94 ASCQ=0x1ASC=0x94 ASCQ=0x1<br>[ 7.610380] sd 1:0:0:0: [sdb] CDB: Read(10): 28 00 00 00 00 00 00 00 08 00<br>[ 7.610385] end_request: I/O error, dev sdb, sector 0<br>[ 7.610427] Buffer I/O error on device sdb, logical block 0<br>[ 8.127039] sd 1:0:0:0: [sdb] Result: hostbyte=DID_OK driverbyte=DRIVER_SENSE<br>[ 8.127043] sd 1:0:0:0: [sdb] Sense Key : Illegal Request [current]<br>[ 8.127045] sd 1:0:0:0: [sdb] &lt;&gt; ASC=0x94 ASCQ=0x1ASC=0x94 ASCQ=0x1<br>[ 8.127050] sd 1:0:0:0: [sdb] CDB: Read(10): 28 00 00 00 00 00 00 00 08 00<br>[ 8.127055] end_request: I/O error, dev sdb, sector 0</p>
<p>只要提前加载scsi_dh_rdac模块即可解决此问题</p>
<p>修改/etc/initramfs-tools/initramfs.conf文件中的MODULES=most为MODULES=dep</p>
<p>/etc/initramfs-tools/modules文件中增加行scsi_dh_rdac</p>
<p>然后更新initrd初始化ram盘</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#update-initramfs -u</span><br></pre></td></tr></table></figure>
<p>重新启动就没有此类错误了。</p>
<p>References:<br>[1]<a href="https://help.ubuntu.com/lts/serverguide/multipath-dm-multipath-config-file.html">The DM-Multipath Configuration File</a><br>[2]<a href="https://en.wikipedia.org/wiki/Linux_DM_Multipath">Linux DM Multipath</a><br>[3]<a href="https://help.ubuntu.com/lts/serverguide/multipath-setting-up-dm-multipath.html">Setting up DM-Multipath Overview</a><br>[4]<a href="https://anothersysadmin.wordpress.com/2008/11/17/howto-debian-and-scsi-multipathing-with-multipath-tools/">HOWTO: Debian and SCSI multipathing with multipath-tools</a><br>[5]<a href="https://help.ubuntu.com/lts/serverguide/multipath-admin-and-troubleshooting.html">DM-Multipath Administration and Troubleshooting</a><br>[6]<a href="https://www.centos.org/docs/5/html/5.2/DM_Multipath/">Using Device-Mapper Multipath</a><br>[7]<a href="https://www.redhat.com/archives/dm-devel/2011-November/msg00141.html">info on enabling only one path with rdac and DS4700</a><br>[8]<a href="http://kaivanov.blogspot.com/2010/10/multipath-usage-guide-for-san-in-rhel.html">Multipath Usage Guide for SANs</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Debian Squeeze AMD64安装Oracle 10g x86_64客户端</title>
    <url>/2012/01/17/linux-oracle-10g-client-x86-64/</url>
    <content><![CDATA[<p>操作系统为Debian Squeeze AMD64,没有安装X,通过ssh远程访问。客户端为debian testing,安装有gnome桌面环境。</p>
<a id="more"></a>
<p>安装过程如下：</p>
<p><strong>1、下载oracle 10g客户端</strong></p>
<p>下载回来的文件为10201_client_linux_x86_64.cpio.gz<br>$gunzip 10201_client_linux_x86_64.cpio.gz<br>$cpio -idmv &lt; 10201_client_linux_x86_64.cpio</p>
<p>解压缩后所有的安装文件位于client目录下。</p>
<p><strong>2、检查硬件是否达到要求</strong></p>
<p>物理RAM必须大于512M,现在的机器内存都没问题。超过726MB RAM时,swap应该在物理RAM的0.75倍以上。Administrator安装类型使用的硬盘空间最多,不过也才850M而已。<br>通过以下命令检查,如果不满足需要做相应的调整</p>
<p>$grep MemTotal /proc/meminfo //检查物理内存大小<br>$grep SwapTotal /proc/meminfo //检查swap大小<br>$df -h //检查可用硬件空间大小</p>
<p><strong>3、安装需要的软件包</strong></p>
<p>$sudo apt-get install build-essential ia32-libs ia32-libs-dev libc6 libc6-i386 libc6-dev libc6-dev-i386</p>
<p>如果不安装ia32-libs,安装时会提示</p>
<p>/…/client/runInstaller: 63: /…/client/install/.oui: not found</p>
<p><strong>4、创建oracle需要的组和用户</strong></p>
<p>oracle安装使用的组<br>#groupadd oinstall</p>
<p>系统管理使用的组<br>#groupadd dba</p>
<p>创建用户oracle<br>#useradd -g oinstall -G dba oracle</p>
<p>为用户oracle设置密码<br>#passwd oracle<br> <strong>5、创建oracle基准目录</strong></p>
<p>oracle安装目录的设置最好遵循oracle <a href="http://docs.oracle.com/cd/B19306_01/install.102/b15660/app_ofa.htm">OFA</a>(Optimal Flexible Architecture)规范的建议。</p>
<p>用以下命令来设置ORACLE BASE目录/u01/app/oracle<br>#mkdir -p /u01/app/oracle<br>#chown -R oracle:oinstall /u01/app/oracle<br>#chmod -R 775 /u01/app/oracle</p>
<p><strong>6、设置oracle用户的环境</strong></p>
<p>设置oracle的用户的主目录home为/u01/app/oracle<br>#usermod -d /u01/app/oracle oracle</p>
<p>从其他用户主目录下拷贝.profile,.bashrc,.bash_logout文件到oracle用户的主目录,在.bashrc文件增加下面的行<br>umask 022<br>然后<br>$source .bashrc</p>
<p>最后设置oracle用户<a href="https://openwares.net/linux/x11_forward_over_ssh.html">远程ssh登录时启用X11 Forward</a></p>
<p>也可以不使用X远程静默安装oracle</p>
<p><strong>7、安装oracle 10g x86_64客户端</strong></p>
<p>登录到远程系统<br>$ssh -XY oracle@remotehost</p>
<p>执行oracle安装程序<br>$/path/to/client/runInstaller -ignoreSysPrereqs</p>
<p>因为oracle 10g认证的linux系统只有redhat-3, SuSE-9, redhat-4, UnitedLinux-1.0, asianux-1 和 asianux-2这几个,所以在其他linux发行版上安装时需要指定命令行参数-ignoreSysPrereqs,否则会提示:<br> Checking operating system version: must be redhat-3, SuSE-9, redhat-4, UnitedLinux-1.0, asianux-1 or asianux-2<br> Failed &lt;&lt;&lt;&lt;<br>然后退出安装</p>
<p>之后在本地机器可以看到OUI(Oracle Universal Installer)界面,后面的安装根据提示来就可以了。因为只安装客户端,所以oracle home的名字修改为OraClient10g_home1,客户端的安装目录修改为/u01/app/oracle/product/10.2.0/client_1</p>
<p>安装完成后,在oracle用户的.bashrc文件中添加以下ORACLE环境变量<br>export ORACLE_BASE=/u01/app/oracle<br>export ORACLE_HOME=$ORACLE_BASE/product/10.2.0/client_1<br>export PATH=$ORACLE_HOME/bin:$PATH<br>export TNS_ADMIN=$ORACLE_HOME/network/admin<br>#export SQLPATH=$ORACLE_HOME/scripts</p>
<p>安装完成</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux route命令</title>
    <url>/2012/10/25/linux-route-intro/</url>
    <content><![CDATA[<p>route命令用于查看和修改IP路由表</p>
<a id="more"></a>
<h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a><strong>格式</strong></h2><p>route [-CFvnee]</p>
<p>route [-v] [-A family] add [-net-host] target [netmask Nm] [gw Gw] [metric N] [mss M] [window W] [irtt I] [reject]<br> [mod] [dyn] [reinstate] [[dev] If]</p>
<p>route [-v] [-A family] del [-net-host] target [gw Gw] [netmask Nm] [metric N] [[dev] If]</p>
<p>route [-V] [–version] [-h] [–help]</p>
<h2 id="选项"><a href="#选项" class="headerlink" title="选项"></a><strong>选项</strong></h2><p><strong>-A</strong> family 指定网络地址类型,默认为inet即internet v4版本,支持的地址类型有：<br>inet (DARPA Internet) inet6 (IPv6) ax25 (AMPR AX.25) netrom (AMPR NET/ROM) ipx (Novell IPX) ddp (Appletalk DDP) x25 (CCITT X.25)<br><strong>-F</strong> 操作内核的FIB(Forwarding Information Base)路由表,这是默认值。<br><strong>-C</strong> 操作内核的路由缓存<br><strong>-v</strong> 冗余显示模式<br><strong>-n</strong> 显示数字地址而不是主机名<br><strong>-e</strong> 使用netstat格式显示路由表<br><strong>-ee</strong> 显示更多的路由表信息</p>
<h2 id="命令"><a href="#命令" class="headerlink" title="命令"></a><strong>命令</strong></h2><p><strong>del</strong> 删除路由表<br><strong>add</strong> 添加路由表</p>
<p><strong>del或add命令子选项：</strong></p>
<p><strong>-net</strong> 指定路由目标target为网络<br><strong>-host</strong> 指定路由目标target为主机<br><strong>target</strong> 目标网络或主机,可以为IP地址或主机/网络名称。target为”0.0.0.0”或者”default”的路由条目为默认路由。<br><strong>netmask NM</strong> 当增加网络路由时指定网络掩码,当target为主机时不用也不能指定掩码(其实掩码默认为255.255.255.255)<br><strong>gw GW</strong> 指定网关。如果目标是不经网关直接可到达的,那么不用指定网关,此时路由表中Gateway会显示为0.0.0.0<br><strong>metric M</strong> 指定路由表项的度量metric为M,此值愈小的路由表项优先级愈高<br><strong>mss M</strong> 指定此路由的TCP最大段大小(Maximum Segment Size)为M字节,默认值为设备最大传输单元MTU(Maximum Transmission Unit)减去IP头部。当路径MTU发现机制无法正常工作时可以指定一个较小的TCP包。<br><strong>window W</strong> 指定此路由TCP窗口尺寸为W字节<br><strong>irtt I</strong> 指定此路由初始往返时间(initial round trip time)为I毫秒。<br><strong>reject</strong> 此路由表项的目标将被阻止,即使存在默认路由。<br><strong>mod,dyn,reinstate</strong> 增加一个动态或修改过的路由,此选项用于诊断目的,一般只有路由守护程序设置此选项。<br><strong>dev If</strong> 强制此路由与指定的接口设备If关联,否则内核会自己决定此路由使用哪一个接口设备。如果dev If是命令的最后一个选项,dev关键字可以省略。</p>
<h2 id="样例"><a href="#样例" class="headerlink" title="样例"></a><strong>样例</strong></h2><p>增加到主机10.100.0.3的路由,网络是直连的,无需经过网关,通过网络接口ppp0进行路由<br>#route add -host 10.100.0.3 dev ppp0</p>
<p>增加到网络10.100.0.0/24的路由,分组经过网关10.100.0.1,通过网络接口ppp0路由。<br>#route add -net 10.100.0.0 netmask 255.255.255.0 gateway 10.100.0.1 dev ppp0</p>
<p>删除默认路由<br>#route del default</p>
<p>添加默认路由,网关192.168.0.1,分组通过网络设备wlan0<br>#route add default gateway 192.168.0.1 dev wlan0</p>
<h2 id="路由表输出格式"><a href="#路由表输出格式" class="headerlink" title="路由表输出格式"></a><strong>路由表输出格式</strong></h2><p><strong>Destination</strong> 目标网络或主机,”0.0.0.0”或”default”为默认路由,可以有多条默认路由,通过metric开区分优先级,metric值越低优先级越高</p>
<p><strong>Gateway</strong> 网关地址,”0.0.0.0”标示网络是直连的,无需经过网关</p>
<p><strong>Flags</strong> 标志</p>
<ul>
<li>  U 路由项是生效的(Up)</li>
<li>  H 路由目标为主机(Host)</li>
<li>  G 使用网关(gateway)</li>
<li>  R 动态选路恢复路由(Reinstate)</li>
<li>  D 路由守护程序或重定向添加路由(Dynamic)</li>
<li>  M 路由守护程序或重定向修改路由(Modified)</li>
<li>  A 由addrconf程序添加的路由</li>
<li>  C 缓存路由项</li>
<li>  ! 拒绝的路由</li>
</ul>
<p><strong>Metric</strong> 到路由目标的距离度量,一般用跳(hop)来度量。<br><strong>Ref</strong> 路由被引用的次数,其他路由依赖于本路由算作引用<br><strong>Use</strong> 路由被使用的次数<br><strong>Iface</strong> 路由使用的接口地址,从此接口发送此路由的数据<br><strong>MSS</strong> 经过此路由的TCP最大段尺寸(Maximum Segment Size)<br><strong>Window</strong> 此路由TCP连接的窗口大小<br><strong>irtt</strong> 初始往返时间Initial RTT (Round Trip Time)。内核使用此参数来估算最佳的TCP参数。<br><strong>Arp</strong> 缓存路由的硬件地址是否是最新的,只适用于缓存的路由。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux TCP/IP 协议栈调优</title>
    <url>/2016/07/26/linux-tcpip-tunning/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="http://colobu.com/2014/09/18/linux-tcpip-tuning/">Linux TCP/IP 协议栈调优</a><br>[2]<br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux系统wma转换到mp3格式</title>
    <url>/2015/03/26/linux-wma2mp3/</url>
    <content><![CDATA[<a id="more"></a>
<p>其实只要是mplayer可以播放的音频或视频都可以转换到其他输出格式，下面这条bash语句可以批量转换当前目录下的所有wma文件为mp3格式文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> *.wma ; <span class="keyword">do</span> mplayer -ao pcm $i &amp;&amp; lame --preset cbr <span class="number">32</span> audiodump.wav -o <span class="string">&quot;\`basename &quot;</span>$i<span class="string">&quot; .wma\`.mp3&quot;</span>; done</span><br><span class="line"></span><br><span class="line">rm audiodump.wav</span><br></pre></td></tr></table></figure>
<p>为了兼容性，使用CBR编码模式。如果参数中去掉cbr,而指定码率则会使用ABR编码模式,其他则会使用VRB编码模式。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>linux 修改按键映射</title>
    <url>/2018/11/16/linux-xmodmap/</url>
    <content><![CDATA[<a id="more"></a>
<p>xmodmap(X modify key map)可以修改X下的键位映射<br>比如０现在用的键盘没有右边的CTRL，很难用，右侧的INSERT键刚好在空格右侧不远的地方，可以把它修改为右CTRL</p>
<p>可以使用xev程序来查看当前的keymap，可以看到右侧的INSERT键位映射为：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">KeyPress event, serial <span class="number">33</span>, synthetic NO, <span class="built_in">window</span> <span class="number">0x2a00001</span>,</span><br><span class="line"> root <span class="number">0xdc</span>, subw <span class="number">0x0</span>, time <span class="number">102519</span>, (<span class="number">936</span>,<span class="number">455</span>), <span class="attr">root</span>:(<span class="number">986</span>,<span class="number">569</span>),</span><br><span class="line"> state <span class="number">0x10</span>, keycode <span class="number">118</span> (keysym <span class="number">0xff63</span>, Insert), same_screen YES,</span><br><span class="line"> XLookupString gives <span class="number">0</span> bytes: </span><br><span class="line"> XmbLookupString gives <span class="number">0</span> bytes: </span><br><span class="line"> XFilterEvent returns: False</span><br></pre></td></tr></table></figure>

<p><strong>导出原映射</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xmodmap -pke &gt; ~/.Xmodmap</span><br></pre></td></tr></table></figure>

<p><strong>修改映射</strong></p>
<p>控制键要先clear，最后再add<br>编辑.Xmodmap文件，文件开头处添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">clear Control</span><br></pre></td></tr></table></figure>

<p>将keycode 118修改为</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">keycode <span class="number">118</span> = Control_R NoSymbol Control_R</span><br></pre></td></tr></table></figure>

<p>然后文件尾部添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">add Control = Control_L Control_R</span><br></pre></td></tr></table></figure>

<p><strong>测试配置</strong></p>
<p>修改好映射文件后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xmodmap ~/.Xmodmap</span><br></pre></td></tr></table></figure>

<p>GDM,XDM和LightDM在开启xsession时会自动读取$HOME/.Xmodmap，但不稳定，时好时坏:(</p>
<p>使用startx时激活你自己的映射表，请添加下面的文件和内容：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">~/.xinitrc</span><br><span class="line"><span class="keyword">if</span> \[ -f $HOME/.Xmodmap \]; then</span><br><span class="line"> /usr/bin/xmodmap $HOME/.Xmodmap</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://wiki.archlinux.org/index.php/Xmodmap_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">Xmodmap</a><br>[2]<a href="http://blog.kankanan.com/article/linux-4e0b4fee6539952e4f4d66205c04.html">linux下修改键位映射</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>nginx 0.7.64,php 5.3.1和mysql 5安装手记</title>
    <url>/2010/01/09/lnmp-install/</url>
    <content><![CDATA[<p>VPS上安装的是Debian Lenny AMD64,Debian让人变懒惰了，不过这次不使用Apache，改用nginx,有些东西还是要从源码编译安装的，记录下来以备忘,文后附安装脚本。当然能用apt-get安装的就直接安装了，省心又省力。<br>　　<br>0. 准备build环境<br>　　sudo apt-get -y install build-essential autoconf</p>
<ol>
<li><p>安装mysql 5<br>　　sudo apt-get -y install mysql-server mysql-client libmysqlclient15-dev<br>　　这里一并安装了libmysqlclient15-dev，因为编译php时需要这个库。</p>
</li>
<li><p>安装nginx 0.7.64<br>　　虽然可以apt-get来安装nginx，但版本太旧。当下nginx最新稳定版本为0.7.64,最新开发版为0.8.31。xxx说稳定压倒一切，所以要安装稳定版。先安装regex支持库PCRE(Perl Compatible Regular Expressions)</p>
<a id="more"></a>
<p>PCRE_VERSION=8.00<br>　　src_path=~/src<br>　　cd $src_path<br>　　wget “<a href="ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-$%7BPCRE_VERSION%7D.tar.bz2&quot;">ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-${PCRE_VERSION}.tar.bz2&quot;</a><br>　　tar jxf pcre-$PCRE_VERSION.tar.bz2<br>　　cd $src_path/pcre-$PCRE_VERSION<br>　　./configure &amp;&amp; make &amp;&amp; sudo make install<br>　　cd /lib &amp;&amp; sudo ln -sf /usr/local/lib/libpcre.so.0.0.1 libpcre.so.0<br>　　<br>　　创建nginx使用的用户www和组www<br>　　sudo groupadd www<br>　　sudo useradd -g www –home-dir /nonexsitent –shell /bin/false www<br>　　<br>　　安装nginx<br>　　cd $src_path<br>　　NGINX_VER=0.7.64<br>　　wget “<a href="http://nginx.org/download/nginx-$NGINX_VER.tar.gz&quot;">http://nginx.org/download/nginx-$NGINX_VER.tar.gz&quot;</a><br>　　tar zxf nginx-$NGINX_VER.tar.gz<br>　　cd nginx-$NGINX_VER<br>　　./configure –user=www –group=www –with-http_stub_status_module –with-　　http_ssl_module<br>　　make &amp;&amp; sudo make install<br>　　<br>　　–with-http_ssl_module选项使nginx可以支持https协议，–with-http_stub_status_module选项支持nginx的状态监视。安装好后所有nginx文件位于/usr/local/nginx目录下，nginx的安装目录不符合FHS(Filesystem Hierarchy Standard)标准。</p>
</li>
<li><p>安装php 5.3.1,通过php-fpm支持FCGI接口<br>　　安装支持库libevent<br>　　LIBEVENT_VER=1.4.13<br>　　cd $src_path<br>　　wget “<a href="http://www.monkey.org/~provos/libevent-$LIBEVENT_VER-stable.tar.gz&quot;">http://www.monkey.org/~provos/libevent-$LIBEVENT_VER-stable.tar.gz&quot;</a><br>　　tar zxf libevent-$LIBEVENT_VER-stable.tar.gz<br>　　cd libevent-$LIBEVENT_VER-stable &amp;&amp; ./configure &amp;&amp; make &amp;&amp; sudo make install<br>　　<br>　　其他支持库<br>　　sudo apt-get install -y libxml2-dev libmcrypt-dev libjpeg62-dev libpng-dev libmhash-dev libcurl4-gnutls-dev libsasl2-dev libgd2-xpm-dev</p>
</li>
</ol>
<p>　　php-fpm(FastCGI Process Manager)是一个php fcgi实现，下面以补丁的方式为php集成php-fpm以支持fcgi接口。nginx不支持传统的CGI接口。<br>　　cd $src_path<br>　　PHP_VER=5.3.1<br>　　wget “<a href="http://php-fpm.org/downloads/0.6/php-fpm-0.6~$PHP_VER.tar.gz&quot;">http://php-fpm.org/downloads/0.6/php-fpm-0.6~$PHP_VER.tar.gz&quot;</a><br>　　tar zxf php-fpm-0.6~$PHP_VER.tar.gz<br>　　php-fpm-0.6-$PHP_VER/generate-fpm-patch</p>
<p>　　wget “<a href="http://us.php.net/get/php-$PHP_VER.tar.bz2/from/us.php.net/mirror&quot;">http://us.php.net/get/php-$PHP_VER.tar.bz2/from/us.php.net/mirror&quot;</a><br>　　tar jxf php-$PHP_VER.tar.bz2<br>　　cd php-$PHP_VER<br>　　patch -p1 &lt; ../fpm.patch<br>　　./buildconf –force<br>　　PHP_CONFIG_PATH=/usr/local/etc<br>　　./configure –with-fpm –with-libevent=shared –with-zlib –enable-xml –disable-rpath –enable-safe-mode –enable-bcmath –enable-shmop –enable-sysvsem –enable-inline-optimization –with-curl –with-curlwrappers –enable-mbregex –enable-mbstring –with-mcrypt –with-gd –enable-gd-native-ttf –with-openssl –with-mhash –enable-pcntl –enable-sockets –with-ldap –with-ldap-sasl –with-xmlrpc –enable-zip –without-pear –with-mysql –with-mysqli –with-pdo-mysql –enable-ftp –with-jpeg-dir –with-png-dir –disable-cli –with-config-file-path=$PHP_CONFIG_PATH</p>
<p>　　make &amp;&amp; sudo make install<br>　　这里将php的配置文件路径改为/usr/local/etc而不是默认的/usr/local/lib。php 5.3.1自带的配置文件貌似有问题，换了低版本的php.ini才能正确加载，不知道现在这个问题还存不存在。安装完毕后把/etc/php-fpm.conf文件里面的unix user of process和unix group of process选项都设置为www，以利于nginx与php-fpm沟通。<br>　　nginx的详细配置以后撰文再叙，<a href="/downloads/lnmp_install.sh">安装脚本在此</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>在Re­quireJS之前加载jQuery</title>
    <url>/2014/07/11/load-jquery-before-re%C2%ADquirejs/</url>
    <content><![CDATA[<a id="more"></a>
<p>有时候可能会需要在加载Re­quireJS之前就加载jQuery,因为有些代码并不在Re­quireJS的管理范围之内,比如这样<br>[html]</p>
<script src="jquery.js"></script>
<script src="require.js" data-main="main.js"></script>
<p>[/html]<br>but这时候会出现错误,怎么办呢？<br>因为jQuery无论如何都是会暴露到全局名字空间的,所以为main.js文件的前部为jQuery定义一个占位模块好了<br>[html]<br>define(‘jquery’, [], function() {<br> return jQuery;<br>});<br>[/html]</p>
<p>其实最新版本的jQuery也是在检测到Re­quireJS之后这样来定义jQuery模块的。</p>
<p>References:<br>[1]<a href="http://www.manuel-strehl.de/dev/load_jquery_before_requirejs.en.html">Load jQuery be­fore Re­quireJS and still use it as de­pend­ency</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>load pubkey &quot;/Users/xxx/.ssh/id_rsa&quot;: invalid format</title>
    <url>/2020/06/06/load-pubkey-users-xxx-ssh-id-rsa-invalid-format/</url>
    <content><![CDATA[<a id="more"></a>
<p>brew upgrade升级了openssh以后，每次登录远程服务器都提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">load pubkey <span class="string">&quot;/Users/xxx/.ssh/id_rsa&quot;</span>: invalid format</span><br></pre></td></tr></table></figure>

<p>因为客户端根本就没存储公钥啊，为什么要读取公钥？公钥放在服务器端了啊</p>
<p>客户端重新生成对应的公钥，满足openssh的无理要求就可以了：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -f ~<span class="regexp">/.ssh/i</span>d_rsa -y &gt; ~<span class="regexp">/.ssh/i</span>d_rsa.pub</span><br></pre></td></tr></table></figure>

<p>以前也没这问题。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>小内存VPS之MySQL配置优化</title>
    <url>/2011/07/02/lowenvps-mysql/</url>
    <content><![CDATA[<p>MySQL是优秀的小型开源数据库,然而默认配置的MySQL对于小内存VPS来说仍然资源占用过多,因此优化配置,减少资源占用是有必要的。</p>
<a id="more"></a>
<p>debian squeeze系统上mysql的主配置文件为/etc/mysql/my.cnf,优化之后,资源占用有明显的下降</p>
<p><strong>参数优化说明</strong></p>
<p>skip-innodb #不使用InnoDB数据库引擎,虽然InnoDB很强大,但对于小内存VPS就没啥必要使用了,关闭InnoDB引擎后,内存占用有明显的下降</p>
<p>skip-external-locking #不使用外部锁，也就是操作系统提供的锁，这个选项现在默认是打开的</p>
<p>key_buffer #与key_buffer_size是同一个参数,不过后者已经不推荐使用了,此参数指定索引缓冲区的大小，对于小内存VPS,16M的默认值有些大了,1M就差不多了</p>
<p>query_cache_limit #不缓存大于此值的结果,设置为256K</p>
<p>query_cache_size #用于缓存查询结果的内存大小,必须是1024的倍数,设置为query_cache_limit的16倍，即4M</p>
<p>sort_buffer_size #排序缓存<br>read_buffer_size #读缓存<br>read_rnd_buffer_size #缓存通过关键字排序的行<br>#这三个参数可以采用默认值，也可以参考/usr/share/doc/mysql-server-5.1/examples/my-small.cnf来设置</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>LRO(Large receive offload)介绍</title>
    <url>/2012/04/02/lro-intro/</url>
    <content><![CDATA[<p>Large receive offload是提高网络inbound吞吐量的一种技术</p>
<a id="more"></a>
<p>LRO(Large Receive Offload)通过将接收到的多个TCP数据包聚合到一个大的缓冲区，然后再传递给上层的网络协议栈处理，以减少上层协议栈开销，改善系统接收TCP数据包的能力。即使该技术完全使用软件实现，也会极大的改善网络处理性能。现在大部分网卡都从硬件上支持此项特性。</p>
<p>可以使用ethtool关闭此项特性</p>
<p>#ethtool -K ethX lro off</p>
<p>查看网络接口的其他offload特性</p>
<p>#ethtool -k- -show-offload ethX</p>
<p>Offload parameters for eth0:<br>rx-checksumming: on<br>tx-checksumming: on<br>scatter-gather: on<br>tcp-segmentation-offload: on<br>udp-fragmentation-offload: off<br>generic-segmentation-offload: on<br>generic-receive-offload: off<br>large-receive-offload: off<br>ntuple-filters: off<br>receive-hashing: off</p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ls命令只显示目录</title>
    <url>/2013/11/22/ls-dir-only/</url>
    <content><![CDATA[<p>串接ls,grep和sed实现只列目录的命令，ls -F grep / sed “s/\///“，长模式列目录的话更简单ls -l grep /</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>lxd容器改变存储后端</title>
    <url>/2019/08/13/lxd-change-storage-backend/</url>
    <content><![CDATA[<a id="more"></a>
<p>已经创建的容器可以通过一定的方法更改为使用其他的存储池/存储后端</p>
<p><strong>本机</strong></p>
<p>本机有两个存储池，分别使用btrfs和zfs</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc storage list</span><br><span class="line">+---------+-------------+--------+--------------------------------------------+---------+</span><br><span class="line"> NAME DESCRIPTION DRIVER SOURCE USED BY </span><br><span class="line">+---------+-------------+--------+--------------------------------------------+---------+</span><br><span class="line"> <span class="keyword">default</span> btrfs /<span class="keyword">var</span>/snap/lxd/common/lxd/disks/<span class="keyword">default</span>.img <span class="number">1</span> </span><br><span class="line">+---------+-------------+--------+--------------------------------------------+---------+</span><br><span class="line"> lxd_zfs zfs /<span class="keyword">var</span>/snap/lxd/common/lxd/disks/lxd_zfs.img <span class="number">2</span> </span><br><span class="line">+---------+-------------+--------+--------------------------------------------+---------+</span><br></pre></td></tr></table></figure>

<p>使用btrfs存储池新建一个alpine容器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc init images:alpine/<span class="number">3.10</span>/amd64 alp -s <span class="keyword">default</span></span><br><span class="line">$ lxc storage show <span class="keyword">default</span></span><br></pre></td></tr></table></figure>

<p>可以看到alp容器使用default存储池，也就是btrfs后端。</p>
<p>然后通过将容器发布为image，使用image创建新容器的方式使新的alp容器使用lxd_zfs存储后端</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc publish -f alp --alias alp_img</span><br><span class="line">$ lxc <span class="keyword">delete</span> alp</span><br><span class="line">$ lxc init alp_img alp -s lxd_zfs</span><br><span class="line">$ lxc image <span class="keyword">delete</span> alp_img</span><br><span class="line">$ lxc storage show lxd_zfs</span><br><span class="line">config:</span><br><span class="line"> size: 15GB</span><br><span class="line"> source: <span class="regexp">/var/</span>snap/lxd/common/lxd/disks/lxd_zfs.img</span><br><span class="line"> zfs.pool_name: lxd_zfs</span><br><span class="line">description: <span class="string">&quot;&quot;</span></span><br><span class="line">name: lxd_zfs</span><br><span class="line">driver: zfs</span><br><span class="line">used_by:</span><br><span class="line">- <span class="regexp">/1.0/</span>containers/alp</span><br><span class="line">- <span class="regexp">/1.0/</span>profiles/<span class="keyword">default</span></span><br><span class="line">status: Created</span><br><span class="line">locations:</span><br><span class="line">- none</span><br></pre></td></tr></table></figure>
<p>可以看到容器alp使用zfs后端存储，其实这是一个全新的容器，不过使用image做了一下中转。</p>
<p><strong>异机</strong></p>
<p>在目标服务器上新建zfs存储池和profile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc storage create lxd_zfs zfs</span><br><span class="line">$ lxc profile create storage_zfs</span><br><span class="line">$ lxc profile device add storage_zfs root disk path=/ pool=lxd_zfs</span><br><span class="line">$ lxc profile show storage_zfs </span><br><span class="line">config: &#123;&#125;</span><br><span class="line">description: <span class="string">&quot;&quot;</span></span><br><span class="line">devices:</span><br><span class="line"> root:</span><br><span class="line"> path: /</span><br><span class="line"> pool: lxd_zfs</span><br><span class="line"> type: disk</span><br><span class="line">name: storage_zfs</span><br><span class="line">used_by: \[\]</span><br></pre></td></tr></table></figure>

<p>这样在向目标服务器上copy/move容器时，指定storage_zfs profile就可以了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc copy container1 remotesvr1: -p storage_zfs</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd clustering using ceph storage backend</title>
    <url>/2019/11/11/lxd-clustering-using-ceph-storage-backend/</url>
    <content><![CDATA[<a id="more"></a>
<p>lxd集群使用ceph后端共享存储，多个host共同管理一组容器，可以提高lxd容器的可用性，但当前版本的lxd集群功能还不够完善，不支持lxd容器在集群host之间live migration，故障迁移支持也不完善。<br>lxd集群部署ceph后端，数据丢失的风险大大降低，集群中host掉线，可以将lxd容器快速移动到其他host继续提供服务。</p>
<p><strong>bootstrap节点配置</strong><br>第一个节点加入一个存在的集群选no，集群剩余其他节点选择加入现有集群。一个集群共享一个ceph pool，不用的集群要使用不用的ceph pool。</p>
<p><strong>其他节点配置</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo lxd init</span><br><span class="line">Would you like to use LXD clustering? (yes/no) \[<span class="keyword">default</span>=no\]: yes</span><br><span class="line">What name should be used to identify <span class="built_in">this</span> node <span class="keyword">in</span> the cluster? \[<span class="keyword">default</span>=web\]: </span><br><span class="line">What IP address or DNS name should be used to reach <span class="built_in">this</span> node? \[<span class="keyword">default</span>=<span class="number">10.100</span><span class="number">.0</span><span class="number">.80</span>\]: </span><br><span class="line">Are you joining an existing cluster? (yes/no) \[<span class="keyword">default</span>=no\]: yes</span><br><span class="line">IP address or FQDN <span class="keyword">of</span> an existing cluster node: <span class="number">10.100</span><span class="number">.0</span><span class="number">.31</span></span><br><span class="line">Cluster fingerprint: 79ec4bdfa32501a664b1adde03a2296f7d663a43676a422781668df1bec2ee12</span><br><span class="line">You can validate <span class="built_in">this</span> fingerprint by running <span class="string">&quot;lxc info&quot;</span> locally on an existing node.</span><br><span class="line">Is <span class="built_in">this</span> the correct fingerprint? (yes/no) \[<span class="keyword">default</span>=no\]: yes</span><br><span class="line">Cluster trust password: </span><br><span class="line">All existing data is lost when joining a cluster, <span class="keyword">continue</span>? (yes/no) \[<span class="keyword">default</span>=no\] yes</span><br><span class="line">Would you like a YAML <span class="string">&quot;lxd init&quot;</span> preseed to be printed? (yes/no) \[<span class="keyword">default</span>=no\]: </span><br></pre></td></tr></table></figure>

<p><strong>集群管理</strong><br>集群节点列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc cluster list</span><br><span class="line">+---------+--------------------------+----------+--------+-------------------+</span><br><span class="line"> NAME URL DATABASE STATE MESSAGE </span><br><span class="line">+---------+--------------------------+----------+--------+-------------------+</span><br><span class="line"> vm02 https:<span class="comment">//10.100.0.33:8443 YES ONLINE fully operational </span></span><br><span class="line">+---------+--------------------------+----------+--------+-------------------+</span><br><span class="line"> vmsvr02 https:<span class="comment">//10.100.0.31:8443 YES ONLINE fully operational </span></span><br><span class="line">+---------+--------------------------+----------+--------+-------------------+</span><br><span class="line"> web https:<span class="comment">//10.100.0.80:8443 YES ONLINE fully operational </span></span><br><span class="line">+---------+--------------------------+----------+--------+-------------------+</span><br></pre></td></tr></table></figure>

<p>容器静态迁移，假设容器名字为foo，将其移动到node2主机运行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc stop foo</span><br><span class="line">$ lxc move foo --target node2</span><br></pre></td></tr></table></figure>
<p>容器所在主机故障时，可以使用lxc move移动容器到健康的节点继续运行，因为使用ceph,这个过程中没有主机间的数据拷贝。</p>
<p>如果lxd集群支持在线迁移和故障自动迁移就好用多了。</p>
<p>References:<br>[1]<a href="https://lxd.readthedocs.io/en/latest/clustering/">Clustering</a><br>[2]<a href="https://ubuntu.com/blog/lxd-clusters-a-primer">LXD Clusters: A Primer</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器与apparmor</title>
    <url>/2019/06/06/lxd-container-apparmor/</url>
    <content><![CDATA[<a id="more"></a>
<p>安全很重要，但也很烦人。</p>
<p>lxd容器test8内无法启动tomcat9,查看服务状态如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># systemctl status tomcat9</span><br><span class="line">● tomcat9.service - Apache Tomcat <span class="number">9</span> Web Application Server</span><br><span class="line"> Loaded: loaded (<span class="regexp">/lib/</span>systemd/system/tomcat9.service; enabled; vendor preset: enabled)</span><br><span class="line"> Active: failed (Result: exit-code) since Thu <span class="number">2019</span>-<span class="number">06</span>-<span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> CST; 10min ago</span><br><span class="line"> Docs: https:<span class="comment">//tomcat.apache.org/tomcat-9.0-doc/index.html</span></span><br><span class="line"> Process: <span class="number">187</span> ExecStartPre=<span class="regexp">/usr/</span>libexec/tomcat9/tomcat-update-policy.sh (code=exited, status=<span class="number">0</span>/SUCCESS)</span><br><span class="line"> Process: <span class="number">191</span> ExecStart=<span class="regexp">/bin/</span>sh /usr/libexec/tomcat9/tomcat-start.sh (code=exited, status=<span class="number">226</span>/NAMESPACE)</span><br><span class="line"> Main PID: <span class="number">191</span> (code=exited, status=<span class="number">226</span>/NAMESPACE)</span><br><span class="line"></span><br><span class="line">Jun <span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> test8 systemd\[<span class="number">1</span>\]: Starting Apache Tomcat <span class="number">9</span> Web Application Server...</span><br><span class="line">Jun <span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> test8 systemd\[<span class="number">1</span>\]: Started Apache Tomcat <span class="number">9</span> Web Application Server.</span><br><span class="line">Jun <span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> test8 systemd\[<span class="number">191</span>\]: tomcat9.service: Failed to set up mount namespacing: Permission den</span><br><span class="line">ied</span><br><span class="line">Jun <span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> test8 systemd\[<span class="number">191</span>\]: tomcat9.service: Failed at step NAMESPACE spawning /bin/sh: Permiss</span><br><span class="line">ion denied</span><br><span class="line">Jun <span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> test8 systemd\[<span class="number">1</span>\]: tomcat9.service: Main process exited, code=exited, status=<span class="number">226</span>/NAMESPA</span><br><span class="line">CE</span><br><span class="line">Jun <span class="number">06</span> <span class="number">20</span>:<span class="number">52</span>:<span class="number">24</span> test8 systemd\[<span class="number">1</span>\]: tomcat9.service: Failed <span class="keyword">with</span> result <span class="string">&#x27;exit-code&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>这里就是因为apparmor阻止了一些资源的访问，细粒度的配置还需要仔细阅读文档，当前可以暂时关闭apparmor对容器的所有限制</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc config set test8 raw.lxc <span class="string">&quot;lxc.apparmor.profile=unconfined&quot;</span></span><br><span class="line">$ lxc restart test8</span><br></pre></td></tr></table></figure>

<p>然后就可以正常启动tomcat9服务了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器运行dmesg权限问题</title>
    <url>/2019/10/24/lxd-container-dmesg-permission/</url>
    <content><![CDATA[<a id="more"></a>
<p>默认配置的非特权lxd容器内，即使以特权用户运行dmesg</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># dmesg</span><br><span class="line">dmesg: read kernel buffer failed: Operation not permitted</span><br></pre></td></tr></table></figure>
<p>也是不允许访问内核缓冲区的，这是因为目前容器尚不能做到只读取自己相关的dmesg信息，如果允许容器运行dmesg,容器则会读取到主机全部的信息，包括主机和其他容器以及apparmor的信息，这是安全问题，lxd以后应该会支持每容器的dmesg信息，现在只能在主机上简单粗暴的设置内核参数kernel.dmesg_restrict，特权容器不受此参数限制。</p>
<p>如果允许容器运行dmesg，则需要关闭此参数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo sysctl kernel.dmesg_restrict=<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/lxc/lxd/issues/1397">deny access to dmesg or use SYSLOG namespace</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>lxd</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器初步</title>
    <url>/2019/06/02/lxd-container-first/</url>
    <content><![CDATA[<a id="more"></a>
<p>docker为应用级容器技术，容器内只能运行一个主进程，而lxd是lxc的上层包装，是系统级容器技术，可以像虚拟化技术一样在容器内运行一个guest OS，但是更轻量。</p>
<p>惯例，主机debian，这次版本是buster。</p>
<p><strong>安装snap</strong></p>
<p>lxd是ubuntu亲生的,所以除了ubuntu可以直接用apt安装，其他发行版需要用snap安装，忍！</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install snapd</span><br></pre></td></tr></table></figure>

<p><strong>安装lxd</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo snap install lxd --channel=<span class="number">3.0</span>/stable</span><br></pre></td></tr></table></figure>
<p>这里选择stable版本</p>
<p><strong>用户权限及sudo</strong></p>
<p>如果想使用当前普通用户来管理lxd容器，则需要将用户添加到lxd用户组中 </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo adduser $USER lxd</span><br></pre></td></tr></table></figure>
<p>当前用户需要重新登录用户组才能生效</p>
<p>因为snap安装的lxd并不在任何传统的文件系统中，它奇葩的位于/snap/bin路径下，so需要编辑/etc/sudoer文件，添加/snap/bin到secure_path</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ which lxd</span><br><span class="line">/snap/bin/lxd</span><br></pre></td></tr></table></figure>

<p>下面就可以进入正题了</p>
<p><strong>初始化lxd</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxd init</span><br></pre></td></tr></table></figure>
<p>基本上一路enter即可，以后再详细了解每一项的含义吧, go</p>
<p><strong>创建容器</strong><br>从官方镜像源创建debian buster容器实例bst</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc launch images:debian/buster/amd64 bst</span><br></pre></td></tr></table></figure>

<p>如果创建ubuntu容器实例ubt，则可以这样</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc launch ubuntu:<span class="number">18.04</span> ubt</span><br></pre></td></tr></table></figure>
<p>ubuntu的源标签是ubuntu，其他所有发行版的源标签是images，再一次，忍！</p>
<p><strong>容器列表</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc list</span><br><span class="line">+------+---------+---------------------+-----------------------------------------------+------------+-----------+</span><br><span class="line"> NAME STATE IPV4 IPV6 TYPE SNAPSHOTS </span><br><span class="line">+------+---------+---------------------+-----------------------------------------------+------------+-----------+</span><br><span class="line"> bst RUNNING <span class="number">10.132</span><span class="number">.77</span><span class="number">.54</span> (eth0) fd42:2d28:<span class="number">4331</span>:ad36:<span class="number">216</span>:3eff:fed5:4b5c (eth0) PERSISTENT <span class="number">0</span> </span><br><span class="line">+------+---------+---------------------+-----------------------------------------------+------------+-----------+</span><br></pre></td></tr></table></figure>

<p><strong>查看容器实例信息</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc info bst</span><br><span class="line">Name: bst</span><br><span class="line">Remote: unix:<span class="comment">//</span></span><br><span class="line">Architecture: x86_64</span><br><span class="line">Created: <span class="number">2019</span>/<span class="number">06</span>/<span class="number">02</span> <span class="number">03</span>:<span class="number">19</span> UTC</span><br><span class="line">Status: Running</span><br><span class="line">Type: persistent</span><br><span class="line">Profiles: <span class="keyword">default</span></span><br><span class="line">Pid: <span class="number">1166</span></span><br><span class="line">Ips:</span><br><span class="line"> eth0:inet10<span class="number">.132</span><span class="number">.77</span>.54vethKTBXNA</span><br><span class="line"> eth0:inet6fd42:2d28:<span class="number">4331</span>:ad36:<span class="number">216</span>:3eff:fed5:4b5cvethKTBXNA</span><br><span class="line"> eth0:inet6fe80::<span class="number">216</span>:3eff:fed5:4b5cvethKTBXNA</span><br><span class="line"> lo:inet127<span class="number">.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"> lo:inet6::<span class="number">1</span></span><br><span class="line">Resources:</span><br><span class="line"> Processes: <span class="number">6</span></span><br><span class="line"> CPU usage:</span><br><span class="line"> CPU usage (<span class="keyword">in</span> seconds): <span class="number">7</span></span><br><span class="line"> Memory usage:</span><br><span class="line"> Memory (current): <span class="number">211.</span>66MB</span><br><span class="line"> Memory (peak): <span class="number">297.</span>09MB</span><br><span class="line"> Network usage:</span><br><span class="line"> eth0:</span><br><span class="line"> Bytes received: <span class="number">1.</span>43MB</span><br><span class="line"> Bytes sent: <span class="number">69.</span>46kB</span><br><span class="line"> Packets received: <span class="number">966</span></span><br><span class="line"> Packets sent: <span class="number">902</span></span><br><span class="line"> lo:</span><br><span class="line"> Bytes received: 0B</span><br><span class="line"> Bytes sent: 0B</span><br><span class="line"> Packets received: <span class="number">0</span></span><br><span class="line"> Packets sent: <span class="number">0</span></span><br></pre></td></tr></table></figure>

<p><strong>容器交互</strong><br>获取容器的shell</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc exec first -- <span class="regexp">/bin/</span>bash</span><br></pre></td></tr></table></figure>

<p>或者执行一次性命令</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc exec first -- apt install procps</span><br></pre></td></tr></table></figure>
<p>源里的镜像很干净，基本的工具都需要自己安装，比如procps包里提供了free, kill, pkill, pgrep, pmap, ps, pwdx, skill, slabtop, snice, sysctl, tload, top, uptime, vmstat, w, 和 watch等基本命令行工具</p>
<p>从容器内部往外拉取文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc file pull first/etc/hosts .</span><br></pre></td></tr></table></figure>
<p>从外部向容器推送文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc file push hosts first/etc/</span><br></pre></td></tr></table></figure>

<p>向容器推送文件夹</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc file push -r folder first/path/to</span><br></pre></td></tr></table></figure>

<p><strong>停止容器</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc stop bst</span><br></pre></td></tr></table></figure>

<p><strong>彻底删除容器</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc <span class="keyword">delete</span> bst</span><br></pre></td></tr></table></figure>

<p><strong>管理远程lxd服务器</strong><br>lxc命令行工具既可以管理本地lxd服务器，也可以管理远程lxd服务器，这里的服务器是指运行的用于管理容器的lxd服务</p>
<p>要管理远程lxd服务器，首先在远程lxd服务器上执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc config set core.https_address <span class="string">&quot;\[::\]&quot;</span></span><br><span class="line">$ lxc config set core.trust_password some-password</span><br></pre></td></tr></table></figure>

<p>第一条命令使lxd服务在所有本地地址上监听8443端口<br>第二条命令设定访问的密码凭证</p>
<p>然后就可以在本地添加远程的lxd服务器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc remote add host-a &lt;ip address or DNS name&gt;</span><br></pre></td></tr></table></figure>
<p>会提示服务器指纹，并要求提供上一步设置的密码，完成之后就可以像管理本地lxd服务一样来管理远程lxd服务，除了要明确的指定远程lxd服务区的别名之外：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc exec host-a:bst -- <span class="regexp">/bin/</span>bash</span><br></pre></td></tr></table></figure>
<p>这就是在本地管理远程lxd服务器的容器实例了。</p>
<p>后面继续探索…</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器挂载NFS/CIFS文件系统</title>
    <url>/2019/10/24/lxd-container-mount-nfs-cifs/</url>
    <content><![CDATA[<a id="more"></a>
<p>lxd容器内挂载NFS文件系统时出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mount -t nfs <span class="number">192.168</span><span class="number">.0</span><span class="number">.62</span>:<span class="regexp">/srv/</span>homes/upload /mnt/nfs/</span><br><span class="line">mount.nfs: Operation not permitted</span><br><span class="line">$ sudo mount -t nfs -v <span class="number">192.168</span><span class="number">.0</span><span class="number">.62</span>:<span class="regexp">/srv/</span>homes/upload /mnt/nfs/</span><br><span class="line">mount.nfs: timeout set <span class="keyword">for</span> Thu Oct <span class="number">24</span> <span class="number">19</span>:<span class="number">05</span>:<span class="number">41</span> <span class="number">2019</span></span><br><span class="line">mount.nfs: trying text-based options <span class="string">&#x27;vers=4.2,addr=192.168.0.62,clientaddr=10.100.0.20&#x27;</span></span><br><span class="line">mount.nfs: mount(<span class="number">2</span>): Operation not permitted</span><br><span class="line">mount.nfs: trying text-based options <span class="string">&#x27;addr=192.168.0.62&#x27;</span></span><br><span class="line">mount.nfs: prog <span class="number">100003</span>, trying vers=<span class="number">3</span>, prot=<span class="number">6</span></span><br><span class="line">mount.nfs: trying <span class="number">192.168</span><span class="number">.0</span><span class="number">.62</span> prog <span class="number">100003</span> vers <span class="number">3</span> prot TCP port <span class="number">2049</span></span><br><span class="line">mount.nfs: prog <span class="number">100005</span>, trying vers=<span class="number">3</span>, prot=<span class="number">17</span></span><br><span class="line">mount.nfs: trying <span class="number">192.168</span><span class="number">.0</span><span class="number">.62</span> prog <span class="number">100005</span> vers <span class="number">3</span> prot UDP port <span class="number">39588</span></span><br><span class="line">mount.nfs: mount(<span class="number">2</span>): Operation not permitted</span><br><span class="line">mount.nfs: Operation not permitted</span><br></pre></td></tr></table></figure>
<p>总之就是权限问题，因为容器是非特权容器，在容器内使用root并不是真正的特权用户，因此仍然无法挂载NFS文件系统，CIFS也是一样的问题。<br>简单的解决办法就是将容器设置为特权容器：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc config set container raw.lxc <span class="string">&quot;lxc.apparmor.profile=unconfined&quot;</span></span><br><span class="line">$ lxc config set container security.privileged <span class="literal">true</span></span><br><span class="line">$ lxc restart container</span><br></pre></td></tr></table></figure>
<p>restart容器之后挂载一切如常。<br><strong>注意一定要同时关闭apparmor</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>lxd</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器设置时区</title>
    <url>/2019/06/12/lxd-container-set-timezone/</url>
    <content><![CDATA[<a id="more"></a>
<p>lxd容器默认使用UTC时间，可以这样设置容器的时区：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc config set mycontainer environment.TZ Asia/Shanghai</span><br></pre></td></tr></table></figure>

<p>也可以设置lxd default profile，这样使用default profile新建的容器会继承时区设置：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile set <span class="keyword">default</span> environment.TZ Asia/Shanghai</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器桥接host网络</title>
    <url>/2019/06/03/lxd-containers-bridged-host-network/</url>
    <content><![CDATA[<a id="more"></a>
<p>lxd容器默认的profile使用独立的私有桥接NAT网络，从外部不能直接访问容器。可以配置容器使用host网桥，从而可以使用与host在同一网段的ip地址，就可以方便的像访问host一样来访问容器了。</p>
<p><strong>host设置网桥</strong></p>
<p>安装bridge-utils</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install bridge-utiles</span><br></pre></td></tr></table></figure>

<p>编辑/etc/network/interfaces文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># This file describes the network interfaces available on your system</span><br><span class="line"># and how to activate them. For more information, see interfaces(5).</span><br><span class="line"></span><br><span class="line">source /etc/network/interfaces.d<span class="comment">/*</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># The loopback network interface</span></span><br><span class="line"><span class="comment">auto lo</span></span><br><span class="line"><span class="comment">iface lo inet loopback</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># The primary network interface</span></span><br><span class="line"><span class="comment">auto enp0s3</span></span><br><span class="line"><span class="comment">iface enp0s3 inet manual</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># bridge interface</span></span><br><span class="line"><span class="comment">auto br0 </span></span><br><span class="line"><span class="comment">iface br0 inet static</span></span><br><span class="line"><span class="comment"> address 192.168.3.6/24</span></span><br><span class="line"><span class="comment"> gateway 192.168.3.1</span></span><br><span class="line"><span class="comment"> # bridge options</span></span><br><span class="line"><span class="comment"> bridge_ports enp0s3</span></span><br><span class="line"><span class="comment"> bridge_stp off </span></span><br><span class="line"><span class="comment"> bridge_fd 0</span></span><br><span class="line"><span class="comment"> bridge_maxwait 0</span></span><br><span class="line"><span class="comment"> bridge_waitport 0 </span></span><br></pre></td></tr></table></figure>
<p>这里配置了host本地网桥br0，需要重新启动网络才能生效。</p>
<p><strong>配置容器网络接口(方法一)</strong></p>
<p>为容器添加网络设备eth0，桥接到host本地网络</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc config device add bst eth0 nic nictype=bridged parent=br0 name=eth0</span><br></pre></td></tr></table></figure>
<p>注意，容器原有的重名网络设备eth0会被直接覆盖，这时候容器新添加的网络设备默认使用dhcp获取ip地址，如果需要指定静态ip，请编辑容器的/etc/network/interfaces文件。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc exec bst -- vim /etc/network/interfaces</span><br></pre></td></tr></table></figure>

<p><strong>配置容器网络接口(方法二)</strong></p>
<p>通过创建新的profile，并使已有容器或新建容器使用此profile</p>
<p>查看现有profile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile list</span><br><span class="line">+---------+---------+</span><br><span class="line"> NAME USED BY </span><br><span class="line">+---------+---------+</span><br><span class="line"> <span class="keyword">default</span> <span class="number">1</span> </span><br><span class="line">+---------+---------+</span><br></pre></td></tr></table></figure>
<p>可以看到有一个容器在使用默认profile，来看一下default profile的配置：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile show <span class="keyword">default</span> </span><br><span class="line">config: &#123;&#125;</span><br><span class="line">description: Default LXD profile</span><br><span class="line">devices:</span><br><span class="line"> eth0:</span><br><span class="line"> name: eth0</span><br><span class="line"> nictype: bridged</span><br><span class="line"> parent: lxdbr0</span><br><span class="line"> type: nic</span><br><span class="line"> root:</span><br><span class="line"> path: /</span><br><span class="line"> pool: <span class="keyword">default</span></span><br><span class="line"> type: disk</span><br><span class="line">name: <span class="keyword">default</span></span><br><span class="line">used_by:</span><br><span class="line">- <span class="regexp">/1.0/</span>containers/bst</span><br></pre></td></tr></table></figure>
<p>其实这就是执行<code>lxd init</code>命令时创建的默认profile</p>
<p>下面创建新的host桥接网络profile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile create hostbridgedprofile</span><br><span class="line">Profile hostbridgedprofile created</span><br></pre></td></tr></table></figure>

<p>编辑新添加的profile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat &lt;&lt;EOF lxc profile edit hostbridgedprofile</span><br><span class="line">description: Host Bridged networking LXD profile</span><br><span class="line">devices:</span><br><span class="line"> eth0:</span><br><span class="line"> name: eth0</span><br><span class="line"> nictype: bridged</span><br><span class="line"> parent: br0</span><br><span class="line"> type: nic</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>

<p>可以确认一下新的profile:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile list</span><br><span class="line">+--------------------+---------+</span><br><span class="line"> NAME USED BY </span><br><span class="line">+--------------------+---------+</span><br><span class="line"> <span class="keyword">default</span> <span class="number">1</span> </span><br><span class="line">+--------------------+---------+</span><br><span class="line"> hostbridgedprofile <span class="number">0</span> </span><br><span class="line">+--------------------+---------+</span><br><span class="line"></span><br><span class="line">$ lxc profile show hostbridgedprofile</span><br><span class="line">config: &#123;&#125;</span><br><span class="line">description: Host Bridged networking LXD profile</span><br><span class="line">devices:</span><br><span class="line"> eth0:</span><br><span class="line"> name: eth0</span><br><span class="line"> nictype: bridged</span><br><span class="line"> parent: br0</span><br><span class="line"> type: nic</span><br><span class="line">name: hostbridgedprofile</span><br><span class="line">used_by: \[\]</span><br></pre></td></tr></table></figure>

<p>在现有容器bst上叠加新添加的profile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile assign bst <span class="keyword">default</span>,hostbridgedprofile </span><br><span class="line">Profiles <span class="keyword">default</span>,hostbridgedprofile applied to bst</span><br></pre></td></tr></table></figure>
<p>注意，这里先使用default，然后用hostbridgedprofile来覆盖默认的网络设置</p>
<p>新建容器可以指定要使用的profile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc launch -p <span class="keyword">default</span> -p hostbridgedprofile images:debian/buster/amd64 new_container</span><br></pre></td></tr></table></figure>

<p>如果一个profile不再使用，可以删除掉，当然不能有容器在使用它才行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile <span class="keyword">delete</span> hostbridgedprofile </span><br><span class="line"><span class="built_in">Error</span>: Profile is currently <span class="keyword">in</span> use</span><br></pre></td></tr></table></figure>

<p><strong>配置容器网络接口(方法三)</strong></p>
<p>重新初始化lxd,注意在有容器实例存在的情况下，重新初始化网络设置是可以的，但是已经存在的storage pool是不能改动的，当然可以添加新的storage pool</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxd init</span><br><span class="line">Would you like to use LXD clustering? (yes/no) \[<span class="keyword">default</span>=no\]: </span><br><span class="line">Do you want to configure a <span class="keyword">new</span> storage pool? (yes/no) \[<span class="keyword">default</span>=yes\]: no</span><br><span class="line">Would you like to connect to a MAAS server? (yes/no) \[<span class="keyword">default</span>=no\]: </span><br><span class="line">Would you like to create a <span class="keyword">new</span> local network bridge? (yes/no) \[<span class="keyword">default</span>=yes\]: no &lt;=这里为no</span><br><span class="line">Would you like to configure LXD to use an existing bridge or host interface? (yes/no) \[<span class="keyword">default</span>=no\]: yes &lt;= 这里为yes</span><br><span class="line">Name <span class="keyword">of</span> the existing bridge or host interface: br0 &lt;= 这里输入主机桥接接口bro</span><br><span class="line">Would you like LXD to be available over the network? (yes/no) \[<span class="keyword">default</span>=no\]: </span><br><span class="line">Would you like stale cached images to be updated automatically? (yes/no) \[<span class="keyword">default</span>=yes\] </span><br><span class="line">Would you like a YAML <span class="string">&quot;lxd init&quot;</span> preseed to be printed? (yes/no) \[<span class="keyword">default</span>=no\]: </span><br></pre></td></tr></table></figure>
<p>这其实是修改的default profile</p>
<p>References:<br>[1]<a href="https://blog.simos.info/how-to-initialize-lxd-again/">How to initialize LXD again</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd拷贝/迁移容器</title>
    <url>/2019/06/04/lxd-copy-move-containers/</url>
    <content><![CDATA[<a id="more"></a>
<p>假设有两个lxd host，分别为lxd-l和lxd-r,在lxd-l机器上添加一个remote叫做lxd-r</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc remote add lxd-r &lt;ip <span class="keyword">of</span> lxd-r&gt;</span><br></pre></td></tr></table></figure>

<p><strong>拷贝容器</strong></p>
<ol>
<li>停止容器并拷贝到远程</li>
</ol>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc stop pridns</span><br><span class="line">$ lxc copy pridns lxd-r:pridns-backup</span><br><span class="line">$ lxc start pridns</span><br></pre></td></tr></table></figure>

<ol start="2">
<li><p>制作容器快照，第一个快照为snap0，以此类推，然后拷贝快照到lxd-r</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc snapshot my-container</span><br><span class="line">$ lxc copy my-container/snap0 lxd-r:my-container-backup</span><br></pre></td></tr></table></figure>
</li>
<li><p>直接拷贝运行中的容器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc copy pridns lxd-r:pridns-backup</span><br><span class="line"><span class="built_in">Error</span>: Unable to perform container live migration. CRIU isn<span class="string">&#x27;t installed on the source server</span></span><br></pre></td></tr></table></figure>
<p>直接拷贝运行中的容器叫做live migration，需要将其运行状态一起拷贝到目标容器，保持二者完全一致，这需要CRIU的支持，lxd已经打包了CUIR,需要在本地和远程host上分别启用CRIU</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo snap set lxd criu.enable=<span class="literal">true</span></span><br><span class="line">$ sudo systemctl reload snap.lxd.daemon</span><br></pre></td></tr></table></figure>
<p>然后再拷贝</p>
</li>
</ol>
<p>lxc move</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd镜像/映像</title>
    <url>/2019/06/04/lxd-images/</url>
    <content><![CDATA[<a id="more"></a>
<p>lxd使用镜像来生成容器，可以有几种不同的方式来使用镜像</p>
<p><strong>内建映像服务</strong></p>
<p>lxd内建三个映像服务，分别是<br>ubuntu - 提供稳定版ubuntu镜像<br>ubuntu-daily - 提供每日构建版ubuntu镜像<br>images - 提供其他发行版镜像</p>
<p>这样使用内置镜像服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc launch ubuntu:<span class="number">18.04</span> my-ubuntu</span><br><span class="line">$ lxc launch ubuntu-daily:<span class="number">19.04</span> my-ubuntu-dev</span><br><span class="line">$ lxc launch images:debian/buster/amd64 my-debian</span><br></pre></td></tr></table></figure>

<p>显示镜像列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc image list ubuntu:</span><br><span class="line">$ lxc image list ubuntu-daily:</span><br><span class="line">$ lxc image list images:</span><br></pre></td></tr></table></figure>

<p><strong>使用远程lxd实例的镜像</strong></p>
<p>添加远程lxd实例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc remote add my-images <span class="number">192.168</span><span class="number">.0</span>.x</span><br></pre></td></tr></table></figure>

<p>使用远程lxd实例的镜像实例化容器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc launch my-images:image-name your-container</span><br></pre></td></tr></table></figure>

<p>远程lxd实例上的镜像列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc image list my-images:</span><br></pre></td></tr></table></figure>

<p>其实lxd内建的镜像服务就是lxd实例，无非其remote的名字为ubuntu, ubuntu-daily和images而已。</p>
<p><strong>手动导入镜像文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc image <span class="keyword">import</span> &lt;file&gt; --alias my-alias</span><br></pre></td></tr></table></figure>

<p>使用此导入的镜像</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc launch my-alias my-container</span><br></pre></td></tr></table></figure>

<p><strong>使用容器或快照创建镜像</strong></p>
<p>使用容器创建镜像</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc my-container stop</span><br><span class="line">$ lxc publish my-container --alias test-image</span><br></pre></td></tr></table></figure>

<p>使用快照创建镜像</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc publish my-container/my-snap --alias test-image2</span><br></pre></td></tr></table></figure>

<p>之后就可以正常的使用这些镜像来生成容器了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器快照</title>
    <url>/2019/06/04/lxd-snapshots/</url>
    <content><![CDATA[<a id="more"></a>
<p>以下使用的容器名字为test8，运行debian/buster/amd64</p>
<p><strong>创建容器快照</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc snapshot test8 test8snap0</span><br></pre></td></tr></table></figure>

<p>默认创建的是无状态快照，如果要将容器当前的运行状态一起保存到快照，需要使用<code>--stateful</code>参数,比如</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc snapshot test8 test8snap1 --stateful</span><br></pre></td></tr></table></figure>

<p><strong>查看容器快照</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc info test8</span><br><span class="line">Name: test8</span><br><span class="line">Remote: unix:<span class="comment">//</span></span><br><span class="line">Architecture: x86_64</span><br><span class="line">Created: <span class="number">2019</span>/<span class="number">06</span>/<span class="number">04</span> <span class="number">07</span>:<span class="number">52</span> UTC</span><br><span class="line">Status: Running</span><br><span class="line">Type: persistent</span><br><span class="line">Profiles: <span class="keyword">default</span></span><br><span class="line">Pid: <span class="number">7769</span></span><br><span class="line">Ips:</span><br><span class="line"> eth0: inet <span class="number">192.168</span><span class="number">.0</span><span class="number">.8</span> vethM2PWUN</span><br><span class="line"> eth0: inet6 fe80::<span class="number">216</span>:3eff:fea7:706b vethM2PWUN</span><br><span class="line"> lo: inet <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br><span class="line"> lo: inet6 ::<span class="number">1</span></span><br><span class="line">Resources:</span><br><span class="line"> Processes: <span class="number">5</span></span><br><span class="line"> CPU usage:</span><br><span class="line"> CPU usage (<span class="keyword">in</span> seconds): <span class="number">123</span></span><br><span class="line"> Memory usage:</span><br><span class="line"> Memory (current): <span class="number">2.</span>05GB</span><br><span class="line"> Memory (peak): <span class="number">2.</span>45GB</span><br><span class="line"> Network usage:</span><br><span class="line"> eth0:</span><br><span class="line"> Bytes received: <span class="number">347.</span>96MB</span><br><span class="line"> Bytes sent: <span class="number">5.</span>86MB</span><br><span class="line"> Packets received: <span class="number">132127</span></span><br><span class="line"> Packets sent: <span class="number">63110</span></span><br><span class="line"> lo:</span><br><span class="line"> Bytes received: <span class="number">4.</span>07kB</span><br><span class="line"> Bytes sent: <span class="number">4.</span>07kB</span><br><span class="line"> Packets received: <span class="number">52</span></span><br><span class="line"> Packets sent: <span class="number">52</span></span><br><span class="line">Snapshots:</span><br><span class="line"> test8snap0 (taken at <span class="number">2019</span>/<span class="number">06</span>/<span class="number">04</span> <span class="number">08</span>:<span class="number">17</span> UTC) (stateless)</span><br></pre></td></tr></table></figure>

<p><strong>快照恢复</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc restore test8 test8snap0</span><br></pre></td></tr></table></figure>

<p><strong>删除快照</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc <span class="keyword">delete</span> test8/test8snap0</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>lxd容器使用zfs存储池</title>
    <url>/2019/08/08/lxd-zfs-storagepool/</url>
    <content><![CDATA[<a id="more"></a>
<p>lxd支持btrfs,zfs,lvm和ceph存储后端，默认使用btrfs，但在线迁移容器的时候btrfs总是不成功，可以尝试更换到zfs存储后端，zfsonlinux项目已经十分成熟。</p>
<p><strong>安装</strong></p>
<p>buster发布后，debian-backports已经启用了，为了安装更新版本的zfs，最好添加这个源：<br>/etc/apt/source.list</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># backports</span><br><span class="line">deb http:<span class="comment">//ftp.cn.debian.org/debian buster-backports main contrib non-free</span></span><br></pre></td></tr></table></figure>
<p>/etc/apt/preferences.d/90_zfs</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Package: libnvpair1linux libuutil1linux libzfs2linux libzpool2linux spl-dkms zfs-dkms zfs-test zfsutils-linux zfsutils-linux-dev zfs-zed</span><br><span class="line">Pin: release n=buster-backports</span><br><span class="line">Pin-Priority: <span class="number">990</span></span><br></pre></td></tr></table></figure>

<p>因为需要编译内核模块,先安装内核头文件</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt update</span><br><span class="line"># apt install linux-headers-$(uname -r) linux-image-amd64</span><br></pre></td></tr></table></figure>

<p>安装zfsonlinux</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install zfs-dkms zfsutils-linux</span><br></pre></td></tr></table></figure>
<p>安装到最后会有一些错误提示，不要害怕，那是因为还没有加载zfs内核模块</p>
<p>加载内核模块</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># modprobe zfs</span><br></pre></td></tr></table></figure>

<p>然后重新执行上一个安装命令，zfs就会配置成功了。</p>
<p>系统自动加载内核模块</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># echo &quot;zfs&quot; &gt;&gt; /etc/modules</span><br></pre></td></tr></table></figure>

<p>如果安装zfs之前已经安装了lxd，那么需要将lxd daemon重启一下，否则lxd会报错：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Error</span>: The <span class="string">&quot;zfs&quot;</span> tool is not enabled</span><br></pre></td></tr></table></figure>

<p>重启lxd daemon</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl reload snap.lxd.daemon</span><br></pre></td></tr></table></figure>

<p><strong>存储池</strong></p>
<p><code>lxd init</code>的时候就可以选择ZFS作为存储后端来新建default storage pool了，默认会使用当前文件系统内的文件来虚拟一个zfs文件系统，也可以使用真实的zfs文件系统来建立存储池。</p>
<p>也可以使用<code>lxc storage create</code>命令来创建新的使用zfs作为存储后端的存储池。<br>创建zfs存储池lxd_zfs</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc storage create lxd_zfs zfs size=100GB</span><br></pre></td></tr></table></figure>

<p>将默认配置的存储池设置为lxd_zfs，前提是没有容器在使用default profile的root disk设备。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc profile device remove <span class="keyword">default</span> root</span><br><span class="line">$ lxc profile device add <span class="keyword">default</span> root disk path=/ pool=lxd_zfs</span><br><span class="line">$ lxc profile show <span class="keyword">default</span> </span><br><span class="line">config: &#123;&#125;</span><br><span class="line">description: Default LXD profile</span><br><span class="line">devices:</span><br><span class="line"> eth0:</span><br><span class="line"> name: eth0</span><br><span class="line"> nictype: bridged</span><br><span class="line"> parent: lxdbr0</span><br><span class="line"> type: nic</span><br><span class="line"> root:</span><br><span class="line"> path: /</span><br><span class="line"> pool: lxd_zfs</span><br><span class="line"> type: disk</span><br><span class="line">name: <span class="keyword">default</span></span><br><span class="line">used_by: \[\]</span><br></pre></td></tr></table></figure>

<p>后面再新建容器就会自动使用zfs存储池lxd_zfs了。<br>也可以将default存储池删除掉，重现创建一个default存储池，只要default存储池没有被镜像、容器或profile使用即可。<br>其实default就是一个名字而已，与其他存储池并无任何不同。</p>
<p>References:<br>[1]<a href="https://angristan.xyz/lxc-zfs-pool-lxd/">Setup a ZFS pool for your LXC containers with LXD</a><br>[2]<a href="https://zfsonlinux.org/">zfsonlinux</a><br>[3]<a href="https://github.com/zfsonlinux/zfs/wiki/Debian">debian</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>Mabatis自动生成entity和mapper接口</title>
    <url>/2013/11/23/mabatis-autogenerator/</url>
    <content><![CDATA[<p>Mybatis Generator可以自动生成模型实体对象POJO,mapper接口和对应的xml配置文件。</p>
<a id="more"></a>
<p><a href="http://mybatis.org/generator/">Mybatis Generator</a>提到的模型model其实就是实体entity。</p>
<p>Mybatis Generator的核心就一个jar包mybatis-generator-core-1.3.2.jar，可以从命令行运行，也有相应的eclipse插件。</p>
<p><strong>配置文件</strong></p>
<p>Mybatis Generator需要一个配置文件来生成代码，下面是配置文件的一个样例：<br>[xml]<br><?xml version="1.0" encoding="UTF-8"?><br><!DOCTYPE generatorConfiguration
PUBLIC "-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN"
"http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd"></p>
<generatorConfiguration>
 <classPathEntry location="/path/to/WebRoot/WEB-INF/lib/postgresql-9.2-1003.jdbc4.jar" />
 <context id="BuildingTables" targetRuntime="MyBatis3">

 <commentGenerator>
 <property name="suppressAllComments" value="true" />
 <property name="suppressDate" value="true" />
 </commentGenerator>

<p> <jdbcConnection driverClass="org.postgresql.Driver"
 connectionURL="jdbc:postgresql://localhost/dbname"
 userId="xxx"
 password="xxx"><br> </jdbcConnection></p>
 <javaTypeResolver >
 <property name="forceBigDecimals" value="true" />
 </javaTypeResolver>

 <javaModelGenerator targetPackage="org.xxx.xxx.entity" targetProject="project_name/src/main">
 <property name="enableSubPackages" value="false" />
 <property name="trimStrings" value="true" />
 </javaModelGenerator>

 <sqlMapGenerator targetPackage="org.xxx.xxx.dao" targetProject="project_name/src/main">
 <property name="enableSubPackages" value="false" />
 </sqlMapGenerator>

 <javaClientGenerator type="XMLMAPPER" targetPackage="org.xxx.xxx.dao" targetProject="project_name/src/main">
 <property name="enableSubPackages" value="false" />
 </javaClientGenerator>

 <table schema="base" tableName="tb_building" domainObjectName="Building" >
 <property name="useActualColumnNames" value="true"/>
 </table>
 <table schema="base" tableName="tb_floor" domainObjectName="Floor" >
 <property name="useActualColumnNames" value="true"/>
 </table>
 <table schema="base" tableName="tb_house" domainObjectName="House" >
 <property name="useActualColumnNames" value="true"/>
 </table>

 </context>
</generatorConfiguration>
\[/xml\]

<p>配置文件的详细语法见<a href="http://mybatis.org/generator/">官方文档</a>。</p>
<p><strong>运行Mybatis Generator</strong></p>
<p><em>命令行</em></p>
<p>$ java -jar mybatis-generator-core-x.x.x.jar -configfile generatorConfig.xml</p>
<p><em>eclipse插件</em></p>
<p>在eclipse中配置新的安装源<a href="http://mybatis.googlecode.com/svn/sub-projects/generator/trunk/eclipse/UpdateSite/">http://mybatis.googlecode.com/svn/sub-projects/generator/trunk/eclipse/UpdateSite/</a><br>然后安装即可。</p>
<p>可以通过file-&gt;new-&gt;Mybatis-&gt;Mybatis Generator Configuration File 新建配置文件<br>在配置文件上右击选择Generate Mybatis/iBatis Artifacts产生mapper接口和实体POJO</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>mac系统中文件的@权限</title>
    <url>/2014/04/19/mac-at-permission/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果文件或目录有扩展属性,则使用-l选项执行ls命令时，会在权限许可字段后面附加一个字符@。<br>如果文件或目录有扩展安全信息，则使用-l选项执行ls命令时，会在权限许可字段后面附件一个字符+。</p>
<blockquote>
<p>If the file or directory has extended<br>attributes, the permissions field printed by the -l option is followed by<br>a ‘@’ character. Otherwise, if the file or directory has extended secu-<br>rity information, the permissions field printed by the -l option is fol-<br>lowed by a ‘+’ character.</p>
</blockquote>
<p>详见man ls(1) on Max OS X</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac安装Eclipse</title>
    <url>/2014/04/20/mac-install-eclipse/</url>
    <content><![CDATA[<a id="more"></a>
<p>系统为mavericks</p>
<p>下载Mac OS X(Cocoa 64)版本的Eclipse IDE for Java EE Developers，当前版本为Kepler。</p>
<p>然后将其解压到/opt目录下就算完成了安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># mkdir /opt</span><br><span class="line">$ sudo tar zxvf ~<span class="regexp">/Downloads/</span>eclipse-jee-kepler-SR2-macosx-cocoa-x86_64.tar.gz -C /opt</span><br></pre></td></tr></table></figure>

<p>安装自带了Eclipse.app,将其从finder中拖到dock中的Lauchpad图标上就可以将其加入到Lauchpad中,也可以直接将其拖到dock中。或许将其直接拖放到Applications文件夹中也可以。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac系统ls命令目录优先</title>
    <url>/2014/05/03/mac-ls-directories-first/</url>
    <content><![CDATA[<a id="more"></a>
<p>linux系统上可以指定ls选项<code>--group-directories-first</code>,但是mac系统上的ls命令没有此选项。</p>
<p>有两个方法：</p>
<ul>
<li>  使用grep过滤<br>定义别名:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias ll=<span class="string">&#x27;ls -lh grep ^total &amp;&amp; ls -lh grep ^d &amp;&amp; ls -lh grep -v ^d grep -v ^total&#x27;</span></span><br></pre></td></tr></table></figure></li>
<li>  使用gnu ls<br>安装gnu版本的命令:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install coreutils</span><br></pre></td></tr></table></figure>
定义别名:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias ls=<span class="string">&quot;gls -p --color=auto --group-directories-first&quot;</span></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X更新bash</title>
    <url>/2014/09/20/mac-os-x-bash-upgrade/</url>
    <content><![CDATA[<a id="more"></a>
<p>最新版本的Mac OS X内置的bash仍然是3.x, 下面使用brew更新bash到4.x</p>
<p>安装bash<br><code>js$ brew install bash</code></p>
<p>/etc/shells文件最后附加一下行:<br><code>js/usr/local/bin/bash</code></p>
<p>更改当前用户的shell<br><code>js$ chsh -s /usr/local/bin/bash</code></p>
<p>即便如此,Terminal仍然使用系统内置的bash,也就是/bin/bash,这可以通过Terminal Preferences来修改。修改Shell open with为Default login shell或者为 command(complete path)，空白处填/usr/local/bin/bash即可。</p>
<p>或者更暴力更直接一点:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># cp /bin/bash /bin/bash-3.bak</span><br><span class="line"># ln -sf /usr/local/bin/bash /bin/bash </span><br></pre></td></tr></table></figure>

<p>最后看一下bash版本:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ echo $BASH_VERSION</span><br><span class="line"><span class="number">4.3</span><span class="number">.24</span>(<span class="number">1</span>)-release</span><br><span class="line"></span><br><span class="line">$ bash --version</span><br><span class="line">GNU bash, version <span class="number">4.3</span><span class="number">.24</span>(<span class="number">1</span>)-release (x86_64-apple-darwin13<span class="number">.3</span><span class="number">.0</span>)</span><br><span class="line">Copyright (C) <span class="number">2013</span> Free Software Foundation, Inc.</span><br><span class="line">License GPLv3+: GNU GPL version <span class="number">3</span> or later &lt;http:<span class="comment">//gnu.org/licenses/gpl.html&gt;</span></span><br><span class="line"></span><br><span class="line">This is free software; you are free to change and redistribute it.</span><br><span class="line">There is NO WARRANTY, to the extent permitted by law.</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>mavericks使用brew安装PostgreSQL</title>
    <url>/2014/05/02/mac-os-x-brew-install-postgresql/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install postgresql</span><br><span class="line">...</span><br><span class="line">To have launchd start postgresql at login:</span><br><span class="line"> ln -sfv /usr/local/opt/postgresql<span class="comment">/*.plist ~/Library/LaunchAgents</span></span><br><span class="line"><span class="comment">Then to load postgresql now:</span></span><br><span class="line"><span class="comment"> launchctl load ~/Library/LaunchAgents/homebrew.mxcl.postgresql.plist</span></span><br><span class="line"><span class="comment">Or, if you don&#x27;t want/need launchctl, you can just run:</span></span><br><span class="line"><span class="comment"> postgres -D /usr/local/var/postgres</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X上使用cqlsh命令</title>
    <url>/2014/12/28/mac-os-x-cqlsh/</url>
    <content><![CDATA[<a id="more"></a>
<p>cqlsh是cassandra用于执行cql命令的交互式终端程序,就如postgresql的psql,或者oracle的sql plus。<br>cqlsh是用python编写的,但当前版本5.0.1尚不支持python 3及以上版本,其代码中有如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">python -c <span class="string">&#x27;import sys; sys.exit(not (0x020500b0 &lt; sys.hexversion &lt; 0x03000000))&#x27;</span> <span class="number">2</span>&gt;<span class="regexp">/dev/</span><span class="literal">null</span> \\</span><br><span class="line"> &amp;&amp; exec python <span class="string">&quot;$0&quot;</span> <span class="string">&quot;$@&quot;</span></span><br></pre></td></tr></table></figure>

<p>可见其只支持大于2.5小于3.0的python。</p>
<p>使用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install cassandra</span><br></pre></td></tr></table></figure>
<p>安装cassandra后,已经自动安装好了cqlsh,直接执行cqlsh会有提示需要安装cassandra-driver</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$cqlsh</span><br><span class="line">Python Cassandra driver not installed, or not on PYTHONPATH.</span><br><span class="line">You might <span class="keyword">try</span> <span class="string">&quot;pip install cassandra-driver&quot;</span>.</span><br><span class="line"></span><br><span class="line">Python: <span class="regexp">/usr/</span>bin/python</span><br><span class="line">Module load path: \[<span class="string">&#x27;/usr/local/Cellar/cassandra/2.1.2/bin&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload&#x27;</span>, <span class="string">&#x27;/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/PyObjC&#x27;</span>, <span class="string">&#x27;/Library/Python/2.7/site-packages&#x27;</span>\]</span><br><span class="line"></span><br><span class="line"><span class="built_in">Error</span>: No <span class="built_in">module</span> named cassandra</span><br></pre></td></tr></table></figure>

<p>然后安装cassandra-driver</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pip install cassandra-driver</span><br></pre></td></tr></table></figure>

<p>如果cqlsh仍然提示需要安装cassandra-driver,则是因为系统当前的pip是python3的</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pip show canssandra-driver</span><br><span class="line">---</span><br><span class="line">Name: cassandra-driver</span><br><span class="line">Version: <span class="number">2.1</span><span class="number">.3</span></span><br><span class="line">Location: <span class="regexp">/Library/</span>Frameworks/Python.framework/Versions/<span class="number">3.4</span>/lib/python3<span class="number">.4</span>/site-packages</span><br><span class="line">Requires: futures, six</span><br></pre></td></tr></table></figure>

<p>那么需要安装pip for python 2.x</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install python</span><br></pre></td></tr></table></figure>
<p>然后为python 2.x 安装cassandra-driver</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pip2 install cassandra-driver</span><br><span class="line">$ pip2 show cassandra-driver</span><br><span class="line">---</span><br><span class="line">Name: cassandra-driver</span><br><span class="line">Version: <span class="number">2.1</span><span class="number">.3</span></span><br><span class="line">Location: <span class="regexp">/usr/</span>local/lib/python2<span class="number">.7</span>/site-packages</span><br><span class="line">Requires: futures, six</span><br></pre></td></tr></table></figure>

<p>因为brew安装的python库路径在/usr/local/lib/python2.7/site-packages,所以还需要将其添加到python模块搜索路径,.bashrc中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> PYTHONPATH=$PYTHONPATH:<span class="regexp">/usr/</span>local/lib/python2<span class="number">.7</span>/site-packages</span><br></pre></td></tr></table></figure>

<p>然后再执行cqlsh应该就可以了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cqlsh</span><br><span class="line">Connected to Test Cluster at <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">9042.</span></span><br><span class="line">\[cqlsh <span class="number">5.0</span><span class="number">.1</span> Cassandra <span class="number">2.1</span><span class="number">.2</span> CQL spec <span class="number">3.2</span><span class="number">.0</span> Native protocol v3\]</span><br><span class="line">Use HELP <span class="keyword">for</span> help.</span><br><span class="line">cqlsh&gt; </span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X 库路径环境变量DYLD_LIBRARY_PATH</title>
    <url>/2015/12/30/mac-os-x-dyld-library-path/</url>
    <content><![CDATA[<a id="more"></a>
<p>安装了oracle instant client,执行sqlplus时,找不到库文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">dyld: Library not loaded: <span class="regexp">/ade/</span>dosulliv_sqlplus_mac/oracle/sqlplus/lib/libsqlplus.dylib</span><br><span class="line"> Referenced <span class="keyword">from</span>: <span class="regexp">/opt/</span>oracle/instantclient_11_2/sqlplus</span><br><span class="line"> Reason: image not found</span><br></pre></td></tr></table></figure>

<p>Mac的库路径环境变量与linux不同，其名字为DYLD_LIBRARY_PATH<br>bashrc中设置此变量：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> DYLD_LIBRARY_PATH=$ORACLE_HOME:$DYLD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>问题解决。</p>
<p>References:<br>[1] <a href="http://blog.chinaunix.net/uid-14504139-id-3867128.html">环境变量LIBRARY_PATH的设置</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>FreeBSD</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X没有free命令</title>
    <url>/2014/10/30/mac-os-x-free-memory/</url>
    <content><![CDATA[<a id="more"></a>
<p>想看内存使用情况,linux上使用free命令,mac上没这命令,擦！</p>
<p>参考[1]对此有详尽的描述，甚至写了python脚本来输出内存使用情况，一般下面这个简单点儿的命令就够了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ top -l <span class="number">1</span> head -n <span class="number">10</span> grep PhysMem</span><br><span class="line">PhysMem: 2001M used(659M wired), 6189M unused.</span><br></pre></td></tr></table></figure>

<p>可以在.bashrc文件中添加一个别名叫free</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias free=<span class="string">&#x27;top -l 1 head -n 10 grep PhysMem&#x27;</span></span><br></pre></td></tr></table></figure>

<p>以后直接使用free来查看就可以了。</p>
<p>References:<br>[1]<a href="http://smilejay.com/2014/06/mac-memory-usage-command-line/">Mac上命令行查看系统内存使用量</a><br>[2]<a href="http://apple.stackexchange.com/questions/4286/is-there-a-mac-os-x-terminal-version-of-the-free-command-in-linux-systems">Is there a Mac OS X Terminal version of the “free” command in Linux systems?</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X安装GNU工具</title>
    <url>/2014/09/23/mac-os-x-install-gnu-tools/</url>
    <content><![CDATA[<a id="more"></a>
<p>Mac OS X使用BSD版本的命令行工具,虽然都共同遵守POSIX标准,但其与GUN命令行工具仍然有很多的不同,而且明显不如GNU版本的命令好用。</p>
<p>可以用homebrew来安装GNU命令行工具,下面是<a href="/downloads/gtools.sh">脚本</a>,更详细的内容请参考[1]<br>可以先<a href="https://openwares.net/linux/mac_os_x_bash_upgrade.html">安装最新版本的bash</a>,再运行下面的脚本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/usr/local/bin/bash</span><br><span class="line"></span><br><span class="line"># add source</span><br><span class="line"># brew tap homebrew/dupes</span><br><span class="line"></span><br><span class="line"># GNU Coreutils</span><br><span class="line">brew install coreutils</span><br><span class="line"></span><br><span class="line"># build tools</span><br><span class="line">brew install autoconf</span><br><span class="line">brew install m4</span><br><span class="line">brew install make</span><br><span class="line"></span><br><span class="line"># misc</span><br><span class="line">brew install binutils</span><br><span class="line">brew install diffutils</span><br><span class="line">brew install ed </span><br><span class="line">brew install findutils </span><br><span class="line">brew install gawk</span><br><span class="line">brew install gnu-indent </span><br><span class="line">brew install gnu-sed </span><br><span class="line">brew install gnu-tar </span><br><span class="line">brew install gnu-which </span><br><span class="line">brew install gnutls </span><br><span class="line">brew install grep </span><br><span class="line">brew install gzip</span><br><span class="line">brew install screen</span><br><span class="line">brew install watch</span><br><span class="line">brew install wdiff </span><br><span class="line">brew install wget</span><br><span class="line"></span><br><span class="line"># third party </span><br><span class="line">brew install git</span><br><span class="line">brew install less</span><br><span class="line">brew install openssh </span><br><span class="line">brew install python3 </span><br><span class="line">brew install rsync</span><br><span class="line">brew install unzip</span><br><span class="line">brew install vim </span><br></pre></td></tr></table></figure>

<p>Update(2020/01/26):<br>homebrew/dupes已经deprecated，其下的formula迁移到brew/core下。<br>–default-names选项已经无效。</p>
<p>References:<br>[1]<a href="http://www.topbug.net/blog/2013/04/14/install-and-use-gnu-command-line-tools-in-mac-os-x/">Install and Use GNU Command Line Tools on Mac OS X</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Mac OS X连接IPP打印机的那些坑</title>
    <url>/2015/11/25/mac-os-x-ipp-printer-bugs/</url>
    <content><![CDATA[<a id="more"></a>
<p>Mac OS X 10.11连接linux系统CUPS使用ipp(Internet Printing Protocol)协议共享的打印机时，遇到两个大坑。</p>
<p><strong>系统打印机配置的坑</strong></p>
<p>使用mac系统的打印机配置来连接共享打印机<br>从System Preferences-&gt;Printers &amp; Scanners对话框添加ip打印机，选择IPP协议，address输入正确的共享打印机地址:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http:<span class="comment">//printer_server_ip:631/printers/HP_LaserJet_P1008</span></span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string">无论使用何种驱动，add时都会有提示:</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">Unable to verify the printer on your network.</span><br><span class="line">Unable to connect to ‘printer_server_ip’ due to an error. Would you still like to create the printer?</span><br></pre></td></tr></table></figure>
<p>如果强制添加，<strong>然而并不能真的打印</strong>。<br>事后发现mac os x 10.11系统打印机配置添加的ipp打印机访问地址是错误的，可以通过cups配置界面看到其错误的地址。</p>
<p><strong>HP官方驱动的坑</strong></p>
<p>一直以为官方驱动应该是最靠谱的，不过这次不行。<br>已经提前安装了HP Mac OS X drivers,500多M!</p>
<p>改用cups来添加共享打印机。<br>mac上的cups默认是没有打开web管理界面的，首先启用web管理界面：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cupsctl WebInterface=yes</span><br></pre></td></tr></table></figure>
<p>然后访问<a href="http://127.0.0.1:631打开cups管理界面来添加远程ipp协议共享打印机。">http://127.0.0.1:631打开cups管理界面来添加远程ipp协议共享打印机。</a></p>
<p>Administration-&gt;Printer-&gt;Add Printer-&gt;Other Network Printers-&gt;Internet Printing Protocol(http)</p>
<p>输入ipp打印机的访问地址：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http:<span class="comment">//printer_server_ip:631/printers/HP_LaserJet_P1008</span></span><br></pre></td></tr></table></figure>

<p>选择HP提供的P1008官方驱动，添加完成。</p>
<p><strong>然而并不能打印！</strong></p>
<p>重新修改已添加打印机配置，Printers-&gt;P1008-&gt;Modify Printer将其驱动更改为cups内置的Generic PostScript Printer</p>
<p>打印测试页，<strong>success</strong>!</p>
<p>References:<br>[1]<a href="https://en.wikipedia.org/wiki/Internet_Printing_Protocol">Internet Printing Protocol</a><br>[2]<a href="https://en.wikipedia.org/wiki/Line_Printer_Daemon_protocol">Line Printer Daemon protocol</a><br>[3]<a href="https://support.apple.com/en-us/HT201311">About AirPrint</a><br>[4]<a href="https://en.wikipedia.org/wiki/PostScript_Printer_Description">PostScript Printer Description</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X版金山快盘同步路径更改为英文</title>
    <url>/2014/08/21/mac-os-x-kuaipan-syncpath-english/</url>
    <content><![CDATA[<p>金山快盘应该出个英文版</p>
<a id="more"></a>
<p>金山快盘在英文Mac系统上仍然使用汉字的“快盘”作为同步目录，实在太突兀了。</p>
<p>也没提供配置，可以如下步骤手工修改：</p>
<p>1、退出金山快盘<br>2、修改同步目录名称或者使用一个新的同步目录，当然是英文路径<br>3、打开终端修改快盘配置:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ defaults write com.kingsoft.kuaipan SyncPath ~<span class="regexp">/fastdisk/</span></span><br></pre></td></tr></table></figure>
<p>4、重新启动快盘</p>
<p>Mac OS X上这配置管理和linux差别好大啊！</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X lsusb命令</title>
    <url>/2014/10/31/mac-os-x-lsusb-command/</url>
    <content><![CDATA[<a id="more"></a>
<p>mac os x上没有lsusb命令,可以使用如下命令列出系统usb设备信息:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ system_profiler SPUSBDataType</span><br><span class="line">USB:</span><br><span class="line"></span><br><span class="line"> USB <span class="number">3.0</span> SuperSpeed Bus:</span><br><span class="line"></span><br><span class="line"> Host Controller Location: Built-<span class="keyword">in</span> USB</span><br><span class="line"> Host Controller Driver: AppleUSBXHCI</span><br><span class="line"> PCI Device ID: <span class="number">0x9c31</span> </span><br><span class="line"> PCI Revision ID: <span class="number">0x0004</span> </span><br><span class="line"> PCI Vendor ID: <span class="number">0x8086</span> </span><br><span class="line"> Bus <span class="built_in">Number</span>: <span class="number">0x0a</span> </span><br><span class="line"></span><br><span class="line"> USB <span class="number">3.0</span> Hi-Speed Bus:</span><br><span class="line"></span><br><span class="line"> Host Controller Location: Built-<span class="keyword">in</span> USB</span><br><span class="line"> Host Controller Driver: AppleUSBXHCI</span><br><span class="line"> PCI Device ID: <span class="number">0x9c31</span> </span><br><span class="line"> PCI Revision ID: <span class="number">0x0004</span> </span><br><span class="line"> PCI Vendor ID: <span class="number">0x8086</span> </span><br><span class="line"> Bus <span class="built_in">Number</span>: <span class="number">0x0a</span> </span><br><span class="line"></span><br><span class="line"> BRCM20702 Hub:</span><br><span class="line"></span><br><span class="line"> Product ID: <span class="number">0x4500</span></span><br><span class="line"> Vendor ID: <span class="number">0x0a5c</span> (Broadcom Corp.)</span><br><span class="line"> Version: <span class="number">1.00</span></span><br><span class="line"> Speed: Up to <span class="number">12</span> Mb/sec</span><br><span class="line"> Manufacturer: Apple Inc.</span><br><span class="line"> Location ID: <span class="number">0x14300000</span> / <span class="number">1</span></span><br><span class="line"> Current Available (mA): <span class="number">500</span></span><br><span class="line"> Current Required (mA): <span class="number">94</span></span><br><span class="line"> Built-In: Yes</span><br><span class="line"></span><br><span class="line"> Bluetooth USB Host Controller:</span><br><span class="line"></span><br><span class="line"> Product ID: <span class="number">0x828f</span></span><br><span class="line"> Vendor ID: <span class="number">0x05ac</span> (Apple Inc.)</span><br><span class="line"> Version: <span class="number">0.99</span></span><br><span class="line"> Speed: Up to <span class="number">12</span> Mb/sec</span><br><span class="line"> Manufacturer: Apple Inc.</span><br><span class="line"> Location ID: <span class="number">0x14330000</span> / <span class="number">4</span></span><br><span class="line"> Current Available (mA): <span class="number">500</span></span><br><span class="line"> Current Required (mA): <span class="number">0</span></span><br><span class="line"> Built-In: Yes</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>也可以用brew安装第三方lsusb命令:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew update</span><br><span class="line">$ brew tap jlhonora/lsusb</span><br><span class="line">$ brew install lsusb</span><br><span class="line">$ lsusb</span><br><span class="line">Bus <span class="number">020</span> Device <span class="number">001</span>: ID 0a5c:<span class="number">4500</span> Broadcom Corp. BRCM20702 Hub </span><br><span class="line">Bus <span class="number">020</span> Device <span class="number">004</span>: ID 05ac:828f Apple Inc. Bluetooth USB Host Controller </span><br><span class="line">Bus <span class="number">010</span> Device <span class="number">001</span>: ID 1d6b:<span class="number">0003</span> Linux Foundation <span class="number">3.0</span> root hub </span><br><span class="line">Bus <span class="number">010</span> Device <span class="number">001</span>: ID 1d6b:<span class="number">0003</span> Linux Foundation <span class="number">3.0</span> root hub </span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/jlhonora/lsusb">lsusb command for Mac OS X</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X使用pypyodbc访问mdb数据库</title>
    <url>/2014/08/15/mac-os-x-pypyodbc-access-mdb/</url>
    <content><![CDATA[<a id="more"></a>
<p>首先使用brew安装unixodbc和mdbtools,unixodbc是odbc驱动管理器,mdbtools提供了一组mdb操作工具,更重要的是mdbtools提供了mdb驱动程序。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install unixodbc</span><br><span class="line">$ brew install mdbtools</span><br></pre></td></tr></table></figure>

<p>但是安装完成后发现/usr/local/lib目录中没有mdbtools驱动动态链接库libmdbodbc.dylib<br>查看mdbtools选项可以发现:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew options mdbtools</span><br><span class="line">--<span class="keyword">with</span>-man-pages</span><br><span class="line"> Build manual pages</span><br></pre></td></tr></table></figure>
<p>mdbtools formula并没有提供<code>--with-unixodbc</code>选项,默认也没有build mdb驱动,因此需要手动来编译安装mdbtools提供的mdb driver</p>
<p><strong>编译安装libmdbodbc</strong><br>brew安装mdbtools时已经将mdbtools的源码包下载到了目录/Library/Caches/Homebrew/,所以直接使用这个源码包编译安装就可以了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tar zxvf mdbtools-<span class="number">0.7</span><span class="number">.1</span></span><br><span class="line">$ cd mdbtools-<span class="number">0.7</span><span class="number">.1</span></span><br><span class="line">$ autoreconf -i -f</span><br><span class="line">$ ./configure --<span class="keyword">with</span>-unixodbc=<span class="regexp">/usr/</span>local --disable-man</span><br><span class="line">$ make</span><br><span class="line">$ cd src/odbc</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure>

<p>这样libmdbodbc驱动程序就安装到了/usr/local/lib目录下。libmdbodbc的源代码就在src/odbc目录下。</p>
<p><strong>配置unixodbc</strong></p>
<p>因为brew的所有包都安装在/usr/local下面,因此这里配置unixodbc应该使用/usr/local/etc/目录下的odbcinst.ini和odbc.ini文件。<br>odbcinst.ini配置如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[MDBTools\]</span><br><span class="line">Description=MDBTools Driver</span><br><span class="line">Driver=libmdbodbc.dylib</span><br><span class="line">Setup=libmdbodbc.dylib</span><br><span class="line">FileUsage=<span class="number">1</span></span><br><span class="line">UsageCount=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>然后就可以像linux平台上一样来访问mdb文件了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ python3</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">import</span> pypyodbc</span><br><span class="line">&gt;&gt;&gt; conn=pypyodbc.connect(<span class="string">&#x27;Driver=MDBTools;DBQ=/path/to/record.mdb&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>因为这里也是使用mdbtools提供的odbc驱动,所以和pypyodbc配合使用时仍然存在<a href="https://openwares.net/linux/pypyodbc_gb_mdb_mess.html">中文字符编码转换的问题</a>,和linux平台上一样<a href="https://openwares.net/linux/pypyodbc_gb_mdb_mess.html">处理</a>即可。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X软件安装新神器homebrew-cask</title>
    <url>/2015/01/08/mac-os-xhomebrew-cask/</url>
    <content><![CDATA[<p>homebrew-cask基于homebrew,提供了很多常用的GUI程序安装,不用到处下载dmg之类的安装包,统一了安装用户体验。</p>
<a id="more"></a>
<p>安装homebrew-cask</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install caskroom/cask/brew-cask</span><br></pre></td></tr></table></figure>

<p>其使用方法与homebrew基本一致，比如安装google-chrome</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew cask install google-chrome</span><br></pre></td></tr></table></figure>

<p>常用命令:</p>
<p>brew cask search //列出所有可以被安装的软件<br>brew cask search drop //查找所有和 drop 相关的应用<br>brew cask info thunder //查看迅雷安装信息<br>brew cask uninstall qq //卸载 QQ</p>
<p>references:<br>[1]<a href="http://caskroom.io/">homebrew-cask</a><br>[2]<a href="http://ksmx.me/homebrew-cask-cli-workflow-to-install-mac-applications/">简洁优雅的Mac OS X软件安装体验 - homebrew-cask</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac OS X卸载JDK</title>
    <url>/2014/09/20/mac-os-x%E5%8D%B8%E8%BD%BDjdk/</url>
    <content><![CDATA[<a id="more"></a>
<p>直接删除jdk目录即可</p>
<p>JDK所在目录为/Library/Java/JavaVirtualMachines/jdk_major.minor.macro_[_update].jdk</p>
<p>比如删除以下 jdk 1.8</p>
<h1 id="rm-rf-Library-Java-JavaVirtualMachines-jdk1-8-0-06-jdk"><a href="#rm-rf-Library-Java-JavaVirtualMachines-jdk1-8-0-06-jdk" class="headerlink" title="rm -rf /Library/Java/JavaVirtualMachines/jdk1.8.0_06.jdk"></a>rm -rf /Library/Java/JavaVirtualMachines/jdk1.8.0_06.jdk</h1><p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
  </entry>
  <entry>
    <title>mac系统tomcat使用80端口</title>
    <url>/2014/04/19/mac-tomcat-port-80/</url>
    <content><![CDATA[<a id="more"></a>
<p>mac与linux一样,1024以下的端口为特权端口,只有root用户才有权监听。</p>
<p>因此要使用80端口要么使用root启动tomcat,要么使用端口转发。</p>
<p><strong>使用ipfw(Internet Protocol Firewall)设置端口转发</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ipfw add 100 fwd 127.0.0.1,8080 tcp from any to any 80 in</span><br></pre></td></tr></table></figure>

<p>不过ipfw已经被标记为废弃状态。</p>
<p><strong>使用pf(packet filter)设置端口转发</strong></p>
<ol>
<li> 创建anchor文件<br>/etc/pf.anchors/tomcat<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rdr pass on lo0 inet proto tcp <span class="keyword">from</span> any to <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> port <span class="number">80</span> -&gt; <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> port <span class="number">8080</span></span><br></pre></td></tr></table></figure></li>
<li> 测试anchor文件<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># pfctl -vnf /etc/pf.anchors/tomcat</span><br></pre></td></tr></table></figure></li>
<li> 添加到主配置文件<br>pf启动时会自动装载/etc/pf.conf文件,因此将anchor文件链接到/etc/pf.conf,转发规则就会自动建立了。<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rdr-anchor <span class="string">&quot;tomcat-forwarding&quot;</span></span><br><span class="line">load anchor <span class="string">&quot;tomcat-forwarding&quot;</span> <span class="keyword">from</span> <span class="string">&quot;/etc/pf.anchors/tomcat&quot;</span></span><br></pre></td></tr></table></figure>
注意要紧随文件中现有的rdr-anchor后面添加上面两行</li>
<li> 打开pf<br>pf默认是关闭的。可以使用以下命令启动pf:<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># pfctl -ef /etc/pf.conf</span><br></pre></td></tr></table></figure>
也可以使用其他配置文件启动pf。</li>
</ol>
<p>也可以修改LaunchDaemons来使pf开机自动打开。<br>/System/Library/LaunchDaemons/com.apple.pfctl.plist<br>[xml]<br><key>ProgramArguments</key><br><array><br><string>pfctl</string><br><string>-e</string><br><string>-f</string><br><string>/etc/pf.conf</string><br></array><br>[/xml]<br>添加的为-e参数,即enable。<br>有一点一定要<strong>注意</strong>,-f和/etc/pf.conf这两个参数不能被打断，因为-f必须紧跟一个文件参数，所以说添加-e参数时不要打断-f参数，否则开机不会自动启动pf，切记。</p>
<ol start="6">
<li> 跨接口转发<br>如果需要跨接口转发，则需设置系统参数：<br>/etc/sysctl.conf<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">net.inet.ip.forwarding=<span class="number">1</span></span><br><span class="line">net.inet6.ip6.forwarding=<span class="number">1</span></span><br></pre></td></tr></table></figure>
这与linux一致。</li>
</ol>
<p>References:<br>[1]<a href="https://gist.github.com/kujohn/7209628">Port Forwarding in Mavericks</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>macos编译安装rtorrent</title>
    <url>/2020/01/28/macos-compile-install-rtorrent/</url>
    <content><![CDATA[<a id="more"></a>
<p>确保安装xcode和brew</p>
<p>安装编译工具和部分依赖</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install automake libtool boost curl lzlib libsigc++ openssl xmlrpc-c</span><br></pre></td></tr></table></figure>

<p>编译安装libtorrent</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone https:<span class="comment">//github.com/rakshasa/libtorrent.git</span></span><br><span class="line">$ cd libtorrent</span><br><span class="line">$ ./autogen.sh</span><br><span class="line">$ CC=clang CXX=clang++ CXXFLAGS=<span class="string">&quot;-Wno-deprecated-declarations -O3 -std=c++11 -stdlib=libc++ -I/usr/local/opt/openssl/include&quot;</span> LDFLAGS=<span class="string">&quot;-L/usr/local/opt/openssl/lib&quot;</span> ./configure</span><br><span class="line">$ make</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure>
<p>libtorrent安装到/usr/local/lib</p>
<p>编译安装rtorrent</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone https:<span class="comment">//github.com/rakshasa/rtorrent.git</span></span><br><span class="line">$ cd rtorrent</span><br><span class="line">$ ./autogen.sh</span><br><span class="line">$ <span class="keyword">export</span> PKG_CONFIG_PATH=<span class="regexp">/usr/</span>local/lib/pkgconfig</span><br><span class="line">$ CC=clang CXX=clang++ CXXFLAGS=<span class="string">&quot;-Wno-deprecated-declarations -O3 -std=c++11 -stdlib=libc++ -I/usr/local/opt/openssl/include&quot;</span> LDFLAGS=<span class="string">&quot;-L/usr/local/opt/openssl/lib&quot;</span> ./configure --<span class="keyword">with</span>-xmlrpc-c</span><br><span class="line">$ make</span><br><span class="line">$ make install</span><br></pre></td></tr></table></figure>
<p>rtorrent安装到/usr/local/bin</p>
<p>运行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rtorrent</span><br></pre></td></tr></table></figure>
<p>默认配置文件为~/.rtorrent.rc</p>
<p>References:<br>[1]<a href="https://gist.github.com/doctorpangloss/ecfbe70c61de9332698d4d4445848f81">libtorrent and rtorrent on mac.sh</a><br>[2]<a href="https://devhints.io/rtorrent">rTorrent cheatsheet</a><br>[3]<a href="https://github.com/rakshasa/rtorrent/wiki/User-Guide#navigating">Navigating</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>macos显示占用端口的应用程序</title>
    <url>/2020/01/26/macos-lsof-netstat-port-inuse/</url>
    <content><![CDATA[<a id="more"></a>
<p>macos版本的netstat并不支持-p选项以显示打开端口的应用程序，可以使用lsof(list open files)来达到同样的目的</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo lsof -nP -iTCP -sTCP:LISTEN</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://tonydeng.github.io/2016/07/07/use-lsof-to-replace-netstat/">使用 lsof 代替 Mac OS X 中的 netstat 查看占用端口的程序</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>MacOS missing xcrun问题</title>
    <url>/2018/11/09/macos-missing-xcrun/</url>
    <content><![CDATA[<a id="more"></a>
<p>升级MacOS后brew upgrade经常会出现如下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">The bottle needs the Apple Command Line Tools to be installed.</span><br><span class="line"> You can install them, <span class="keyword">if</span> desired, <span class="attr">with</span>:</span><br><span class="line"> xcode-select --install</span><br><span class="line"></span><br><span class="line">xcrun: error: invalid active developer path (<span class="regexp">/Library/</span>Developer/CommandLineTools), missing xcrun at: <span class="regexp">/Library/</span>Developer/CommandLineTools/usr/bin/xcrun</span><br></pre></td></tr></table></figure>

<p>是因为系统升级后没有安装相应版本的Apple Command Line Tools<br>解决办法就是像错误提示里说的一样：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xcode-select --install</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>macos write img to usb stick</title>
    <url>/2020/02/15/macos-write-img-to-usb-stick/</url>
    <content><![CDATA[<a id="more"></a>
<p>insert usb stick, the device name of usb stick is /dev/disk2</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ diskutil list #find device name <span class="keyword">of</span> usb stick</span><br><span class="line">/dev/disk2 (external, physical):</span><br><span class="line"> #: TYPE NAME SIZE IDENTIFIER</span><br><span class="line"> <span class="number">0</span>: GUID_partition_scheme *<span class="number">32.2</span> GB disk2</span><br><span class="line"> <span class="number">1</span>: EFI TAILS <span class="number">8.6</span> GB disk2s1</span><br><span class="line">$ diskutil unmountdisk /dev/disk2</span><br><span class="line">$ sudo dd <span class="keyword">if</span>=tails-amd64-<span class="number">4.3</span>.img <span class="keyword">of</span>=<span class="regexp">/dev/</span>disk2 bs=64m</span><br><span class="line">$ diskutil eject /dev/disk2</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>MacOSX mplayer OSD issue</title>
    <url>/2019/02/08/macosx-mplayer-osd-issue/</url>
    <content><![CDATA[<a id="more"></a>
<p>mplayer的OSD(On-Screen Display)依赖于X11，so字幕无法显示:(，目前改投IINA了</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>macosx sed的-i参数</title>
    <url>/2019/07/09/macosx-sed-i-parameter/</url>
    <content><![CDATA[<a id="more"></a>
<p>macosx上自带的很多命令行工具都是bsd版本的，包括sed</p>
<p>sed的参数-i与gnu版本稍有不同,其-i参数后面的备份文件扩展名不可省略，即使是空字符串，也就是不要备份，而gnu版本不要备份的话是可以忽略掉的。<br>bsd版本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;&#x27;</span> <span class="string">&#x27;s/123/456/&#x27;</span> test</span><br></pre></td></tr></table></figure>

<p>gnu版本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;s/123/456/&#x27;</span> test</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>macports安装mypaint</title>
    <url>/2018/12/11/macports-install-mypaint/</url>
    <content><![CDATA[<p>brew没有打包mypaint，所以使用macports来安装</p>
<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo port install mypaint</span><br></pre></td></tr></table></figure>

<p>提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Warning: Xcode does not appear to be installed; most ports will likely fail to build.</span><br></pre></td></tr></table></figure>
<p>xcode其实早已经安装过了，执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xcodebuild</span><br><span class="line">xcode-select: error: tool <span class="string">&#x27;xcodebuild&#x27;</span> requires Xcode, but active developer directory <span class="string">&#x27;/Library/Developer/CommandLineTools&#x27;</span> is a command line tools instance</span><br></pre></td></tr></table></figure>

<p>需要配置xcodebuild</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo xcode-select --<span class="keyword">switch</span> /Applications/Xcode.app/Contents/Developer/</span><br></pre></td></tr></table></figure>

<p>然后再执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo port install mypaint</span><br></pre></td></tr></table></figure>
<p>就编译安装成功了，mypaint依赖于X11，所以事先需要安装xQuartz，或者macports安装xorg-server</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo port install xorg-server</span><br></pre></td></tr></table></figure>
<p>其实这也是在安装xQuartz而已</p>
<p>mypaint是X11程序，在MacOS上运行效果并不是很好。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>MAC平台PAC文件编写和自动代理配置</title>
    <url>/2014/03/27/mac%E5%B9%B3%E5%8F%B0pac%E6%96%87%E4%BB%B6%E7%BC%96%E5%86%99%E5%92%8C%E8%87%AA%E5%8A%A8%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>使用PAC(Proxy auto-config)可以使用户代理根据不同的URL采用不同的代理访问策略。</p>
<a id="more"></a>
<p>PAC是由netscape在很早以前提出的,没想到在多年以后在我朝发扬光大。因为主流系统平台(linux/mac/windows)和用户代理(firefox,chrome,safari,opera)都支持PAC,因此使用PAC就可以在一个集中的位置来维护全局代理策略,再也不用为各个用户代理单独安装插件,单独维护代理策略了。</p>
<p><strong>PAC撰写</strong><br>PAC 文件用 JavaScript 编写,其入口函数为FindProxyForURL(url, host),用户代理调用此函数,根据返回值来决定如何访问指定的URL。</p>
<p>最简单,看起来没什么用处的PAC文件,所有的网址都不通过代理直接访问:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">FindProxyForURL</span>(<span class="params">url, host</span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> <span class="string">&quot;DIRECT&quot;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参数:</p>
<ul>
<li>  url<br>将要访问的网络地址</li>
<li>  host<br>将要访问的网络地址中的host部分。比如访问<a href="https://www.github.com/path/to/resources,%E5%88%99host%E9%83%A8%E5%88%86%E4%B8%BAwww.github.com">https://www.github.com/path/to/resources,则host部分为www.github.com</a></li>
</ul>
<p>返回值:</p>
<ul>
<li>  DIRECT<br>直接访问,不经过代理</li>
<li>  PROXY host:port<br>使用HTTP代理访问</li>
<li>  SOCKS host:port<br>使用SOCKS代理访问</li>
<li>  SOCKS5 host:port<br>使用SOCKS5代理访问。注意safari虽然支持socks5,但不支持PAC文件返回的SOCKS5,会将返回的SOCKS5类型的代理忽略掉,只能识别SOCKS。因此对于SOCKS5代理,可以写两种形式,不支持的用户代理自动忽略即可。</li>
</ul>
<p>PAC文件中可以使用的一些函数:</p>
<ul>
<li><p>  isPlainHostName(host) 判断是否是简单域名，例如 localhost 就是一个简单域名</p>
</li>
<li><p>  dnsDomainIs(host, domain) 判断给定的 host 是否属于某个域名</p>
</li>
<li><p>  dnsResolve(host) 做 DNS 解析，返回 host 的 ip，注意：DNS 解析可能会 block 住浏览器</p>
</li>
<li><p>  isInNet(ip, subnet, netmask) 判断 ip 是否属于某个子网</p>
</li>
<li><p>  myIpAddress() 返回本机的 ip (貌似不太可靠，见 wikipedia 的说明)</p>
</li>
<li><p>  shExpMatch(str, pattern) 判断两个字符串是否匹配，pattern 中可以包含 shell 使用的通配符。不要使用javascript的RegExp</p>
</li>
</ul>
<p>Reference[2]对PAC文件的编写描述的十分详细。</p>
<p><strong>PAC配置</strong><br>MAC现在已经不能使用本地的pac文件,必须通过网络访问PAC文件。可以将proxy.pac放在网络上,比如自己的VPS上。也可以开启本地web服务器,将其放在本地。<br>应该在web服务器上将pac文件的MIME类型设置为application/x-ns-proxy-autoconfig 或者 application/x-javascript-config,当然不设置也没有关系。<br>如果使用nginx,则在/etc/nginx/mime.types文件中添加即可。</p>
<p>启用本地apache服务:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apachectl start</span><br></pre></td></tr></table></figure>
<p>然后将proxy.pac放入/Library/WebServer/Documens/目录下。</p>
<p>配置PAC代理时,填入<a href="http://localhost/proxy.pac%E5%8D%B3%E5%8F%AF%E3%80%82">http://localhost/proxy.pac即可。</a></p>
<p>References:<br>[1]<a href="http://www.poemcode.net/2011/07/pac-on-mac/">一波三折的PAC on Mac</a><br>[2]<a href="http://chenyufei.info/blog/2012-03-18/pac-and-debug/">PAC 文件及其调试</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>制作SystemRescueCd启动U盘</title>
    <url>/2016/12/12/make-systemrescuecd-boot-usb/</url>
    <content><![CDATA[<a id="more"></a>
<p>官方下载的SystemRescueCd ISO并不支持制作启动u盘，所以需要先将iso转换成可硬盘/u盘启动的iso<br>使用isohybrid命令来转换，需要先安装syslinux-utils包</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install syslinux-utils </span><br></pre></td></tr></table></figure>
<p>然后执行转换</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ isohybrid systemrescuecd-x86-x.x.x.iso</span><br></pre></td></tr></table></figure>
<p>此命令会进行就地转换，因为如需保留原iso的话请先备份。</p>
<p>然后写入u盘就可以了：<br>[bash 1=”dd” if=”systemrescuecd.iso” of=”/dev/sdc” 2=”[/bash” language=”#”]```</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>mariadb清除mysql-bin文件</title>
    <url>/2019/07/09/mariadb-purge-mysql-bin-files/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果/etc/mysql/my.cnf中打开了log-bin选项，即使没有做主从复制，数据目录下仍然会持续的生成大量的mysql-bin.0000*文件，这玩意儿就像归档日志吧。</p>
<p>如果你做了主从复制，下面就不要看了。<br>没做主从复制的话，可以先清除掉这些文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mysql&gt; reset master;</span><br></pre></td></tr></table></figure>
<p>这样会删除掉所有的log-bin，重新生成一个mysql-bin.000001<br>然后修改/etc/mysql/my.cnf，注释掉下面的行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#log-bin=mysql-bin</span><br></pre></td></tr></table></figure>
<p>重新启动mariadb服务，以后就不会再生成这些文件了。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>markdown可视化编辑器</title>
    <url>/2015/03/30/markdown-visual-editor/</url>
    <content><![CDATA[<a id="more"></a>
<p>用vim写markdwon还是太原始了，有不少的可视化编辑器可用。</p>
<p><strong>linux</strong></p>
<p>linux平台推荐<a href="https://remarkableapp.github.io/">Remarkable</a>,比<a href="http://sourceforge.net/projects/retext/">ReText</a>好用。</p>
<p><strong>mac os x</strong> </p>
<p>mac平台上可能用mou的比较多，但还有一个<a href="http://macdown.uranusjr.com/">MacDown</a>也相当好用，还是free的呢！<br>而且支持brew安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew cask install macdown</span><br></pre></td></tr></table></figure>

<p><strong>online</strong></p>
<p>在线编辑推荐<a href="https://www.zybuluo.com/mdeditor">Cmd</a>,或者<a href="https://stackedit.io/">StackEdit</a>,很不错的。</p>
<p><strong>cross platform</strong></p>
<p>还有一个跨平台的编辑器<a href="http://pad.haroopress.com/user.html">Haroopad</a></p>
<p><strong>preview</strong></p>
<p><a href="http://marboo.biz/zh_CN/">Marboo</a>可以与其他文本编辑器结合，比如vim，实时预览markdown文档。</p>
<p>References:<br>[1]<a href="http://www.jianshu.com/p/6c157af09e84">Mac 下两款 Markdown 编辑器 Mou/MacDown 大 PK</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>mavericks安装tomcat7</title>
    <url>/2014/04/19/mavericks-tomcat7/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>下载解压</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd ~/Downloads</span><br><span class="line">$ wget http:<span class="comment">//mirror.esocc.com/apache/tomcat/tomcat-7/v7.0.53/bin/apache-tomcat-7.0.53.tar.gz</span></span><br><span class="line">$ cd /usr/local</span><br><span class="line">$ sudo tar xvzf ~<span class="regexp">/Downloads/</span>apache-tomcat-<span class="number">7.0</span><span class="number">.53</span>.tar.gz</span><br><span class="line">$ sudo ln -s apache-tomcat-<span class="number">7.0</span><span class="number">.53</span> tomcat</span><br></pre></td></tr></table></figure>

<p><strong>创建运行tomcat的非特权用户</strong><br>使用root用户运行tomcat会有安全性方面的问题,如果tomcat被攻陷则整个系统就会沦陷。因此创建一个非特权用户来运行tomcat</p>
<p>首先选择一个User ID和Group ID,500以上的ID用于正常的用户,因此需要选择一个0-500之间的数字作为GID和UID。</p>
<p>列出当前系统组,用户及其ID</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dscl . -list /Groups PrimaryGroupID sort -n -k <span class="number">2</span></span><br><span class="line">$ dscl . -list /Users UniqueID sort -n -k <span class="number">2</span> </span><br></pre></td></tr></table></figure>
<p>这里选择101作为UID和GID,创建组和用户：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># dscl . -create /Groups/_tomcat PrimaryGroupID 101</span><br><span class="line"># dscl . -create /Groups/_tomcat RealName &quot;Tomcat Users&quot;</span><br><span class="line"># dscl . -create /Groups/_tomcat Password \\*</span><br><span class="line"># dscl . -create /Users/_tomcat UniqueID 101</span><br><span class="line"># dscl . -create /Users/_tomcat PrimaryGroupID 101</span><br><span class="line"># dscl . -create /Users/_tomcat HomeDirectory /usr/local/tomcat</span><br><span class="line"># dscl . -create /Users/_tomcat UserShell /usr/bin/false</span><br><span class="line"># dscl . -create /Users/_tomcat RealName &quot;Tomcat Administrator&quot;</span><br><span class="line"># dscl . -create /Users/_tomcat Password \\*</span><br></pre></td></tr></table></figure>
<p>新创建用户的shell设置为/usr/bin/false,使其无法登录,密码设置为*为禁用账户。</p>
<p><strong>设置tomcat目录权限</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ cd /usr/local/tomcat</span><br><span class="line"># chmod 644 conf/*</span><br><span class="line"># chown root:_tomcat conf/tomcat-users.xml</span><br><span class="line"># chmod 640 conf/tomcat-users.xml</span><br><span class="line"># mkdir conf/Catalina</span><br><span class="line"># chown _tomcat:_tomcat conf/Catalina</span><br><span class="line"># chown _tomcat:admin logs temp webapps work</span><br><span class="line"># chmod 2770 logs temp webapps work</span><br></pre></td></tr></table></figure>

<p><strong>launchd脚本</strong><br>写一个launchd包装脚本来启动tomcat,并且一直等待tomcat进程直到其退出。<br>/usr/local/tomcat/bin/tomcat-launchd.sh</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"></span><br><span class="line"># tomcat-launchd.sh</span><br><span class="line"># </span><br><span class="line"># Wrapper script that starts Tomcat and waits for the Tomcat process </span><br><span class="line"># to exit. This is needed for proper interaction with launchd.</span><br><span class="line"></span><br><span class="line">#---------------------------------------------------------</span><br><span class="line"># Helper functions</span><br><span class="line">#---------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># NOTE: We are inheriting CATALINA_HOME from launchd, because its value </span><br><span class="line"># was defined in the launchd plist configuration file.</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">shutdown</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"> </span><br><span class="line"> # Bye Tomcat!</span><br><span class="line"> echo <span class="string">&quot;Shutting down Tomcat... &quot;</span></span><br><span class="line"> $CATALINA_HOME/bin/catalina.sh stop</span><br><span class="line"> echo <span class="string">&quot;done.&quot;</span></span><br><span class="line"> </span><br><span class="line"> # Cleaning up the temporary file</span><br><span class="line"> rm -f $CATALINA_PID </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">startup</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"> </span><br><span class="line"> # Define the file where we want the Tomcat process ID to be stored.</span><br><span class="line"> <span class="keyword">export</span> CATALINA_PID=$(mktemp /tmp/\<span class="string">`basename -s .sh $0\`.XXXXXX)</span></span><br><span class="line"><span class="string"> if \[ $? -ne 0 \]</span></span><br><span class="line"><span class="string"> then</span></span><br><span class="line"><span class="string"> echo &quot;$0: Failed to create temporary file. Aborting.&quot;</span></span><br><span class="line"><span class="string"> exit 1</span></span><br><span class="line"><span class="string"> fi</span></span><br><span class="line"><span class="string"> rm -f $CATALINA_PID</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> # Let&#x27;s go!</span></span><br><span class="line"><span class="string"> echo &quot;Starting up Tomcat... &quot;</span></span><br><span class="line"><span class="string"> . $CATALINA_HOME/bin/catalina.sh start</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> # Register the shutdown function as callback to execute when a signal </span></span><br><span class="line"><span class="string"> # is sent to this process.</span></span><br><span class="line"><span class="string"> #捕捉以下信号使tomcat关闭</span></span><br><span class="line"><span class="string"> trap shutdown HUP INT QUIT ABRT KILL ALRM TERM TSTP</span></span><br><span class="line"><span class="string"> echo &quot;done.&quot; </span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">function wait_for_tomcat_to_exit() &#123;</span></span><br><span class="line"><span class="string"> echo &quot;Waiting for Tomcat to exit (PID: \`cat $CATALINA_PID\`)... &quot;</span></span><br><span class="line"><span class="string"> #等待tomcat进程退出</span></span><br><span class="line"><span class="string"> wait \`cat $CATALINA_PID\`</span></span><br><span class="line"><span class="string"> echo &quot;done waiting for Tomcat to exit.&quot;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#---------------------------------------------------------</span></span><br><span class="line"><span class="string"># Let&#x27;s go</span></span><br><span class="line"><span class="string">#---------------------------------------------------------</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">startup</span></span><br><span class="line"><span class="string">wait_for_tomcat_to_exit</span></span><br></pre></td></tr></table></figure>

<p>plist配置文件:<br>/usr/local/tomcat/conf/org.apache.tomcat.plist<br>[xml]<br><?xml version="1.0" encoding="UTF-8"?><br><!DOCTYPE plist PUBLIC "-//Apple Computer//DTD PLIST 1.0//EN"
 "http://www.apple.com/DTDs/PropertyList-1.0.dtd"><br><plist version="1.0"><br><dict><br> <key>Label</key><br> <string>org.apache.tomcat</string><br> <key>ServiceDescription</key><br> <string>Tomcat Servlet/JSP Server</string><br> <key>UserName</key><br> <string>_tomcat</string><br> <key>GroupName</key><br> <string>_tomcat</string><br> <key>EnvironmentVariables</key><br> <dict><br> <key>CATALINA_HOME</key><br> <string>/usr/local/tomcat</string><br> <key>JAVA_HOME</key><br> <string>/Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home</string><br> </dict><br> <key>ProgramArguments</key><br> <array><br> <string>/usr/local/tomcat/bin/tomcat-launchd.sh</string><br> </array><br> <key>StandardOutPath</key><br> <string>/usr/local/tomcat/logs/launchd-stdout.log</string><br> <key>StandardErrorPath</key><br> <string>/usr/local/tomcat/logs/launchd-stderr.log</string><br> <key>RunAtLoad</key><br> <true/><br> <key>KeepAlive</key><br> <true/><br></dict><br></plist><br>[/xml]</p>
<p>JAVA_HOME变量的值由以下命令确定:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ /usr/libexec/java_home</span><br></pre></td></tr></table></figure>

<p>然后将plist文件符号链接到/Library/LaunchDaemons目录:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># cd /Library/LaunchDaemons</span><br><span class="line"># ln -sfv /usr/local/tomcat/conf/org.apache.tomcat.plist</span><br></pre></td></tr></table></figure>

<p><strong>使用launchd管理tomcat</strong><br>设置完成后,可以使用以下命令加载配置并启动tomcat</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># launchctl load /Library/LaunchDaemons/org.apache.tomcat.plist</span><br></pre></td></tr></table></figure>
<p>修改plist配置文件后重新加载配置:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># launchctl unload /Library/LaunchDaemons/org.apache.tomcat.plist</span><br><span class="line"># launchctl load /Library/LaunchDaemons/org.apache.tomcat.plist</span><br></pre></td></tr></table></figure>

<p>plist文件中RunAtLoad设置为true会使tomcat开机自动运行。而如果KeepAlive设置为true，则当tomcat进程退出后，无论是什么原因导致tomcat进程退出,launchd守护进程会重新启动tomcat。因此更改tomcat配置后可以这样重新启动tomcat进程:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># launchctl stop org.apache.tomcat</span><br></pre></td></tr></table></figure>
<p>或者直接kill tomcat进程亦可。</p>
<p>如果KeepAlive设置为false,则需要手工启动tomcat进程,如下:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># launchctl stop org.apache.tomcat</span><br><span class="line"># launchctl start org.apache.tomcat</span><br></pre></td></tr></table></figure>

<p><strong>servlet api符号链接</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ln -sfv /usr/local/tomcat/lib/servlet-api.jar /usr/share/java/servlet-api.jar</span><br><span class="line"># ln -sfv /usr/local/tomcat/lib/servlet-api.jar /usr/share/java/servlet-api-3.0.jar</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://www.joel.lopes-da-silva.com/2008/05/13/installing-tomcat-on-mac-os-x/">installing Tomcat On Mac OS X</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>mcelog and rasdaemon</title>
    <url>/2019/10/28/mcelog-and-rasdaemon/</url>
    <content><![CDATA[<a id="more"></a>
<p>用于记录MCE(Machine Check Exception)日志的mcelog已经deprecated,debian buster系统上被rasdaemon包替代，RAS是指Reliability, Availability and Serviceability,rasdaemon将日志写入syslog,可以直接阅读syslog或者使用journalctl</p>
<p>References:<br>[1]<a href="https://wiki.archlinux.org/index.php/Machine-check_exception">Machine-check exception</a><br>[2]<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=890301">mcelog replaced with rasdaemon</a><br>[3]<a href="https://pagure.io/rasdaemon">rasdaemon</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>MeeGo移植到Dell Streak,HTC Desire和Nexus One手机</title>
    <url>/2010/09/30/meego-port-to-android/</url>
    <content><![CDATA[<p>不同的开发者已经将MeeGo(米果)移植到多种Android(安卓)平台手机,MeeGo平台主要是由Intel和Nokia主导的.</p>
<a id="more"></a>
<p><a href="http://wiki.meego.com/ARM/MSMQSD">MeeGo wiki</a>上的一个页面提供了一些当前移植工作的细节,展示了两台使用MeeGo界面的Nexus One和HTC Desire手机.另一张图片上展示了Dell Streak手机上面的MeeGo命令行登录提示符.</p>
<p>这三种设备都使用Snapdragon QSD8250处理器,但是他们的显示核心没有开源许可下的驱动,因此MeeGo暂时无法在这些手机上支持硬件加速,MeeGo在这些设备上的用户界面运行会比较慢一些,当前的移植并不适合日常使用.</p>
]]></content>
      <categories>
        <category>Mobile</category>
      </categories>
  </entry>
  <entry>
    <title>站点迁移过程中遇到的几个小问题</title>
    <url>/2014/06/11/migration-issues/</url>
    <content><![CDATA[<p>迁移到linode啦</p>
<a id="more"></a>
<p>1、fonts.googleapis.com</p>
<p>最近一直感觉站点很慢，这次迁移时仔细测试了下，发现wordpress使用了google在线自体google fonts，因此需要访问fonts.googleapis.com，但是这个地址撞墙了，因此我们应该 #Fuck GFW# 先。</p>
<p>360这次总算做了次好事，提供了google fonts的国内CDN镜像。因此将fonts.googleapis.com更换为fonts.useso.com就好了，换完真的变快不少。</p>
<p>找到站点根目录，然后执行以下语句批量替换掉：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sed -i <span class="string">&#x27;s/fonts\\.googleapis/fonts\\.useso/g&#x27;</span> \<span class="string">`find . xargs grep -rl &#x27;fonts.googleapis&#x27;\`</span></span><br></pre></td></tr></table></figure>

<p>2、awstats的qqhostinfo插件</p>
<p>qqhostinfo插件用来通过访问者的ip查找其地理位置，因为其原来的查找脚本qqwry.pl代码太乱，我以前自己写了一个<a href="https://openwares.net/linux/awstats_ip_geo_qqwrypl.html">ip_geo_qqwry.pl</a>，使用纯真网络的IP数据库。</p>
<p><a href="/downloads/qqhostinfo.pm">qqhostinfo</a>也做了很简单的修改，从qqwry.pl切换到了<a href="/downloads/ip_geo_qqwry.zip">ip_geo_qqwry.pl</a>,使用的IP数据库名字为qqwry.dat。</p>
<p>下载后将qqhostinfo.pm拷贝到/usr/share/awstats/plugins目录，将ip_geo_qqwry.pl和qqwry.dat拷贝到/usr/local/lib/site_perl目录就可以了。</p>
<p>最新的qqwry.dat数据库可以去纯真网络下载。</p>
<p>3、安装perl模块URI</p>
<p>awstats需要URI模块，不然会有错误提示:</p>
<p>Error: Plugin load for plugin ‘decodeutfkeys’ failed with return code: Error: Can’t locate URI/Escape.pm in @INC (@INC contains: /etc/perl /usr/local/lib/perl/5.14.2 /usr/local/share/perl/5.14.2 /usr/lib/perl5 /usr/share/perl5 /usr/lib/perl/5.14 /usr/share/perl/5.14 /usr/local/lib/site_perl . /usr/share/awstats/lib /usr/share/awstats/plugins) at (eval 3) line 1. </p>
<p>不要使用CPAN来安装，那玩意太烦了，直接apt-get就好了:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install liburi-perl</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>修改echofon左上角logo超链接</title>
    <url>/2010/10/07/modify-echofon-logo-hyperlink/</url>
    <content><![CDATA[<p>众所周知的原因,从国内访问twitter必须走各种不正常的手段,这完全是拜Great Fucking Wall所赐,其余不多说,你都懂的.</p>
<a id="more"></a>
<p>各种翻墙手段从SSH,VPN,TOR,各种’敏感词’软件…到API代理不一而足,修改hosts也是一法,但可用IP十分难觅,广泛传播的基本上都被block了.</p>
<p>最近找到一个可用IP,修改hosts后堪算完美,可用https直连访问官方网站.只有一点不够爽,那就是点击echofon左上角的logo时链接到http而不是https的官方网站,后果可想而知”The connection was reset”,WHAT THE FUCK! </p>
<p>可以通过修改echofon文件中的一处URL来解决此问题.此文件位于~/.mozilla/firefox/*/extensions/twitternotifier@naan.net/chrome/Echofon.jar中,Echofon.jar是个zip格式的压缩文件,用vim可以直接编辑zip档案里面的文本文件,需要修改的文件为压缩包中的content/window.xml,打开此文件定位到大约第54行，将此处的URL链接改为https链接重启firefox即可.</p>
]]></content>
      <categories>
        <category>Firefox</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>修改文件系统标签(filesystem label)</title>
    <url>/2013/01/25/modify-filesystem-label/</url>
    <content><![CDATA[<p>修改ext2/3/4,ntfs,fat/fat32文件系统的标签</p>
<a id="more"></a>
<p><strong>ext2/3/4文件系统:</strong></p>
<p>#e2label /dev/sdb1 new_label</p>
<p><strong>ntfs文件系统:</strong></p>
<p>#ntfslabel /dev/sdb2 new_label</p>
<p><strong>fat/fat32文件系统</strong></p>
<p>#dosfslabel /dev/sdb3 new_label<br>或者<br>#mlabel -i /dev/sdb3 ::new_label</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>挂载virtualbox共享文件夹</title>
    <url>/2019/06/02/mount-virtualbox-share-folders/</url>
    <content><![CDATA[<a id="more"></a>
<p>首先需要<a href="https://openwares.net/2019/06/02/guiless-install-virtualbox-guest-additions/">安装guest addtions</a></p>
<p>主机端：</p>
<p>为客户机配置共享文件夹，略。</p>
<p>客户机：</p>
<p>列出可用的share folders</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo VBoxControl sharedfolder list</span><br><span class="line">Oracle VM VirtualBox Guest Additions Command Line Management Interface Version <span class="number">6.0</span><span class="number">.8</span></span><br><span class="line">(C) <span class="number">2008</span>-<span class="number">2019</span> Oracle Corporation</span><br><span class="line">All rights reserved.</span><br><span class="line"></span><br><span class="line">Shared Folder mappings (<span class="number">1</span>):</span><br><span class="line"></span><br><span class="line"><span class="number">01</span> - Downloads \[idRoot=<span class="number">0</span> writable auto-mount host-icase guest-icase mnt-pt=<span class="regexp">/media/</span>host/\]</span><br></pre></td></tr></table></figure>

<p>如果设定了自动挂装, virtualbox会自动挂载之，否则可以手动挂载：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mount -t vboxsf Downloads /media/host</span><br></pre></td></tr></table></figure>

<p>访问权限问题，将当前用户加入vboxsf组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo adduser $USER vboxsf</span><br></pre></td></tr></table></figure>

<p>然后注销重新登录，或者使用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ newgrp vboxsf</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>mplayer播放audio cd</title>
    <url>/2018/06/11/mplayer-play-audio-cd/</url>
    <content><![CDATA[<a id="more"></a>
<p>从头顺序播放：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mplayer -cdrom-device /dev/sr0 cdda:<span class="comment">// -cache 5000</span></span><br></pre></td></tr></table></figure>

<p>播放指定音轨：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mplayer -cdrom-device /dev/sr0 cdda:<span class="comment">//5 -cache 5000</span></span><br></pre></td></tr></table></figure>

<p>播放部分音轨：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mplayer -cdrom-device /dev/sr0 cdda:<span class="comment">//6-13 -cache 5000</span></span><br></pre></td></tr></table></figure>

<p>一定要加cache参数，因为读取CDROM是很慢的，不缓存会爆音。</p>
<p>References:<br>[1] <a href="https://www.cyberciti.biz/faq/linux-unix-mplayer-playing-audio-dvd-cd-using-bash-shell/">Mplayer: Play Audio CD Using Linux Command Line</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>mplayer播放视频时旋转</title>
    <url>/2013/05/06/mplayer-rotate/</url>
    <content><![CDATA[<p>手机拍了些视频，从电脑上用mplayer播放竟然图像不是正的。</p>
<a id="more"></a>
<p>使用mplayer的-vf选项来旋转或镜像视频，vf即vedio filter,这个选项的子参数rotate用来旋转、镜像视频。使用方法如下：</p>
<p>$mplayer -vf rotate[=0,1,2,3] video.xxx</p>
<p>rotate或rotate=0 镜像并顺时针旋转90度<br>rotate=1 顺时针旋转90度<br>rotate=2 顺时针旋转270度<br>rotate=3 镜像并顺时针旋转270度</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>MPlayer</tag>
      </tags>
  </entry>
  <entry>
    <title>mplayer声道切换快捷键</title>
    <url>/2010/09/07/mplayer-switch-channel-hotkey/</url>
    <content><![CDATA[<p>　　无论在Ubuntu还是windows平台上，播放视频我只用原汁原味的mplayer，但在这个两个平台上切换声道的快捷键却是不同的，注意不是切换音轨，是切换同一条音轨里的声道。这个快捷键在Ubuntu上是#,而windows上是a,按这个键在“禁止声音”和各个声道之间循环切换</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>MPlayer</tag>
      </tags>
  </entry>
  <entry>
    <title>名词：MRP,LSP和RFS进程</title>
    <url>/2011/11/12/mrp-lsp-and-rfs/</url>
    <content><![CDATA[<p>MRP是managed recovery process的缩写,LSP是logical standby process的缩写。RFS指remote file server process。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>multiarch架构与lib目录</title>
    <url>/2012/03/27/multiarch-and-lib-dir/</url>
    <content><![CDATA[<p>Debian的下一个版本Wheezy将会全面支持Multiarch架构。</p>
<a id="more"></a>
<p>Multiarch本质上是一个文件系统规范,为在一个系统内安装不同架构的库和二进制目标程序提供一个通用的解决方案,目前的multiarch仅限于库文件,对二进制目标文件的支持尚未提上日程,还有许多工作要做。</p>
<p>multiarch对跨平台编译(cross-build)和模拟器/兼容层同样有重要意义。multiarch会大大降低cross-build的复杂性,因为编译和运行时都使用同样的库目录,大大减少了出现问题的可能性。multiarch对模拟器/兼容层一视同仁,为其支持库提供与native库一样的布局视图,改善用户体验。</p>
<p>有一点需要澄清,multiarch并不能支持二进制应用程序跨平台运行。比如为power架构编译的二进制程序是不可能拿到amd64平台上来直接运行的,multiarch也不行。只有类似java这种字节码的应用程序才可以真正做到无修改跨平台直接运行,其实java并不是跨平台的,java本身就是一种平台。但是multiarch规范了同一个平台下不同的子平台之间的混合运行环境,比如amd64与x86之间。</p>
<p>FHS 2.3制定的库规范可以称之为双架构”biarch”。FHS规定64bits平台,包括PPC64, s390x, sparc64 and AMD64,必须将其64bits共享库部署到/lib64目录,而32bits共享库部署到/lib目录,这样方便大量的32位程序正常运行而不用做任何改变,而IA64平台则须将其64bits库部署到/lib目录，因为其并没有32bits平台的负担。red hat和suse采用了这种设计,但是debian没有。因为biarch缺乏伸缩性,并不能轻易的扩展到其他多种平台,而debian的目标之一是成为通用操作系统,支持多种异构平台,因此需要更通用的解决方案,这就是multiarch。</p>
<p>multiarch的实现也十分简洁,就是将架构相关的库部署到架构相关的路径下。比如/usr/lib/libfoo,如果机器是amd64架构,则将其放置到/usr/lib/x86_64-linux-gnu/libfoo,如果机器是i386架构,则将其放置到/usr/lib/i386-linux-gnu/libfoo,如果机器是ppc64架构,则将其放置到/usr/lib/powerpc64-linux-gnu/libfoo。</p>
<p>multiarch路径包含一个GNU三位元组,用来描述系统架构。比如,x86_64-linux-gnu,x86_64指处理器类型,linux指操作系统内核,gnu则指用户空间的ABI。对于原生库,cross-build库还是模拟器支持库的部署路径都是一样的,没有任何差别。</p>
<p>Debian Squeeze及之前的版本,AMD64平台上,/lib64是/lib目录的符号链接,/usr/lib64是/usr/lib的符号链接。而如果安装了ia32-libs库,则/lib32和/usr/lib32用来部署32位程序的共享库。这并没有遵守FHS 2.3的规定。从Wheezy开始,Debian全面支持multiarch架构。/lib64,/usr/lib64,/lib32,/usr/lib32等和ia32-libs库都是debian要消灭的目标,现在testing AMD64版本中,/lib64目录下还只剩一个符号链接ld-linux-x86-64.so.2,指向/lib/x86_64-linux-gnu/ld-2.13.so,这是因为bash的大部分命令还在硬编码/lib64/ld-linux-x86-64.so.2,估计不久的将来,最晚到wheezy正式发布,/lib64目录会被彻底消灭。ia32-libs也会被化解整合到/lib/i386-linux-gnu/,/usr/lib/i386-linux-gnu等目录下。这样有些软件在testing平台安装时,可能不得不手工做很多的符号链接以弥合这种库路径的变化,当然源内的软件是不会存在这种问题的。</p>
<p>如果multiarch的目标完全实现,在同一个系统内安装不同架构的库和二进制目标文件。那么下一个目标极有可能就是通用二进制(<a href="http://en.wikipedia.org/wiki/Universal_binary">Universal binary</a>),这也算是水到渠成的事了。通用二进制的目标文件里面用不同section存储不同架构的二进制代码,比如支持power和amd64的通用二进制目标程序,在power平台运行时会执行存储power机器码的section,而在amd64平台运行时则会执行存储amd64机器码的section。当然这种方式存在冗余,每一种平台上只会用到一种机器码段,其他的机器码则没有任何用处,只是在白白的浪费存储空间。通用二进制势必会对操作系统底层,以及应用程序的build和release模式产生重大影响。</p>
<p>其实现在linux平台上已经有了<a href="http://icculus.org/fatelf/">FatELF</a>(Universal Binaries for Linux)项目,不过据说开发者Ryan Gordon<a href="http://techsingular.net/?p=480">已经放弃该项目</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>multipath: error getting device</title>
    <url>/2015/11/03/multipath-error-getting-device/</url>
    <content><![CDATA[<a id="more"></a>
<p>dmesg有如下类似错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">kernel: device-mapper: table: <span class="number">253</span>:<span class="number">3</span>: multipath: error getting device</span><br><span class="line">kernel: device-mapper: ioctl: error adding target to table</span><br><span class="line">kernel: device-mapper: table: <span class="number">253</span>:<span class="number">3</span>: multipath: error getting device</span><br><span class="line">kernel: device-mapper: ioctl: error adding target to table</span><br></pre></td></tr></table></figure>

<p>极有可能是因为multipathd试图在一个已经打开的设备上创建多路径设备，通常是因为这些设备并不是多路径设备，应该在配置文件中屏蔽掉而没有屏蔽的原因。</p>
<p>Are most likely due to multipathd attempting to create a multipath device on top of an already opened device. This is usually because there are device that should be blacklisted which are not.</p>
<p>References:<br>[1]<a href="https://bugzilla.redhat.com/show_bug.cgi?id=675366">multipath: error getting device</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>多路径冗余I/O</title>
    <url>/2011/03/18/multipath-io/</url>
    <content><![CDATA[<p>多路径冗余I/O(Multipath I/O)是指服务器通过多条物理路径连接到块存储设备</p>
<a id="more"></a>
<p>当因为主机HBA卡、线缆、存储交换机或者存储设备的RAID控制器故障等原因造成一条物理路径失效时,服务器可以将通过此物理路径的I/O转移到其他正常的物理路径上面,应用程序不会觉察到这种改变，从而提高系统的可用性。</p>
<p>硬件方面需要服务器有2块或以上的HBA接口卡，网络上有两个或以上的存储交换机，块存储设备有两个或以上的冗余控制器，各个物理路径之间没有任何硬件相互依赖。</p>
<p>多路径冗余I/O也可以实现I/O的负载均衡，提高系统性能，但主要还是一种容错机制。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>Debian multipath-tools升级失败解决办法</title>
    <url>/2012/08/01/multipath-tools-upgrade-fail-solution/</url>
    <content><![CDATA[<p>debian wheezy升级multipath-tools时出现错误,升级失败</p>
<a id="more"></a>
<p>错误提示：<br>…<br>Device does not exist.<br>Command failed<br>invoke-rc.d: initscript multipath-tools, action “stop” failed.<br>dpkg: warning: subprocess old pre-removal script returned error exit status 1<br>…</p>
<p>这是由于旧版multipath-tools init脚本存在错误所致,可以通过提取升级包中的init脚本替换当前init脚本来解决：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ cp /<span class="keyword">var</span>/cache/apt/archives/multipath-tools_0<span class="number">.4</span><span class="number">.9</span>+git0.4dfdaf2b-6_amd64.deb /tmp</span><br><span class="line">$ cd /tmp</span><br><span class="line">$ aunpack multipath-tools_0<span class="number">.4</span><span class="number">.9</span>+git0.4dfdaf2b-6_amd64.deb</span><br><span class="line"># mv /etc/init.d/multipath-tools /etc/init.d/multipath-tools-1</span><br><span class="line"># cd /tmp/multipath-tools_0.4.9+git0.4dfdaf2b-6_amd64</span><br><span class="line"># cp etc/init.d/multipath-tools /etc/init.d/multipath-tools</span><br><span class="line"># /etc/init.d/multipath-tools restart</span><br><span class="line"># rm /etc/init.d/multipath-tools-1</span><br></pre></td></tr></table></figure>
<p>如果没有aunpack命令则需要安装包atool</p>
<p>之后重新执行升级指令即可</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#apt-get dist-upgrade</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>MurmurHash算法</title>
    <url>/2015/10/30/murmurhash%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<a id="more"></a>
<p>MurmurHash是一种非加密的哈希算法，目前主要用于数据分区。</p>
<p>其名字来自于MUltiply and Rotate,因为要经过多次MUltiply and Rotate，所以叫Murmur.</p>
<p>当前版本为MurmurHash3，cassandra使用了这个哈希算法来对数据进行分区，因此对应分区器的名字为Murmur3Partitioner,此分区器是cassandra当前默认的分区器。</p>
<p>推荐使用Murmur3Partitioner分区器。</p>
<p>References:<br>[1]<a href="https://en.wikipedia.org/wiki/MurmurHash">MurmurHash</a><br>[2]<a href="http://calvin1978.blogcn.com/articles/murmur.html">陌生但默默一统江湖的MurmurHash</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>.mybashrc</title>
    <url>/2015/07/28/mybasrc/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># bash</span><br><span class="line">set -o vi</span><br><span class="line">PS1=<span class="string">&#x27;$&#123;debian_chroot:+($debian_chroot)&#125;\\\[\\033\[00;31m\\\]\\u@\\h\\\[\\033\[00m\\\]:\\\[\\033\[00;33m\\\]\\w\\\[\\033\[00m\\\]\\$ \\\[\\033\[00;32m\\\]&#x27;</span></span><br><span class="line"></span><br><span class="line"># bash history</span><br><span class="line"><span class="keyword">export</span> HISTCONTROL=ignoredups</span><br><span class="line">shopt -s histappend</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> PATH=$HOME/bin:<span class="regexp">/sbin:/u</span>sr/sbin:<span class="regexp">/usr/</span>local/sbin:<span class="regexp">/opt/</span>bin:$PATH</span><br><span class="line"></span><br><span class="line"># xterm</span><br><span class="line"><span class="keyword">if</span> \[ <span class="string">&quot;$TERM&quot;</span> == <span class="string">&quot;xterm&quot;</span> \]; then</span><br><span class="line"> <span class="keyword">export</span> TERM=xterm-256color</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># mac os x</span><br><span class="line"><span class="keyword">if</span> \[ \<span class="string">`uname\` == &quot;Darwin&quot; \]; then</span></span><br><span class="line"><span class="string"> alias ll=&#x27;ls -lh grep ^total &amp;&amp; ls -lh grep ^d &amp;&amp; ls -lh grep -v ^d grep -v ^total&#x27;</span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># freebsd</span></span><br><span class="line"><span class="string">if \[ \`uname\` == &quot;FreeBSD&quot; \]; then</span></span><br><span class="line"><span class="string"> # gnuls</span></span><br><span class="line"><span class="string"> alias ls=&#x27;gnuls --color=auto --show-control-chars&#x27;</span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># linux </span></span><br><span class="line"><span class="string">if \[ \`uname\` == &quot;Linux&quot; \]; then</span></span><br><span class="line"><span class="string"> alias ll=&#x27;ls -lh --group-directories-first&#x27;</span></span><br><span class="line"><span class="string"> alias update=&#x27;sudo apt-get update &amp;&amp; sudo apt-get dist-upgrade -y &amp;&amp; sudo apt-get autoremove -y&#x27; </span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># general</span></span><br><span class="line"><span class="string">alias la=&#x27;ls -a&#x27;</span></span><br><span class="line"><span class="string">alias ccd=&#x27;clear;cd&#x27;</span></span><br><span class="line"><span class="string">alias :q=&#x27;exit&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># mail</span></span><br><span class="line"><span class="string">export MAIL=$HOME/Maildir</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#oracle</span></span><br><span class="line"><span class="string">alias sqlplus=&#x27;rlwrap sqlplus&#x27;</span></span><br><span class="line"><span class="string">alias rman=&#x27;rlwrap rman&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#export ORACLE_SID=</span></span><br><span class="line"><span class="string">#export ORACLE_BASE=/u01/app/oracle</span></span><br><span class="line"><span class="string">#export ORACLE_HOME=$ORACLE_BASE/product/10.2.0/db_1</span></span><br><span class="line"><span class="string">#export PATH=$ORACLE_HOME/bin:$PATH</span></span><br><span class="line"><span class="string">#export TNS_ADMIN=$ORACLE_HOME/network/admin</span></span><br><span class="line"><span class="string">#export SQLPATH=$ORACLE_BASE/scripts</span></span><br></pre></td></tr></table></figure>

<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatis Generator配置文件context元素的defaultModelType属性</title>
    <url>/2013/12/30/mybatis-generator-context-defaultmodeltype/</url>
    <content><![CDATA[<p>MyBatis Generator配置文件context元素有一个defaultModelType属性,这个属性的值会影响实体类(或叫domain类,model类)的生成。</p>
<a id="more"></a>
<p>这个属性用于设置产生的模型类型。模型类型定义了MBG如何去产生模型类。对于一些模型类型,MBG会为每一张表产生单独的实体类,而其他的模型类型,MBG会依据表的结构产生一些不同的实体类。<br>这个属性支持以下三个值:</p>
<ul>
<li>  <strong>conditional</strong><br>这是默认值<br>这个模型与hierarchical模型相似,除了如果一个实体类只包含一个字段,则不会单独生成此实体类。因此,如果一个表的主键只有一个字段,那么不会为该字段生成单独的实体类,会将该字段合并到基本实体类中。</li>
<li>  <strong>flat</strong><br>该模型为每一张表只生成一个实体类。这个实体类包含表中的所有字段。一般使用这个模型就够了。</li>
<li>  <strong>hierarchical</strong><br>如果表有主键,那么该模型会产生一个单独的主键实体类,如果表还有BLOB字段，则会为表生成一个包含所有BLOB字段的单独的实体类,然后为所有其他的字段生成一个单独的实体类。MBG会在所有生成的实体类之间维护一个继承关系。<br>显然这个模型比较复杂。</li>
</ul>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatis Generator产生的Example类</title>
    <url>/2013/12/26/mybatis-generator-example/</url>
    <content><![CDATA[<p>Example类用于构造复杂的筛选条件。</p>
<a id="more"></a>
<p><strong>基本概念</strong></p>
<ul>
<li>  <strong>Criterion</strong></li>
</ul>
<p>Criterion是最基本,最底层的Where条件，用于字段级的筛选，feild用于指代字段名字,列举如下:</p>
<p>只有一个条件,不需要其他参考值<br>feild IS NOLL<br>feild IS NOT NULL</p>
<p>与一个参考值进行算数运算<br>feild &gt; value<br>feild &gt;= value<br>feild = value<br>feild value<br>feild &lt;= value<br>feild &lt; value</p>
<p>与一个参考值进行模糊查询,参值中的%,?只能在构造查询条件时手动指定。</p>
<p>feild LIKE value<br>feild NOT LIKE value</p>
<p>介于两个参考值之间</p>
<p>feild BETWEEN value AND secondValue</p>
<p>在或不在一个参考值集合中,item来自于value集合</p>
<p>feild IN (item,item,item,…)<br>feild NOT IN (item,item,item,…)</p>
<p>MyBatis Generator会为每个字段产生如上的Criterion，如果表的字段比较多,产生的Example类会十分庞大。理论上通过Example类可以构造你想到的任何筛选条件。</p>
<ul>
<li><p>  <strong>Criteria</strong><br>Criteria包含一个Cretiron的集合,每一个Criteria对象内包含的Cretiron之间是由AND连接的,是逻辑与的关系。</p>
</li>
<li><p>  <strong>oredCriteria</strong><br>Example内有一个成员叫oredCriteria,是Criteria的集合,就想其名字所预示的一样，这个集合中的Criteria是由OR连接的，是逻辑或关系。oredCriteria就是ORed Criteria。</p>
</li>
</ul>
<p><strong>用法</strong></p>
<p>示例来自<a href="http://mybatis.org/generator/generatedobjects/exampleClassUsage.html">官方文档</a>。</p>
<p>[java]<br>TestTableExample example = new TestTableExample();</p>
<p> example.or()<br> .andField1EqualTo(5)<br> .andField2IsNull();</p>
<p> example.or()<br> .andField3NotEqualTo(9)<br> .andField4IsNotNull();</p>
<p> List<Integer> field5Values = new ArrayList<Integer>();<br> field5Values.add(8);<br> field5Values.add(11);<br> field5Values.add(14);<br> field5Values.add(22);</p>
<p> example.or()<br> .andField5In(field5Values);</p>
<p> example.or()<br> .andField6Between(3, 7);<br>[/java]<br>or()方法会产生一个新的Criteria对象,添加到oredCriteria中,并返回这个Criteria对象，从而可以链式表达，为其添加Criterion。<br>产生的动态SQL是这样的：<br>[sql]<br>where (field1 = 5 and field2 is null)<br> or (field3 &lt;&gt; 9 and field4 is not null)<br> or (field5 in (8, 11, 14, 22))<br> or (field6 between 3 and 7)<br>[/sql]</p>
<p><strong>其他</strong></p>
<p>Example类的distinct字段用于指定DISTINCT查询。</p>
<p>orderByClause字段用于指定ORDER BY条件,这个条件没有构造方法,直接通过传递字符串值指定。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>配置Mybatis Generator不要生成Example类</title>
    <url>/2013/12/19/mybatis-generator-ignore-example/</url>
    <content><![CDATA[<a id="more"></a>
<p>Mybatis Generator默认设置会生成一大堆罗哩罗嗦的Example类,主要是用各种不同的条件来操作数据库,大部分是用不到的,用到的时候手工修改mapper和接口文件就行了。</p>
<p>[sql]</p>
<table schema="general" tableName="tb_table_name" domainObjectName="EntityName"
 enableCountByExample="false" enableUpdateByExample="false" enableDeleteByExample="false"
 enableSelectByExample="false" selectByExampleQueryId="false" >
 <property name="useActualColumnNames" value="true"/>
</table>
\[/sql\]

<p>这样生成的mapper和dao接口就清爽多了。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis Generator的properties子元素</title>
    <url>/2013/12/19/mybatis-generator-properties-subelement/</url>
    <content><![CDATA[<a id="more"></a>
<p>Mybatis Generator配置文件中<br>generatorConfiguration元素有一个子元素<a href="http://mybatis.org/generator/configreference/properties.html">properties</a>，可以用来指定一个java属性文件,从而配置文件内可以通过${property}来引用属性对应的值。可以将一些通用的属性放到共享的属性文件中减少一些冗余。</p>
<p>properties子元素有两个互斥的属性resource和url,resource用来指定类路径下的属性文件,url用来指定文件系统路径指示的属性文件。<br>二者只能使用一个,resource总是不成功,Mybatis Generator的类路径就没整明白,jdbc驱动类还是用的绝对路径:(</p>
<p>样例属性文件generatorConfig.properties<br>[xml]<br>classPath=/path/to/WEB-INF/lib/postgresql-9.3-1100.jdbc41.jar<br>driverClass=org.postgresql.Driver<br>dbURL=jdbc:postgresql://localhost/reis<br>userId=general<br>passwd=general<br>project=projectname/src/main<br>[/xml]</p>
<p><strong>更新(12/30/2013):</strong></p>
<p>将资源文件放入eclipse已经存在的classpath中,或者将资源文件所在的文件夹添加到eclipse类路径里就可以用resource属性来引用资源文件了。<br>比如资源文件放在WEB-INF/conf文件夹里面,WEB-INF/conf不在eclipse的类路径下,所以需要设置eclipse添加该文件夹,如下：<br>project -&gt; properties -&gt; java build path -&gt; libraries -&gt; add class folder,选择WEB-INF/conf确定就可以了。<br>这样工程根目录下的.classpath文件内会添加一行:<br>[xml]<br><classpathentry kind="lib" path="root/WEB-INF/conf"/><br>[/xml]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatis Generator配置文件table元素的属性useActualColumnNames</title>
    <url>/2013/12/30/mybatis-generator-table-useactualcolumnnames/</url>
    <content><![CDATA[<a id="more"></a>
<p>useActualColumnNames用于指定生成实体类时是否使用实际的列名作为实体类的属性名。取值true或false:</p>
<ul>
<li>  true<br>MyBatis Generator会使用数据库中实际的字段名字作为生成的实体类的属性名。</li>
<li>  false<br>这是默认值。如果设置为false,则MyBatis Generator会将数据库中实际的字段名字转换为Camel Case风格作为生成的实体类的属性名。</li>
</ul>
<p>如果明确的使用columnOverride元素指定了字段对应的实体的属性名,那么useActualColumnNames会被忽略。</p>
<p>假设表有一个字段名为start_date,如果这个属性设置为true,则生成的实体类的属性名为start_date,生成的setter/getter为setStart_date/getStart_date。如果useActualColumnNames设置为false,则生成的实体类的属性名为startDate,生成的setter/getter为setStartDate/getStartDate。</p>
<p>那为什么要在数据库表字段中使用Snake Case下划线风格呢?因为大部分数据库服务器对象的命名是不分大小写的,因此使用Snake Case命名风格还是十分有必要的。MyBatis Generator考虑的还真是仔细,将Snake Case转换为Camel Case以与Java风格保持一致。</p>
<p>参考:<br><a href="http://mybatis.org/generator/configreference/table.html">table element</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis获取PostgreSQL数据库插入记录的自增序列值</title>
    <url>/2013/11/23/mybatis-get-serial-value/</url>
    <content><![CDATA[<a id="more"></a>
<p>有这么几种方法：</p>
<ul>
<li>  useGeneratedKeys</li>
</ul>
<p>这是insert独有的属性，告诉Mybatis使用JDBC的getGeneratedKeys 方法去获取数据库内部产生的key。<br>如果自增键的名字不叫id,还需要设置一个属性keyProperty来告诉Mybaits获取回来的结果设置到那个字段上。<br><strong>最好明确设置keyProperty属性</strong>。<br>[xml]<br><insert id="insert" parameterType="org.xxx.xxx.entity.Building"
 useGeneratedKeys="true" keyProperty="myid"></p>
<p>INSERT INTO … </p>
</insert>
\[/xml\]

<p>使用Mybatis Generator生成mapper文件时,只要在table元素下添加子元素generatedKey即可,如下:<br>[xml]<br><generatedKey column="id" sqlStatement="JDBC"/><br>[/xml]</p>
<p>column是自动生成的键,使用JDBC标准生成键方式。<br>最好将generatedKey子元素放到table元素的最后,否则可能会有错误提示。</p>
<ul>
<li>  selectKey</li>
</ul>
<p>selectKey定义一个子查询，将查询的自增键的结果赋予insert参数的相应字段。selectKey有以下几个属性：</p>
<p>keyProperty - selectKey子查询的结果应该设置到传入参数的哪个字段上<br>resultType - 查询的结果类型。Mybaits其实可以自己查询出结果类型。<br>order - 插入语句执行之前还是之后执行selectKey子查询，只能取值BEFORE或AFTER<br>statementType - 语句类型。STATEMENT，PREPARED或CALLABLE</p>
<p>插入语句之后执行selectKey子查询<br>[xml]<br><selectKey order="AFTER" keyProperty="id" resultType="java.lang.Integer"><br> SELECT currval(‘mytable_id_seq’)<br></selectKey><br>[/xml]</p>
<p>插入语句之前执行selectKey子查询<br>[xml]<br><selectKey order="BEFORE" keyProperty="id" resultType="java.lang.Integer"><br> SELECT nextval(‘mytable_id_seq’)<br></selectKey><br>[/xml]</p>
<p>PostgreSQL为serial字段生成的sequence名字为: 表名_列名_seq,但是这个序列并不能单独访问，否则会有提示：<br>ERROR: currval of sequence “mytable_id_seq” is not yet defined in this session</p>
<ul>
<li>  RETURNING子句</li>
</ul>
<p>PostgreSQL的INSERT语句可以有一个RETURNING字句，返回刚插入记录的字段值。而且RETURNING的语法与SELECT是一样的，这个功能还是十分强大的，不过这是PostgreSQL独有的SQL标准之外的扩展特性。</p>
<p>[xml]<br><insert id="insert" parameterType="org.xxx.xxx.entity.Building" resultType="int"><br>INSERT INTO … VALUES (…) RETURNING id<br></insert><br>[/xml]</p>
<p>useGeneratedKeys是最简单的，只要数据库支持就应该使用这个方法。</p>
<p>无论使用哪个方法，返回的自增键的值都应该从insert方法的参数对应的字段去取，而不是获取insert方法的返回值，insert方法总是返回INSERT INTO语句影响的行数，如果插入成功其值为1，如果插入失败其值为0</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatis mapper文件中的变量引用方式#{var}与${var}</title>
    <url>/2013/12/26/mybatis-mapper/</url>
    <content><![CDATA[<a id="more"></a>
<p>By default, using the #{} syntax will cause MyBatis to generate PreparedStatement properties and set the values safely against the PreparedStatement parameters (e.g. ?). While this is safer, faster and almost always preferred, sometimes you just want to directly inject a string unmodified into the SQL Statement. For example, for ORDER BY, you might use something like this:</p>
<p>ORDER BY ${columnName}<br>Here MyBatis won’t modify or escape the string.</p>
<p>NOTE It’s not safe to accept input from a user and supply it to a statement unmodified in this way. This leads to potential SQL Injection attacks and therefore you should either disallow user input in these fields, or always perform your own escapes and checks.</p>
<p>默认情况下,使用#{}语法,MyBatis会产生PreparedStatement语句中，并且安全的设置PreparedStatement参数，这个过程中MyBatis会进行必要的安全检查和转义。</p>
<p>有时候可能需要直接插入一个不做任何修改的字符串到SQL语句中。这时候应该使用${}语法。比如，ORDER BY字句</p>
<p>ORDER BY ${columnName}</p>
<p>MyBatis会原原本本的将columnName变量的值插入到SQL语句中,不做任何检查和转换。以这种方式将用户的输入直接插入到SQL语句中是不安全的，可能会导致潜在的SQL注入攻击，因此应该禁止直接将用户数据插入这些字段，或者执行必要的转义和检查。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBatis传入参数与parameterType</title>
    <url>/2013/12/25/mybatis-parametertype/</url>
    <content><![CDATA[<a id="more"></a>
<p>Mybatis的Mapper文件中的select、insert、update、delete元素中有一个parameterType属性，用于对应的mapper接口方法接受的参数类型。</p>
<p>可以接受的参数类型有基本类型和复杂类型。</p>
<p>mapper接口方法一般接受一个参数,可以通过使用@Param注释将多个参数绑定到一个map做为输入参数。</p>
<ol>
<li> <strong>简单数据类型</strong></li>
</ol>
<p>mapper接口方法:<br>[java]<br>User selectByPrimaryKey(Integer id);<br>[/java]<br>sql映射:<br>[xml]<br> <select id="selectByPrimaryKey" resultMap="BaseResultMap" parameterType="java.lang.Integer" ><br> select<br> <include refid="Base_Column_List" /><br> from base.tb_user<br> where id = #{id,jdbcType=INTEGER}<br> </select><br>[/xml]</p>
<p>对于简单数据类型,sql映射语句中直接#{变量名}这种方式引用就行了,其实这里的”变量名”可以是任意的。mapper接口方法传递过来的值,至于其叫什么名字其实是不可考也没必要知道的。<br>而且JAVA反射只能获取方法参数的类型,是无从得知方法参数的名字的。</p>
<p>比如上面这个示例中,使用#{id}来引用只是比较直观而已,使用其他名字来引用也是一样的。所以当在if元素中test传递的参数时,就必须要用_parameter来引用这个参数了。像这样：</p>
<p>[xml]<br> <select id="selectByPrimaryKey" resultMap="BaseResultMap" parameterType="java.lang.Integer" ><br> select<br> <include refid="Base_Column_List" /><br> from tb_user<br> <if test="_parameter != 0"><br> where id = #{id,jdbcType=INTEGER}<br> </if><br> </select><br>[/xml]<br>如果test测试条件中使用id就会提示错误,因为这个参数其实没有名字,只是一个值或引用而已,只能使用_parameter来引用。</p>
<ol start="2">
<li><strong>对象类型</strong><br>传入JAVA复杂对象类型的话,sql映射语句中就可以直接引用对象的属性名了,这里的属性名是实实在在的真实的名字,不是随意指定的。<br>mapper接口方法:<br>[java]<br>int insert(User user);<br>[/java]<br>sql映射：<br>[xml]<insert id="insert" parameterType="User" useGeneratedKeys="true" keyProperty="id">
insert into tb_user (name, sex) 
values (#{name,jdbcType=CHAR}, #{sex,jdbcType=CHAR})
\[/xml\]

</li>
</ol>
<p>虽然可以明确的引用对象的属性名了,但如果要在if元素中测试传入的user参数,仍然要使用_parameter来引用传递进来的实际参数,因为传递进来的User对象的名字是不可考的。如果测试对象的属性,则直接引用属性名字就可以了。</p>
<p>测试user对象:<br>[xml]<br><if test="_parameter != null"><br>[/xml]<br>测试user对象的属性:<br>[xml]<br><if test="name != null"><br>[/xml]<br>3.  <strong>map类型</strong></p>
<p>传入map类型,直接通过#{keyname}就可以引用到键对应的值。使用@param注释的多个参数值也会组装成一个map数据结构,和直接传递map进来没有区别。</p>
<p>mapper接口:<br>[java]<br>int updateByExample(@Param(“user”) User user, @Param(“example”) UserExample example);<br>[/java]</p>
<p>sql映射:<br>[xml]<br> <update id="updateByExample" parameterType="map" ><br> update tb_user<br> set id = #{user.id,jdbcType=INTEGER},<br> …<br> <if test="_parameter != null" ><br> <include refid="Update_By_Example_Where_Clause" /><br> </if><br>[/xml]<br>注意这里测试传递进来的map是否为空,仍然使用_parameter</p>
<ol start="4">
<li> <strong>集合类型</strong></li>
</ol>
<blockquote>
<p>You can pass a List instance or an Array to MyBatis as a parameter object. When you do, MyBatis will automatically wrap it in a Map, and key it by name. List instances will be keyed to the name “list” and array instances will be keyed to the name “array”.</p>
</blockquote>
<p>可以传递一个List或Array类型的对象作为参数,MyBatis会自动的将List或Array对象包装到一个Map对象中,List类型对象会使用list作为键名,而Array对象会用array作为键名。</p>
<p>集合类型通常用于构造IN条件，sql映射文件中使用foreach元素来遍历List或Array元素。</p>
<p>mapper接口:<br>[java]<br>User selectUserInList(List<Interger> idlist);<br>[/java]<br>sql动态语句映射:<br>[xml]<br><select id="selectUserInList" resultType="User"><br> SELECT *<br> FROM USER<br> WHERE ID in<br> <foreach item="item" index="index" collection="list"
 open="(" separator="," close=")"><br> #{item}<br> </foreach><br></select><br>[/xml]</p>
<ol start="6">
<li>对象类型中的集合属性<br>对于单独传递的List或Array,在SQL映射文件中映射时,只能通过list或array来引用。但是如果对象类型有属性的类型为List或Array，则在sql映射文件的foreach元素中,可以直接使用属性名字来引用。<br>mapper接口:<br>[java]<br>List<User> selectByExample(UserExample example);<br>[/java]<br>sql映射文件:<br>[xml]<where >
<foreach collection="oredCriteria" item="criteria" separator="or" >
<if test="criteria.valid" >
\[/xml\]

</li>
</ol>
<p>在这里,UserExample有一个属性叫oredCriteria,其类型为List,所以在foreach元素里直接用属性名oredCriteria引用这个List即可。</p>
<p>item=”criteria”表示使用criteria这个名字引用每一个集合中的每一个List或Array元素</p>
<p>参考：<br><a href="http://zhuyuehua.iteye.com/blog/1717525">MYBATIS 的parameter</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Mybatis自动扫描包设置注意事项</title>
    <url>/2013/11/22/mybatis-scan-mappers/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用mybatis:scan扫描mapper接口很方便<br>[xml]<br>&lt;mybatis:scan base-package=”net.openwares.test.mapper” /&gt;<br>[/xml]</p>
<p>但要注意一点：<br>不要将非mapper接口放入指定的基本包中，因为默认情况下mybatis:scan会将包里的所有接口当作mapper来扫描，所以如果是其他接口就会出现错误。</p>
<p>可以在mybatis:scan元素的基本包里添加多个包，使用逗号或分号分割即可。</p>
<p>下面摘录自Mybatis文档</p>
<blockquote>
<p><a href="mybatis:scan/">mybatis:scan/</a> supports filtering the mappers created by either specifying a marker interface or an annotation. The annotation property specifies an annotation to search for. The marker-interface attribute specifies a parent interface to search for. If both properties are specified, mappers are added for interfaces that match either criteria. By default, these two properties are null, so all interfaces in the given base package(s) will be loaded as mappers.</p>
</blockquote>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>轻轻松松修改mysql默认字符集为utf8</title>
    <url>/2009/04/20/mysql-default-charset/</url>
    <content><![CDATA[<p>utf8是我很喜欢的的字符集，在我的Debian lenny上安装mysql后，默认的字符集是latin1，现在就让我们把mysql相关的所有默认字符集都更改为utf8。</p>
<p>在/etc/mysql/conf.d目录下面新建一个文件charset.cnf，增加如下内容：<br>[client]<br>default-character-set = utf8<br>[mysql]<br>default-character-set = utf8<br>[mysqld]<br>default-character-set =utf8</p>
<p>然后执行命令sudo /etc/init.d/mysql reload，现在连上你的数据库看看吧，默认的字符集和校对集全部变成了utf8。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Mozilla可能最早于FireFox 3.5.1开始原生支持64bits计算平台</title>
    <url>/2009/07/07/native-64-bits-firefox-3-5-1/</url>
    <content><![CDATA[<p>可能首先只会支持linux 64bits计算平台,现在的firefox-3.5.1pre已经可以看到linux平台上的<a href="http://ftp.mozilla.org/pub/mozilla.org/firefox/nightly/latest-firefox-3.5.x/">x86_64 Build</a>了,当然只有en-US版本。</p>
]]></content>
      <categories>
        <category>News</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>禁止nautilus为自动挂装设备自动弹出窗口</title>
    <url>/2013/01/18/nautilus-disable-automount-open/</url>
    <content><![CDATA[<p>每当插入移动存储设备,nautilus会自动挂装并自动弹出窗体提示浏览设备或者弹出设备</p>
<a id="more"></a>
<p>可以禁止自动挂装或者禁止自动挂装后自动弹出窗口</p>
<p>打开<br>#dconf-editor</p>
<p>如下两项<br>org.gnome.desktop.media-handling.automount<br>org.gnome.desktop.media-handling.automount-open</p>
<p>分别控制自动挂装和自动挂装后自动弹出窗口，做相应选择即可。</p>
<p>或者使用命令行<br>$ gsettings set org.gnome.desktop.media-handling automount false<br>$ gsettings set org.gnome.desktop.media-handling automount-open false</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian amd64安装dropbox客户端</title>
    <url>/2012/03/16/nautilus-dropbox/</url>
    <content><![CDATA[<p>凡是优秀的网络服务在景德镇都难逃一样的命运,Dropbox亦属此列。</p>
<a id="more"></a>
<p>dropbox可以与nautilus集成,使用起来很方便,先安装包nautilus-dropbox</p>
<p>$sudo apt-get install nautilus-dropbox</p>
<p>安装完此包,dropbox客户端实际上并未安装完成,还需要安装dropbox专属的dropboxd,这不是开源的,使用dropbox命令来安装</p>
<p>$dropbox start -i</p>
<p>此时撞墙是难免的了,会提示一下信息</p>
<p>“Trouble connecting to Dropbox servers. May Be your internet connection is down, or you need to set your http_proxy environment variable.”</p>
<p>一直在用ssh tunnel,本来以为用proxychains或tsocks就可以搞定它,但是</p>
<p>$proxychains dropbox start -i<br>或<br>$tsocks dropbox start -i</p>
<p>还是会报同样的错误,proxychains或tsocks的配置都是测试了正确的,查阅了部分资料,猜测是因为dropbox命令respawn出了新的子shell来下载dropboxd,而新的子shell并不在proxychains或tsocks的代理范围之内,看来要全局代理才行</p>
<p>安装privoxy来设置全局http代理</p>
<p>$sudo apt-get install privoxy</p>
<p>然后编辑/etc/privoxy/config文件,添加</p>
<p>forward-socks5 / 127.0.0.1:7070 .</p>
<p>注意7070是ssh forward的端口,根据实际情况更改,然后</p>
<p>$sudo /etc/init.d/privoxy restart</p>
<p>设置http全局代理</p>
<p>$export http_proxy=<a href="http://127.0.0.1:8118/">http://127.0.0.1:8118</a></p>
<p>8118是privoxy默认的http代理端口,然后</p>
<p>$dropbox restart -i</p>
<p>就可以正常安装dropboxd了,安装完后dropbox客户端可以单独设置sock5代理,全局http代理就可以不用了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Nautilus smb共享挂载点</title>
    <url>/2016/01/11/nautilus-smb-share-mount-point/</url>
    <content><![CDATA[<a id="more"></a>
<p>Nautilus可以自动挂装smb共享目录，但是mount命令却看不到共享目录的挂载点。</p>
<p>nautilus使用gvfs来自动挂载smb共享,需要安装gvfs-fuse来提供本地文件系统视图:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install gvfs-fuse</span><br></pre></td></tr></table></figure>

<p>系统重新启动</p>
<p>当前debian系统nautilus自动将共享目录挂载到/run/user/$UID/gvfs下，形如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">smb-share:server=server_name,share=foobar</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Netbeans 7.4 菜单无法使用问题</title>
    <url>/2013/12/28/netbeans-menu-cannot-drop/</url>
    <content><![CDATA[<p>为什么Java IDE里到处是坑。Eclipse kepler慢吞吞,崩溃不止,好不容易想换Netbeans试试,菜单竟然无法使用！</p>
<a id="more"></a>
<p>除了坑还是坑啊！！！</p>
<p>系统环境:<br>debian testing jessie amd64 + openjdk-7-jdk 7u21-2.3.9-5 + Netbeans 7.4</p>
<p>新安装的Netbeans 7.4,鼠标点击主菜单,菜单显示出来了,一松鼠标,主菜单又没了,这是闹那样啊!!!</p>
<p>这bug据说有年头了,为啥这坑还不填上呢!!!</p>
<p><strong>解决方法:</strong></p>
<p>编辑netbeans的桌面加载文件 .local/share/applications/netbeans-7.4.desktop</p>
<p>将Exec那行添加前缀,改成如下形式:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Exec=env DESKTOP_SESSION=<span class="string">&quot;gnome-shell&quot;</span> /bin/sh <span class="string">&quot;/path/to/netbeans&quot;</span></span><br></pre></td></tr></table></figure>

<p>问题解决。不过要点击netbeans的桌面图标打开netbeans才行,如果用命令行,要把上面的命令敲全了!</p>
<p>坑啊坑,能不能少一点儿！！！</p>
<p>参考:</p>
<p><a href="https://bugs.launchpad.net/gala/+bug/1074491">Netbeans menu don’t work when maximized or enlarged</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>使用nc(netcat)传输文件</title>
    <url>/2014/09/30/netcat-file-transport/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果手上没有移动存储器，也不想开ftp,那么两台电脑之间可以使用nc(netcat)传输文件,比如现在要在一台mac和一台linux机器之间传输文件。</p>
<p>要接收文件的机器开启监听准备接收文件,本机器的ip地址为1.2.3.4</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nc -l -p <span class="number">1234</span> &gt; foo.bar</span><br></pre></td></tr></table></figure>

<p>发送文件的机器开始发送文件 </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nc <span class="number">1.2</span><span class="number">.3</span><span class="number">.4</span> <span class="number">1234</span> &lt; foo.bar</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>使用netcat、iperf3测量网络带宽</title>
    <url>/2016/10/04/netcat-iperf3-measuring-bandwidth/</url>
    <content><![CDATA[<a id="more"></a>
<p>netcat大名鼎鼎，功能多样。<br>netcat衍生版本众多，nmap.org提供的版本ncat是其中的佼佼者。</p>
<p><strong>ncat带宽测量</strong></p>
<p>机器A:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ncat -l -p <span class="number">2000</span> &gt; <span class="regexp">/dev/</span><span class="literal">null</span></span><br></pre></td></tr></table></figure>

<p>机器B:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dd <span class="keyword">if</span>=<span class="regexp">/dev/</span>zero bs=1024M count=<span class="number">1</span> ncat address_of_A <span class="number">2000</span></span><br><span class="line"><span class="number">1</span>+<span class="number">0</span> records <span class="keyword">in</span></span><br><span class="line"><span class="number">1</span>+<span class="number">0</span> records out</span><br><span class="line"><span class="number">1073741824</span> bytes transferred <span class="keyword">in</span> <span class="number">12.486022</span> secs (<span class="number">85995510</span> bytes/sec)</span><br></pre></td></tr></table></figure>

<p>两台机器之间的带宽大约在82MB/s。</p>
<p><strong>使用pv</strong></p>
<p>可以更动态、更直观的看到两者之间的速度</p>
<p>机器A:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ncat -l -p <span class="number">2000</span> pv &gt; <span class="regexp">/dev/</span><span class="literal">null</span></span><br></pre></td></tr></table></figure>

<p>机器B:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dd <span class="keyword">if</span>=<span class="regexp">/dev/</span>zero bs=256M pv ncat address_of_A <span class="number">2000</span></span><br></pre></td></tr></table></figure>

<p><strong>iperf3带宽评估</strong></p>
<p>iperf/iperf3是更为专业的网络吞吐量测工具，使用也很简。<br>服务端:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ iperf3 -s</span><br><span class="line">Server listening on <span class="number">5201</span></span><br></pre></td></tr></table></figure>

<p>客户端</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ iperf3 -c ip_of_server</span><br></pre></td></tr></table></figure>

<p>iperf3会有更细致的吞吐量报告。<br>更详细的使用参见man。</p>
<p>References:<br>[1]<a href="https://joncraton.org/blog/46/netcat-for-windows/">Netcat for Windows</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>在新内核上安装ATI Catalyst 10.9及之前版本的驱动</title>
    <url>/2010/10/12/new-kernel-install-ati-catalyst-10-9-and-before/</url>
    <content><![CDATA[<p>因为安全以及GPL相关事宜,linux内核调整了compat_alloc_user_space()函数,将其从asm/compat.h文件移动到linux/compat.h,并将该函数提升为EXPORT_SYMBOL_GPL导出的符号。</p>
<a id="more"></a>
<p>这就打破了ATI的专有fglrx驱动,因为闭源ATI驱动需要compat_alloc_user_space()函数, 并且希望从asm/compat.h里找到该函数。</p>
<p>在此更新之后的内核包括Ubuntu 10.10(Maverick MeerKat)上安装fglrx驱动时会出现错误,大体有以下字样,”kcl_ioctl.c:196 : error: implicit declaration of function ‘compat_alloc_user_space’”,就是因为这个问题。在ATI修复此问题之前可以通过一下方式来安装fglrx驱动。</p>
<p>下载ati fglrx驱动并生成相应的ubuntu安装包<br>$ sh ./ati-driver-installer-10-7-x86.x86_64.run –buildpkg Ubuntu/lucid</p>
<p>根据<a href="https://openwares.net/linux/extract_modify_rebuilde_deb_package.html">修改deb</a>这篇文章的提示将生成的deb解开，包括数据和控制文件。修改fglrx/usr/src/fglrx-8.75/kcl_ioctl.c第196行的compat_alloc_user_space为arch_compat_alloc_user_space，重新打包deb，然后$sudo dpkg -i fglrx_new.deb即可.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>NFS使用固定端口</title>
    <url>/2020/07/05/nfs%E4%BD%BF%E7%94%A8%E5%9B%BA%E5%AE%9A%E7%AB%AF%E5%8F%A3/</url>
    <content><![CDATA[<a id="more"></a>
<p>NFS通常情况下会使用动态端口，对于防火墙配置很不友好。<br>可以设置使用固定的几个端口。<br>修改以下配置文件：<br>/etc/default/nfs-common:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">STATDOPTS=<span class="string">&quot;--port 3000 --outgoing-port 3001&quot;</span></span><br></pre></td></tr></table></figure>

<p>/etc/default/nfs-kernel-server:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RPCMOUNTDOPTS=<span class="string">&quot;--manage-gids --port 3002&quot;</span></span><br></pre></td></tr></table></figure>

<p>新添加配置文件：<br>/etc/sysctl.d/nfs-static-ports.conf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">fs.nfs.nlm_tcpport = <span class="number">3003</span></span><br><span class="line">fs.nfs.nlm_udpport = <span class="number">3003</span></span><br></pre></td></tr></table></figure>
<p>然后：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo sysctl -p /etc/sysctl.d/nfs-<span class="keyword">static</span>-ports.conf</span><br><span class="line">$ sudo systemctl restart nfs-utils.service</span><br><span class="line">$ sudo systemctl restart nfs-kernel-server.service</span><br></pre></td></tr></table></figure>

<p>然后打通防火墙的TCP和UDP端口:111,2049,3000-3003就可以了。</p>
<p>如果出现错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mount.nfs: access denied by server <span class="keyword">while</span> mounting ...</span><br></pre></td></tr></table></figure>
<p>可以检查/etc/exports设置的访问网段是否正确，如果通过防火墙NAT方式访问，端口号会大约1024，需要添加insecure访问选项，比如(insecure,rw)</p>
<p>修改/etc/exports后，可以使用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo exportfs -a</span><br></pre></td></tr></table></figure>
<p>重新导出文件系统</p>
<p>References:<br>[1]<a href="https://wiki.debian.org/SecuringNFS">SecuringNFS</a><br>[2]<a href="https://www.peterbeard.co/blog/post/setting-up-iptables-for-nfs-on-ubuntu/">Setting Up iptables for NFS on Ubuntu</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx添加upstream健康检查模块</title>
    <url>/2019/07/27/nginx-add-upstream-health-check-module/</url>
    <content><![CDATA[<a id="more"></a>
<p>nginx社区版仅支持十分有限的upstream健康检查，其他高级特性需要商业订阅。<br>github上有个开源的upstream检查模块<a href="https://github.com/yaoweibin/nginx_upstream_check_module">nginx_upstream_check_module</a></p>
<p><strong>安装</strong></p>
<p>安装必要的编译环境</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install build-essential patch libpcre3 libpcre3-dev zlib1g zlib1g-dev libssl1<span class="number">.1</span> libssl-dev</span><br></pre></td></tr></table></figure>

<p>下载最新的nginx stable 1.16版本，clone nginx_upstream_check_module master分支</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget http:<span class="comment">//nginx.org/download/nginx-1.16.1.tar.gz</span></span><br><span class="line">$ git clone https:<span class="comment">//github.com/yaoweibin/nginx_upstream_check_module</span></span><br></pre></td></tr></table></figure>

<p>为源码打补丁</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tar zxvf nginx-<span class="number">1.16</span><span class="number">.1</span>.tar.gz</span><br><span class="line">$ cd nginx-<span class="number">1.16</span><span class="number">.1</span>/</span><br><span class="line">$ patch -p1 &lt; ../nginx_upstream_check_module/check_1<span class="number">.14</span><span class="number">.0</span>+.patch</span><br></pre></td></tr></table></figure>

<p>配置、编译、安装nginx</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./configure --add-<span class="built_in">module</span>=../nginx_upstream_check_module --<span class="keyword">with</span>-http_ssl_module --<span class="keyword">with</span>-stream_ssl_preread_module --<span class="keyword">with</span>-http_v2_module --<span class="keyword">with</span>-stream</span><br><span class="line">...</span><br><span class="line">Configuration summary</span><br><span class="line"> + using system PCRE library</span><br><span class="line"> + using system OpenSSL library</span><br><span class="line"> + using system zlib library</span><br><span class="line"></span><br><span class="line"> nginx path prefix: <span class="string">&quot;/usr/local/nginx&quot;</span></span><br><span class="line"> nginx binary file: <span class="string">&quot;/usr/local/nginx/sbin/nginx&quot;</span></span><br><span class="line"> nginx modules path: <span class="string">&quot;/usr/local/nginx/modules&quot;</span></span><br><span class="line"> nginx configuration prefix: <span class="string">&quot;/usr/local/nginx/conf&quot;</span></span><br><span class="line"> nginx configuration file: <span class="string">&quot;/usr/local/nginx/conf/nginx.conf&quot;</span></span><br><span class="line"> nginx pid file: <span class="string">&quot;/usr/local/nginx/logs/nginx.pid&quot;</span></span><br><span class="line"> nginx error log file: <span class="string">&quot;/usr/local/nginx/logs/error.log&quot;</span></span><br><span class="line"> nginx http access log file: <span class="string">&quot;/usr/local/nginx/logs/access.log&quot;</span></span><br><span class="line"> nginx http client request body temporary files: <span class="string">&quot;client_body_temp&quot;</span></span><br><span class="line"> nginx http proxy temporary files: <span class="string">&quot;proxy_temp&quot;</span></span><br><span class="line"> nginx http fastcgi temporary files: <span class="string">&quot;fastcgi_temp&quot;</span></span><br><span class="line"> nginx http uwsgi temporary files: <span class="string">&quot;uwsgi_temp&quot;</span></span><br><span class="line"> nginx http scgi temporary files: <span class="string">&quot;scgi_temp&quot;</span></span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br></pre></td></tr></table></figure>
<p>安装目录位于/usr/local/nginx</p>
<p>添加systemd服务nginx.service<br>将以下内容的文件nginx.service添加到/lib/systemd/system/nginx.service</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># Stop dance for nginx</span><br><span class="line"># =======================</span><br><span class="line">#</span><br><span class="line"># ExecStop sends SIGSTOP (graceful stop) to the nginx process.</span><br><span class="line"># If, after 5s (--retry QUIT/5) nginx is still running, systemd takes control</span><br><span class="line"># and sends SIGTERM (fast shutdown) to the main process.</span><br><span class="line"># After another 5s (TimeoutStopSec=5), and if nginx is alive, systemd sends</span><br><span class="line"># SIGKILL to all the remaining processes in the process group (KillMode=mixed).</span><br><span class="line">#</span><br><span class="line"># nginx signals reference doc:</span><br><span class="line"># http://nginx.org/en/docs/control.html</span><br><span class="line">#</span><br><span class="line">\[Unit\]</span><br><span class="line">Description=A high performance web server and a reverse proxy server</span><br><span class="line">Documentation=man:nginx(<span class="number">8</span>)</span><br><span class="line">After=network.target nss-lookup.target</span><br><span class="line"></span><br><span class="line">\[Service\]</span><br><span class="line">Type=forking</span><br><span class="line">PIDFile=<span class="regexp">/usr/</span>local/nginx/logs/nginx.pid</span><br><span class="line">ExecStartPre=<span class="regexp">/usr/</span>local/nginx/sbin/nginx -t -q -g <span class="string">&#x27;daemon on; master_process on;&#x27;</span></span><br><span class="line">ExecStart=<span class="regexp">/usr/</span>local/nginx/sbin/nginx -g <span class="string">&#x27;daemon on; master_process on;&#x27;</span></span><br><span class="line">ExecReload=<span class="regexp">/usr/</span>local/nginx/sbin/nginx -g <span class="string">&#x27;daemon on; master_process on;&#x27;</span> -s reload</span><br><span class="line">ExecStop=-<span class="regexp">/sbin/</span>start-stop-daemon --quiet --stop --retry QUIT/<span class="number">5</span> --pidfile /run/nginx.pid</span><br><span class="line">TimeoutStopSec=<span class="number">5</span></span><br><span class="line">KillMode=mixed</span><br><span class="line"></span><br><span class="line">\[Install\]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<p>enable服务并启动</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl enable nginx.service </span><br><span class="line">Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /lib/systemd/system/nginx.service.</span><br><span class="line">$ sudo systemctl start nginx.service</span><br></pre></td></tr></table></figure>

<p><strong>健康检查配置</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line"> upstream cluser &#123;</span><br><span class="line">server <span class="number">192.168</span><span class="number">.0</span><span class="number">.17</span>:<span class="number">8080</span>;</span><br><span class="line">server <span class="number">192.168</span><span class="number">.0</span><span class="number">.18</span>:<span class="number">8080</span>;</span><br><span class="line">server <span class="number">192.168</span><span class="number">.0</span><span class="number">.19</span>:<span class="number">8080</span>;</span><br><span class="line"></span><br><span class="line">check interval=<span class="number">1000</span> fall=<span class="number">1</span> rise=<span class="number">2</span> timeout=<span class="number">1000</span> default_down=<span class="literal">true</span> type=http;</span><br><span class="line">check_http_send <span class="string">&quot;HEAD /aurl/ HTTP/1.0\\r\\n\\r\\n&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> server &#123;</span><br><span class="line"> listen <span class="number">80</span>;</span><br><span class="line"> server_name localhost;</span><br><span class="line"></span><br><span class="line"> location /aurl/ &#123;</span><br><span class="line">proxy_pass http:<span class="comment">//cluser/aurl/;</span></span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> location /status &#123;</span><br><span class="line"> check_status;</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>设置的检查间隔为1000毫秒，一次没有响应就标记节点down(fall)了，接连两次检查有响应节点才算up(rise)，没有检查之前节点的默认状态为down，使用http方式检查，检查的超时时间为1000毫秒，总之1000毫秒没有应答就是无响应。</p>
<p>使用_http方式_检查upstream服务的_业务入口/aurl/_是否已经就绪</p>
<p><strong>upstream状态</strong></p>
<p>访问<a href="http://your_ip/status%E6%9F%A5%E7%9C%8B%E6%A3%80%E6%9F%A5%E7%BB%93%E6%9E%9C">http://your_ip/status查看检查结果</a><br>Nginx http upstream check status<br>Check upstream server number: 3, generation: 1</p>
<p>Index</p>
<p>Upstream</p>
<p>Name</p>
<p>Status</p>
<p>Rise counts</p>
<p>Fall counts</p>
<p>Check type</p>
<p>Check port</p>
<p>0</p>
<p>cluser</p>
<p>192.168.0.17:8080</p>
<p>up</p>
<p>30</p>
<p>0</p>
<p>tcp</p>
<p>0</p>
<p>1</p>
<p>cluser</p>
<p>192.168.0.18:8080</p>
<p>up</p>
<p>19</p>
<p>0</p>
<p>tcp</p>
<p>0</p>
<p>2</p>
<p>cluser</p>
<p>192.168.0.19:8080</p>
<p>up</p>
<p>15</p>
<p>0</p>
<p>tcp</p>
<p>0</p>
<p>References:<br>[1]<a href="https://github.com/yaoweibin/nginx_upstream_check_module">Health checks upstreams for nginx</a><br>[2]<a href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-health-check/">HTTP Health Checks</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>debian squeeze配置nginx支持CGI程序</title>
    <url>/2011/05/08/nginx-cgi-support/</url>
    <content><![CDATA[<p>nginx默认不支持传统的CGI程序,但是通过FCGI包装程序可以让nginx支持CGI</p>
<a id="more"></a>
<p>只要是符合FCGI接口的包装程序都可以用来使nginx支持CGI程序，有很多这样的程序,有perl写的，有C写的，也有C++写，等等。</p>
<p>nginx.org提供了一个<a href="http://wiki.nginx.org/SimpleCGI">perl包装程序</a>,但没有提供system V风格的init文件，对这个程序稍加改造，然后写一个init控制文件就可以在debian squeeze上使用了。</p>
<p>安装perl必要的支持库<br>$sudo apt-get -y install libfcgi-perl libfcgi-procmanager-perl libio-all-perl</p>
<p>改造后的perl包装程序cgiwrap-fcgi.pl代码：<br> 1 #!/usr/bin/perl<br> 2 <strong>use</strong> FCGI;<br> 3 <strong>use</strong> Socket;<br> 4 <strong>use</strong> FCGI::ProcManager;<br> 5 <strong>use</strong> IO::All;<br> 6 <strong>sub</strong> shutdown { FCGI::CloseSocket($socket); <strong>exit</strong>; }<br> 7 <strong>sub</strong> restart { FCGI::CloseSocket($socket); &main; }<br> 8 <strong>use sigtrap</strong> ‘handler’, \&amp;shutdown, ‘normal-signals’;<br> 9 <strong>use sigtrap</strong> ‘handler’, \&amp;restart,  ‘HUP’;<br> 10 <strong>require</strong> ‘syscall.ph’;<br> 11 <strong>use</strong> POSIX qw(setsid);<br> 12  <br> 13 &daemonize;<br> 14<br> 15 END()   { }<br> 16 BEGIN() { }<br> 17 {<br> 18   <strong>no warnings</strong>;<br> 19   <em>CORE::GLOBAL::<strong>exit</strong> = <strong>sub</strong> { <strong>die</strong> “fakeexit\nrc=” . <strong>shift</strong>() . “\n”; };<br> 20 };<br> 21  <br> 22 <strong>eval</strong> q{exit};<br> 23 <strong>if</strong> ($@) {<br> 24   <strong>exit</strong> <strong>unless</strong> $@ =~ <strong>/**^fakeexit</strong>/<strong>;<br> 25 }<br> 26 &main;<br> 27  <br> 28 **sub</strong> daemonize() {<br> 29   <strong>chdir</strong> ‘/‘ <strong>or</strong> <strong>die</strong> “Can’t chdir to /: $!”;<br> 30   <strong>defined</strong>( <strong>my</strong> $pid = <strong>fork</strong> ) <strong>or</strong> <strong>die</strong> “Can’t fork: $!”;<br> 31   <strong>exit</strong> <strong>if</strong> $pid;<br> 32   setsid() <strong>or</strong> <strong>die</strong> “Can’t start a new session: $!”;<br> 33   <strong>umask</strong> 0;<br> 34 }<br> 35  <br> 36 <strong>sub</strong> main {<br> 37   $$ &gt; io(“/var/run/cgiwrap-fcgi/cgiwrap-fcgi.pid”);<br> 38   $proc_manager = FCGI::ProcManager-&gt;<strong>new</strong>( {n_processes =&gt; 2} );<br> 39   $socket = FCGI::OpenSocket( “/var/run/cgiwrap-fcgi/cgiwrap-fcgi.sock”, 10 )<br> 40   ; #use UNIX sockets - user running this script must have w access to the ‘nginx’ folder!!<br> 41   $request =<br> 42   FCGI::Request( \</em>STDIN, \<em>STDOUT, \</em>STDERR, \%req_params, $socket,<br> 43   &amp;FCGI::FAIL_ACCEPT_ON_INTR );<br> 44   $proc_manager-&gt;pm_manage();<br> 45   <strong>if</strong> ($request) { request_loop() }<br> 46   FCGI::CloseSocket($socket);<br> 47 }<br> 48  <br> 49 <strong>sub</strong> request_loop {<br> 50   <strong>while</strong> ( $request-&gt;Accept() &gt;= 0 ) {<br> 51     $proc_manager-&gt;pm_pre_dispatch();<br> 52  <br> 53     #processing any STDIN input from WebServer (for CGI-POST actions)<br> 54     $stdin_passthrough = ‘’;<br> 55     { <strong>no warnings</strong>; $req_len = 0 + $req_params{‘CONTENT_LENGTH’}; };<br> 56     <strong>if</strong> ( ( $req_params{‘REQUEST_METHOD’} <strong>eq</strong> ‘POST’ ) &amp;&amp; ( $req_len != 0 ) ) {<br> 57       <strong>my</strong> $bytes_read = 0;<br> 58       <strong>while</strong> ( $bytes_read &lt; $req_len ) {<br> 59         **my** $data = ‘’;<br> 60         **my** $bytes = **read**( STDIN, $data, ( $req_len - $bytes_read ) );<br> 61         **last** **if** ( $bytes == 0  !**defined**($bytes) );<br> 62         $stdin_passthrough .= $data;<br> 63         $bytes_read += $bytes;<br> 64       }<br> 65     }<br> 66  <br> 67     #running the cgi app<br> 68     **if** (<br> 69       ( **-x** $req_params{SCRIPT_FILENAME} ) &amp;&amp;    #can I execute this?<br> 70       ( **-s** $req_params{SCRIPT_FILENAME} ) &amp;&amp;    #Is this file empty?<br> 71       ( **-r** $req_params{SCRIPT_FILENAME} )       #can I read this file?<br> 72     ) {<br> 73       **pipe**( CHILD_RD,   PARENT_WR );<br> 74       **pipe**( PARENT_ERR, CHILD_ERR );<br> 75       **my** $pid = **open**( CHILD_O, “-“ );<br> 76       **unless** ( **defined**($pid) ) {<br> 77         **print**(“Content-type: text/plain\r\n\r\n”);<br> 78         **print** “Error: CGI app returned no output - Executing $req_params{SCRIPT_FILENAME} failed !\n”;<br> 79         **next**;<br> 80       }<br> 81       $oldfh = **select**(PARENT_ERR);<br> 82       $     = 1;<br> 83       **select**(CHILD_O);<br> 84       $ = 1;<br> 85       **select**($oldfh);<br> 86       **if** ( $pid &gt; 0 ) {<br> 87         <strong>close</strong>(CHILD_RD);<br> 88         <strong>close</strong>(CHILD_ERR);<br> 89         <strong>print</strong> PARENT_WR $stdin_passthrough;<br> 90         <strong>close</strong>(PARENT_WR);<br> 91         $rin = $rout = $ein = $eout = ‘’;<br> 92         <strong>vec</strong>( $rin, <strong>fileno</strong>(CHILD_O),    1 ) = 1;<br> 93         <strong>vec</strong>( $rin, <strong>fileno</strong>(PARENT_ERR), 1 ) = 1;<br> 94         $ein    = $rin;<br> 95         $nfound = 0;<br> 96  <br> 97         <strong>while</strong> ( $nfound = <strong>select</strong>( $rout = $rin, <strong>undef</strong>, $ein = $eout, 10 ) ) {<br> 98           <strong>die</strong> “$!” <strong>unless</strong> $nfound != -1;<br> 99           $r1 = <strong>vec</strong>( $rout, <strong>fileno</strong>(PARENT_ERR), 1 ) == 1;<br>100           $r2 = <strong>vec</strong>( $rout, <strong>fileno</strong>(CHILD_O),    1 ) == 1;<br>101           $e1 = <strong>vec</strong>( $eout, <strong>fileno</strong>(PARENT_ERR), 1 ) == 1;<br>102           $e2 = <strong>vec</strong>( $eout, <strong>fileno</strong>(CHILD_O),    1 ) == 1;<br>103  <br>104           <strong>if</strong> ($r1) {<br>105             <strong>while</strong> ( $bytes = <strong>read</strong>( PARENT_ERR, $errbytes, 4096 ) ) {<br>106               <strong>print</strong> STDERR $errbytes;<br>107             }<br>108             <strong>if</strong> ($!) {<br>109               $err = $!;<br>110               <strong>die</strong> $!;<br>111               <strong>vec</strong>( $rin, <strong>fileno</strong>(PARENT_ERR), 1 ) = 0<br>112               <strong>unless</strong> ( $err == EINTR <strong>or</strong> $err == EAGAIN );<br>113             }<br>114           }<br>115           <strong>if</strong> ($r2) {<br>116             <strong>while</strong> ( $bytes = <strong>read</strong>( CHILD_O, $s, 4096 ) ) {<br>117               <strong>print</strong> $s;<br>118             }<br>119             <strong>if</strong> ( !<strong>defined</strong>($bytes) ) {<br>120               $err = $!;<br>121               <strong>die</strong> $!;<br>122               <strong>vec</strong>( $rin, <strong>fileno</strong>(CHILD_O), 1 ) = 0<br>123               <strong>unless</strong> ( $err == EINTR <strong>or</strong> $err == EAGAIN );<br>124             }<br>125           }<br>126           <strong>last</strong> <strong>if</strong> ( $e1  $e2 );<br>127         }<br>128         <strong>close</strong> CHILD_RD;<br>129         <strong>close</strong> PARENT_ERR;<br>130         <strong>waitpid</strong>( $pid, 0 );<br>131       } <strong>else</strong> {<br>132         <strong>foreach</strong> $key ( <strong>keys</strong> %req_params ) {<br>133           $ENV{$key} = $req_params{$key};<br>134         }<br>135  <br>136         # cd to the script’s local directory<br>137         <strong>if</strong> ( $req_params{SCRIPT_FILENAME} =~ *<em>/**^(.</em>)\/[^\/] +$<strong>/</strong> ) {<br>138           <strong>chdir</strong> $1;<br>139         }<br>140         <strong>close</strong>(PARENT_WR);<br>141         #close(PARENT_ERR);<br>142         <strong>close</strong>(STDIN);<br>143         <strong>close</strong>(STDERR);<br>144  <br>145         #fcntl(CHILD_RD, F_DUPFD, 0);<br>146         <strong>syscall</strong>( &amp;SYS_dup2, <strong>fileno</strong>(CHILD_RD),  0 );<br>147         <strong>syscall</strong>( &amp;SYS_dup2, <strong>fileno</strong>(CHILD_ERR), 2 );<br>148  <br>149         #open(STDIN, “&lt;&amp;CHILD_RD”);<br>150         <strong>exec</strong>( $req_params{SCRIPT_FILENAME} );<br>151         <strong>die</strong>(“exec failed”);<br>152       }<br>153     } <strong>else</strong> {<br>154       <strong>print</strong>(“Content-type: text/plain\r\n\r\n”);<br>155       <strong>print</strong> “Error: No such CGI app - $req_params{SCRIPT_FILENAME} may not exist or is not executable by this process.\n”;<br>156     }<br>157   }<br>158 }  </p>
<p>system V风格的init文件cgiwrap-fcgi:<br> 1 #!/bin/sh<br> 2<br> 3 ### BEGIN INIT INFO<br> 4 # Provides:         cgiwrap-fcgi<br> 5 # Required-Start:   $local_fs<br> 6 # Required-Stop:    $local_fs<br> 7 # Should-Start:     $syslog<br> 8 # Should-Stop:      $syslog<br> 9 # Default-Start:    2 3 4 5<br>10 # Default-Stop:     0 1 6<br>11 # Short-Description:fcgi support for nginx<br>12 # Description:      cgiwrap-fcgi is a perl script to provide simple cgi support for nginx http daemon<br>13 ### END INIT INFO<br>14<br>15 PATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin<br>16 DAEMON=/usr/local/bin/cgiwrap-fcgi.pl<br>17 NAME=cgiwrap-fcgi<br>18 DESC=<strong>“**cgiwrap-fcgi daemon</strong>“**<br>19 CGIWRAP_FCGIPIDDIR=/var/run/cgiwrap-fcgi<br>20 CGIWRAP_FCGIPID=$CGIWRAP_FCGIPIDDIR/cgiwrap-fcgi.pid<br>21<br>22 check_nginx_fcgi_piddir(){<br>23     <strong>if</strong> <strong>test</strong> <strong>!</strong> <strong>-d</strong> $CGIWRAP_FCGIPIDDIR*<em>;** <strong>then</strong><br>24         mkdir <strong>-m</strong> 02700 <strong>“</strong>$CGIWRAP_FCGIPIDDIR**”**<br>25         chown www-data:www-data <strong>“</strong>$CGIWRAP_FCGIPIDDIR**”**<br>26     <strong>fi</strong><br>27<br>28     <strong>if</strong> <strong>test</strong> <strong>!</strong> <strong>-x</strong> $CGIWRAP_FCGIPIDDIR**;** <strong>then</strong><br>29         <strong>echo</strong> <strong>“**Cannot access $CGIWRAP_FCGIPIDDIR directory,are you root?</strong>“** <strong>&gt;**</strong>&amp;<strong>2<br>30         **exit</strong> 1<br>31     <strong>fi</strong><br>32 }<br>33<br>34 start() {<br>35     check_nginx_fcgi_piddir<br>36     <strong>echo</strong> <strong>“**Starting $DESC: $NAME…</strong>“**<br>37<br>38     start-stop-daemon --start --quiet --oknodo --pidfile $CGIWRAP_FCGIPID \<br>39     --chuid www-data:www-data  --exec $DAEMON <strong>&gt;</strong> /dev/null 2<strong>&gt;&amp;1</strong><br>40     <strong>echo</strong> <strong>“**done.</strong>“**<br>41 }<br>42<br>43 stop() {<br>44     <strong>echo</strong> -n <strong>“**Stopping $DESC: **”</strong><br>45     pid=`cat $CGIWRAP_FCGIPID 2&gt;/dev/null`  true<br>46<br>47     <strong>if</strong> <strong>test</strong> <strong>!</strong> <strong>-f</strong> $CGIWRAP_FCGIPID <strong>-o</strong> <strong>-z</strong> <strong>“</strong>$pid**”;** <strong>then</strong><br>48         <strong>echo</strong> <strong>“**not running ( there is no $CGIWRAP_FCGIPID).</strong>“**<br>49         <strong>exit</strong> 0<br>50     <strong>fi</strong><br>51<br>52     <strong>if</strong> <strong>kill</strong> $pid <strong>;</strong> <strong>then</strong><br>53         cat /dev/null <strong>&gt;</strong> $CGIWRAP_FCGIPID**;**<br>54         <strong>echo</strong> <strong>“**success!</strong>“**<br>55     <strong>else</strong><br>56         <strong>echo</strong> <strong>“**Can’t stop $DESC</strong>“**<br>57     <strong>fi</strong><br>58<br>59     <strong>return</strong> 0<br>60 }<br>61<br>62 status() {<br>63     pid=`cat $CGIWRAP_FCGIPID 2&gt;/dev/null`  true<br>64<br>65     <strong>if</strong> <strong>[</strong> <strong>-z</strong> ${pid} <strong>]**</strong>;** <strong>then</strong><br>66         <strong>echo</strong> <strong>“</strong>${DESC} is not running.<strong>“</strong><br>67     <strong>else</strong><br>68         <strong>echo</strong> <strong>“</strong>${DESC} is running.<strong>“</strong><br>69     <strong>fi</strong><br>70 }<br>71<br>72 RETVAL=0<br>73<br>74 <strong>case</strong> <strong>“</strong>$1**”** <strong>in</strong><br>75     start**)**<br>76         start<br>77         <strong>;;</strong><br>78     stop**)**<br>79         stop<br>80         <strong>;;</strong><br>81     restart**)**<br>82         stop<br>83         start<br>84         <strong>;;</strong><br>85     force-reload**)**<br>86         <strong>;;</strong><br>87     status**)**<br>88        status<br>89         <strong>;;</strong><br>90     **</em>)**<br>91         <strong>echo</strong> <strong>“</strong>$0 {startstoprestartforece-reloadstatus}<strong>“</strong><br>92         <strong>exit</strong> 3<br>93         <strong>;;</strong><br>94 <strong>esac</strong><br>95<br>96 <strong>exit</strong> $RETVAL  </p>
<p>这个init控制文件支持start,stop,status,restart,forec-reload控制指令。</p>
<p><a href="/downloads/cgiwrap-fcgi.tar.gz">下载</a>以后，将cgiwrap-fcgi.pl拷贝到/usr/local/bin/目录下,将cgiwrap-fcgi拷贝到/etc/init.d/目录下，然后执行:<br>$sudo update-rc.d cgiwrap-fcgi defaults<br>更新/etc/rcX.d目录下的符号链接，这样debian启动时会自动启动cgiwrap-fcgi.pl程序</p>
<p>手动控制cgiwarp-fcgi.pl程序</p>
<p>$sudo /etc/init.d/cgiwrap-fcgi restart #重新启动<br>$sudo /etc/init.d/cgiwrap-fcgi stop #停止<br>$sudo /etc/init.d/cgiwrap-fcgi status #查看cgiwrap-fcgi的运行状态</p>
<p>cgiwrap-fcgi.pl使用unix socket文件/var/run/cgiwrap-fcgi/cgiwrap-fcgi.sock来监听CGI程序请求，因此只要将对nginx的CGI请求转发到此socket即可，对应的nginx配置文件cgiwrap-fcgi.conf为:<br>1 location ~ \.(cgipl).*$ {<br>2     gzip off;<br>3     fastcgi_pass unix:/var/run/cgiwrap-fcgi/cgiwrap-fcgi.sock;<br>4     fastcgi_index index.cgi;<br>5     include fastcgi_params;<br>6 }<br>下载后将此文件拷贝到/etc/nginx/目录下，然后在虚拟主机配置文件的server节include cgiwrap-fcgi.conf即可。</p>
<p>三个文件的打包<a href="/downloads/cgiwrap-fcgi.tar.gz">下载</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>使用fcgiwrap为nginx提供cgi支持</title>
    <url>/2013/05/11/nginx-fcgiwrap-cgi-support/</url>
    <content><![CDATA[<p>nginx不支持cgi程序，通过fcgi包装程序，可以使nginx间接支持cgi程序。</p>
<a id="more"></a>
<p>现在fcgiwrap已经进入了官方源，因此<a href="https://openwares.net/linux/nginx_cgi_support.html">以前的fcgi包装方法</a>就不用了。</p>
<p><strong>安装</strong></p>
<p>#apt-get install fcgiwrap</p>
<p><strong>配置</strong> </p>
<p>/etc/nginx/fcgiwrap.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">location ~ \\.(cgipl).*$ &#123;</span><br><span class="line"> gzip off;</span><br><span class="line"> fastcgi_pass unix:<span class="regexp">/var/</span>run/fcgiwrap.socket;</span><br><span class="line"> fastcgi_index index.cgi;</span><br><span class="line"> fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</span><br><span class="line"> include fastcgi_params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>使用</strong></p>
<p>在站点配置文件中包含fcgiwrap.conf即可<br>…<br>include fcgiwrap.conf<br>…</p>
<p><strong>配置 -TCP方式</strong><br>还可以将fcgiwrap配置成TCP方式提供服务，不过这需要修改/etc/init.d/fcgiwrap服务脚本</p>
<p>#socket 方式配置</p>
<h1 id="FCGI-APP-Variables"><a href="#FCGI-APP-Variables" class="headerlink" title="FCGI_APP Variables"></a>FCGI_APP Variables</h1><p>FCGI_CHILDREN=”1”<br>FCGI_SOCKET=”/var/run/$NAME.socket”</p>
<p>改为<br>#TCP 方式</p>
<h1 id="FCGI-APP-Variables-1"><a href="#FCGI-APP-Variables-1" class="headerlink" title="FCGI_APP Variables"></a>FCGI_APP Variables</h1><p>FCGI_CHILDREN=”1”<br>FCGI_PORT=”8999”<br>FCGI_ADDR=”127.0.0.1”</p>
<p>然后修改/etc/nginx/fcgiwrap.conf为：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">location ~ \\.(cgipl).*$ &#123;</span><br><span class="line"> gzip off;</span><br><span class="line"> fastcgi_pass <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">8999</span>;</span><br><span class="line"> fastcgi_index index.cgi;</span><br><span class="line"> fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;</span><br><span class="line"> include fastcgi_params;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参见<a href="https://library.linode.com/web-servers/nginx/perl-fastcgi/debian-6-squeeze">Nginx and Perl-FastCGI on Debian 6</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx for windows x64</title>
    <url>/2018/11/17/nginx-for-windows-x64/</url>
    <content><![CDATA[<a id="more"></a>
<p>Kevin Worthington 一直在维护<a href="https://kevinworthington.com/nginx-for-windows/">nginx for windows x64</a>版本的build,致敬。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>nginx gitweb配置</title>
    <url>/2011/05/10/nginx-gitweb-configuration/</url>
    <content><![CDATA[<p>gitweb是git的web接口，使用单向的http协议来发布git repositories。</p>
<a id="more"></a>
<p>关于gitweb在Apache服务器下的配置，见<a href="https://openwares.net/linux/gitweb_configuration.html">gitweb配置(configuration)</a></p>
<p><strong>配置</strong></p>
<p>假定git repositories所在的目录为/home/yourname/public_html/git，首先,把gitweb使用到的资源文件(图片和CSS)符号链接到此目录<br>$ln -sf /usr/share/gitweb/* .</p>
<p>然后将gitweb主程序gitweb.cgi链接到git repositories目录<br>$ln -sd /usr/lib/cgi-bin/gitweb.cgi gitweb.cgi</p>
<p>修改/etc/gitweb.conf文件中的$projectroot为/home/yourname/public_html/git</p>
<p>最后是nginx virtualhost配置文件：<br>1 server {<br>2     listen      80;<br>3     server_name git.openwares.net;<br>4     root        /home/yourname/public_html/git;<br>5     index       gitweb.cgi;<br>6     access_log  off;<br>7<br>8     include     cgiwrap-fcgi.conf;<br>9 }  </p>
<p>第8行 include cgiwrap-fcgi.conf; 让虚拟主机支持CGI应用程序,因为gitweb.cgi就是这样的CGI程序,nginx如何支持CGI程序见<a href="https://openwares.net/linux/nginx_cgi_support.html">debian squeeze配置nginx支持CGI程序</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx location指令</title>
    <url>/2011/05/03/nginx-location-instruction/</url>
    <content><![CDATA[<p>location指令隶属于NginxHttpCoreModule模块，是nginx最重要的指令之一,其语法如下：</p>
<a id="more"></a>
<p><strong>syntax:</strong> location [=~~*^~@] /uri/ { … }<br>default: no<br>默认值:无默认值<br><strong>context:</strong> server<br>上下文:server指令语句 </p>
<p>This directive allows different configurations depending on the URI. It can be configured using both literal strings and regular expressions. To use regular expressions, you must use a prefix:</p>
<ol>
<li><p> “~” for case sensitive matching</p>
</li>
<li><p>“~*” for case insensitive matching</p>
<p>这条指令依据不同的URI(Uniform Resource Identifier)可以有不同的配置。它可以被配置为使用字面字符值和规则表示式(Regular Expression),使用规则表达式，必须使用一下前缀来修饰：</p>
</li>
<li><p> “~” 用于区分大小的正则表达式匹配</p>
</li>
<li><p> “~*” 用于不区分大小的正则表达式匹配</p>
</li>
</ol>
<p>To determine which location directive matches a particular query, the literal strings are checked first. Literal strings match the beginning portion of the query - the most specific match will be used. Afterwards, regular expressions are checked in the order defined in the configuration file. The first regular expression to match the query will stop the search. If no regular expression matches are found, the result from the literal string search is used. </p>
<p>当决定哪一个location指令匹配一个特殊的请求时，nginx首先检查字面字符值。字面字符值匹配请求的开始部分 - 最相关的匹配会被采用。之后，以在配置文件内定义的顺序来检查规则表达式。当找到第一个匹配此请求的规则表达式后搜索停止(，并使用此结果)。如果没有与请求匹配的规则表达式，那么先前最相关配置的字面字符值会被采用。</p>
<p>For case insensitive operating systems, like Mac OS X or Windows with Cygwin, literal string matching is done in a case insensitive way (0.7.7). However, comparison is limited to single-byte locale’s only.<br>对于大小写不敏感的操作系统，比如Mac OS X或者使用Cygwin的windows操作系统，字面字符值会以大小下不敏感的方式(since 0.7.7)进行匹配。然而，这种比较仅限于单字节字符locale。</p>
<p>Regular expression may contain captures (0.7.40), which can then be used in other directives.<br>规则表达式可以包含捕获(since 0.7.40),也可以在其他指令内使用规则表达式捕获特性。</p>
<p>It is possible to disable regular expression checks after literal string matching by using “^<del>“ prefix. If the most specific match literal location has this prefix: regular expressions aren’t checked.<br>可以使用”^</del>“前缀在字面字符值匹配以后禁止再检查规则表达式。如果最相关匹配的字面字符值location指令有前缀”^~”，那么将会禁止继续检查规则表达式。</p>
<p>By using the “=” prefix we define the exact match between request URI and location. When matched search stops immediately. E.g., if the request “/“ occurs frequently, using “location = /“ will speed up processing of this request a bit as search will stop after first comparison.<br>使用”=”前缀在请求的URI和location指令之间定义<strong>精确匹配</strong>。当找到匹配，搜索立刻停止。比如，如果”/“请求很频繁，那么使用”location = /“将会加速对此请求的匹配搜索，因为搜索会在第一次匹配后停止。</p>
<p>On exact match with literal location without “=” or “^<del>“ prefixes search is also immediately terminated.<br>当<strong>精确匹配</strong>到没有 “=” 或者 “^</del>“ 前缀的字面字符值location指令时，搜索同样立刻停止。</p>
<p>To summarize, the order in which directives are checked is as follows:</p>
<ol>
<li> Directives with the “=” prefix that match the query exactly. If found, searching stops.</li>
<li> All remaining directives with conventional strings. If this match used the “^~” prefix, searching stops.</li>
<li> Regular expressions, in the order they are defined in the configuration file.</li>
<li> If #3 yielded a match, that result is used. Otherwise, the match from #2 is used.</li>
</ol>
<p>总结一下，指令搜索的顺序如下：</p>
<ol>
<li> 带有”=”前缀的指令匹配精确的请求值。如果找到，搜索立刻停止。</li>
<li> 所有其余的使用字面字符值的location指令。如果最相关匹配指令带有”^~”前缀，那么搜索停止，否则继续搜索。</li>
<li> 规则表达式按照它们在配置文件内定义的顺序进行搜索。</li>
<li> 如果第3条找到一个匹配，那么使用这个结果，否则使用第二条中搜索到的匹配。</li>
</ol>
<p>Example:</p>
<p>location = / {</p>
<h1 id="matches-the-query-only"><a href="#matches-the-query-only" class="headerlink" title="matches the query / only."></a>matches the query / only.</h1><h1 id="仅仅精确匹配请求"><a href="#仅仅精确匹配请求" class="headerlink" title="仅仅精确匹配请求 /"></a>仅仅精确匹配请求 /</h1><p> [ configuration A ]<br>}<br>location / {</p>
<h1 id="matches-any-query-since-all-queries-begin-with-but-regular"><a href="#matches-any-query-since-all-queries-begin-with-but-regular" class="headerlink" title="matches any query, since all queries begin with /, but regular"></a>matches any query, since all queries begin with /, but regular</h1><h1 id="expressions-and-any-longer-conventional-blocks-will-be"><a href="#expressions-and-any-longer-conventional-blocks-will-be" class="headerlink" title="expressions and any longer conventional blocks will be"></a>expressions and any longer conventional blocks will be</h1><h1 id="matched-first"><a href="#matched-first" class="headerlink" title="matched first."></a>matched first.</h1><p>#与任意请求相匹配，因为所有的请求都是以/开头的，但是规则表达式和任何更长的字面字符值会优先匹配<br> [ configuration B ]<br>}<br>location ^~ /images/ {</p>
<h1 id="matches-any-query-beginning-with-images-and-halts-searching"><a href="#matches-any-query-beginning-with-images-and-halts-searching" class="headerlink" title="matches any query beginning with /images/ and halts searching,"></a>matches any query beginning with /images/ and halts searching,</h1><h1 id="so-regular-expressions-will-not-be-checked"><a href="#so-regular-expressions-will-not-be-checked" class="headerlink" title="so regular expressions will not be checked."></a>so regular expressions will not be checked.</h1><p>#匹配任何以/images/开始的请求，并立刻停止搜索，因此规则表达式将不会被检查。<br> [ configuration C ]<br>}<br>location ~* \.(gifjpgjpeg)$ {</p>
<h1 id="matches-any-request-ending-in-gif-jpg-or-jpeg-However-all"><a href="#matches-any-request-ending-in-gif-jpg-or-jpeg-However-all" class="headerlink" title="matches any request ending in gif, jpg, or jpeg. However, all"></a>matches any request ending in gif, jpg, or jpeg. However, all</h1><h1 id="requests-to-the-images-directory-will-be-handled-by"><a href="#requests-to-the-images-directory-will-be-handled-by" class="headerlink" title="requests to the /images/ directory will be handled by"></a>requests to the /images/ directory will be handled by</h1><h1 id="Configuration-C"><a href="#Configuration-C" class="headerlink" title="Configuration C."></a>Configuration C.</h1><p>#匹配任何以gif,jpg,jpeg字符结尾的请求,然后所有到/images/目录的请求将会被Configuration C处理<br> [ configuration D ]<br>}</p>
<p>Example requests:</p>
<ul>
<li>  / -&gt; configuration A</li>
<li>  /documents/document.html -&gt; configuration B</li>
<li>  /images/1.gif -&gt; configuration C</li>
<li>  /documents/1.jpg -&gt; configuration D</li>
</ul>
<p>Note that you could define these 4 configurations in any order and the results would remain the same. While nested locations are allowed by the configuration file parser, their use is discouraged and may produce unexpected results.<br>注意可以以任何顺序定义例子中的4个location配置，其搜索结果都是一样的。虽然配置文件解析器允许嵌套的location指令，但是不鼓励这样使用，因为可能会产生不可预料的结果。</p>
<p>The prefix “@” specifies a named location. Such locations are not used during normal processing of requests, they are intended only to process internally redirected requests </p>
<p>前缀”@”指定一个命名location。这样的location并不在正常的请求处理中使用，他们仅仅用于处理内部重定向请求。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx,mysql,php(fastcgi)轻松安装</title>
    <url>/2011/04/04/nginx-mysql-phpfastcgi-install/</url>
    <content><![CDATA[<p>vps资源有限,所以安装lnmp(linux/nginx/mysql/php)是比较适宜的选择。</p>
<a id="more"></a>
<p>debian源里的nginx版本总是很低,php又没有fpm模块,原来都是下载源代码编译安装,虽然也很简单,但未免太过繁琐、配置文件混乱且安全性更新等很难顾及,还是以debian的方式来管理比较方便,<a href="http://www.dotdeb.org/">dotdeb.org</a>(The repository for Debian-based LAMP servers)为我们做好了这一切。dotdeb.org现在已经开始维护nginx repository,真的很方便。</p>
<p>/etc/apt/sources.list文件添加<br>deb <a href="http://packages.dotdeb.org/">http://packages.dotdeb.org</a> stable all</p>
<p>然后获取源的key并刷新源</p>
<p>1 $wget <a href="http://www.dotdeb.org/dotdeb.gpg">http://www.dotdeb.org/dotdeb.gpg</a><br>2 $cat dotdeb.gpg sudo apt-key add -<br>3 $sudo apt-get update  </p>
<p>安装lnmp<br>1 $sudo apt-get install nginx-light mysql-server php5-cli php5-fpm php5-mysql  </p>
<p>源里nginx版本现在为0.8.54,mysql为5.1.56,php5为5.3.5,还是比较新的,希望稳定性也能经受住考验。</p>
<p>It’s ok!</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx php fastcgi虚拟主机配置</title>
    <url>/2011/04/23/nginx-php-virtualhost-configuration/</url>
    <content><![CDATA[<p><a href="https://openwares.net/linux/nginx_mysql_phpfastcgi_install.html">安装lnmp</a>或使用<a href="https://openwares.net/linux/debian_lnmp_one_click_install.html">lnmp一键安装脚本</a>完成后,php的FastCGI接口php-fpm(FastCGI Process Manager)已经就绪,nginx通过php-fpm来处理用户对php应用程序的请求。</p>
<a id="more"></a>
<p><strong>配置文件布局</strong></p>
<p>nginx的主配置目录位于/etc/nginx,可用的虚拟主机配置文件请放置到/etc/nginx/sites-available,启用虚拟主机只需在/etc/nginx/sites-enabled目录下建一个到虚拟主机配置文件的符号链接即可,与apache的配置文件布局基本一致。Debian的配置文件布局还是很赏心悦目的。</p>
<p><strong>虚拟主机配置</strong></p>
<p>/etc/nginx目录下新建文件php-fpm.conf,输入一下内容,注意不要带行号</p>
<p>1 #pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000<br>2 location ~ \.php$ {<br>3     fastcgi_pass   127.0.0.1:9000;<br>4     fastcgi_index  index.php;<br>5     include        fastcgi_params;<br>6 }  </p>
<p>php-fpm默认配置是在127.0.0.1:9000上监听php请求的,也可以配置成使用unix domain socket监听请求,根据你的配置，相应的修改第三行的参数fastcgi_pass。</p>
<p>/etc/nginx/sites-available目录下新建虚拟主机配置文件,这里是openwares.net.conf,内容如下：</p>
<p> 1 server {<br> 2     listen      80;<br> 3     server_name openwares.net <a href="http://www.openwares.net/">www.openwares.net</a>;<br> 4     root        /home/username/www/openwares.net;<br> 5     index       index.php;<br> 6     access_log  /var/log/nginx/openwares.net_access.log;<br> 7     error_log   /var/log/nginx/openwares.net_error.log;<br> 8<br> 9     include php-fpm.conf;<br>10 }  </p>
<p>最后在/etc/nginx/sites-enabled目录下建立一个符号链接就可以了</p>
<p>$cd /etc/nginx/sites-enabled<br>$sudo ln -sf /etc/nginx/sites-available/openwares.net.conf openwares.net.conf</p>
<p>配置完成后重新装载nginx配置<br>$sudo /etc/init.d/nginx reload</p>
<p><strong>测试</strong></p>
<p>在/home/username/www/openwares.net/目录下新建about.php</p>
<p>从浏览器访问about.php，输出php版本信息就配置成功了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx反向代理websocket</title>
    <url>/2015/11/05/nginx-revers-proxy-websocket/</url>
    <content><![CDATA[<a id="more"></a>
<p>配置文件中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">...</span><br><span class="line"> location /wsapp/ &#123;</span><br><span class="line"> proxy_pass http:<span class="comment">//wsbackend;</span></span><br><span class="line"> </span><br><span class="line"> # proxy websocket reverse</span><br><span class="line"> proxy_http_version <span class="number">1.1</span>;</span><br><span class="line"> proxy_set_header Upgrade $http_upgrade;</span><br><span class="line"> proxy_set_header Connection <span class="string">&quot;upgrade&quot;</span>;</span><br><span class="line"> &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://www.nginx.com/blog/websocket-nginx/">NGINX as a WebSocket Proxy</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx部署Let&#39;s Encrypt证书</title>
    <url>/2016/05/14/nginx-setup-lets-encrypt-cert/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>感谢<a href="https://letsencrypt.org/">Let’s Encrypt</a>让互联网更安全。</strong></p>
<p>Let’s Encrypt的客户端刚刚更名为certbot,以前叫letsencrypt。certbot可以自动化的申请，安装和更新证书，让生活更美好。<br>不过当前nginx插件尚不成熟，而且certbot自身尚处于beta阶段，当前版本0.7.0，debian源里的版本也比较陈旧。</p>
<p>因此还是需要一些简单的手工配置。</p>
<p><strong>安装</strong></p>
<p>从官方仓库克隆certbot</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo git clone https:<span class="comment">//github.com/certbot/certbot /opt/certbot</span></span><br></pre></td></tr></table></figure>

<p>执行certbot-auto会自动安装发行版依赖和python依赖：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd /opt/certbot</span><br><span class="line">$ ./certbot-auto </span><br></pre></td></tr></table></figure>

<p><strong>配置nginx</strong></p>
<p>申请证书时，let’s encrypt需要访问域名的特定目录来确认域名的所有权，由certbot配合来完成验证。</p>
<p>需要访问的目录为${webroot-path}/.well-known/acme-challenge/,申请证书时,certbot会写入认证所需信息，由let’s encrypt来验证。</p>
<p>将此目录映射到/var/www/letsencrypt,先建立目录：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ cd /<span class="keyword">var</span>/www</span><br><span class="line"># mkdir letsencrypt</span><br><span class="line"># chgroup www-data letsencrypt</span><br></pre></td></tr></table></figure>

<p>然后修改站点配置文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"> listen <span class="number">80</span> default_server;</span><br><span class="line"> server_name my-domain;</span><br><span class="line"></span><br><span class="line"> location /.well-known/acme-challenge &#123;</span><br><span class="line"> root /<span class="keyword">var</span>/www/letsencrypt;</span><br><span class="line"> &#125;</span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>最后重新加载nginx配置文件:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># nginx -t &amp;&amp; sudo nginx -s reload</span><br></pre></td></tr></table></figure>

<p><strong>配置certbot</strong></p>
<p>新建一个配置文件/etc/letsencrypt/configs/my-domain.conf来指定要申请证书的域名等相关信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># This is an example of the kind of things you can do in a configuration file.</span><br><span class="line"># All flags used by the client can be configured here. Run Certbot with</span><br><span class="line"># &quot;--help&quot; to learn more about the available options.</span><br><span class="line"></span><br><span class="line"># Use a 4096 bit RSA key instead of 2048</span><br><span class="line">rsa-key-size = 2048 # or 4096</span><br><span class="line"></span><br><span class="line"># Uncomment and update to register with the specified e-mail address</span><br><span class="line">email = xxx@gmail.com</span><br><span class="line"></span><br><span class="line"># Uncomment and update to generate certificates for the specified</span><br><span class="line"># domains.</span><br><span class="line">domains = my-domain, www.my-domain</span><br><span class="line"></span><br><span class="line"># Uncomment to use a text interface instead of ncurses</span><br><span class="line">text = True</span><br><span class="line"></span><br><span class="line"># Uncomment to use the standalone authenticator on port 443</span><br><span class="line"># authenticator = standalone</span><br><span class="line"># standalone-supported-challenges = tls-sni-01</span><br><span class="line"></span><br><span class="line"># Uncomment to use the webroot authenticator. Replace webroot-path with the</span><br><span class="line"># path to the public_html / webroot folder being served by your web server.</span><br><span class="line">authenticator = webroot</span><br><span class="line">webroot-path = <span class="regexp">/var/</span>www/letsencrypt/</span><br></pre></td></tr></table></figure>

<p>可以使用webroot插件来减轻验证配置，自动修改web server来完整验证。</p>
<p><strong>申请证书</strong></p>
<p>因为let’s encrypt限制每个站点在一定时间内申请的证书数量，所以可以用<code>--test-cert</code>选项进行测试，此时申请的证书是无效的，<br>但操作步骤是完全一样的，测试通过后去掉此选项就是申请正式证书了。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./certbot-auto --test-cert --config /etc/letsencrypt/configs/mydomain.conf certonly</span><br><span class="line">Checking <span class="keyword">for</span> <span class="keyword">new</span> version...</span><br><span class="line">Requesting root privileges to run certbot...</span><br><span class="line"> sudo CERTBOT_AUTO=./certbot-auto /home/xxx/.local/share/letsencrypt/bin/letsencrypt </span><br><span class="line">--test-cert --config /etc/letsencrypt/configs/mydomain certonly</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Please read the Terms <span class="keyword">of</span> Service at https:<span class="comment">//letsencrypt.org/documents/LE-</span></span><br><span class="line">SA-v1<span class="number">.0</span><span class="number">.1</span>-July-<span class="number">27</span>-<span class="number">2015.</span>pdf. You must agree <span class="keyword">in</span> order to register <span class="keyword">with</span> the ACME</span><br><span class="line">server at https:<span class="comment">//acme-staging.api.letsencrypt.org/directory</span></span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">(A)gree/(C)ancel: A</span><br><span class="line"></span><br><span class="line">IMPORTANT NOTES:</span><br><span class="line"> - Congratulations! Your certificate and chain have been saved at</span><br><span class="line"> /etc/letsencrypt/live/mydomain/fullchain.pem. Your cert</span><br><span class="line"> will expire on <span class="number">2016</span>-<span class="number">08</span>-<span class="number">12.</span> To obtain a <span class="keyword">new</span> version <span class="keyword">of</span> the</span><br><span class="line"> certificate <span class="keyword">in</span> the future, simply run Certbot again.</span><br><span class="line"> - If you lose your account credentials, you can recover through</span><br><span class="line"> e-mails sent to xxx@gmail.com.</span><br><span class="line"> - Your account credentials have been saved <span class="keyword">in</span> your Certbot</span><br><span class="line"> configuration directory at /etc/letsencrypt. You should make a</span><br><span class="line"> secure backup <span class="keyword">of</span> <span class="built_in">this</span> folder now. This configuration directory will</span><br><span class="line"> also contain certificates and private keys obtained by Certbot so</span><br><span class="line"> making regular backups <span class="keyword">of</span> <span class="built_in">this</span> folder is ideal.</span><br></pre></td></tr></table></figure>

<p>申请的证书位于/etc/letsencrypt/live/mydomain/目录下</p>
<p><strong>安装证书</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"> listen <span class="number">443</span> ssl default_server;</span><br><span class="line"> server_name my-domain;</span><br><span class="line"></span><br><span class="line"> ssl_certificate /etc/letsencrypt/live/my-domain/fullchain.pem;</span><br><span class="line"> ssl_certificate_key /etc/letsencrypt/live/my-domain/privkey.pem;</span><br><span class="line"></span><br><span class="line"> ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>更多ssl优化设置参见[4]</p>
<p><strong>更新证书</strong></p>
<p>let’s encrypt发行的证书只有90天的有效期，到期需要更新证书。如果参数没有变化，更新证书只需简单的执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./certbot-auto renew</span><br></pre></td></tr></table></figure>

<p>certbot-auto会使用上次申请证书时使用的参数来更新证书。<br>如果要测试证书更新，添加选项<code>--dry-run</code>，此时不会更改系统当前设置。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./certbot-auto renew --dry-run</span><br><span class="line">Checking <span class="keyword">for</span> <span class="keyword">new</span> version...</span><br><span class="line">Requesting root privileges to run certbot...</span><br><span class="line"> sudo CERTBOT_AUTO=./certbot-auto /home/guoqiang/.local/share/letsencrypt/bin/letsencrypt renew --dry-run</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">Processing /etc/letsencrypt/renewal/cucc.tazzfdc.com.conf</span><br><span class="line">-------------------------------------------------------------------------------</span><br><span class="line">** DRY RUN: simulating <span class="string">&#x27;certbot renew&#x27;</span> close to cert expiry</span><br><span class="line">** (The test certificates below have not been saved.)</span><br><span class="line"></span><br><span class="line">Congratulations, all renewals succeeded. The following certs have been renewed:</span><br><span class="line"> /etc/letsencrypt/live/cucc.tazzfdc.com/fullchain.pem (success)</span><br><span class="line">** DRY RUN: simulating <span class="string">&#x27;certbot renew&#x27;</span> close to cert expiry</span><br><span class="line">** (The test certificates above have not been saved.)</span><br></pre></td></tr></table></figure>

<p><strong>自动更新证书</strong></p>
<p>可以添加cron脚本来自动更新证书，当证书无需更新时，renew命令并不会去更新证书，所以crontab设置的时间间隔并无强制要求，但一般无需设置太过频繁的调度。<br>let’s encrypt证书大约还剩一个月有效期时，可以进行更新。</p>
<p>自动更新脚本renew‑letsencrypt.sh：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">cd /opt/certbot/</span><br><span class="line">./certbot-auto renew</span><br><span class="line"><span class="keyword">if</span> \[ $? -ne <span class="number">0</span> \]; then</span><br><span class="line"> ERRORLOG=\<span class="string">`tail /var/log/letsencrypt/letsencrypt.log\`</span></span><br><span class="line"><span class="string"> echo -e &quot;The Let&#x27;s Encrypt cert has not been renewed! \\n \\n&quot; \\</span></span><br><span class="line"><span class="string"> $ERRORLOG</span></span><br><span class="line"><span class="string">else</span></span><br><span class="line"><span class="string"> nginx -s reload</span></span><br><span class="line"><span class="string">fi</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">exit 0</span></span><br></pre></td></tr></table></figure>

<p>将脚本添加到crontab自动运行即可。比如，每月1号执行此脚本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">0</span> <span class="number">0</span> <span class="number">1</span> * * <span class="regexp">/usr/</span>local/bin/renew-letsencrypt.sh</span><br></pre></td></tr></table></figure>

<p><strong>未来</strong></p>
<p>以上安装配置仍然十分繁琐，nginx插件成熟并且进入官方源后，只要几条指令就可以安装和更新证书了：</p>
<p>安装certbot:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install certbot certbot-nginx</span><br></pre></td></tr></table></figure>

<p>安装证书：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ certbot --nginx</span><br></pre></td></tr></table></figure>

<p>更新证书：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ certbot renew</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://letsencrypt.org/getting-started/">Getting Started</a><br>[2]<a href="https://certbot.eff.org/docs/using.html#installation">User Guide</a><br>[3]<a href="https://www.nginx.com/blog/free-certificates-lets-encrypt-and-nginx/">Using Free SSL/TLS Certificates from Let’s Encrypt with NGINX</a><br>[4]<a href="http://nginx.org/en/docs/http/configuring_https_servers.html">Configuring HTTPS servers</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx启用ssl_preread时获取客户真实ip地址</title>
    <url>/2020/02/07/nginx-ssl-preread-real-client-ip/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用ssl_preread分流请求时，真正的服务程序无法获取到真实的客户ip，这时候可以借助<a href="https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt">proxy_protocol</a>来获取真实的客户ip地址</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line"> proxy_headers_hash_bucket_size 6400; #添加此行</span><br><span class="line"> include mime.types;</span><br><span class="line"> default_type application/octet-stream;</span><br><span class="line"></span><br><span class="line"> log_format main <span class="string">&#x27;$proxy_protocol_addr - $remote_user \[$time_local\] &quot;$request&quot; &#x27;</span></span><br><span class="line"> <span class="string">&#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;</span></span><br><span class="line"> &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #修改此行,用$proxy_protocol_addr替换$remote_addr</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line"> listen 8443 ssl http2 proxy_protocol default_server;#此行添加proxy_protocol指令</span><br><span class="line">...</span><br><span class="line"># ssl preread for request certs</span><br><span class="line">stream &#123;</span><br><span class="line"> map $ssl_preread_alpn_protocols $tls_port &#123;</span><br><span class="line"> ~\\bacme-tls/<span class="number">1</span>\\b <span class="number">10443</span>;</span><br><span class="line"> <span class="keyword">default</span> <span class="number">8443</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> server &#123;</span><br><span class="line"> listen <span class="number">443</span>;</span><br><span class="line"> listen \[::\]:<span class="number">443</span>;</span><br><span class="line"> proxy_pass <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:$tls_port;</span><br><span class="line"> proxy_protocol on; #添加此行</span><br><span class="line"> ssl_preread on;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样access日志就可以获取到真实的客户ip地址($proxy_protocol_addr)了，但是nginx的error日志格式无法改变，只能更改日志级别，因此preread之后的错误日志就没办法了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx ssl 反向代理wordpress</title>
    <url>/2019/07/07/nginx-ssl-reverse-proxy-wordpress/</url>
    <content><![CDATA[<a id="more"></a>
<p>wordpress部署在docker上，使用http协议，现在部署https协议，增设一个nginx服务器，反向代理http协议的wordpress</p>
<p>nginx反向代理需要增设协议头</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">proxy_set_header X-Forwarded-Proto $scheme; </span><br></pre></td></tr></table></figure>
<p>完整的nginx反向代理设置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">server_nameopenwares.net;</span><br><span class="line">listen8443 ssl http2;</span><br><span class="line"></span><br><span class="line">ssl_certificate /etc/nginx/ssl/fullchain.cer;</span><br><span class="line">ssl_certificate_key /etc/nginx/ssl/openwares.net.key;</span><br><span class="line">ssl_protocols TLSv1<span class="number">.3</span>;</span><br><span class="line"></span><br><span class="line">location / &#123;</span><br><span class="line">proxy_pass http:<span class="comment">//localhost/;</span></span><br><span class="line">proxy_set_header Host $host;</span><br><span class="line"> proxy_set_header X-Forwarded-Proto $scheme; </span><br><span class="line"> proxy_set_header Accept-Encoding <span class="string">&quot;gzip&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>编辑wordpress的wp-config.php文件，在文件前面添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">define(<span class="string">&#x27;FORCE_SSL_ADMIN&#x27;</span>, <span class="literal">true</span>);</span><br><span class="line"><span class="keyword">if</span> ($_SERVER\[<span class="string">&#x27;HTTP_X_FORWARDED_PROTO&#x27;</span>\] == <span class="string">&#x27;https&#x27;</span>)</span><br><span class="line"> $_SERVER\[<span class="string">&#x27;HTTPS&#x27;</span>\]=<span class="string">&#x27;on&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>最后需要参考[3]将数据库中的链接从http修改为https。</p>
<p>References:<br>[1]<a href="https://wordpress.org/support/article/administration-over-ssl/">Administration Over SSL</a><br>[2]<a href="https://zhihu.websoft9.com/6408/wordpress%E4%BD%BF%E7%94%A8nginx%E5%81%9A%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E7%9A%84ssl%E8%AE%BE%E7%BD%AE">WordPress使用Nginx做反向代理的SSL设置</a><br>[3]<a href="https://isabelcastillo.com/mysql-wordpress-http-to-https">MySQL Queries To Change WordPress From HTTP to HTTPS In The Database</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx,tomcat,memcached会话共享集群配置</title>
    <url>/2016/05/31/nginx-tomcat-memcached-session-share-cluster/</url>
    <content><![CDATA[<a id="more"></a>
<p>tomcat自身支持会话复制的集群。</p>
<p>此post主要讲使用memcached存储会话，使用msm(memcached-session-manager)来管理会话复制。</p>
<p>通过配置共享会话的tomcat集群，可以提高服务的高可用性，并可以做到不停机连续更新应用程序。</p>
<p>示例配置采用两台机器，ip分别为10.100.0.20和10.100.0.21。每台机器分别部署nginx,tomcat和memcached。两个tomcat实例和两个memcached实例通过msm组成一个会话共享集群，前端由nginx做负载均衡。</p>
<p>还可以在nginx之前做DNS负载均衡。</p>
<p><strong>nginx配置</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">upstream servers &#123;</span><br><span class="line"> server <span class="number">10.100</span><span class="number">.0</span><span class="number">.20</span>:<span class="number">8080</span>;</span><br><span class="line"> server <span class="number">10.100</span><span class="number">.0</span><span class="number">.21</span>:<span class="number">8080</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">location / &#123;</span><br><span class="line"> proxy_pass http:<span class="comment">//servers;</span></span><br><span class="line"> proxy_set_header Accept-Encoding <span class="string">&quot;gzip&quot;</span>;</span><br><span class="line"></span><br><span class="line"> # proxy websocket reverse</span><br><span class="line"> proxy_http_version <span class="number">1.1</span>;</span><br><span class="line"> proxy_set_header Upgrade $http_upgrade;</span><br><span class="line"> proxy_set_header Connection <span class="string">&quot;upgrade&quot;</span>;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p>nginx会将客户请求分发到后端服务器组</p>
<p><strong>memcached配置</strong><br>安装</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install memcached</span><br></pre></td></tr></table></figure>

<p>memcached默认安装只监听本地回环地址，更改/etc/memcached.conf，注释掉下面的行:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">#-l 127.0.0.1</span><br></pre></td></tr></table></figure>

<p>重启memcached服务会监听所有本地接口。</p>
<p><strong>msm和tomcat配置</strong></p>
<p>kiro序列化性能较高，因此这里使用kiro序列化器。</p>
<p>将msm基础包memcached-session-manager-${version}.jar，memcached-session-manager-tc8-${version}.jar和spymemcached-2.11.1.jar，以及kryo序列化支持jar包拷贝到$CATALINA_HOME/lib/目录。</p>
<p>debian系统中tomcat8的lib目录位于/usr/share/tomcat8/lib/</p>
<p>还有一个包<a href="http://objenesis.org/download.html">Objenesis</a>也需要下载安装到此目录中。</p>
<p><strong>sticky sessions + kryo配置</strong></p>
<p>/etc/tomcat8/context.xml文件中context一节最后添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;Manager className=<span class="string">&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot;</span></span><br><span class="line"> memcachedNodes=<span class="string">&quot;n1:10.100.0.20:11211,n2:10.100.0.21:11211&quot;</span></span><br><span class="line"> failoverNodes=<span class="string">&quot;n1&quot;</span></span><br><span class="line"> requestUriIgnorePattern=<span class="string">&quot;.*\\.(icopnggifjpgcssjs)$&quot;</span></span><br><span class="line"> transcoderFactoryClass=<span class="string">&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot;</span></span><br><span class="line"> /&gt;</span><br></pre></td></tr></table></figure>

<p>msm默认处于sticky模式，因此不用显式指定sticky参数。failoverNodes参数指定本机memcached节点名称,这样正常情况下msm会存储会话到其他memcached节点，当没有其他节点可用时才会使用failoverNodes。</p>
<p><strong>non-sticky sessions + kryo配置</strong></p>
<p>/etc/tomcat8/context.xml文件中context一节最后添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;Manager className=<span class="string">&quot;de.javakaffee.web.msm.MemcachedBackupSessionManager&quot;</span></span><br><span class="line">memcachedNodes=<span class="string">&quot;n1:10.100.0.20:11211,n2:10.100.0.21:11211&quot;</span></span><br><span class="line">sticky=<span class="string">&quot;false&quot;</span></span><br><span class="line">sessionBackupAsync=<span class="string">&quot;false&quot;</span></span><br><span class="line">lockingMode=<span class="string">&quot;auto&quot;</span></span><br><span class="line">transcoderFactoryClass=<span class="string">&quot;de.javakaffee.web.msm.serializer.kryo.KryoTranscoderFactory&quot;</span></span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure>

<p>这里明确指定sticky参数为false，注意不要设置requestUriIgnorePattern参数，否则当前配置下会出现问题，无法完成session共享。</p>
<p>sticky会话模式就是将用户“粘”在某一个服务器节点上，即同一个会话中的请求必须被转发到同一个节点上，除非该节点宕机才转发到故障转移节点。</p>
<p>non-sticky会话模式则是每一次请求都可能转发到不同节点。</p>
<p>sticky会话模式性能更好。</p>
<p>References:<br>[1]<a href="https://github.com/magro/memcached-session-manager/wiki/SetupAndConfiguration">SetupAndConfiguration</a><br>[2]<a href="http://www.cnblogs.com/zhengyun_ustc/archive/2012/11/17/topic4.html">分布式session</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx环境安装twip4 API代理</title>
    <url>/2010/10/01/nginx-twip4-api-setup/</url>
    <content><![CDATA[<p>twip4最近已经支持nginx环境下架设API代理,已经试用几天,比较稳定,架设也很简单.</p>
<a id="more"></a>
<p>首先当然是注册一个twitter应用,应用程序类型选browser,callback URL随意填,缺省的存取类型选择Read &amp; Write.</p>
<p><strong>设置步骤</strong></p>
<p>1、获取最新的开发版本.去官网<a href="http://code.google.com/p/twip/w/list">下载</a>,或者git svn clone <a href="http://twip.googlecode.com/svn/trunk">http://twip.googlecode.com/svn/trunk</a> twip4获取最新的代码树<br>2、拷贝config-example.php到config.php,编辑config.php,OAUTH_KEY/OAUTH_SECRET分别填入注册应用程序的Consumer key/Consumer secret,BASE_URL为访问通过浏览器访问twip4应用程序的地址,比如<a href="http://example.com/twip/,%E4%B8%80%E5%AE%9A%E4%B8%8D%E8%A6%81%E5%BF%98%E8%AE%B0%E6%9C%80%E5%90%8E%E7%9A%84/,COMPRESS%E8%AE%BE%E7%BD%AE%E4%B8%BATRUE%E5%8F%AF%E4%BB%A5%E5%8E%8B%E7%BC%A9%E4%BC%A0%E8%BE%93%E7%9A%84%E5%86%85%E5%AE%B9">http://example.com/twip/,一定不要忘记最后的/,COMPRESS设置为TRUE可以压缩传输的内容</a>.<br>3、编辑nginx配置文件，增加rewrite规则.把rewrite_rules.txt里面的rewrite规则写在主机的配置文件里面即可<br>4、访问BASE_URL来配置O模式或T模式代理,注意要访问index.html而不是index.php,注意主机配置的index指令或显示指定</p>
<p>seesmic只能使用O模式而不能使用T模式,其他客户端未测试.</p>
]]></content>
      <categories>
        <category>Social</category>
      </categories>
      <tags>
        <tag>Twitter</tag>
      </tags>
  </entry>
  <entry>
    <title>nodetool自动监控bootstrapping\repairing\rebuilding进度</title>
    <url>/2018/11/24/nodetool-bootstrapping-repairing-rebuilding-progress/</url>
    <content><![CDATA[<a id="more"></a>
<p>不用其他监控套件，只是用nodetool工具借助netstats指令简单的监控收发数据流进度：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">watch -n <span class="number">10</span> <span class="string">&#x27;nodetool netstats grep &quot;Receiving\\Sending&quot; gawk &#123;&#x27;</span><span class="string">&quot;&#x27;&quot;</span><span class="string">&#x27; print $1&quot; - &quot;$11/$4*100&quot;% Complete, &quot;($4-$11)/1024/1024/1024&quot; GB remaining&quot; &#x27;</span><span class="string">&quot;&#x27;&quot;</span><span class="string">&#x27;&#125;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://anthonyfisk.blogspot.com/2016/05/on-cassandra-stream-monitoring.html">On Cassandra Stream Monitoring</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>nodetool连接超时错误</title>
    <url>/2014/12/27/nodetool-connection-timeout/</url>
    <content><![CDATA[<a id="more"></a>
<p>nodetool查看本地集群状态时,N久以后出现无法连接、连接超时的错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool status</span><br><span class="line">nodetool: Failed to connect to <span class="string">&#x27;127.0.0.1:7199&#x27;</span> - ConnectException: <span class="string">&#x27;Connection timed out&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>经排查为/etc/hosts文件配置错误所致,文件中实际的主机名(不是localhost)对应的ip地址解析行设置错误,这是由于主机ip地址更换后未及时更新hosts文件所致。更改为正确的ip地址类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.104</span> yoga.localdomain yoga</span><br></pre></td></tr></table></figure>

<p>然后重新启动cassandra服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo /etc/init.d/cassandra restart</span><br><span class="line">\[ ok \] Restarting cassandra (via systemctl): cassandra.service.</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl restart cassandra.service</span><br></pre></td></tr></table></figure>

<p>然后再重新执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool status</span><br><span class="line">Datacenter: datacenter1</span><br><span class="line">=======================</span><br><span class="line">Status=Up/Down</span><br><span class="line">/ State=Normal/Leaving/Joining/Moving</span><br><span class="line">-- Address Load Tokens Owns (effective) Host ID Rack</span><br><span class="line">UN <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> <span class="number">139.45</span> KB <span class="number">256</span> <span class="number">100.0</span>% <span class="number">27e51705</span>-c13d-4f4b-b4f8-de3759fcd895 rack1</span><br></pre></td></tr></table></figure>

<p>如果cassandra尚未完全启动时就执行该命令，会有异常抛出，类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nodetool status</span><br><span class="line">error: No nodes present <span class="keyword">in</span> the cluster. Has <span class="built_in">this</span> node finished starting up?</span><br><span class="line">-- StackTrace --</span><br><span class="line">java.lang.RuntimeException: No nodes present <span class="keyword">in</span> the cluster. Has <span class="built_in">this</span> node finished starting up?</span><br><span class="line"> at org.apache.cassandra.dht.Murmur3Partitioner.describeOwnership(Murmur3Partitioner.java:<span class="number">129</span>)</span><br><span class="line"> at org.apache.cassandra.service.StorageService.effectiveOwnership(StorageService.java:<span class="number">3762</span>)</span><br><span class="line"> at org.apache.cassandra.service.StorageService.effectiveOwnership(StorageService.java:<span class="number">103</span>)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line"> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"> at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</span><br><span class="line"> at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:<span class="number">75</span>)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line"> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"> at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</span><br><span class="line"> at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:<span class="number">279</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:<span class="number">112</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:<span class="number">46</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:<span class="number">237</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.PerInterface.invoke(PerInterface.java:<span class="number">138</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.MBeanSupport.invoke(MBeanSupport.java:<span class="number">252</span>)</span><br><span class="line"> at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.invoke(DefaultMBeanServerInterceptor.java:<span class="number">819</span>)</span><br><span class="line"> at com.sun.jmx.mbeanserver.JmxMBeanServer.invoke(JmxMBeanServer.java:<span class="number">801</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:<span class="number">1487</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:<span class="number">97</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:<span class="number">1328</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:<span class="number">1420</span>)</span><br><span class="line"> at javax.management.remote.rmi.RMIConnectionImpl.invoke(RMIConnectionImpl.java:<span class="number">848</span>)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line"> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:<span class="number">57</span>)</span><br><span class="line"> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:<span class="number">43</span>)</span><br><span class="line"> at java.lang.reflect.Method.invoke(Method.java:<span class="number">606</span>)</span><br><span class="line"> at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:<span class="number">322</span>)</span><br><span class="line"> at sun.rmi.transport.Transport$1.run(Transport.java:<span class="number">177</span>)</span><br><span class="line"> at sun.rmi.transport.Transport$1.run(Transport.java:<span class="number">174</span>)</span><br><span class="line"> at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line"> at sun.rmi.transport.Transport.serviceCall(Transport.java:<span class="number">173</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:<span class="number">556</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:<span class="number">811</span>)</span><br><span class="line"> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:<span class="number">670</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1145</span>)</span><br><span class="line"> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">615</span>)</span><br><span class="line"> at java.lang.Thread.run(Thread.java:<span class="number">745</span>)</span><br></pre></td></tr></table></figure>

<p>Mac OS X平台上/etc/hosts文件中根本就不设置主机名对应的IP地址解析,而出现的错误提示也略有不同:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">nodetool: Failed to connect to <span class="string">&#x27;127.0.0.1:7199&#x27;</span> - ConnectException: <span class="string">&#x27;Operation timed out&#x27;</span>.</span><br></pre></td></tr></table></figure>
<p>解决办法也是一样的,对于动态ip的客户端测试环境而言,直接将主机名对应的ip设置为127.0.0.1亦可：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> mba</span><br></pre></td></tr></table></figure>
<p>重新加载cassandra就可以了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ launchctl unload /usr/local/opt/cassandra/homebrew.mxcl.cassandra.plist</span><br><span class="line">$ launchctl load /usr/local/opt/cassandra/homebrew.mxcl.cassandra.plist</span><br></pre></td></tr></table></figure>

<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle数据库nologging和force logging模式</title>
    <url>/2011/10/27/nologging-and-force-logging/</url>
    <content><![CDATA[<p><strong>查询force logging模式</strong></p>
<p>SQL&gt; select log_mode,force_logging from v$database;</p>
<a id="more"></a>
<p>LOG_MODE FORCE_LOGGING</p>
<hr>
<p>ARCHIVELOG NO</p>
<p><strong>将数据库置为force logging模式</strong></p>
<p>SQL&gt;alter database force logging;<br>Database altered.</p>
<p><strong>取消force logging模式</strong></p>
<p>SQL&gt; ALTER DATABASE no force logging;<br>Database altered.</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>ntpdate错误: no server suitable for synchronization found</title>
    <url>/2019/05/05/ntpdate-error-no-server-suitable-for-synchronization-found/</url>
    <content><![CDATA[<a id="more"></a>
<p>客户端执行ntpdate同步时间时发生错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ntpdate\[<span class="number">10877</span>\]: no server suitable <span class="keyword">for</span> synchronization found</span><br></pre></td></tr></table></figure>

<p>debug模式运行ntpdate:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># ntpdate -d 192.168.0.3</span><br><span class="line">ntpdate -d <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span></span><br><span class="line"> <span class="number">5</span> May <span class="number">14</span>:<span class="number">52</span>:<span class="number">58</span> ntpdate\[<span class="number">10877</span>\]: ntpdate <span class="number">4.2</span>.6p5@<span class="number">1.2349</span>-o Fri Jul <span class="number">22</span> <span class="number">17</span>:<span class="number">30</span>:<span class="number">52</span> UTC <span class="number">2016</span> (<span class="number">1</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">receive(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">receive(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">receive(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">transmit(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line">receive(<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>)</span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>: Server dropped: Leap not <span class="keyword">in</span> sync</span><br><span class="line">server <span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>, port <span class="number">123</span></span><br><span class="line">stratum <span class="number">3</span>, precision -<span class="number">23</span>, leap <span class="number">11</span>, trust <span class="number">000</span></span><br><span class="line">refid \[<span class="number">192.168</span><span class="number">.0</span><span class="number">.3</span>\], delay <span class="number">0.02617</span>, dispersion <span class="number">0.00005</span></span><br><span class="line">transmitted <span class="number">4</span>, <span class="keyword">in</span> filter <span class="number">4</span></span><br><span class="line">reference time: e07906ca.595bf596 Sun, May <span class="number">5</span> <span class="number">2019</span> <span class="number">14</span>:<span class="number">52</span>:<span class="number">58.349</span></span><br><span class="line">originate timestamp: e07906d0.bb8e930a Sun, May <span class="number">5</span> <span class="number">2019</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">04</span><span class="number">.732</span></span><br><span class="line">transmit timestamp: e07906d0.84432bb9 Sun, May <span class="number">5</span> <span class="number">2019</span> <span class="number">14</span>:<span class="number">53</span>:<span class="number">04</span><span class="number">.516</span></span><br><span class="line">filter delay: <span class="number">0.02632</span> <span class="number">0.02621</span> <span class="number">0.02617</span> <span class="number">0.02617</span> </span><br><span class="line"> <span class="number">0.00000</span> <span class="number">0.00000</span> <span class="number">0.00000</span> <span class="number">0.00000</span> </span><br><span class="line">filter offset: <span class="number">0.215621</span> <span class="number">0.215522</span> <span class="number">0.215512</span> <span class="number">0.215605</span></span><br><span class="line"> <span class="number">0.000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span> <span class="number">0.000000</span></span><br><span class="line">delay <span class="number">0.02617</span>, dispersion <span class="number">0.00005</span></span><br><span class="line">offset <span class="number">0.215512</span></span><br><span class="line"></span><br><span class="line"> <span class="number">5</span> May <span class="number">14</span>:<span class="number">53</span>:<span class="number">04</span> ntpdate\[<span class="number">10877</span>\]: no server suitable <span class="keyword">for</span> synchronization found</span><br></pre></td></tr></table></figure>

<p>提示错误Server dropped: Leap not in sync</p>
<p>在ntp服务器上与上游强制同步一次时间即可</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># service ntp stop</span><br><span class="line"># ntpdate -b pool.ntp.org</span><br><span class="line"># service ntp start</span><br></pre></td></tr></table></figure>

<p>然后再在客户端上重新进行时间同步</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ntpdate 192.168.0.3</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>debian启动时激活numlock</title>
    <url>/2014/03/14/numlock-on-startup/</url>
    <content><![CDATA[<p>debian启动时默认关闭numlock有一阵子了。</p>
<a id="more"></a>
<p>一直懒的弄它,这几天实在受不鸟了。</p>
<p>numlock状态在console和X环境下是分别单独控制的。X终端模拟器继承X下的设置。</p>
<p><strong>console</strong></p>
<p>配置文件/etc/kbd/config中添加LEDS选项</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># Turn on numlock by default</span><br><span class="line">LEDS=+num</span><br></pre></td></tr></table></figure>

<p>或者在~/.bash_profile添加setleds命令打开numlock</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">setleds -D +num</span><br></pre></td></tr></table></figure>

<p><strong>X</strong></p>
<p>X环境下需要使用numlockx命令来打开numlock,所以需要先安装numlockx</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#apt-get install numlockx</span><br></pre></td></tr></table></figure>
<p>因为使用gdm,所以在gdm配置文件/etc/gdm3/Init/Default中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> \[ -x /usr/bin/numlockx \]; then</span><br><span class="line">/usr/bin/numlockx;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<p>记得要在最后一行exit 0之前添加。</p>
<p>References:<br>[1]<a href="https://wiki.archlinux.org/index.php/Activating_Numlock_on_Bootup">Activating Numlock on Bootup</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>oh OnionShare</title>
    <url>/2019/07/08/oh-onionshare/</url>
    <content><![CDATA[<a id="more"></a>
<p><a href="https://onionshare.org/">OnionShare</a>是一个安全匿名的开源文件分享工具，可以使用它在本地机器通过tor网络发布共享服务，生成一个不可猜测的onion地址，通过这个地址其他人可以使用tor browser来获取分享的文件。只要生成的onion地址没有泄露，文件就是安全的。文件传输的过程不会被任何第三方窃取。</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install onionshare</span><br></pre></td></tr></table></figure>

<p><strong>分享文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ onionshare go.sh </span><br><span class="line">Onionshare <span class="number">1.3</span><span class="number">.2</span> https:<span class="comment">//onionshare.org/</span></span><br><span class="line">Connecting to the Tor network: <span class="number">100</span>% - Done</span><br><span class="line">Configuring onion service on port <span class="number">17620.</span></span><br><span class="line">Starting ephemeral Tor onion service and awaiting publication</span><br><span class="line">Settings saved to /home/xxx/.config/onionshare/onionshare.json</span><br><span class="line">Preparing files to share.</span><br><span class="line"> * Serving Flask app <span class="string">&quot;onionshare.web&quot;</span> (lazy loading)</span><br><span class="line"> * Environment: production</span><br><span class="line"> WARNING: Do not use the development server <span class="keyword">in</span> a production environment.</span><br><span class="line"> Use a production WSGI server instead.</span><br><span class="line"> * Debug mode: off</span><br><span class="line"> * Running on http:<span class="comment">//127.0.0.1:17620/ (Press CTRL+C to quit)</span></span><br><span class="line">Give <span class="built_in">this</span> address to the person you<span class="string">&#x27;re sending the file to:</span></span><br><span class="line"><span class="string">http://huq64ocyu666ecom.onion/negligee-easing</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Press Ctrl-C to stop server</span></span><br></pre></td></tr></table></figure>

<p><strong>获取文件</strong></p>
<p>将生成的连接通过安全路径发送，然后在tor browser中打开连接即可，简单可靠又安全，美中不足，速度慢慢慢。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian安装OpenSIPS服务器</title>
    <url>/2012/10/21/opensips-install-setup/</url>
    <content><![CDATA[<p>OpenSIPS是成熟的开源SIP服务器</p>
<a id="more"></a>
<p><strong>渊源</strong></p>
<p>OpenSIPS(Open SIP Server) fork自大名鼎鼎的OpenSER(Open SIP Express Router)。后来由于开发者的分歧,OpenSER分裂为两个项目,OpenSER因为商标问题改名为Kamailio,另外一些开发者fork了OpenSER成立了OpenSIPS项目。目前,OpenSIPS和Kamailio差别并不大。</p>
<p><strong>安装</strong></p>
<p>添加<a href="http://apt.opensips.org/">OpenSIPS官方源</a></p>
<p>编辑/etc/apt/source.list,添加</p>
<p>deb <a href="http://apt.opensips.org/">http://apt.opensips.org/</a> testing main</p>
<p>添加源认证密钥<br>wget <a href="http://apt.opensips.org/key.asc">http://apt.opensips.org/key.asc</a><br>apt-key add key.asc</p>
<p>更新并安装OpenSIPS,使用postgresql作为后端数据库</p>
<p>#apt-get update<br>#apt-get install opensips opensips-postgres-module</p>
<p><strong>配置</strong></p>
<p>编辑/etc/opensips/opensips.cfg,修改listen=udp:127.0.0.1:5060为实际的参数<br>监听指定的IP和端口,端口默认为UDP/5060<br>listen=udp:sip_server_ip:5060<br>或者监听本地所有IP<br>listen=udp:0.0.0.0:5060</p>
<p>其他参数默认即可。</p>
<p>编辑/etc/opensips/opensipsctlrc,指定适当的数据库参数<br> 1 # SIP服务器域名<br> 2  SIP_DOMAIN=sip_server_ip<br> 3<br> 4 # 后端数据库引擎<br> 5  DBENGINE=PGSQL<br> 6<br> 7 # 数据库主机地址<br> 8  DBHOST=localhost<br> 9<br>10 # 数据库名字<br>11  DBNAME=opensips<br>12<br>13 # 数据库读写权限用户<br>14  DBRWUSER=opensips<br>15<br>16 # 数据库读写权限用户密码<br>17  DBRWPW=”opensipsrw”<br>18<br>19 # 数据库超级用户<br>20  DBROOTUSER=”postgres”<br>21<br>22 # 用户名使用的列名<br>23  USERCOL=”username” </p>
<p><strong>创建数据库</strong><br>postgresql数据库超级用户postgres的密码最好设置的简单些,建库脚本会不厌其烦的要求输入超级用户postgres的密码</p>
<p>使用opensipsdbctl来管理OpenSIPS使用的数据库</p>
<p>#opensipsdbctl create</p>
<p>中间会多次提示postgres用户的密码</p>
<p><strong>创建sip用户</strong></p>
<p>#opensipsctl add username password</p>
<p><strong>重新启动OpenSIPS服务器</strong></p>
<p>#/etc/init.d/opensips restart<br>或者<br>#opensipsctl restart</p>
<p><strong>显示在线sip用户</strong></p>
<h1 id="opensipsctl-online"><a href="#opensipsctl-online" class="headerlink" title="opensipsctl online"></a>opensipsctl online</h1><p>或者</p>
<h1 id="opensipsctl-ul-show"><a href="#opensipsctl-ul-show" class="headerlink" title="opensipsctl ul show"></a>opensipsctl ul show</h1><p><strong>NAT穿越</strong></p>
<p>OpenSIPS自身默认使用UDP端口5060,但是RTP(Real-time Transport Protocol)协议使用动态端口,具体使用媒体格式和动态端口由SDP(Session Description Protocol)协议协商。OpenSIPS支持NAT-T穿越(NAT Traversal Module),而且支持STUN服务器(stun模块)。</p>
<p>现在ISP对SIP多有封锁,所以真正实施起来NAT穿越不如建vpn通道来的更实际。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>openssl升级导致的shadowsocks报错问题</title>
    <url>/2016/11/30/openssl-upgrade-shadowsocks-error/</url>
    <content><![CDATA[<a id="more"></a>
<p>ss无法启动了，/var/log/shadowsocks.log报错:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">AttributeError: <span class="regexp">/usr/</span>lib/x86_64-linux-gnu/libcrypto.so<span class="number">.1</span><span class="number">.1</span>: <span class="literal">undefined</span> symbol: EVP_CIPHER_CTX_cleanup</span><br></pre></td></tr></table></figure>

<p>是因为openssl1.1.0版本中，废弃了EVP_CIPHER_CTX_cleanup函数，可以用EVP_CIPHER_CTX_reset来代替此函数</p>
<p>此文件/usr/lib/python2.7/dist-packages/shadowsocks/crypto/openssl.py中搜索所有的EVP_CIPHER_CTX_cleanup以EVP_CIPHER_CTX_reset代替即可，总共有两处。</p>
<p>References:<br>[1]<a href="https://blog.lyz810.com/article/2016/09/shadowsocks-with-openssl-greater-than-110/">解决openssl升级到1.1.0后shadowsocks服务报错问题</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenVPN for Galaxy S i9000(android 2.2)设置</title>
    <url>/2011/03/10/openvpn-for-android-setup/</url>
    <content><![CDATA[<p>VPN(Virtual Private Network)提供认证、加密等服务,提高端到端通信的安全性,OpenVPN是优秀的开源VPN解决方案,andriod系统支持OpenVPN，下面为其安装配置方法。</p>
<a id="more"></a>
<p><strong>安装OpenVPN</strong></p>
<p>如果你的ROM不带OpenVPN,去<a href="https://github.com/fries/android-external-openvpn">这里</a>下载编译好的静态二进制文件OpenVPN,解压后复制到/system/xbin/openvpn,然后打开手机terminal执行</p>
<p>1 #mkdir /system/xbin/bb<br>2 #ln -s /system/xbin/busybox /system/xbin/bb/ifconfig<br>3 #ln -s /system/xbin/busybox /system/xbin/bb/route  </p>
<p><strong>配置OpenVPN</strong></p>
<p>新建目录openvpn<br>#mkdir /sdcard/openvpn  </p>
<p>将证书文件ca.crt,.crt文件,.key文件拷贝至该目录<br>新增client.ovpn文件,编辑其内容如下:<br> 1 ##############################################<br> 2 # Sample client-side OpenVPN 2.0 config file #<br> 3 # for connecting to multi-client server.     #<br> 4 #                                            #<br> 5 # This configuration can be used by multiple #<br> 6 # clients, however each client should have   #<br> 7 # its own cert and key files.                #<br> 8 #                                            #<br> 9 # On Windows, you might want to rename this  #<br> 10 # file so it has a .ovpn extension           #<br> 11 ##############################################<br> 12<br> 13 # Specify that we are a client and that we<br> 14 # will be pulling certain config file directives<br> 15 # from the server.<br> 16 #声明为OpenVPN客户端<br> 17 client<br> 18<br> 19 # Use the same setting as you are using on<br> 20 # the server.<br> 21 # On most systems, the VPN will not function<br> 22 # unless you partially or fully disable<br> 23 # the firewall for the TUN/TAP interface.<br> 24 #使用tun设备,必须与服务器设置一致<br> 25 ;dev tap<br> 26 dev tun<br> 27<br> 28 # Windows needs the TAP-Win32 adapter name<br> 29 # from the Network Connections panel<br> 30 # if you have more than one.  On XP SP2,<br> 31 # you may need to disable the firewall<br> 32 # for the TAP adapter.<br> 33 ;dev-node MyTap<br> 34<br> 35 # Are we connecting to a TCP or<br> 36 # UDP server?  Use the same setting as<br> 37 # on the server.<br> 38 #使用UDP协议,必须与服务器设置一致<br> 39 ;proto tcp<br> 40 proto udp<br> 41<br> 42 # The hostname/IP and port of the server.<br> 43 # You can have multiple remote entries<br> 44 # to load balance between the servers.<br> 45 #指定OpenVPN服务器ip和端口<br> 46 remote your_openvpn_server_ip port<br> 47 ;remote my-server-2 1194<br> 48<br> 49 # Choose a random host from the remote<br> 50 # list for load-balancing.  Otherwise<br> 51 # try hosts in the order specified.<br> 52 ;remote-random<br> 53<br> 54 # Keep trying indefinitely to resolve the<br> 55 # host name of the OpenVPN server.  Very useful<br> 56 # on machines which are not permanently connected<br> 57 # to the internet such as laptops.<br> 58 resolv-retry infinite<br> 59<br> 60 # Most clients don’t need to bind to<br> 61 # a specific local port number.<br> 62 #不绑定客户端特定的端口<br> 63 nobind<br> 64<br> 65 # Downgrade privileges after initialization (non-Windows only)<br> 66 ;user nobody<br> 67 ;group nogroup<br> 68<br> 69 # Try to preserve some state across restarts.<br> 70 #保持状态<br> 71 persist-key<br> 72 persist-tun<br> 73<br> 74 # If you are connecting through an<br> 75 # HTTP proxy to reach the actual OpenVPN<br> 76 # server, put the proxy server/IP and<br> 77 # port number here.  See the man page<br> 78 # if your proxy server requires<br> 79 # authentication.<br> 80 ;http-proxy-retry # retry on connection failures<br> 81 ;http-proxy <strong>[**proxy server</strong>]** **[**proxy port #]<br> 82<br> 83 # Wireless networks often produce a lot<br> 84 # of duplicate packets.  Set this flag<br> 85 # to silence duplicate packet warnings.<br> 86 **;**mute-replay-warnings<br> 87<br> 88 # SSL/TLS parms.<br> 89 # See the server config file for more<br> 90 # description.  It’s best to use<br> 91 # a separate .crt/.key file pair<br> 92 # for each client.  A single ca<br> 93 # file can be used for all clients.<br> 94 #指定证书文件和key文件<br> 95 ca ca.crt<br> 96 cert client.crt<br> 97 key client.key<br> 98<br> 99 # Verify server certificate by checking<br>100 # that the certicate has the nsCertType<br>101 # field set to “server”.  This is an<br>102 # important precaution to protect against<br>103 # a potential attack discussed here:<br>104 #  <a href="http://openvpn.net/howto.html#mitm">http://openvpn.net/howto.html#mitm</a><br>105 #<br>106 # To use this feature, you will need to generate<br>107 # your server certificates with the nsCertType<br>108 # field set to “server”.  The build-key-server<br>109 # script in the easy-rsa folder will do this.<br>110 ns-cert-type server<br>111<br>112 # If a tls-auth key is used on the server<br>113 # then every client must also have the key.<br>114 **;**tls-auth ta.key 1<br>115<br>116 # Select a cryptographic cipher.<br>117 # If the cipher option is used on the server<br>118 # then you must also specify it here.<br>119 **;**cipher x<br>120<br>121 # Enable compression on the VPN link.<br>122 # Don’t enable this unless it is also<br>123 # enabled in the server config file.<br>124 #在VPN上使用数据压缩,必须与服务器设置一致<br>125 comp-lzo<br>126<br>127 # Set log file verbosity.<br>128 #设置日志文件级别<br>129 verb 3<br>130<br>131 # Silence repeating messages<br>132 **;**mute 20  </p>
<p><strong>使用OpenVPN</strong></p>
<p>android默认没有加载tun.ko内核模块,使用vpn前需先加载该模块,tun.ko一般位于/lib/modules目录下,如果你的ROM没有此模块的话,需要下载并将其拷贝到此目录下<br>1 #cd /sdcard/openvpn<br>2 #insmod /lib/modules/tun.ko<br>3 #openvpn –config client.ovpn  </p>
<p>现在就可以使用OpenVPN加密通道了,如果想停止vpn,执行<br>1 #killall openvpn  </p>
<p>可以写个脚本让OpenVPN随系统自动加载内核模块并启动服务.</p>
]]></content>
      <categories>
        <category>Mobile</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>使用OpenVPN Settings管理Android OpenVPN客户端</title>
    <url>/2011/04/08/openvpn-settings-manual/</url>
    <content><![CDATA[<p>曾经写过一篇<a href="https://openwares.net/mobile/openvpn_for_android_setup.html">Android手机OpenVPN客户端设置</a>的文字,但是每次要打开终端操作还是太繁琐了</p>
<a id="more"></a>
<p>市场里有一款软件OpenVPN Settings大大简化了Android手机OpenVPN客户端的操作。</p>
<p>先按照那篇文字设置好OpenVPN,然后打开OpenVPN Settings,打开Advanced设置菜单,如下图<br><a href="https://openwares.net/linux/openvpn_settings_manual.html/attachment/openvpn_setting"><img src="/images/2011/04/openvpn_setting.png" title="openvpn_setting"></a></p>
<p>关于是否要”Load tun kernel module”,主要看ROM有没有把tun编译进内核,在终端下输入以下命令：</p>
<p>#ls /dev grep tun</p>
<p>如果有输出说明内核已经支持tun设备,无需再让OpenVPN settings加载tun模块；如果没有输出,则需要先加载tun.ko内核模块，才可以使用vpn。如需加载，点击打开”TUN module settings”,”Load module using”选择insmod,”Path to tun module”输入tun.ko完整的路径，一般为/lib/modules/tun.ko</p>
<p>“Path to configurations”输入配置文件路径/sdcard/openvpn<br>“Path to openvpn binary”输入下载的<a href="https://github.com/downloads/fries/android-external-openvpn/openvpn-static-2.1.1.bz2">静态openvpn</a>二进制文件所在位置/system/xbin/openvpn</p>
<p>这样使用起来就方便多了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>突然掉电导致的ORA-01207错误</title>
    <url>/2014/10/17/ora-01207/</url>
    <content><![CDATA[<a id="more"></a>
<p>硬件维护的时候有人不小心把生产库的电源断掉了,重新启动盘柜和服务器后,oracle 10g 10.2.0.4 startup时出现错误提示:</p>
<p>[sql]<br>数据库装载完毕。<br>ORA-01122: 数据库文件 1 验证失败<br>ORA-01110: 数据文件 1: ‘E:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\SYSTEM01.DBF’<br>ORA-01207: 文件比控制文件更新 - 旧的控制文件 (file is more recent than controlfile - old controlfile)<br>[/sql]</p>
<p>由于时间紧迫，且对此错误不甚熟悉，就先将生产库切到了dataguard物理备库,有时间再研究此问题如何恢复。</p>
<p>References:<br>[1]<a href="http://www.ixdba.net/article/da/363.html">ORA-01207: old control file完全解决方案</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>恢复目录表空间满导致rman错误ORA-01654</title>
    <url>/2014/10/10/ora-01654/</url>
    <content><![CDATA[<a id="more"></a>
<p>查看rman脚本备份日志，发现如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">starting full resync <span class="keyword">of</span> recovery catalog</span><br><span class="line">RMAN-<span class="number">00571</span>: ===========================================================</span><br><span class="line">RMAN-<span class="number">00569</span>: =============== ERROR MESSAGE STACK FOLLOWS ===============</span><br><span class="line">RMAN-<span class="number">00571</span>: ===========================================================</span><br><span class="line">RMAN-<span class="number">03002</span>: failure <span class="keyword">of</span> crosscheck command at <span class="number">10</span>/<span class="number">10</span>/<span class="number">2014</span> <span class="number">10</span>:<span class="number">26</span>:<span class="number">33</span></span><br><span class="line">RMAN-<span class="number">03014</span>: implicit resync <span class="keyword">of</span> recovery catalog failed</span><br><span class="line">RMAN-<span class="number">03009</span>: failure <span class="keyword">of</span> full resync command on <span class="keyword">default</span> channel at <span class="number">10</span>/<span class="number">10</span>/<span class="number">2014</span> <span class="number">10</span>:<span class="number">26</span>:<span class="number">33</span></span><br><span class="line">ORA-<span class="number">01654</span>: unable to extend index RMAN_USR.RLH_U1 by <span class="number">128</span> <span class="keyword">in</span> tablespace RMAN_TS</span><br></pre></td></tr></table></figure>

<p>rman恢复目录所在表空间无法扩展</p>
<p>查看表空间利用率<br>[sql]<br>SQL&gt; SELECT * FROM dba_tablespace_usage_metrics ORDER BY used_percent DESC;<br>[/sql]<br>恢复目录所在表空间利用率已经达到96%</p>
<p>扩大数据文件大小<br>[sql]<br>SQL&gt; alter database datafile ‘/u01/oradata/catlogdb/rman01.dbf’ resize 300M;<br>[/sql]</p>
<p>重新运行rman,问题解决。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>ORA-12518 TNS:监听程序无法分发客户机连接</title>
    <url>/2016/04/22/ora-12518/</url>
    <content><![CDATA[<a id="more"></a>
<p>最常见的原因是process和session数量设置过低。</p>
<p><strong>查看修改process参数</strong> </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&gt; show parameter process</span><br><span class="line"></span><br><span class="line">NAME TYPE VALUE</span><br><span class="line">------------------------------------ --------------------------------- -------------------</span><br><span class="line">aq_tm_processes integer <span class="number">0</span></span><br><span class="line">db_writer_processes integer <span class="number">3</span></span><br><span class="line">gcs_server_processes integer <span class="number">0</span></span><br><span class="line">job_queue_processes integer <span class="number">20</span></span><br><span class="line">log_archive_max_processes integer <span class="number">2</span></span><br><span class="line">processes integer <span class="number">150</span></span><br></pre></td></tr></table></figure>

<p>偏低，修改process参数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&gt; alter system set processes=<span class="number">1000</span> scope = spfile;</span><br></pre></td></tr></table></figure>
<p>这里无法直接修改内存值，也就是不能使用scope=both,否则会有提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">02095</span>: specified initialization parameter cannot be modified</span><br></pre></td></tr></table></figure>

<p><strong>查看修改session参数</strong></p>
<p>查看</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&gt; show parameter session</span><br><span class="line">NAME TYPE VALUE</span><br><span class="line">------------------------------------ --------------------------------- --------------------</span><br><span class="line">java_max_sessionspace_size integer <span class="number">0</span></span><br><span class="line">java_soft_sessionspace_limit integer <span class="number">0</span></span><br><span class="line">license_max_sessions integer <span class="number">0</span></span><br><span class="line">license_sessions_warning integer <span class="number">0</span></span><br><span class="line">logmnr_max_persistent_sessions integer <span class="number">1</span></span><br><span class="line">session_cached_cursors integer <span class="number">20</span></span><br><span class="line">session_max_open_files integer <span class="number">10</span></span><br><span class="line">sessions integer <span class="number">170</span></span><br><span class="line">shared_server_sessions integer</span><br></pre></td></tr></table></figure>

<p>修改</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&gt; alter system set sessions=<span class="number">1105</span> scope = spfile;</span><br></pre></td></tr></table></figure>

<p>sessions是个派生值,由processes的值决定,公式sessions=1.1*process + 5</p>
<p>因为修改的是spfile,所以并不会立即生效，只有重新启动oracle，设置才会生效。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>ORA-19815</title>
    <url>/2020/06/26/ora-19815/</url>
    <content><![CDATA[<a id="more"></a>
<p>客户端连接失败，提示ORA-19815，alert.log有以下提示：<br>Errors in file /u01/app/oracle/admin/orcl/bdump/orcl_arc0_2734.trc:<br>ORA-19815: WARNING: db_recovery_file_dest_size of 2147483648 bytes is 100.00% used, and has 0 remaining bytes available.<br>Wed Jun 24 09:02:21 2020</p>
<hr>
<p>You have following choices to free up space from flash recovery area:</p>
<ol>
<li>Consider changing RMAN RETENTION POLICY. If you are using Data Guard,<br>then consider changing RMAN ARCHIVELOG DELETION POLICY.</li>
<li>Back up files to tertiary device such as tape using RMAN<br>BACKUP RECOVERY AREA command.</li>
<li>Add disk space and increase db_recovery_file_dest_size parameter to<br>reflect the new space.</li>
<li>Delete unnecessary files using RMAN DELETE command. If an operating<br>system command was used to delete files, then use RMAN CROSSCHECK and<br>DELETE EXPIRED commands.</li>
</ol>
<p>查看磁盘空间还有很多剩余空间，是因为默认的归档目标设置为USE_DB_RECOVERY_FILE_DEST，并且flash_recovery_area的最大尺寸设置为了2GB(db_recovery_file_dest_size= 2147483648)，可以有多种方法来解决此问题，通过设置RMAN归档保持策略来自动删除过期的日志文件。也可以使用RMAN DELETE来删除日志文件。如果使用操作系统命令直接删除归档文件，并不能真正释放空间，还需要执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target /</span><br><span class="line">rman&gt; crosscheck archivelog all;</span><br><span class="line">rman&gt; <span class="keyword">delete</span> expired archivelog all;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g 重做日志归档路径参数</title>
    <url>/2011/10/31/oracle-10g-archive-destination/</url>
    <content><![CDATA[<p>oracle 10g redo log归档路径参数</p>
<a id="more"></a>
<p>oracle 10g版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select * <span class="keyword">from</span> v$version;</span><br><span class="line"></span><br><span class="line">BANNER</span><br><span class="line">----------------------------------------------------------------</span><br><span class="line">Oracle Database 10g Enterprise Edition Release <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> - 64bi</span><br><span class="line">PL/SQL Release <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> - Production</span><br><span class="line">CORE <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> Production</span><br><span class="line">TNS <span class="keyword">for</span> <span class="number">64</span>-bit Windows: Version <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> - Production</span><br><span class="line">NLSRTL Version <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> - Production</span><br></pre></td></tr></table></figure>

<p>oracle 10g默认的归档路径为USE_DB_RECOVERY_FILE_DEST</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; archive log list</span><br><span class="line">Database log mode No Archive Mode</span><br><span class="line">Automatic archival Disabled</span><br><span class="line">Archive destination USE_DB_RECOVERY_FILE_DEST</span><br><span class="line">Oldest online log sequence <span class="number">9</span></span><br><span class="line">Current log sequence <span class="number">11</span></span><br></pre></td></tr></table></figure>
<p>查看该参数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; show parameter db_recovery_file_dest;</span><br><span class="line"></span><br><span class="line">X:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\flash_recovery_area</span><br></pre></td></tr></table></figure>
<p>修改归档路径</p>
<p>LOG_ARCHIVE_DEST参数用来设置本地归档，LOG_ARCHIVE_DUPLEX_DEST参数设置第二个本地归档路径，而LOG_ARCHIVE_DEST_n既可以设置本地归档路径，也可以设置网络归档路径，dataguard环境下需要使用这组参数。</p>
<p>db_recovery_file_dest,LOG_ARCHIVE_DEST以及LOG_ARCHIVE_DEST_n这三组参数是互不兼容的，设置其中一组，必须将其他两组的参数置空,否则会提示错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">02097</span>: parameter cannot be modified because specified value is invalid</span><br><span class="line">ORA-<span class="number">16018</span>: cannot use LOG_ARCHIVE_DEST <span class="keyword">with</span> LOG_ARCHIVE_DEST_n or DB_RECOVERY_FILE_DEST</span><br></pre></td></tr></table></figure>
<p>设置log_archive_dest参数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter system set db_recovery_file_dest=<span class="string">&#x27;&#x27;</span>;</span><br><span class="line">SQL&gt; alter system set log_archive_dest=<span class="string">&#x27;path to store redo logs&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>当使用LOG_ARCHIVE_DEST_n参数时，还要设置LOG_ARCHIVE_DEST_STATE_n参数来启用或禁止相对应的归档路径。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g 控制文件冗余</title>
    <url>/2011/11/12/oracle-10g-control-files/</url>
    <content><![CDATA[<p>oracle 10g 默认安装会在oracle/product/10.2.0/oradata/${ORACLE_SID}/下生成3个控制文件</p>
<a id="more"></a>
<p>分别为CONTROL01.CTL,CONTROL02.CTL和CONTROL03.CTL,由spfile参数CONTROL_FILES指定这三个控制文件的位置。这三个控制文件其实是完全一样的，其中两个为冗余备份。</p>
<p>如果其中任意一个控制文件损坏，则数据库会当机，因为spfile引用了全部三个控制文件，此时可以通过修改CONTROL_FILES参数剔除损坏的控制文件，或者用完整的控制文件来覆盖损坏的控制文件，这样就可以正常启动数据库了，当然前提是至少有一个控制文件是完整无误的。</p>
<p>默认情况下oracle将三个控制文件放到了同一个目录，这样风险相对较高，可以将三个控制文件分散到不同的驱动器上提高安全性，同时可以提高控制文件的写入效率。只要修改CONTROL_FILES参数，并将控制文件拷贝到对应的路径下，关闭并重新打开数据库即可。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g 增量备份机制</title>
    <url>/2012/03/21/oracle-10g-incremental-backup/</url>
    <content><![CDATA[<p>oracle从10g开始有了真正的增量备份机制。</p>
<a id="more"></a>
<p><strong>块变化跟踪</strong></p>
<p>为什么说“真正”呢,因为之前的版本在做增量备份时需要全扫描数据库,查找变化了的数据块,其实这样还不如做全备份,所以十分鸡肋。而10g开始对增量备份机制进行了改进,可以实时跟踪自上次备份以来变化了的数据块,这样进行增量备份时只要读取这个列表然后备份变化了的数据块即可,不用全库扫描自然会快很多,减轻系统IO负载。</p>
<p>但默认情况下这种跟踪机制并没有打开。</p>
<p>1、查询跟踪机制是否打开</p>
<p>SQL&gt;select filename,status from v$block_change_tracking;<br>STATUS</p>
<hr>
<p>DISABLED</p>
<p>2、打开块变化跟踪机制</p>
<p>SQL&gt;alter database enable block change tracking using file ‘/u01/app/oracle/product/10.2.0/oradata/db_target/block_change.log’;</p>
<p>Database altered.</p>
<p><strong>增量备份类型和级别</strong></p>
<p>RMAN提供了两种增量备份类型:DIFFERENTIAL(差异增量)和CUMULATIVE(累积增量)。默认情况下RMAN创建的增量备份是DIFFERENTIAL方式,如果要建立CUMULATIVE方式的增量备份,需要要在执行BACKUP命令时显式指定。</p>
<p>DIFFERENTIAL方式备份自上次更高级别或同级别的备份以来变化的数据块,而CUMULATIVE方式则备份自上次更高级别的备份以来变化的数据块。</p>
<p>oracle 10g只支持两个备份级别0级和1级,虽然其他级别可能也可以使用,但官方只提到了这两个备份级别。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g 日志分析工具LogMiner简单使用</title>
    <url>/2014/02/12/oracle-10g-logminer-usage/</url>
    <content><![CDATA[<p>LogMiner用于分析REDO日志,既可以分析online redo log file,也可以分析archive redo log file。</p>
<a id="more"></a>
<p>最近因为要分析一个数据库的表结构,所以想起了logminer。这个数据库没有表结构说明,应用程序也只有一部分源代码,想了解库结构,logminer正好派上用场了。</p>
<p>先切换日志,然后在应用程序中做一些操作,然后分析当前redo日志,就可以看到哪些表的哪些字段做了修改。</p>
<p>这里使用的是windows平台上的oracle 10g 10.2.0.4数据库(一个服务器上的测试环境)。</p>
<p><strong>简单步骤</strong></p>
<ol>
<li> <strong>安装logmnr包</strong></li>
</ol>
<p>安装logminer的两个包DBMS_LOGMNR和DBMS_LOGMNR_D,系统默认安装自带了logminer包。<br>[sql]</p>
<blockquote>
<p>conn / as sysdba<br>SQL&gt; @D:\oracle\product\10.2.0\db_1\RDBMS\ADMIN\dbmslm.sql<br>SQL&gt; @D:\oracle\product\10.2.0\db_1\RDBMS\ADMIN\dbmslmd.sql<br>SQL&gt; @D:\oracle\product\10.2.0\db_1\RDBMS\ADMIN\dbmslms.sql<br>[/sql]<br>2.  <strong>添加附加日志支持</strong></p>
</blockquote>
<p>打开Supplemental Logging,可以获得更多的日志信息<br>使用下面的语句之一开启Supplemental Logging的不同程度的支持:<br>[sql]SQL&gt;ALTER DATABASE ADD SUPPLEMENTAL LOG DATA (PRIMARY KEY, UNIQUE INDEX) COLUMNS;[/sql]<br>或者<br>[sql]SQL&gt;ALTER DATABASE ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;[/sql]</p>
<ol start="3">
<li> <strong>创建数据字典</strong><br>[sql]<br>SQL&gt; alter system set utl_file_dir=’d:\oracle\logmnr’ scope=spfile;<br>SQL&gt; EXECUTE dbms_logmnr_d.build(‘dictionary.ora’,’d:\oracle\logmnr’);<br>SQL&gt; shutdown immediate;<br>SQL&gt; startup;<br>[/sql]<br>如果logminer数据库与被分析的日志文件都在同一个数据库中,也可以使用在线数据字典。</li>
<li> <strong>添加要分析的日志文件</strong></li>
</ol>
<p>切换日志,做一些操作后,就可以将日志文件添加到logminer进行分析<br>[sql]<br>SQL&gt; ALTER SYSTEM SWITCH LOGFILE;<br>…<br>SQL&gt; EXECUTE dbms_logmnr.add_logfile(LogFileName=&gt;’D:\oracle\product\10.2.0\<br>oradata\orcl\REDO03.log’,Options=&gt;dbms_logmnr.new);<br>[/sql]<br>注意第一个添加的日志使用参数dbms_logmnr.new,后续添加的日志使用dbms_logmnr.addfile,如:<br>[sql]<br>EXECUTE dbms_logmnr.add_logfile(LogFileName=&gt;’D:\oracle\product\10.2.0\oradata\orcl\<br>REDO01.log’,Options=&gt;dbms_logmnr.addfile);<br>[/sql]<br>去掉要分析的日志文件使用如下命令:<br>[sql]<br>SQL&gt;execute dbms_logmnr.remove_logfile(logfilename=&gt;’\path\to\redofile’);<br>[/sql]<br>5.  <strong>分析日志文件</strong></p>
<p>使用生成的字典分析日志文件:<br>[sql]<br>SQL&gt; execute dbms_logmnr.start_logmnr(dictfilename=&gt;’d:\oracle\logmnr\dictionary.ora’);<br>[/sql]<br>使用在线字典分析日志文件:<br>[sql]<br>SQL&gt; execute dbms_logmnr.start_logmnr(Options =&gt; DBMS_LOGMNR.DICT_FROM_ONLINE_CATALOG);<br>[/sql]</p>
<p>可以通过指定时间段或SCN段来限定日志分析范围,提高分析速度:<br>[sql]SQL&gt;execute dbms_logmnr.start_logmnr (dictfilename =&gt;’dictionary.ora’，<br>starttime =&gt;to_date(‘01-Aug-2013 08:30:00’, ‘DD-MON-YYYY HH:MI S’),<br>endtime =&gt; to_date(‘01-Aug-2013 08:50:00’, ‘DD-MON-YYYY HH:MI S’));[/sql]<br>或<br>[sql]<br>SQL&gt; execute dbms_logmnr.start_logmnr (dictfilename =&gt;’dictionary.ora’,<br>startscn =&gt;1000,endscn =&gt;1050);<br>[/sql]<br>6.  <strong>查询结果</strong></p>
<p>分析结果在表v$logmnr_contents中,表中关键的字段有:<br>sql_redo - 所做的sql语句<br>username - 执行sql的数据库用户名<br>operation - sql操作类型,比如INSERT,DELETE等<br>table_name - sql操作的表名字<br>比如根据特征字符串这样查询:<br>[sql]<br>SQL&gt; select sql_redo,table_name from v$logmnr_contents<br>where operation=’INSERT’ and sql_redo like ‘%foobar%’;<br>[/sql]</p>
<p>可以使用DESC获取v$logmnr_contents完整的字段列表。</p>
<ol start="7">
<li> <strong>退出logminer</strong></li>
</ol>
<p>[sql]SQL&gt; execute dbms_logmnr.end_logmnr;[/sql]</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 10g 超过最大进程数</title>
    <url>/2011/05/07/oracle-10g-processes-exceeded/</url>
    <content><![CDATA[<p>Oracle 10g 超过最大进程数错误ORA-00020的解决办法</p>
<a id="more"></a>
<p>今天升级业务系统,升级完毕后遇到,打开应用出现错误提示</p>
<blockquote>
<p>Microsoft OLE DB Provider for Oracle 错误 ‘80004005 ORA-12518: TNS: 监听程序无法分发客户机连接</p>
</blockquote>
<p>查看oracle\product\10.2.0\admin\orcl\udump\目录下的trc文件(trace file),发现有如下提示：</p>
<blockquote>
<p>ORA-00020: maximum number of processes 150 exceeded</p>
</blockquote>
<p>原来是超过了默认的最大进程数150，这主要是因为应用程序写的有问题，彻底解决还要找出应用程序的问题。</p>
<p>临时的解决办法是适当增加oracle 10g的最大进程数</p>
<p>SQL&gt;alter system set processes=300 scope=spfile;<br>SQL&gt;shutdown immediate;<br>SQL&gt;startup;</p>
<p>查看数据库设置的进程数<br>SQL&gt; select value from v$parameter where name = ‘processes’;<br>或者<br>SQL&gt;show parameter process;</p>
<p>查看已经存在的进程数<br>SQL&gt; select count(*) from v$process;</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 10g重新配置Enterprise Manager</title>
    <url>/2011/04/25/oracle-10g-reconfig-enterprise-manager/</url>
    <content><![CDATA[<p>在一台新服务器上安装oracle 10g 10.2.0.4,操作系统平台为windows 2003 R2 x64,</p>
<a id="more"></a>
<p>安装进度到85%时出现错误提示</p>
<p>“由于以下错误,Enterprise Manager配置失败 - 用户名/口令无效。[ORA-01012: not logged on] 有关详细资料，请参阅E:\oracle\product\10.2.0\db_1\cfgtoollogs\dbca\orcl\emConfig.log中的日志文件。您可以以后通过手动运行E:\oracle\product\10.2.0\db_1\bin\dmca脚本，重新使用Enterprise Manager配置此数据库。”</p>
<p>这应该也是因为CA证书过期的问题导致em无法配置,但与以前出现的错误却不同。先参考<a href="https://openwares.net/database/x64_oracle_10g_emdbconsole_error.html">x64安装oracle 10.2.0.4无法启动em dbconsole问题解决</a>打上Patch 8350262</p>
<p><strong>重新配置em</strong></p>
<p>设置好环境变量ORACLE_HOME和ORACLE_SID,然后cmd命令行执行以下命令删除掉原来的Database Control repository</p>
<blockquote>
<p>emca -deconfig dbcontrol db -repos drop</p>
</blockquote>
<p>根据提示输入sid,端口号1521,口令,最后输入Y确认<br>然后输入以下命令重新建立Database Control repository</p>
<blockquote>
<p>emca -config dbcontrol db -repos create</p>
</blockquote>
<p>重建完成后重新启动一下服务ORacleDBConsole或重新启动机器<br>浏览器输入<a href="https://localhost:1158/em%E8%AE%BF%E9%97%AEEnterprise">https://localhost:1158/em访问Enterprise</a> Manager即可</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g使用物理备库恢复主库损坏/丢失的数据文件</title>
    <url>/2019/09/25/oracle-10g-recover-primary-datafiles-by-standby-database/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>0 症状</strong></p>
<p>oracle 10g dataguard主库某一数据文件发现有损坏，使用dbv检测数据文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&gt; dbv file=E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\db_1\\database\\afsts.dbf feedback=<span class="number">100</span></span><br><span class="line">....</span><br><span class="line">DBV-<span class="number">00102</span>: File I/O error on FILE (E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\db_1\\database\\afsts.dbf) during verification read operation (-<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>操作系统中拷贝数据文件会出现错误”无法复制 AFSTS: 数据错误(循环冗余检查)。”，事件查看器中发现错误“设备 \Device\Harddisk1\DR1 有一个不正确的区块。”，数据文件有物理损坏。</p>
<p>此时数据文件无法拷贝和删除，需要将数据文件离线，然后用chkdsk系统工具修复，或者使用“分区”右键属性里的”工具”-&gt;”查错”-&gt;“开始检查”,选中“自动修复文件系统错误”</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&gt; chkdsk e: <span class="regexp">/F /</span>I /C</span><br></pre></td></tr></table></figure>
<p>/I和/C用于跳过部分检查，减少扫描时间。<br>修复错误后，数据文件的内容可能已经不正确了，需要使用standby数据库数据文件恢复。</p>
<p><strong>注：使用rman restore数据文件可以直接恢复，无需提前修复文件系统错误。</strong></p>
<p><strong>1 修复</strong></p>
<p>1.1 首先确保用于恢复的数据文件是没有损坏的</p>
<p>备库端:</p>
<p>a. dbv检查</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&gt; dbv file=E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\db_1\\database\\afsts.dbf feedback=<span class="number">100</span></span><br><span class="line">........</span><br><span class="line">Total Pages Examined : <span class="number">61440</span></span><br><span class="line">Total Pages Processed (Data) : <span class="number">70</span></span><br><span class="line">Total Pages Failing (Data) : <span class="number">0</span></span><br><span class="line">Total Pages Processed (Index): <span class="number">58217</span></span><br><span class="line">Total Pages Failing (Index): <span class="number">0</span></span><br><span class="line">Total Pages Processed (Other): <span class="number">1009</span></span><br><span class="line">Total Pages Processed (Seg) : <span class="number">0</span></span><br><span class="line">Total Pages Failing (Seg) : <span class="number">0</span></span><br><span class="line">Total Pages Empty : <span class="number">2144</span></span><br><span class="line">Total Pages Marked Corrupt : <span class="number">0</span></span><br><span class="line">Total Pages Influx : <span class="number">0</span></span><br><span class="line">Highest block SCN : <span class="number">1519113269</span> (<span class="number">2.1519113269</span>)</span><br></pre></td></tr></table></figure>
<p>确保Total Pages Failing (Data),Total Pages Failing (Index),Total Pages Failing (Seg) 和Total Pages Marked Corrupt皆为0</p>
<p>b. rman检查</p>
<p>找出数据文件的编号</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">sql&gt; select FILE#,NAME,STATUS from v$datafile where name like &#x27;%AFSTS.DBF%&#x27;;</span><br></pre></td></tr></table></figure>

<p>数据文件检查</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target sys/password@db_feich;</span><br><span class="line">RMAN&gt; backup validate check logical datafile <span class="number">20</span>;</span><br><span class="line">SQL&gt; select * <span class="keyword">from</span> v$database_block_corruption;</span><br></pre></td></tr></table></figure>
<p>因为物理standby是mounted状态，是不可写的。所以此检查对于正在进行日志恢复的standby是无法实施的。</p>
<p>1.2 备库端操作</p>
<p>备份数据文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target sys/password@db_standby;</span><br><span class="line">RMAN&gt; backup <span class="keyword">as</span> copy datafile <span class="number">20</span> format <span class="string">&#x27;d:\\afsts.bak&#x27;</span>;</span><br><span class="line"><span class="comment">//RMAN&gt; backup datafile 20 format &#x27;d:\\afsts.bak&#x27;;</span></span><br></pre></td></tr></table></figure>

<p>1.3 主库端操作</p>
<p>a. 将备库备份的数据文件拷贝到主库相同的目录结构下</p>
<p>b. 将备份加入恢复目录catalog</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target sys/password@db_primary;</span><br><span class="line">RMAN&gt; catalog datafilecopy <span class="string">&#x27;d:\\afsts.bak&#x27;</span>;</span><br><span class="line">RMAN&gt; list datafilecopy all;</span><br><span class="line">RMAN&gt; list datafilecopy <span class="string">&#x27;d:\\afsts.bak&#x27;</span>;</span><br><span class="line"><span class="comment">//RMAN&gt; catalog backuppiece &#x27;d:\\afsts.bak&#x27;;</span></span><br><span class="line"><span class="comment">//RMAN&gt; list backup of datafile 20;</span></span><br><span class="line"><span class="comment">//RMAN&gt; list backuppiece &#x27;d:\\afsts.bak&#x27;;</span></span><br></pre></td></tr></table></figure>

<p>c. 数据文件离线</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sqlplus sys/password@db_primary <span class="keyword">as</span> sysdba;</span><br><span class="line">SQL&gt; alter database datafile <span class="number">20</span> offline;</span><br></pre></td></tr></table></figure>

<p>d. restore/recover数据文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target sys/password@db_primary;</span><br><span class="line">RMAN&gt; restore datafile <span class="number">20</span>;</span><br><span class="line">RMAN&gt; recover datafile <span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<p>e. 数据文件上线</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; sql <span class="string">&#x27;alter database datafile 20 online&#x27;</span>;</span><br><span class="line"><span class="comment">//SQL&gt; alter database datafile 20 online;</span></span><br></pre></td></tr></table></figure>

<p>f. 检查数据文件完整性</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; backup validate check logical datafile <span class="number">20</span>;</span><br><span class="line">SQL&gt; select * <span class="keyword">from</span> v$database_block_corruption;</span><br><span class="line">no rows selected</span><br></pre></td></tr></table></figure>
<p>也可以再用dbv检查一下</p>
<p>完毕，也可以用主库数据文件恢复备库丢失或损坏的数据文件，只不过操作方向不同而已。</p>
<p>References:<br>[1]<a href="https://support.oracle.com/knowledge/Oracle%20Database%20Products/453153_1.html#aref_section22">Recovering the primary database’s datafile using the physical standby, and vice versa (Doc ID 453153.1)</a><br>[2]<a href="http://yvrk1973.blogspot.com/2012/08/recover-primary-databases-datafile.html">Recover the Primary Database’s datafile using a copy of a Physical Standby Database’s Datafile</a><br>[3]<a href="https://shivanandarao-oracle.com/2014/05/03/recovering-a-corruptedlost-datafile-on-primary-database-from-the-standby-database/">Recovering a corrupted/lost datafile on Primary database from the Standby database</a><br>[4]<a href="http://oracle-help.com/dataguard/steps-to-recover-the-standby-databases-datafile-using-backup-of-primary-databases-datafile/">Steps to recover the standby database’s datafile using a backup of the primary database’s data file</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>oracle 10g 修改SGA,PGA大小</title>
    <url>/2011/02/15/oracle-10g-sga-size/</url>
    <content><![CDATA[<p>一、概念<br>SGA指系统全局区域(System Global Area),是用于存储数据库信息的内存区，该信息为数据库进程所共享。</p>
<a id="more"></a>
<p>PGA指进程全局区域(Process Global Area),包含单个服务器进程或单个后台进程的数据和控制信息，与几个进程共享的SGA 正相反,PGA 是只被一个进程使用的区域，PGA 在创建进程时分配,在终止进程时回收。 Oracle 10g提供了PGA内存的自动管理。参数pga_aggregate_target可以指定PGA内存的最大值。当参数 pga_aggregate_target大于0时，Oracle将自动管理pga内存，并且各进程的所占PGA之和，不大于 pga_aggregate_target所指定的值。</p>
<p>二、配置<br>oracle推荐OLTP(on-line Transaction Processing)系统oracle占系统总内存的80%,然后再分配80%给SGA,20%给PGA。也就是<br>SGA=system_total_memory*80%<em>80%<br>PGA=system_total_memory</em>80%*20%</p>
<p>三、操作<br>用SYS用户以SYSDBA身份登录系统<br>alter system set sga_max_size=2000m scope=spfile;<br>alter system set sga_target=2000m scope=spfile;<br>alter system set pga_aggregate_target=500m scope=spfile;</p>
<p>然后重新启动数据库<br>最后查看一下是否生效<br>show parameter sga_max_size;<br>show parameter sga_target;<br>show parameter pga_aggregate_target;</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle 10g DataGuard手记之基础配置</title>
    <url>/2011/12/27/oracle-10g-windows-x64-dataguard/</url>
    <content><![CDATA[<p>DataGuard为企业数据的高可用性,数据安全以及灾难恢复提供支持,一般由一个primary db与几个物理或逻辑standby db组成一个DataGuard配置。</p>
<a id="more"></a>
<p><strong>系统环境</strong></p>
<p>操作系统为windows server 2003 r2 enterprise x64 edition service pack 2,database为oracle 10g 10.2.0.4 enterprise x64 edition。服务器均为AMD64架构,主机RAID5本地硬盘加RAID1光纤盘阵。</p>
<p>primary库：<br>ip 10.0.0.1<br>$ORACLE_BASE E:\ORACLE<br>$ORACLE_HOME E:\ORACLE\PRODUCT\10.2.0\DB_1<br>$ORACLE_SID orcl</p>
<p>standby库standby01：<br>ip 10.0.0.2<br>$ORACLE_BASE E:\ORACLE<br>$ORACLE_HOME E:\ORACLE\PRODUCT\10.2.0\DB_1<br>$ORACLE_SID orcl</p>
<p>主库primary与(第一个)物理备库standby01的oracle版本与物理结构是完全一致的,所有oracle文件的路径在两台服务器上都是一样的。</p>
<p><strong>方案</strong></p>
<p>配置DataGuard的目标是保证业务系统数据的最高可用性,迅速从硬件故障,数据损坏或灾难中恢复数据库。物理standby性能和稳定性都优于逻辑standby,并且由于备库不需要用于查询,因此备库采用物理standby模式。</p>
<p>DataGuard有三种保护模式,最大性能模式,最大可用模式和最大保护模式。</p>
<ul>
<li><p>  最大保护模式可以确保没有数据丢失。这种模式要求所有的事务在提交前其redo数据不但要写入本地online redo log,还要同时提交到standby的standby redo log,并确认redo数据至少在一个standby上可用,然后才会在primary上提交该事务。当出现故障导致无standby可用时,primary会shutdown,直到至少有一个standby恢复。</p>
</li>
<li><p>  最大性能模式是dataguard默认的数据保护模式。在这种模式下,只要redo数据写到本地online redo log中事务就可以提交。primary仍然向standby写入redo logs,但这种写入是异步的,对产生redo数据的事务没有影响。最大性能模式对系统的影响最小,但有丢失数据的风险。</p>
</li>
<li><p>  最大可用模式是这两种模式的折衷,在正常情况下,最大可用模式和最大保护模式是一样的,同样要求事务提交前其redo数据不但要写入到本地online redo log还要至少写入到一个standby的standby redo log。但在standby出现故障不可用时，最大可用模式会自动降低成最大性能模式。当故障消除并且standby的redo log与primary完全同步后,primary会自动的恢复到最大可用模式运行。这种情况下dataguard消除redo log gaps时会使用到FAL_SERVER和FAL_CLIENT这两个参数。所以standby故障不会导致primay不可用。只要至少有一个standby可用的情况下，即使primary down掉，也能保证不丢失数据。</p>
</li>
</ul>
<p>因为系统环境较好,可以配置多个物理standby,系统可用性要求高,并且可以容忍极少量数据丢失,因此采用最高可用模式。</p>
<p><strong>DataGuard基础配置</strong></p>
<p><strong>主库(primary)端配置：</strong><br> <strong>1、打开force logging模式</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database force logging;</span><br></pre></td></tr></table></figure>
<p>然后查询</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select force_logging <span class="keyword">from</span> v$database;</span><br><span class="line">FOR</span><br><span class="line">---</span><br><span class="line">YES</span><br></pre></td></tr></table></figure>
<p>说明已经开启FORCE LOGGING模式</p>
<p><strong>2、创建密码文件</strong><br>如果密码文件不存在需要<a href="https://openwares.net/database/oracle_passwd_file.html">创建密码文件</a>,DataGuard配置里面的每一个数据库都必须使用密码文件,并且所有数据库的SYS用户密码必须相同,这样才能成功的传输REDO LOGS。主库安装时已经自动创建了密码文件,备库安装时也使用相同的SYS密码进行安装并自动创建密码文件,所以此时不必再重复创建密码文件。</p>
<p><strong>3、配置Standby Redo Log</strong></p>
<p>最大保护模式和最大可用模式必须使用standby redo log,并且推荐所有的数据库都使用LGRW ASYNC日志传输模式。创建standby数据库时就要计划好standby redo log的配置,并创建所有需要的日志组和组成员。为了增加可用性,可以多路standby redo log文件,就像多路online redo log文件那样。多路时每个日志组内的所有日志文件内容都是一样的,可以将它们分散到不同的驱动器上以提高可用性和IO性能。</p>
<p>创建standby redo log的步骤如下：</p>
<p>1)确保日志文件的大小与主、备库online redo log文件的大小保持一致。这样日志传输和应用都比较方便。</p>
<p>2)确定适当数目的standby redo log日志组<br>standby redo log日志组至少要比online redo log日志组多一个。然而官方推荐根据primary数据库的线程数来计算standby redo log日志组的数量,参考公式如下</p>
<p>(每线程的日志组数+1)*线程数</p>
<p>这样可以降低primary库LGRW进程被阻塞的可能性。<br>比如,primary有两个线程,每个线程有两个日志组,那么推荐配置6个standby redo log日志组。<br>单实例数据库只有一个线程,所以配置比默认的3组online redo log多一组即4组standby redo log即可。 </p>
<p>3)创建standby redo log日志组</p>
<p>正常情况下standby redo log日志组仅需要在Standby库进行配置，考虑到主备切换，在primary端亦进行配置<br>先查询一下online redo log日志文件的大小</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select group#,thread#,archived,status,bytes/1024/1024 from v$log;</span><br><span class="line">GROUP# THREAD# ARC STATUS BYTES/1024/1024</span><br><span class="line">------ ---------- --- ---------------- ---------------</span><br><span class="line"> <span class="number">1</span> <span class="number">1</span> YES INACTIVE <span class="number">50</span></span><br><span class="line"> <span class="number">2</span> <span class="number">1</span> NO CURRENT <span class="number">50</span></span><br><span class="line"> <span class="number">3</span> <span class="number">1</span> YES INACTIVE <span class="number">50</span></span><br></pre></td></tr></table></figure>
<p>online redo log日志文件的大小为50M,组号为1-3,所以standby redo log日志组的组号为4-7,下面创建standby redo log日志组</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database add standby logfile group <span class="number">4</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO01.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br><span class="line">SQL&gt; alter database add standby logfile group <span class="number">5</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO02.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br><span class="line">SQL&gt; alter database add standby logfile group <span class="number">6</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO03.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br><span class="line">SQL&gt; alter database add standby logfile group <span class="number">7</span> (<span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\STDBYREDO04.LOG&#x27;</span>) size 50M;</span><br><span class="line">Database altered.</span><br></pre></td></tr></table></figure>
<p>验证standby redo log日志组是否创建成功</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; SELECT GROUP#,THREAD#,SEQUENCE#,ARCHIVED,STATUS FROM V$STANDBY_LOG</span><br><span class="line"> GROUP# SEQUENCE# ARC STATUS</span><br><span class="line">---------- ---------- --- ----------</span><br><span class="line"> <span class="number">4</span> <span class="number">0</span> YES UNASSIGNED</span><br><span class="line"> <span class="number">5</span> <span class="number">0</span> YES UNASSIGNED</span><br><span class="line"> <span class="number">6</span> <span class="number">0</span> YES UNASSIGNED</span><br><span class="line"> <span class="number">7</span> <span class="number">0</span> YES UNASSIGNED</span><br></pre></td></tr></table></figure>
<p><strong>4、设置oracle net service names</strong></p>
<p>在主库primary的$ORACLE_HOME/NETWORK/ADMIN/tnsname.ora文件中添加如下oracle net service name,primary标识主库和standby01标识(第一个)物理备库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">primary =</span><br><span class="line"> (DESCRIPTION =</span><br><span class="line"> (ADDRESS = (PROTOCOL = TCP)(HOST = <span class="number">10.0</span><span class="number">.0</span><span class="number">.1</span>)(PORT = <span class="number">1521</span>))</span><br><span class="line"> (CONNECT_DATA =</span><br><span class="line"> (SERVER = DEDICATED)</span><br><span class="line"> (SERVICE_NAME = orcl)</span><br><span class="line"> )</span><br><span class="line"> )</span><br><span class="line"></span><br><span class="line">standby01 =</span><br><span class="line"> (DESCRIPTION =</span><br><span class="line"> (ADDRESS = (PROTOCOL = TCP)(HOST = <span class="number">10.0</span><span class="number">.0</span><span class="number">.2</span>)(PORT = <span class="number">1521</span>))</span><br><span class="line"> (CONNECT_DATA =</span><br><span class="line"> (SERVER = DEDICATED)</span><br><span class="line"> (SERVICE_NAME = orcl)</span><br><span class="line"> )</span><br><span class="line"> )</span><br></pre></td></tr></table></figure>
<p><strong>5、设置primary初始化参数</strong><br>对于primary数据库,作为primary脚色需要定义几个初始化参数控制redo传输服务。还有几个附加的初始化参数需要定义以控制redo数据的接收和日志应用服务,当primary库转换到standby角色时会使用这些参数,方便主备库角色转换。</p>
<p><a href="https://openwares.net/database/dataguard_init_paras.html">DataGuard相关的初始化参数</a>详细解释见<a href="https://openwares.net/database/dataguard_init_paras.html">这里</a></p>
<p>因为需要修改的初始化参数较多,先从spfile导出pfile,然后用编辑pfile,最后再用pfile重建spfile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; create pfile <span class="keyword">from</span> spfile;</span><br></pre></td></tr></table></figure>
<p>会在$ORACLE_HOME/database/目录下生成INITorcl.ora</p>
<p>下面是primary库需要修改或添加的初始化参数：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">DB_NAME=<span class="string">&#x27;orcl&#x27;</span></span><br><span class="line">DB_UNIQUE_NAME=<span class="string">&#x27;primary&#x27;</span></span><br><span class="line">LOG_ARCHIVE_CONFIG=<span class="string">&#x27;DG_CONFIG=(primary,standby01)&#x27;</span></span><br><span class="line">LOG_ARCHIVE_DEST_1=<span class="string">&#x27;LOCATION=D:\\archived_log\\ VALID_FOR=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=primary&#x27;</span></span><br><span class="line">LOG_ARCHIVE_DEST_2=<span class="string">&#x27;SERVICE=standby01 LGWR ASYNC VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=standby01&#x27;</span></span><br><span class="line">LOG_ARCHIVE_DEST_STATE_1=enable</span><br><span class="line">LOG_ARCHIVE_DEST_STATE_2=enable</span><br></pre></td></tr></table></figure>
<p><strong>注</strong>：因为LOG_ARCHIVE_DEST_n与LOG_ARCHIVE_DEST(LOG_ARCHIVE_DUPLEX_DEST)参数不兼容,因此需要把LOG_ARCHIVE_DEST(LOG_ARCHIVE_DUPLEX_DEST)参数reset为空,归档日志路径问题详见<a href="https://openwares.net/2011/10/31/oracle_10g_archive_destination/">oracle 10g重做日志归档路径参数</a>。</p>
<p><strong>注</strong>：LOG_ARCHIVE_DEST_1指定的本地归档目录必须在参数生效前已经存在,不然启动数据库时会报如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">16032</span>: parameter LOG_ARCHIVE_DEST_1 destination string cannot be translated</span><br><span class="line">ORA-<span class="number">09291</span>: sksachk: invalid device specified <span class="keyword">for</span> archive destination</span><br><span class="line">OSD-<span class="number">04018</span>: Unable to access the specified directory or device.</span><br><span class="line">O/S-<span class="built_in">Error</span>: (OS <span class="number">2</span>) XXXXXXXXXXXXXXXXXXXX</span><br></pre></td></tr></table></figure>
<p>下面是standby脚色需要的初始化参数,为primary设置这些参数以方便在primary与standby脚色之间转换</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">FAL_SERVER=standby01</span><br><span class="line">FAL_CLIENT=primary</span><br><span class="line">STANDBY_FILE_MANAGEMENT=auto</span><br></pre></td></tr></table></figure>
<p>修改完毕后用pfile创建spfile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; shutdown immediate</span><br><span class="line">SQL&gt; create spfile <span class="keyword">from</span> pfile=<span class="string">&#x27;INITorcl.ora&#x27;</span></span><br><span class="line">SQL&gt; startup</span><br></pre></td></tr></table></figure>
<p><strong>6、确保primary处于归档模式</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; archive log list</span><br><span class="line">Database log mode Archive Mode</span><br><span class="line">Automatic archival Enabled</span><br></pre></td></tr></table></figure>
<p>如果并未打开归档模式,执行以下命令将数据库置于归档模式</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; shutdown immediate;</span><br><span class="line">SQL&gt; startup mount;</span><br><span class="line">SQL&gt; alter database archivelog;</span><br><span class="line">SQL&gt; alter database open;</span><br></pre></td></tr></table></figure>
<p><strong>7、为物理备库生成control文件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database create standby controlfile <span class="keyword">as</span> <span class="string">&#x27;\\path\\to\\control_file&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p><strong>物理备库(standby01)端配置</strong></p>
<p><strong>1、创建备库</strong><br>有多种方式创建物理备库,使用冷备份或RMAN或其他方法,oracle推荐使用RMAN。因为primary与standby01结构完全一致,而且primary有停库的机会,所以采用最简单的冷备份来创建物理备库standby01,方法如下：</p>
<p>需要拷贝的有密码文件,standby控制文件,数据文件,联机日志文件,初始化参数文件。初始化参数文件拷贝主库上生成并修改好的pfile INITorcl.ora,然后根据物理备库的实际情况做相应修改后生成spfile即可。</p>
<p>首先查询数据库,找到这些文件所在的位置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select name <span class="keyword">from</span> v$datafile; <span class="comment">//数据文件</span></span><br><span class="line">SQL&gt; select member <span class="keyword">from</span> v$logfile; <span class="comment">//在线日志文件</span></span><br><span class="line">SQL&gt; SELECT NAME FROM V$CONTROLFILE; <span class="comment">//控制文件</span></span><br><span class="line">SQL&gt; show parameter log_archive_dest; <span class="comment">//归档日志文件</span></span><br></pre></td></tr></table></figure>
<p>online redo log,standby redo log所在路径为<br>$ORACLE_BASE\PRODUCT\10.2.0\ORADATA\ORCL\<br>密码文件PWDorcl.ora,初始化参数文件INITorcl.ora,普通用户数据文件所在路径为<br>$ORACLE_HOME\database\<br>系统用户数据文件所在路径为<br>$ORACLE_BASE\PRODUCT\10.2.0\ORADATA\ORCL\<br>归档日志文件所在的路径为<br>D:\ARCHIVED_LOG</p>
<p>对于控制文件稍微有些不同,standby库不能直接使用primary库的控制文件,不然standby会报”ORA-01665: control file is not a standby control file”错误,需要从primary库为standby生成控制文件,在primary库端执行命令</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database create standby controlfile <span class="keyword">as</span> <span class="string">&#x27;d:\\control01.ctl&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>然后分别关闭primary和standby01</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; shutdown immediate</span><br></pre></td></tr></table></figure>
<p>将上述文件拷贝到standby01库相应的目录下,因为两边库结构完全一致,所以直接从primary拷贝$ORACLE_BASE\PRODUCT\10.2.0\ORADATA\ORCL和$ORACLE_HOME\database\这两个目录覆盖到standby对应目录下即可。</p>
<p>最后将生成的控制文件拷贝到standby01库初始化参数contro_files设置的路径,这里使用的是默认值,也就是standby01库的$ORACLE_BASE\PRODUCT\10.2.0\ORADATA\ORCL\目录下。注意控制文件是有冗余的,拷贝control01.ctl为control02.ctl和control03.ctl,分别覆盖standby01原来的三个控制文件,这三个控制文件是完全一样的。为了安全可靠,也可以修改初始化参数control_files,将三个控制文件放到不同的驱动器上面。关于控制文件见<a href="https://openwares.net/database/oracle_10g_control_files.html">oracle 10g 控制文件冗余</a>。</p>
<p><strong>2、设置oracle net service names</strong></p>
<p>在备库standby01的$ORACLE_HOME/NETWORK/ADMIN/tnsname.ora文件中添加如下oracle net service name,primary标识主库和standby01标识(第一个)物理备库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">primary =</span><br><span class="line"> (DESCRIPTION =</span><br><span class="line"> (ADDRESS = (PROTOCOL = TCP)(HOST = <span class="number">10.0</span><span class="number">.0</span><span class="number">.1</span>)(PORT = <span class="number">1521</span>))</span><br><span class="line"> (CONNECT_DATA =</span><br><span class="line"> (SERVER = DEDICATED)</span><br><span class="line"> (SERVICE_NAME = orcl)</span><br><span class="line"> )</span><br><span class="line"> )</span><br><span class="line"></span><br><span class="line">standby01 =</span><br><span class="line"> (DESCRIPTION =</span><br><span class="line"> (ADDRESS = (PROTOCOL = TCP)(HOST = <span class="number">10.0</span><span class="number">.0</span><span class="number">.2</span>)(PORT = <span class="number">1521</span>))</span><br><span class="line"> (CONNECT_DATA =</span><br><span class="line"> (SERVER = DEDICATED)</span><br><span class="line"> (SERVICE_NAME = orcl)</span><br><span class="line"> )</span><br><span class="line"> )</span><br></pre></td></tr></table></figure>
<p><strong>3、设置standby01初始化参数</strong></p>
<p>直接根据stanby角色修改从primary库拷贝过来的INITorcl.ora,下面是standby01库需要修改或添加的初始化参数：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">DB_NAME=<span class="string">&#x27;orcl&#x27;</span></span><br><span class="line">DB_UNIQUE_NAME=<span class="string">&#x27;standby01&#x27;</span></span><br><span class="line">LOG_ARCHIVE_CONFIG=<span class="string">&#x27;DG_CONFIG=(primary,standby01)&#x27;</span></span><br><span class="line">LOG_ARCHIVE_DEST_1=<span class="string">&#x27;LOCATION=D:\\archived_log\\ VALID_FOR=(ALL_LOGFILES,ALL_ROLES) DB_UNIQUE_NAME=standby01&#x27;</span></span><br><span class="line">LOG_ARCHIVE_DEST_STATE_1=enable</span><br><span class="line">FAL_SERVER=primary</span><br><span class="line">FAL_CLIENT=standby01</span><br><span class="line">STANDBY_FILE_MANAGEMENT=auto</span><br></pre></td></tr></table></figure>
<p>下列参数用于standby01从备库到主库角色转换</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">LOG_ARCHIVE_DEST_2=<span class="string">&#x27;SERVICE=primary LGWR ASYNC VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=primary&#x27;</span></span><br><span class="line">LOG_ARCHIVE_DEST_STATE_2=enable</span><br></pre></td></tr></table></figure>
<p>修改完毕后用pfile创建spfile</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; create spfile <span class="keyword">from</span> pfile=<span class="string">&#x27;INITorcl.ora&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p><strong>4、启动物理备库standby并开启redo应用</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; startup mount</span><br><span class="line">SQL&gt; alter database recover managed standby database disconnect <span class="keyword">from</span> session;</span><br></pre></td></tr></table></figure>
<p>使用下面语句停止redo应用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database recover managed standby database cancel;</span><br></pre></td></tr></table></figure>
<p><strong>5、检查物理备库standby01是否正确同步</strong></p>
<p>在primary库上手工强制归档并查询归档日志</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter system <span class="keyword">switch</span> logfile;</span><br><span class="line">SQL&gt; select max(sequence#) from v$archived_log;</span><br><span class="line">MAX(SEQUENCE#)</span><br><span class="line">--------------</span><br><span class="line"> <span class="number">486</span></span><br></pre></td></tr></table></figure>
<p>在standby01上查询归档日志</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select max(sequence#) from v$archived_log;</span><br><span class="line">MAX(SEQUENCE#)</span><br><span class="line">--------------</span><br><span class="line"> <span class="number">486</span></span><br></pre></td></tr></table></figure>

<p>如果从primary上做如下查询,能看到如下的记录</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; select name,sequence# from v$archived_log order by sequence#;</span><br><span class="line">NAME SEQUENCE#</span><br><span class="line">------------ -------------</span><br><span class="line">standby01 <span class="number">486</span></span><br><span class="line">D:\\ARCHIVED_LOG\\ARC00486_0765555401<span class="number">.001</span> <span class="number">486</span></span><br></pre></td></tr></table></figure>
<p>同一个归档文件分别写到了本地归档路径和standby01备库。</p>
<p>这说明dataguard数据同步是正确的。</p>
<p><strong>6、开启实时redo应用</strong></p>
<p>上面第4步的redo应用并不是实时的,只有当主库的online redo归档并触发备库的standby redo归档后才将归档日志的数据应用到备库,这样就会有较大的延迟,造成一段时间内主备库差异较大。<br>dataguard提供了实时应用redo日志的方法,如果开启了日志实时应用,日志应用服务会将从primary接收到的redo数据立即应用到standby库,而不会等到当前的standby redo log日志归档后再应用redo数据。实时日志应用必须要在standby库配置standby redo log文件。</p>
<p>开启redo实时应用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;</span><br></pre></td></tr></table></figure>
<p>默认dataguard运行于最大性能模式,如何升级到其他模式另文再叙。</p>
<p>P.S.:创建更多的物理standby备库并没有什么特别的,只要在primary的pfile中增加更多的网络归档路径,比如LOG_ARCHIVE_DEST_3、LOG_ARCHIVE_DEST_4等,当然对应的LOG_ARCHIVE_DEST_STATE_3、LOG_ARCHIVE_DEST_STATE_4也要设置为enable,还有参数LOG_ARCHIVE_CONFIG=’DG_CONFIG=(primary,standby01,standby02,…)’,再就是适当的设置FAL_SERVER和FAL_CLIENT就可以了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 11g dataguard 新特性</title>
    <url>/2014/10/17/oracle-11g-dataguard-new-feature/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>Active Dataguard</strong></p>
<p>在Oracle 11g之前，物理备库（physical Standby）在应用redo的时候，是不可以打开的，只可以mount。从11g开始，在应用redo的时候，物理备库可以处于read-only模式，这就称为Active Dataguard 。通过Active Dataguard，可以在物理备库进行查询或者导出数据，从而减少对主库的访问和压力。</p>
<p>Active Dataguard适用于一些只读性的应用，比如，有的应用程序只是查询数据，进行一些报表业务，不会产生redo数据，这些应用可以转移到备库上，避免对主库资源的争用。</p>
<p>Oracle Active Dataguard 是Oracle Database Enterprise Edition的一个功能，需要额外付费授权来使用这个功能。</p>
<p>如需启用Active Dataguard, 只需要将备库以 read-only 模式打开，而且执行 ALTER DATABASE RECOVER MANAGED STANDBY DATABASE语句就可以。需要注意的是：主库和备库的COMPATIBLE 参数至少要设置为11.0.0。</p>
<p><strong>Duplicate from active database</strong> </p>
<p>11g以前使用rman创建备库需要先进行备份,然后将备份传输到备库或者可以被备库直接访问到，会大量占用额外的存储空间。<br>11g提供了从运行的主库直接创建备库的功能,这样就不再需要提前rman备份数据库,数据库直接从target拷贝到auxiliary,方便快捷，当然其他的一些设置是省不了的。</p>
<p>References:<br>[1]<a href="http://kyle.xlau.org/posts/oracle-data-guard-part1.html">Oracle 11g Data Guard 物理备库快速配置指南（上）</a><br>[2]<a href="http://kyle.xlau.org/posts/oracle-data-guard-part2.html">Oracle 11g Data Guard 物理备库快速配置指南（下）</a><br>[3]<a href="http://docs.oracle.com/cd/B28359_01/server.111/b28294/rcmbackp.htm#g648533">Creating a Standby Database with Recovery Manager</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>2003 R2平台oracle 9206数据库冷备份恢复的路径依赖问题</title>
    <url>/2010/05/20/oracle-9206-database-cold-backup-restore/</url>
    <content><![CDATA[<p>windows 2003 R2做oracle数据库冷备份恢复时遇到路径依赖问题，原库oracle安装在F分区，而恢复到的oracle安装在E分区。两边数据库的版本是完全一致的，除了安装路径不同,sid实例名都为orcl。停下服务器后，把原库的控制文件、数据文件、联机日志文件(online redo files)、初始化参数文件(spfile)、密码文件拷贝到了新库安装目录。如果数据库运行于归档模式,还应单独备份归档日志文件。实际上为了省事，把oracle的安装目录整个同步了一遍。拷贝完后oracle服务无法启动，无法启动就对了。这些关键文件的路径都变了，库肯定是打不开了。怎么办？</p>
<p>两个方法，一是重新安装oracle使其路径与原库一致,二是修改关键文件的路径。第一种没啥意思，就第二种吧。</p>
<p>因为机器名字不同了，所以要打开\oracle\ora92\network\admin下面的几个文件tnsnames.ora、snmp_ro.ora和listener.ora把里面的机器名改成正确的值,snmp_ro.ora和listener.ora文件里面的文件路径改为正确的值。</p>
<p>参数文件里面记录了控制文件的路径，要把这些路径更改过来。oracle 9i默认是使用spfile的，而spfile是二进制的，最好不要直接修改，导出pfile，修改控制文件路径后再导回去就ok了</p>
<a id="more"></a>
<p>&gt;sqlplus “/ as sysdba”<br>SQL&gt;create pfile=”e:\oracle\admin\orcl\pfile\initorcl.ora” from spfile</p>
<p>然后打开initorcl.ora修改控制文件路径为实际的控制文件路径，再导回到spfile</p>
<p>SQL&gt;create spfile from pfile=”e:\oracle\admin\orcl\pfile\initorcl.ora”</p>
<p>然后重建控制文件，因为控制文件里面记录了数据文件、日志文件的路径。数据文件好多啊，还是先从原库备份一下控制文件吧</p>
<p>SQL&gt;alter database backup controlfile to trace;</p>
<p>找到生成的trc文件，路径为F:\oracle\admin\orcl\udump\orcl_ora_xxxx.trc，看看生成时间就能知道是哪个了。从这个文件里面提取出一个sql文件来，因为日志文件是完整的，就提取NORESETLOGS这段,保存到文件createctrlfile.sql。oracle 9206生成的这个脚本有个bug,CHARACTER SET ZHS16GBK这行的上面一行多了个逗号，去掉就可以了。语句的样子大体如下</p>
<p>STARTUP NOMOUNT<br>CREATE CONTROLFILE REUSE DATABASE “ORCL” NORESETLOGS NOARCHIVELOG<br>– SET STANDBY TO MAXIMIZE PERFORMANCE<br> MAXLOGFILES 50<br> MAXLOGMEMBERS 5<br> MAXDATAFILES 100<br> MAXINSTANCES 1<br> MAXLOGHISTORY 2722<br>LOGFILE<br> GROUP 1 ‘F:\ORACLE\ORADATA\ORCL\REDO01.LOG’ SIZE 100M,<br> GROUP 2 ‘F:\ORACLE\ORADATA\ORCL\REDO02.LOG’ SIZE 100M,<br> GROUP 3 ‘F:\ORACLE\ORADATA\ORCL\REDO03.LOG’ SIZE 100M<br>– STANDBY LOGFILE<br>DATAFILE<br> ‘F:\ORACLE\ORADATA\ORCL\SYSTEM01.DBF’,<br> ‘F:\ORACLE\ORADATA\ORCL\UNDOTBS01.DBF’,<br> ‘F:\ORACLE\ORADATA\ORCL\CWMLITE01.DBF’,<br> ‘F:\ORACLE\ORADATA\ORCL\DRSYS01.DBF’,<br> …<br>CHARACTER SET ZHS16GBK<br>;</p>
<p>把这个sql里面的数据文件和日志文件的路径修改成正确的路径后，执行一下语句</p>
<blockquote>
<p>sqlplus “/ as sysdba”<br>SQL&gt;shutdown immediate<br>SQL&gt;@createctrlfile.sql</p>
</blockquote>
<p>提示控制文件重建完成就ok了，然后</p>
<p>SQL&gt;alter database open</p>
<p>就可以启动数据库了。抱怨一句，oracle数据库的这些关键文件为什么不用相对路径呢？相对于$ORACLE_HOME不就得了吗，真烦！</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g 数据文件大小与大文件表空间</title>
    <url>/2012/10/15/oracle-big-file-tablespace/</url>
    <content><![CDATA[<p>oracle可以使用的数据文件大小受oracle和文件系统的限制。</p>
<a id="more"></a>
<p>oracle支持2K,4K,8K,16K,32K的块大小block_size,但默认的表空间只使用22 bits来表达块号block#,所以通常的表空间可以使用的数据文件大小从2k*(222-1)约8G到32K*(222-1)约128G不等。一般block_size设置为8K的情况下,数据文件最大可以到约32G大小。</p>
<p>oracle 10g引入了大文件表空间big file tablespace特性,扩充到32 bits来表达块号block#。那么当block_size为2K时,数据文件大小可以达到约8T,当block_size为32K时可以达到128T。一般block_size设置为8K的情况下,则最大数据文件可以为32T大小。</p>
<p>当然这只是oracle的限制,还要考虑到OS文件系统的限制,这二者中的最小值才是实际的限制,但是也要有这么大的存储才行。</p>
<p>但是大文件表空间只可用于本地管理表空间LMT(Locally Managed Tablespace),而且只能使用一个数据文件。创建语句如下:</p>
<p>SQL&gt; CREATE BIGFILE TABLESPACE bfsbs<br>DATAFILE ‘/path/to/datafile’<br>SIZE 100M<br>AUTOEXTEND ON<br>NEXT 100M<br>MAXSIZE 2T<br>EXTENT MANAGEMENT LOCAL;</p>
<p>可以不指定区段管理方式,oracle 10g默认使用自动的本地管理表空间。 </p>
<p>oracle默认创建普通小文件表空间,使用ALTER DATABASE 命令来修改数据库默认的表空间类型:</p>
<p>SQL&gt; ALTER DATABASE SET DEFAULT BIGFILE TABLESPACE;</p>
<p>虽然大文件表空间可以使用很大的数据文件,但是最好别用太大的数据文件,管理起来可不是那么方便。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle字符集</title>
    <url>/2012/10/16/oracle-character-set/</url>
    <content><![CDATA[<p>oracle的字符集牵扯到数据库字符集,国家字符集,客户端字符集这几个概念。</p>
<a id="more"></a>
<p><strong>oracle支持的字符集</strong></p>
<p>oracle支持单字节字符集如ASCII字符集,传统的多字节字符集如GBK字符集,当然更优先支持UNICODE字符集。</p>
<p>oracle支持GBK的兼容字符集叫做ZHS16GBK,但即使是用于中文系统也建议优先使用UNICODE字符集。UNICODE字符集涵盖更多的字符,而且标准兼容性更好。</p>
<p>ORACLE支持UNICODE的字符集主要有UFT8,AL32UTF8和AL16UTF16。UTF8从8i开始出现,最高支持到Unicode 3.0标准,而且此字符集不再升级。AL32UTF8和AL16UTF16从9i开始出现,在10g r2中支持Unicode 4.0标准,此二者的区别在于一个是UTF-8编码转换格式,另一个为UTF-16编码转换格式。</p>
<p>oracle推荐新建的数据库都采用AL32UTF8作为数据库字符集。AL32UTF8涵盖了ZHS16GBK支持的所有字符,但并不是其超集,因为二者的编码格式是不兼容的。</p>
<p><strong>数据库字符集(Database Character Set)</strong></p>
<p>Oracle数据库使用数据库字符集来:<br>1)存储SQL CHAR datatypes (CHAR, VARCHAR2, CLOB, and LONG)<br>2)用作表名,列名,PL/SQl变量名等标识符<br>3)输入和存储SQL和PL/SQL源代码</p>
<p>查询数据库字符集</p>
<p>第一种方法:<br>[sql]<br>SQL&gt; SELECT userenv(‘language’) FROM dual;<br>USERENV(‘LANGUAGE’)</p>
<hr>
<p>AMERICAN_AMERICA.AL32UTF8<br>[/sql]<br>字符集为AL32UTF8</p>
<p>第二种方法：<br>[sql]<br>SQL&gt; SELECT value FROM v$nls_parameters WHERE parameter=’NLS_CHARACTERSET’;<br>VALUE</p>
<hr>
<p>AL32UTF8<br>[/sql]<br><strong>国家字符集(National Character Set)</strong></p>
<p>国家字符集可以使数据库在没有指定UNICODE数据库字符集时来存储UNICODE字符数据,国家字符集只用于NCHAR, NVARCHAR2和NCLOB类型字段的数据存储。NCHAR, NVARCHAR2和NCLOB只支持UNICODE字符而不支持其他的单字节和多字节字符集。CHAR, VARCHAR2, CLOB和LONG则可以支持所有的字符编码类型。如果数据库字符集为UNICODE字符集,则没什么必要使用NCHAR, NVARCHAR2和NCLOB等数据类型。<br>oracle 10g只支持两种国家字符集UTF8和AL16UTF16,UTF8为变长编码,AL16UTF16为双字节编码,优先使用UTF8。</p>
<p>查询国家字符集<br>[sql]<br>SQL&gt; SELECT value FROM v$nls_parameters WHERE parameter=’NLS_NCHAR_CHARACTERSET’;<br>VALUE</p>
<hr>
<p>UTF8<br>[/sql]<br><strong>客户端字符集</strong></p>
<p>客户端字符集通过NLS_LANG环境变量或注册表orale home下的键NLS_LANG来设置。</p>
<p>NLS_LANG参数由以下部分组成:<br>NLS_LANG=<Language>_<Territory>.<Clients Characterset></p>
<p>linux平台:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">export</span> NLS_LANG=AMERICAN_AMERICA.AL32UTF8</span><br></pre></td></tr></table></figure>
<p>在这里,AMERICAN是语言,AMERICA是区域,AL32UTF8则为客户端字符集。</p>
<p>oracle数据库根据数据库字符集和客户端字符集来决定是否进行字符集转换。如果客户端字符集与数据库字符集完全一致,则无需进行字符编码转换。如果客户端字符集是数据库字符集的子集,也无需进行字符编码转换,其他情形下则需要在客户端字符集和数据库字符集之间进行转换。这个规则对于写入和查询都是一样的。</p>
<p>客户端字符集不是由数据库字符集决定的,而是由客户端系统环境所决定的。oracle无从知晓客户端的系统环境,只能依靠客户端设置的NLS_LANG参数来决定客户端使用的字符集。客户端的NLS_LANG参数应该设置成与客户端操作系统一致的字符集,因为客户端依赖操作系统的字符集来进行输入和输出。所以如果操作系统使用utf-8字符集,则客户端字符集设置为AL32UTF8即可。如果操作系统使用GKB字符集,则客户端字符集需要设置为ZHS16GBK。当然,如果oracle客户端自身支持字符集的转换,也可以按客户端自身设置的字符集来设定NLS_LANG变量。</p>
<p>还有一种情形,如果使用sql文件作为客户端的输入,则应视sql文件使用的字符集而设定客户端的字符集,因为文件使用的字符集可以和操作系统使用的字符集不一致。理论上是这样的,但如果某些oracle客户端将sql输入文件转换成与系统一致的字符编码格式再传送到服务器端执行则另当别论。</p>
<p>一句话,NLS_LANG设置的原则为:<strong>客户端送给数据库何种字符集编码的字符流,将NLS_LANG设置成这种字符集即可</strong>,这样数据库就会知道如何正确的去解读接受的字符流。</p>
<p><strong>exp/imp与客户端字符集</strong></p>
<p>expdp/impdp都是在服务器端执行的,所以不会牵扯到客户端字符集。<br>exp/imp时设置的客户端字符集如果与数据库字符集不同,则数据库在导出到数据文件或从数据文件导入时发生字符集转换。</p>
<p>很显然,从数据库exp导出到数据文件时,设置客户端字符集与数据库字符集一致是最佳的,因为这样不会发生字符集转换,导出文件是二进制格式的,无论以何种字符集导出都是可以在OS中正常存储和拷贝的。</p>
<p>当从数据文件导入到数据库时,客户端字符集要设置成导出数据文件使用的字符集,这样数据库才能正确理解客户端发送的数据流。此时数据库字符集可能与客户端字符相同,也可能不同。如果相同则无需在导出数据文件和数据库之间转换字符集,如果不同则需要在导出数据文件和字符集之间转换字符集,甚至如果字符集不兼容,则会丢失数据。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle exp/imp用户不同导致job停止工作</title>
    <url>/2011/05/03/oracle-exp-imp-job/</url>
    <content><![CDATA[<p>因为oracle数据库用户很多,统一用system用户进行导入/导出,导致普通用户的job作业停止工作</p>
<a id="more"></a>
<p>使用一下语句查看系统里所有的job</p>
<p>1 SQL&gt;<strong>select</strong> * from dba_jobs;  </p>
<p>发现所有普通用户job的LOG_USER和PRIV_USER字段都变成了system,而SCHEMA_USER还是原来的用户的schema名字。这是由于imp导入用户与job的属主用户不同造成的。</p>
<p>解决方法之一用job属主用户进行导入,参考”<a href="https://openwares.net/database/oracle_jobs_exp_imp.html">Oracle Jobs与Exp/Imp</a>“</p>
<p>重新导入太麻烦了，也可以这样解决：</p>
<p>以sysdba角色登录，执行一下语句修正两个字段LOG_USER和PRIV_USER的值为SCHEMA_USER字段的值</p>
<p>1 - -login sys as sysdba<br>2 <strong>update</strong> dba_jobs <strong>set</strong> log_user=’username’,priv_user=’username’ where schema_user=’username’;<br>3 <strong>commit</strong>;  </p>
<p>如果job的broken属性是Y,以job owner用户登录执行以下语句：</p>
<p>1 - -login as job’s owner,<br>2 BEGIN<br>3   FOR i <strong>IN</strong> (<strong>SELECT</strong> job FROM user_jobs WHERE broken=’Y’)<br>4   LOOP<br>5        dbms_job.broken(i.job,false);<br>6        dbms_job.run(i.job,true);<br>7   END LOOP;<br>8 END;  </p>
<p>或者这样执行<br>SQL&gt;exec dbms_job.broken(job_id,false);<br>SQL&gt;exec dbms_job.run(job_id);</p>
<p>这样就o了</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle expdp and impdp</title>
    <url>/2016/08/05/oracle-expdp/</url>
    <content><![CDATA[<a id="more"></a>
<p>expdp是10g及以后新增的数据导出工具，数据导出速度有了很大的提升。而且expdp比exp有了更细粒度的导出支持，比如可以排除指定的表。</p>
<p>expdp真正的数据导出是在服务器端执行的，因此需要先建立directory数据库对象。</p>
<p><strong>创建directory对象</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; CREATE DIRECTORY dir_expdp <span class="keyword">as</span> <span class="string">&#x27;\\\\192.168.0.82\\exp&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>directory对象可以使用网络路径，这样可以从数据库服务器expdp到网络上的远程机器。</p>
<p>查询目录对象:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; SELECT * FROM dba_directories;</span><br></pre></td></tr></table></figure>

<p>当前并没有alter directory对象的支持，如果修改只能先drop，然后再create。</p>
<p><strong>导出数据</strong></p>
<p>expdp使用schemas来指定需要导出的schema，类似于exp的owner参数，可以理解为用户名，其实二者并不同，只是一般二者同名而已。<br>directory指定使用哪个目录对象，就是上一步创建的目录对象。<br>dumpfile指定导出的数据文件<br>logfile指定导出日志文件<br>exclude指定需要排除的数据库对象，包括table等很多种对象</p>
<p>比如：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ expdp system/passwd@orcl schemas=user1,user2 EXCLUDE=TABLE:<span class="string">&quot;IN(&#x27;table1&#x27;,&#x27;table2&#x27;)&quot;</span></span><br><span class="line">directory=dir_expdp dumpfile=$&#123;dmp_file&#125; logfile=$&#123;explog_file&#125;</span><br></pre></td></tr></table></figure>

<p><strong>expdp优化</strong><br>expdp的优化主要在于提高并行度，也就是指定parallel参数，一般此参数等于cpu个数，并且要小于dump文件的个数,可以在dumpfile中指定％U让expdp自动按需要按顺序生成dump文件</p>
<p>查看cpu数量：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql&gt; show parameter cpu</span><br></pre></td></tr></table></figure>

<p>列如：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ expdp system/passwd@orcl schemas=user1,user2 EXCLUDE=TABLE:<span class="string">&quot;IN(&#x27;table1&#x27;,&#x27;table2&#x27;)&quot;</span></span><br><span class="line">directory=dir_expdp dumpfile=db_%U.dmp logfile=explog_file parallel=<span class="number">16</span></span><br></pre></td></tr></table></figure>

<p>还可以使用filesize来限制每个dump文件的最大尺寸。</p>
<p><strong>impdp导入</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ impdp system/passwd@orcl schemas=user1,user2 directory=dir_impdp dumpfile=db_%U.dmp logfile=explog_file parallel=<span class="number">16</span></span><br></pre></td></tr></table></figure>

<p>impdp导入时也可以使用%U来指定输入的dump文件,也可以使用parallel参数来提速.</p>
<p>如果出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ora-<span class="number">31684</span> object type user already exists</span><br></pre></td></tr></table></figure>
<p>是因为在导入之前已经创建了user的原因,可以忽略掉此错误,或者impdp添加参数exclude=user</p>
<p><strong>使用参数文件</strong></p>
<p>可以将所有的expdp,impdp参数写入一个参数文件,然后在命令行上引用此文件,比如编辑一个expdp.par参数文件:<br>expdp.par</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">schemas=user1,user2,user3</span><br><span class="line">exclude=TABLE:<span class="string">&quot;IN(&#x27;table1&#x27;,&#x27;table2&#x27;,&#x27;table3&#x27;,&#x27;table4&#x27;,&#x27;table5&#x27;)&quot;</span></span><br><span class="line">directory=dir_expdp</span><br><span class="line">dumpfile=db_%U.dmp</span><br><span class="line">logfile=db.log</span><br><span class="line">parallel=<span class="number">4</span></span><br><span class="line">version=<span class="number">10.2</span><span class="number">.0</span><span class="number">.3</span><span class="number">.0</span> </span><br></pre></td></tr></table></figure>

<p>然后这样使用参数文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ expdp parfile=expdp.par</span><br></pre></td></tr></table></figure>

<p><strong>排除对象</strong></p>
<p>使用exclude参数排除对象,其语法为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">EXCLUDE=object_type\[:name_clause\] \[, ...\]</span><br></pre></td></tr></table></figure>

<p>Object_type用于指定要排除的对象类型,name_clause用于指定要排除的具体对象.</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">EXCLUDE=SCHEMA:&quot;=&#x27;HR&#x27;&quot; #排除名字为HR的schema</span><br><span class="line">EXCLUDE=USER #排除所有创建user的DDL语句</span><br><span class="line">EXCLUDE=USER:&quot;=&#x27;HR&#x27;&quot; #排除创建用户HR的DDL语句</span><br><span class="line">EXCLUDE=VIEW,PACKAGE,FUNCTION #排除视图,包和函数</span><br><span class="line">EXCLUDE=INDEX #排除索引</span><br><span class="line">EXCLUDE=GRANT #排除授权</span><br><span class="line">EXCLUDE=TRIGGER #排除触发器</span><br><span class="line">EXCLUDE=TABLE:&quot;IN (&#x27;COUNTRIES&#x27;, &#x27;REGIONS&#x27;)&quot; #排除某些表</span><br><span class="line">EXCLUDE=SCHEMA:&quot;LIKE &#x27;SYS%&#x27;&quot; #排除以SYS开头的schema</span><br></pre></td></tr></table></figure>

<p>exclude参数可以多次出现,也可以将所有的排除写到一个exclude参数中.</p>
<p>include语法与EXCLUDE相同,但二者不能同时使用.</p>
<p>References:<br>[1]<a href="https://docs.oracle.com/cd/B19306_01/server.102/b14215/dp_export.htm">Data Pump Export</a><br>[2]<a href="http://blog.csdn.net/tonyzhou_cn/article/details/10176783">优化IMPDP/EXPDP导入导出速度</a><br>[3]<a href="http://shitou118.blog.51cto.com/715507/310033">expdp impdp 数据库导入导出命令详解</a><br>[4]<a href="http://www.dba-oracle.com/t_ora_31684_import_impdp.htm">ORA-31684 import error Tips</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 临时表空间扩容</title>
    <url>/2013/09/29/oracle-extend-temp-tablespace/</url>
    <content><![CDATA[<p>临时表空间主要用途是在数据库进行排序运算、管理索引、访问视图等操作时提供临时的运算空间，当运算完成之后系统会自动清理。临时表空间不足时会影响系统性能。</p>
<a id="more"></a>
<p><strong>查询临时表空间</strong><br>[sql]<br>sql&gt; select file_name,tablespace_name,bytes/1024/1024 as “total temp space(M)” from dba_temp_files;<br>FILE_NAME TABLESPACE_NAME total temp space(M)</p>
<hr>
<p>D:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\TEMP01.DBF TEMP 1000<br>[/sql]<br><strong>查看临时表空间剩余容量</strong><br>[sql]<br>SQL&gt; select tablespace_name,bytes_free/1024/1024 “free temp space(M)” from v$temp_space_header;<br>TABLESPACE_NAME free temp space(M)</p>
<hr>
<p>TEMP 805<br>[/sql]<br><strong>重新设定临时表空间容量</strong><br>[sql]<br>SQL&gt; alter database tempfile ‘D:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\TEMP01.DBF’ resize 1024M;<br>Database altered<br>[/sql]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle instant client and tnsping</title>
    <url>/2016/04/28/oracle-instant-client-and-tnsping/</url>
    <content><![CDATA[<a id="more"></a>
<p>最近版本的即时客户端已经没有了tnsping这个命令，可以从相应版本的客户端或服务器bin目录中拷贝此文件，或者用脚本简单的替代：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">tnsping &gt;<span class="regexp">/dev/</span><span class="literal">null</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span> </span><br><span class="line"> <span class="function"><span class="title">tnsping</span>(<span class="params"></span>)</span> &#123; </span><br><span class="line"> sqlplus -L -S x/x@$<span class="number">1</span> &lt;<span class="regexp">/dev/</span><span class="literal">null</span> grep ORA- (grep -v ORA-<span class="number">01017</span> echo OK) </span><br><span class="line"> &#125; </span><br></pre></td></tr></table></figure>

<p>将此段脚本放入.profile或.bashrc即可。</p>
<p>又或者直接测试一下服务器的1521端口是否正常开放:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ telnet a.b.c.d <span class="number">1521</span></span><br><span class="line">Trying a.b.c.d...</span><br><span class="line">Connected to a.b.c.d.</span><br><span class="line">Escape character is <span class="string">&#x27;^\]&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>这样就说明oracle监听是正常的。</p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle即时客户端安装python3 oracle驱动cx_Oracle</title>
    <url>/2015/12/27/oracle-instant-installpython3-cx-oracle/</url>
    <content><![CDATA[<a id="more"></a>
<p>下载安装instantclient-sdk包，这个包里有编译需要的头和库文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo unzip instantclient-sdk-linux.x64-<span class="number">12.1</span><span class="number">.0</span><span class="number">.2</span><span class="number">.0</span>.zip -d /opt/oracle</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">不然会有错误提示:</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">oci.h: No such file or directory</span><br></pre></td></tr></table></figure>

<p><strong>安装cx_Oracle</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo pip3 install cx_oracle</span><br></pre></td></tr></table></figure>

<p>会有错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">usr/bin/ld: cannot find -lclntsh</span><br><span class="line"></span><br><span class="line">collect2: error: ld returned <span class="number">1</span> exit status</span><br><span class="line"></span><br><span class="line">error: command <span class="string">&#x27;x86_64-linux-gnu-gcc&#x27;</span> failed <span class="keyword">with</span> exit status <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>是因为找不到libclntsh库，创建一个符号连接:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd /opt/oracle/instantclient_12_1</span><br><span class="line">$ sudo ln -sf libclntsh.so<span class="number">.12</span><span class="number">.1</span> libclntsh.so</span><br><span class="line">$ sudo ln -sf libclntshcore.so<span class="number">.12</span><span class="number">.1</span> libclntshcore.so</span><br><span class="line">$ sudo ln -sf libocci.so<span class="number">.12</span><span class="number">.1</span> libocci.so</span><br></pre></td></tr></table></figure>

<p>重新安装就可以了。</p>
<p>如果安装过程中提示找不到oracle安装，要注意sudo是在root用户的环境下执行pip3安装,要在root用户下设置相应的oracle环境变量。</p>
<p><strong>python3连接oracle</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt; <span class="keyword">import</span> cx_Oracle</span><br><span class="line">&gt;&gt;&gt; conn = cx_Oracle.connet(<span class="string">&#x27;user/passwd@db&#x27;</span>)</span><br><span class="line">&gt;&gt;&gt; print(conn.version)</span><br><span class="line"><span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span></span><br><span class="line">&gt;&gt;&gt; conn.close()</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle Jobs与Exp/Imp</title>
    <url>/2009/09/21/oracle-jobs-exp-imp/</url>
    <content><![CDATA[<p>最近因为一点儿小问题，用Exp/Imp做了一次数据恢复。恢复以后本来正常的snapshot刷新出了问题，job不工作了，本来一天要更新两次数据，现在数据停止更新了。<br> 用system登录oracle，然后select * from dba_jobs;发现所有的jobs的LOG_USER和PRIV_USER变成了system用户，而SCHEMA_USER还是原来的用户，而且NEXT_DATE也变的面目全非。原来是Imp时jobs全部corrupt掉了。</p>
<p>出现这个情况的原因是Exp和Imp的时候都是使用的system用户，所以为带有jobs的用户做Exp/Imp时，一定要用这个用户自身来导入、导出。</p>
<a id="more"></a>
<p>因为用户已经删除没有机会再重新Exp，只好重新用拥有jobs的用户来进行Imp，一定要为该用户授予DBA角色，不然无法进行导入，会有错误提示：</p>
<p> “IMP-00013: 只有 DBA 才能导入由其它 DBA 导出的文件<br> IMP-00000: 未成功终止导入”</p>
<p>即使授予了DBA角色，仍然会有警告：</p>
<p> “警告: 此对象由 SYSTEM 导出, 而不是当前用户”</p>
<p>但并不影响正确的导入。</p>
<p>导入完成后，重新查看jobs发现已经都正常了。<br>手工刷新一次，仍然提示错误：</p>
<p> “已连接。<br> BEGIN proc_refreshsnapshot; END;</p>
<p> *<br> ERROR 位于第 1 行:<br> ORA-12034: “xxx”.”xxx” 上的实体化视图日志比上次刷新后的内容新<br> ORA-06512: 在”SYS.DBMS_SNAPSHOT”, line 803<br> ORA-06512: 在”SYS.DBMS_SNAPSHOT”, line 860<br> ORA-06512: 在”SYS.DBMS_SNAPSHOT”, line 841<br> ORA-06512: 在”xxx.PROC_REFRESHSNAPSHOT”, line 3<br> ORA-06512: 在line 1”</p>
<p>把所有snapshot table做一次完全刷新，exec dbms_snapshot.refresh(‘xxx’,’C’);,<br>问题解决，现在一切正常。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle手工建库新用户登录错误Error accessing PRODUCT_USER_PROFILE</title>
    <url>/2015/11/19/oracle-login-error-product-user-profile/</url>
    <content><![CDATA[<a id="more"></a>
<p>手工创建oracle数据库，新建用户sqlplus登录时有错误提示信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR:</span><br><span class="line">ORA-<span class="number">00942</span>: table or view does not exist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">Error</span> accessing PRODUCT_USER_PROFILE</span><br><span class="line">Warning: Product user profile information not loaded!</span><br><span class="line">You may need to run PUPBLD.SQL <span class="keyword">as</span> SYSTEM</span><br></pre></td></tr></table></figure>

<p>可以正常登录，不影响使用。</p>
<p>用system用户登录数据库，执行脚本$ORACLE_HOME/sqlplus/admin/pupbld.sql可以消除此错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sqlplus system/xxxx@orcl</span><br><span class="line">SQL&gt;@/u01/app/oracle/product/<span class="number">10.2</span><span class="number">.0</span>/db_1/sqlplus/admin/pupbld.sql</span><br><span class="line"></span><br><span class="line">DROP SYNONYM PRODUCT_USER_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">01434</span>: private synonym to be dropped does not exist</span><br><span class="line"></span><br><span class="line"> DATE_VALUE FROM PRODUCT_USER_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">3</span>:</span><br><span class="line">ORA-<span class="number">00942</span>: table or view does not exist</span><br><span class="line"></span><br><span class="line">DROP TABLE PRODUCT_USER_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">00942</span>: table or view does not exist</span><br><span class="line"></span><br><span class="line">ALTER TABLE SQLPLUS_PRODUCT_PROFILE ADD (LONG_VALUE LONG)</span><br><span class="line">*</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">00942</span>: table or view does not exist</span><br><span class="line"></span><br><span class="line">Table created.</span><br><span class="line"></span><br><span class="line">DROP TABLE PRODUCT_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">00942</span>: table or view does not exist</span><br><span class="line"></span><br><span class="line">DROP VIEW PRODUCT_PRIVS</span><br><span class="line">*</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">00942</span>: table or view does not exist</span><br><span class="line"></span><br><span class="line">View created.</span><br><span class="line"></span><br><span class="line">Grant succeeded.</span><br><span class="line"></span><br><span class="line">DROP PUBLIC SYNONYM PRODUCT_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">01432</span>: public synonym to be dropped does not exist</span><br><span class="line"></span><br><span class="line">Synonym created.</span><br><span class="line"></span><br><span class="line">DROP SYNONYM PRODUCT_USER_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">01434</span>: private synonym to be dropped does not exist</span><br><span class="line"></span><br><span class="line">Synonym created.</span><br><span class="line"></span><br><span class="line">DROP PUBLIC SYNONYM PRODUCT_USER_PROFILE</span><br><span class="line"> *</span><br><span class="line">ERROR at line <span class="number">1</span>:</span><br><span class="line">ORA-<span class="number">01432</span>: public synonym to be dropped does not exist</span><br><span class="line"></span><br><span class="line">Synonym created.</span><br></pre></td></tr></table></figure>

<p>重新登录新用户，错误提示消失。</p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 游标泄露问题查找</title>
    <url>/2016/11/29/oracle-open-cursor-leak/</url>
    <content><![CDATA[<a id="more"></a>
<p>游标会占用系统资源，oracle中游标分配在shared pool内存池，用完了连接(connection)、语句(statement,preparedStatement)和结果集(resultSet)一定要记得释放，不然系统打开游标会持续上升，直到达到系统设置的阈值，无法获取游标的事务就会失败。</p>
<p><strong>查看系统配置的最大打开游标数量和当前已打开游标数量</strong><br>[sql]<br>sql&gt; select (select count(*) from V$OPEN_CURSOR) as opened_cursors,<br>(select value from v$parameter where name=’open_cursors’) as max_cursors from dual;<br>OPENED_CURSORS MAX_CURSORS</p>
<hr>
<p> 1362 65535<br>[/sql]</p>
<p><strong>查询会话打开的游标</strong></p>
<p>[sql]<br>sql&gt; select s.sid, s.username, s.osuser,s.machine, a.value<br>from v$sesstat a, v$statname b, v$session s<br>where a.statistic# = b.statistic# and s.sid=a.sid and b.name = ‘opened cursors current’ and s.username is not null<br>order by a.value desc;<br> SID USERNAME OSUSER MACHINE VALUE</p>
<hr>
<p> 405 TT NETWORK?SERVICE WORKGROUP\VIRT-APP-EXTERN 51<br> 466 TT NETWORK?SERVICE WORKGROUP\VIRT-APP 49<br> 491 TT Administrator WORKGROUP\VIRT-APP 13<br> 422 TT Administrator WORKGROUP\VIRT-APP 11<br> 475 TT Administrator WORKGROUP\VIRT-APP 10<br>……<br>[/sql]<br>或者<br>[sql]<br>sql&gt; select o.sid, s.username, s.osuser, s.machine, count(*) num<br>from v$open_cursor o, v$session s<br>where o.sid = s.sid<br>group by o.sid,s.username, s.osuser, s.machine<br>order by num desc;<br> SID USERNAME OSUSER MACHINE NUM</p>
<hr>
<p> 464 TT NETWORK?SERVICE WORKGROUP\VIRT-APP-EXTERN 34<br> 471 TT NETWORK?SERVICE WORKGROUP\VIRT-APP-EXTERN 30<br> 475 TT Administrator WORKGROUP\VIRT-APP 28<br> 491 TT Administrator WORKGROUP\VIRT-APP 27<br>……<br>[/sql]</p>
<p><strong>查询会话执行的sql语句</strong></p>
<p>[sql]<br>sql&gt; select sid, sql_text, count(sql_text) as num<br>from v$open_cursor<br>group by sid, sql_text having count(sql_text)&gt;5<br>order by num desc;<br> SID SQL_TEXT NUM</p>
<hr>
<p> 464 select b.*,bb.buildno,bb.BUILDNAME from bldroom b join build 40<br> 464 select t2.businessname,t3.firstname,t1.opion,t1.receivedatet 36<br> 464 select distinct t2.certid,t2.certno from rightcertroom t1 jo 34<br>……<br>[/sql]</p>
<p>或者更直接的查询每个sql语句打开的游标数量<br>[sql]<br>sql&gt; select s.sid, s.osuser,s.machine, o.sql_text, count(o.sql_text) as num<br>from v$open_cursor o<br>join v$session s on o.sid=s.sid<br>group by s.sid, s.osuser,s.machine,o.sql_text having count(o.sql_text)&gt;50<br>order by num desc;<br> SID OSUSER MACHINE SQL_TEXT NUM</p>
<hr>
<p> 464 tomcat8 clean select t2.businessname,t3.firstname,t1.opion,t1.receivedatet 35<br> 464 tomcat8 clean select b.*,bb.buildno,bb.BUILDNAME from bldroom b join build 34<br> 464 tomcat8 clean select distinct t2.certid,t2.certno from rightcertroom t1 jo 28<br>……<br>[/sql]</p>
<p>找到对应的SQL语句就可以审计对应的代码，查找资源泄露的情况。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle密码文件</title>
    <url>/2011/12/27/oracle-passwd-file/</url>
    <content><![CDATA[<p>oracle密码文件用于存放所有具有sysdba或者sysoper权限用户的口令,可以用密码文件创建工具ORAPWD来创建密码文件,有些操作系统在进行标准安装时会自动创建密码文件,比如windows操作系统。</p>
<a id="more"></a>
<p>oracle密码文件只存放具有sysdba或sysoper权限的用户口令,如果为普通用户授予sysdba或者sysoper权限,那么此时会把普通用户的密码从数据库中读到密码文件中保存下来，当然这时要求数据库必须处于open状态。</p>
<p><strong>创建密码文件</strong></p>
<p>ORAPWD的语法如下：<br>$&gt; orapwd file=<passwdfilename> password=<passwd> entries=<max_users> force=&lt;y/n&gt; nosysdba=&lt;y/n&gt;</p>
<p>参数含义：<br>file - 参数文件名。unix/linux平台上密码文件的名字必须为orapw<ORACLE_SID>或者orapw,必须提供全路径文件名,路径一般为$ORACLE_HOME/dbs。windows平台上密码文件的名字为PWD<ORACLE_SID>.ora,路径为$ORACLE_HOME\database。该参数必须提供。</p>
<p>password - SYS用户密码。该参数必须提供。</p>
<p>entries - 设置密码文件允许的可以同时连接到数据库的具有SYSDBA或SYSOPER权限的最大用户数。可选参数。</p>
<p>force - 是否覆盖已经存在的密码文件。可选。</p>
<p>nosysdba - 是否阻止DBA用户登陆。可选,一般用不到！</p>
<p><strong>系统初始化参数REMOTE_LOGIN_PASSWORDFILE</strong></p>
<p>除了创建密码文件外,还必须设置初始化参数REMOTE_LOGIN_PASSWORDFILE。该参数可用值如下：</p>
<p>NONE - 该参数使oracle数据库就像根本不存在密码文件一样,不允许特权用户通过非安全连接登陆,此时可以使用OS验证登陆数据库。</p>
<p>EXCLUSIVE - 默认值。仅一个oracle实例可以访问此密码文件。此时密码文件可以被修改,可以添加,修改,删除用户,也可以用alter user命令来修改SYS用户密码。</p>
<p>SHARED - 同一个服务器上的多个实例或者RAC的多个实例可以使用密码文件。此时密码文件不能被修改,也不能修改用户密码。此参数一般用于RAC环境。</p>
<p><strong>oracle认证服务</strong></p>
<p>$ORACLE_HOME/network/admin/sqlnet.ora文件中的参数SQLNET.AUTHENTICATION_SERVICES用于指定用户登陆认证方式。有以下值可用：</p>
<p><strong>Oracle Net Services可用的认证方法：</strong></p>
<ul>
<li><p>  NONE - 不使用认证方式。可以用用户名和密码来访问数据库。</p>
</li>
<li><p>  ALL - 所有可用的认证方式。用户名/密码组合或者OS验证都可以。unix/linux平台如果使用OS验证登陆方式,设置为此值即可。</p>
</li>
<li><p>  NTS - windows NT native authentication Service,windows原生OS认证。windows平台默认设置为此参数,故connect / as sysdba可以登陆oracle进行数据库管理,此时既是使用OS认证,不需要提供SYS密码。</p>
</li>
</ul>
<ul>
<li><p>不设置此参数或SQLNET.AUTHENTICATION_SERVICES =</p>
<p>  对Linux系统，默认支持OS认证和口令文件认证。</p>
<p>  对Windows系统，默认只支持口令文件认证，不支持OS认证。</p>
</li>
</ul>
<p><strong>Oracle Advanced Security可用的认证方法：</strong></p>
<p>kerberos5 - Kerberos认证</p>
<p>radius - radius认证</p>
<p>dcegssapi - DCE GSSAPI认证</p>
<p>这方面更详细的描述请移步<a href="http://www.dbabeta.com/2008/oracle_os_pwfile_authentication.html">Oracle OS认证与口令文件认证详解</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle $SQLPATH环境变量</title>
    <url>/2012/01/18/oracle-sqlpath-env/</url>
    <content><![CDATA[<p>SQL*PLUS启动时会自动查找运行两个脚本glogin.sql和login.sql</p>
<a id="more"></a>
<p>glogin.sql是sqlplus的全局登录profile,是oracle系统自带的脚本,其路径是固定的$ORACLE_HOME/sqlplus/admin。当用户启动sqlplus时,会从这个固定的路径加载glogin.sql,一般来说我们不用关心glogin.sql。</p>
<p>login.sql是用户登录的profile,sqlplus加载glogin.sql之后会查找并试图加载login.sql。sqlplus先从当前路径查找login.sql,如果找到就加载此脚本并停止继续查找,如果当前路径未找到该脚本,则继续从环境变量$SQLPATH指定的路径查找,如找到login.sql则加载之,之后不再继续查找。如果$SQLPATH未设定或指定的目录下未找到login.sql,则停止查找。</p>
<p>可以将习惯的sqlplus设置置于login.sql脚本,并设置$SQLPATH环境变量,就不用每次登录再手工设置了。</p>
<p>glogin.sql和login.sql类似于shell的登录脚本。</p>
<p>P.S.<br>我的login.sql<br>[sql]<br>–<br>–SQL*PLUS user login profile file<br>–</p>
<p>–the default editor for ED[IT] command<br>define _editor=vim</p>
<p>–enable dbms_output.put_line output<br>set serveroutput on size 1000000 format wrapped</p>
<p>–trim the spool out<br>set trimspool on</p>
<p>–for LONG,COLB display<br>set long 5000</p>
<p>–chars per line to output<br>set linesize 100</p>
<p>–lines per page<br>set pagesize 9999</p>
<p>–set prompt,format as user@dbname_ip&gt;<br>set termout off<br>define gname=idle<br>column global_name new_value gname</p>
<p>select lower(user)‘@’substr(global_name,1,decode(dot,0,length(global_name),dot-1))<br>‘_’(select utl_inaddr.get_host_address from dual) global_name<br>from (select global_name,instr(global_name,’.’)dot from global_name);</p>
<p>set sqlprompt ‘&amp;gname&gt;’<br>set termout on<br>[/sql]</p>
<p>References:<br>[1]<a href="https://docs.oracle.com/cd/E11882_01/server.112/e16604/ch_twelve040.htm#SQPUG060">SET System Variable Summary</a><br>[2]<a href="http://www.adp-gmbh.ch/ora/sqlplus/define.html">define [SQL*Plus]</a><br>[3]<a href="http://www.adp-gmbh.ch/ora/sqlplus/set.html">SET [SQL*Plus]</a><br>[4]<a href="http://www.adp-gmbh.ch/ora/sqlplus/column.html">column [SQL*Plus]</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g为表空间增加数据文件</title>
    <url>/2012/10/15/oracle-tablespace-add-datafile/</url>
    <content><![CDATA[<p>使用ALTER TABLESPACE语句,比较简单,记录以备忘。</p>
<a id="more"></a>
<p>先查询一下表空间数据文件:<br>[sql]<br>select tablespace_name, file_id,file_name, round(bytes/(1024*1024),0) total_space<br>from dba_data_files order by tablespace_name;<br>[/sql]</p>
<p>增加数据文件：<br>[sql]<br>SQL&gt; ALTER TABLESPACE tbsname<br>ADD DATAFILE ‘/path/to/datafile’<br>SIZE 500M<br>AUTOEXTEND ON<br>NEXT 500M<br>MAXSIZE UNLIMITED;<br>[/sql]</p>
<p>虽然此处设置MAXSIZE为UNLIMITED,但数据文件的最大大小受制于其表空间类型和block_size的大小。<br>使用小文件表空间,block_size为8K时,单个数据文件的最大大小约在8k*(222-1)=33554424K≈32767.99M。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle查看修改表空间属性状态</title>
    <url>/2016/11/29/oracle-tablespace-status/</url>
    <content><![CDATA[<a id="more"></a>
<p>oracle表空间有四种状态ONLINE,READ WRITE,READ ONLY和OFFLINE,READ WRITE和READ ONLY是ONLINE的特殊情况。</p>
<p>查询表空间状态：<br>[sql]<br>sql&gt; select tablespace_name,status from dba_tablespaces;<br>[/sql]</p>
<p>修改表空间状态：<br>[sql]<br>sql&gt; alter tablespace tablespace_name offline/online/read only/read write;<br>[/sql]</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 10g 查看表空间使用情况</title>
    <url>/2012/09/18/oracle-tablespace-usage/</url>
    <content><![CDATA[<p>表空间的空间利用情况信息主要来自表dba_data_files和dba_free_space</p>
<a id="more"></a>
<p>temp表空间的使用情况信息则来自于dba_temp_files和v$temp_space_header</p>
<p>SQL语句:<br>[sql]<br>SELECT df.tablespace_name “tablespace name”,df.total_space “total space(M)”,fs.free_space “free space(M)”,<br> ROUND((1-fs.free_space/df.total_space)<em>100,2) “usage(%)”<br>FROM<br>(SELECT tablespace_name,ROUND(SUM(bytes)/(1024</em>1024),2) total_space FROM dba_data_files GROUP BY tablespace_name) df,<br>(SELECT tablespace_name,ROUND(SUM(bytes)/(1024<em>1024),2) free_space FROM dba_free_space GROUP BY tablespace_name) fs<br>WHERE df.tablespace_name=fs.tablespace_name<br>UNION ALL<br>SELECT tf.tablespace_name “tablespace name”,tf.total_space “total space(M)”,tsh.free_space “free space(M)”,<br> ROUND((1-tsh.free_space/tf.total_space)<em>100,2) “usage(%)”<br>FROM<br>(SELECT tablespace_name,ROUND(SUM(bytes)/(1024</em>1024),2) total_space FROM dba_temp_files GROUP BY tablespace_name) tf,<br>(SELECT tablespace_name,ROUND(SUM(bytes_free)/(1024</em>1024),2) free_space FROM v$temp_space_header<br> GROUP BY tablespace_name) tsh<br>WHERE tf.tablespace_name=tsh.tablespace_name ORDER BY 4 DESC;<br>[/sql]<br>10g有个未公开的视图dba_tablespace_usage_metrics可以便捷的查询表空间使用情况<br>AQL&gt;SELECT * FROM dba_tablespace_usage_metrics ORDER BY used_percent DESC;<br>但是这个视图查询的结果与上面脚本查询的结果并不一致,据说dba_tablespace_usage_metrics视图计算利用率时包含了已经drop但是还没有purge的表所使用的空间.</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>oracle 自定义数据类型对象</title>
    <url>/2014/02/13/oracle-type/</url>
    <content><![CDATA[<p>除了标准的基本数据类型以外,用户还可以自定义数据类型对象,而且自定义类型对象还可以有方法,构造函数,这实质上就是OOP思想在DBMS里的投射。</p>
<a id="more"></a>
<p>oracle支持的自定义类型有object, SQLJ object,可变数组(varying array,varray), 嵌套表(nested table type), 或不完全对象类型( incomplete object type). </p>
<p><strong>创建类型(CREATE TYPE)</strong></p>
<p>比较常用的是object类型,可以使用基本数据类型或其他自定义数据类型来定义object类型,而且支持继承。</p>
<p>简单的语法,更详细的语法见oracle文档[1]<br>[sql]<br>CREATE OR REPLACE TYPE type_name AS OBJECT(<br> foo VARCHAR(10),<br> bar VARCHAR(100,<br> …<br>) NOT FINAL FINAL;<br>[/sql]</p>
<p>NOT FINAL 指明类型可以被其他类型继承,继承时使用UNDER关键字指明父类型。<br>FINAL 指明类型不可以被其他类型继承。</p>
<p>类型中的字段又称为类型的属性(Attribute)</p>
<p>类型创建以后可以像基本数据类型一样用于创建表字段。<br>[sql]<br>CREATE TABLE table_name (<br> foo bar_type,<br>);<br>[/sql]</p>
<p>也可以创建只有自定义数据类型的对象表:</p>
<p>[sql]<br>CREATE TABLE table_name OF object_type;<br>[/sql]<br>可以使用VALUE函数来获取对象表的值。</p>
<p><strong>更改类型(ALTER TYPE)</strong></p>
<p>ALTER TYPE详细用法见oracle文档[2]<br>为类型添加新的属性(字段)的语法如下:<br>[sql]ALTER TYPE type_name ADD ATTRIBUTE column data_type [CASCADE];[/sql]</p>
<p>CASCADE为可选属性,指明是否一并更改当前类型的子类型。</p>
<p><strong>对象实例条件测试(IS OF)</strong></p>
<p>使用IS OF来测试对象是否是指定类型的实例，详细语法参见oracle文档[3]<br>[sql]… expr IS [NOT] OF [TYPE] ([ONLY] [SCHEMA.]type_name)[/sql];</p>
<p>ONLY 指明确匹配指定的类型,不匹配子类型。当expr的结果是type_name的类型或子类型(不指定ONLY)时条件测试为真,否则为假。</p>
<p><strong>改变类型(TREAT函数)</strong></p>
<p>使用TREAT函数来改变表达式的类型为指定的类型,类似于编程语言中常见的强制类型转换,详细的语法见oracle文档[4]</p>
<p>[sql]TREAT(expr AS [REF] [schema.]type_name)[/sql]</p>
<p>REF 指明表达式为引用类型,还真全活,连引用都有-_-#</p>
<p><strong>更新类型对象属性值</strong></p>
<p>可以像编程语言中访问对象的属性一样来访问类型的属性,使用”.”操作符<br>[sql]<br>SQL&gt;UPDATE table_name t set t.foo.bar=foobar where t.xxx=yyy;<br>[/sql]</p>
<p>但如果需要使用TREAT函数进行类型转换,则UPDATE时比较麻烦,目前使用的方法如下,不知道有没有更好的方法:<br>[sql]<br>SQL&gt; UPDATE (SELECT TREAT(t.foo as bar).foobar f,t.column c from table_name t) SET f=xxx WHERE c=yyy;<br>[/sql]</p>
<p><strong>标准兼容性</strong></p>
<p>SQL标准中没有自定义数据类型,因为这个特性是不可移植的,应该谨慎使用。<br>PostgreSQL也支持自定义数据类型,语法与oracle大同小异。</p>
<p>references:<br>[1]<a href="http://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_8001.htm">CREATE TYPE</a><br>[2]<a href="http://docs.oracle.com/cd/B19306_01/server.102/b14200/statements_4002.htm">ALTER TYPE</a><br>[3]<a href="http://docs.oracle.com/cd/B28359_01/server.111/b28286/conditions014.htm#SQLRF52157">IS OF type Condition</a><br>[4]<a href="http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions198.htm">TREAT</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>Oracle User和Schema的区别和联系</title>
    <url>/2011/03/22/oracle-userschema/</url>
    <content><![CDATA[<p>一般来讲User和Schema有相同的名字,所以比较容易混淆，而实际上User和Schema是完全不同的东西。</p>
<a id="more"></a>
<p><strong>Schema</strong></p>
<p>先看一下Oracle Database Concepts中对Schema的定义：</p>
<blockquote>
<p>A schema is a collection of logical structures of data, or schema objects. A schema is<br>owned by a database user and has the same name as that user. Each user owns a single schema.</p>
</blockquote>
<p>一个Schema是数据逻辑结构的集合，或者叫Schema对象的集合。一个Schema被一个数据库User所拥有并且与User有相同的名字。每一个User只能拥有一个Schema。</p>
<p>当然User可以访问其他User拥有的Schema，只要Schema的拥有者或sysdba向该用户授予访问这个Schema的权限即可。</p>
<p>可以用SQL创建和操纵Scheme对象，Schema对象有以下几类：<br>■ Clusters<br>■ Database links<br>■ Database triggers<br>■ Dimensions<br>■ External procedure libraries<br>■ Indexes and index types<br>■ Java classes, Java resources, and Java sources<br>■ Materialized views and materialized view logs<br>■ Object tables, object types, and object views<br>■ Operators<br>■ Sequences<br>■ Stored functions, procedures, and packages<br>■ Synonyms<br>■ Tables and index-organized tables<br>■ Views</p>
<p>存储在数据库中的其他类型的一些对象，也可以用SQL创建和操纵，但是他们并不包含在Schema中：<br>■ Contexts<br>■ Directories<br>■ Profiles<br>■ Roles<br>■ Tablespaces<br>■ Users</p>
<p>Schema对象是逻辑数据存储结构，schema对象没有一对一的磁盘物理文件来存储它们的信息。然而，逻辑上oracle在数据库的表空间上存储schema对象，每一个schema对象物理上存储在表空间的一个或多个数据文件中。一个表空间可以包含多个schema的对象，一个schema的对象也可以存在于多个不同的表空间中。</p>
<p><strong>User</strong></p>
<p>User则无其他奇特之处,和其他系统广泛使用的用户概念差不多,User可以通过认证登录入系统，并对某些资源具有特定的权限(select,update,delete,drop,connect等)。User对象被创建之后，如果这个User没有创建任何Schema对象，那么这个对象是没有相关联的、默认的schema的。</p>
<p><strong>总结</strong></p>
<p>总的来讲，Schema是一种逻辑容器，可以包含各种schema逻辑对象，而User则是对资源访问权限的一种表达。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>pandoc转换markdown为pdf</title>
    <url>/2016/06/01/pandoc%E8%BD%AC%E6%8D%A2markdown%E4%B8%BApdf/</url>
    <content><![CDATA[<a id="more"></a>
<p>pandoc是一款强悍的文档的转换工具，支持绝大多数文档格式之间的相互转换，而且具有强大的控制能力。</p>
<p><strong>安装</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install texlive-xetex pandoc</span><br></pre></td></tr></table></figure>

<p><strong>转换markdown</strong></p>
<p>默认latex引擎pdflatex不支持中文，需要使用xelatex引擎，并且要指定中文字体</p>
<p>可以这样查看系统中文字体:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ fc-list :lang=zh</span><br></pre></td></tr></table></figure>

<p>然后mkd转换到pdf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pandoc foo.mkd --latex-engine=xelatex -V CJKmainfont=<span class="string">&quot;Noto Sans CJK SC&quot;</span> -o foo.pdf</span><br></pre></td></tr></table></figure>

<p>然而对中文的支持还是有些问题，这样会把较长的文本行截断，需要定制template来解决此问题。</p>
<p>先导出pandoc默认模板：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pandoc -D latex &gt; mytemplate.tex</span><br></pre></td></tr></table></figure>

<p>在生成的模板文件mytemplate.tex文件的第一行后面添加如下行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\\XeTeXlinebreaklocale <span class="string">&quot;zh&quot;</span></span><br><span class="line">\\XeTeXlinebreakskip = 0pt plus 1pt minus <span class="number">0.</span>1pt</span><br></pre></td></tr></table></figure>

<p>将模板文件mytemplate.lex置于~/.pandoc/templates/路径下，或者置于转换命令当前目录下。</p>
<p>然后这样转换：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pandoc manual.mkd --latex-engine=xelatex -V CJKmainfont=<span class="string">&quot;Noto Sans CJK SC&quot;</span> -o manual.pdf --template=mytemplate.tex</span><br></pre></td></tr></table></figure>

<p>还有一个小问题，默认生成的pdf边距比较大，可以通过geometry参数来控制边距。</p>
<p>所以最后的命令行大约是这个样子的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pandoc manual.mkd --latex-engine=xelatex -V CJKmainfont=<span class="string">&quot;Noto Sans CJK SC&quot;</span> -o manual.pdf -V geometry:<span class="string">&quot;top=2cm, bottom=1.5cm, left=1cm, right=1cm&quot;</span> --template=mytemplate.tex</span><br></pre></td></tr></table></figure>

<p>可以用模板文件指定使用的字体，模板文件可以很复杂，嗯，latex太复杂了。</p>
<p>pandoc转换markdown时，对两个tab缩进支持不好，还没找到好的解决办法。</p>
<p><strong>Mac OS X</strong></p>
<p>安装pandoc和mactex</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew install pandoc</span><br><span class="line">$ brew cask install mactex</span><br></pre></td></tr></table></figure>

<p>中文字体可以使用苹方简体中文 “PingFang SC”</p>
<p>References:<br>[1]<a href="https://github.com/jgm/pandoc/wiki/Pandoc-With-Chinese-(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">Pandoc With Chinese (简体中文)</a><br>[2]<a href="http://pandoc.org/faqs.html">pandoc faqs</a><br>[3]<a href="http://tex.stackexchange.com/questions/179926/pandoc-markdown-to-pdf-without-cutting-off-code-block-lines-that-are-too-long">Pandoc: Markdown to PDF, without cutting off code block lines that are too long</a><br>[4]<a href="https://jdhao.github.io/2017/12/10/pandoc-markdown-with-chinese/">纯文本做笔记 — 使用 Pandoc 与 Markdown 生成 PDF 文件</a><br>[5]<a href="http://blog.jqian.net/post/xelatex.html">使用xelatex生成中文pdf</a><br>[6]<a href="https://www.jianshu.com/p/7f9a9ff053bb">使用pandoc转换md为PDF并添加中文支持</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>parameter与argument</title>
    <url>/2013/11/11/parameter-and-argument/</url>
    <content><![CDATA[<p>Parameter叫参数，argument叫引数。</p>
<a id="more"></a>
<p><strong>parameter</strong>又叫<strong>形式参数</strong>(formal parameter),是函数定义时其signature中声明的来引用值的变量。<br>[cpp]<br>int add (int parameter1, int parameter2){<br> return parameter1 + parameter2;<br>}<br>[/cpp]<br>在这里parameter1和parameter2就是<strong>参数</strong>(parameter)。</p>
<p>而调用参数时提供的值则是<strong>argument</strong>,又叫<strong>实际参数</strong>(actual parameter),比如<br>[cpp]<br>int sum = add(1, 2);<br>[/cpp]<br>在这里，1和2就是<strong>引数</strong>(argument)。</p>
<p>可以使用多组不同的引数来调用函数，因而可以不是很严格的这样理解：参数为类型(type)，而引数为参数的实例(instance)。</p>
<p>在命令上传递给程序的调用参数，我们在程序内部引用时他们都是arguments，这也是一致的，也就是，<br>我们与命令调用者约定的调用接口是形式参数列表(parameters list)，调用者从shell上实际调用命令时提供的就是引数列表(arguments list)。</p>
<p>最好分清楚二者，不要混用，虽然混用也没有太大的问题。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>PC BIOS代码和数据分布示意图(PC BIOS Code and Data Layout)</title>
    <url>/2009/07/04/pc-bios-code-data-layout/</url>
    <content><![CDATA[<p>本图示意了实模式下PC BIOS代码和数据在内存中的映射位置。请注意，保护模式下可能与此不同，映射到了高端内存位置，具体不详。<br><a href="/images/2009/07/bios.jpg"><img src="/images/2009/07/bios-212x300.jpg" alt="bios" title="bios"></a></p>
<p>pdf格式文件<a href="/downloads/bios.pdf">bios.pdf</a>，OpenOfficeOrg源文件<a href="/downloads/bios.odg">bios.odg</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>oracle初始化参数文件pfile和spfile</title>
    <url>/2011/11/03/pfile-and-spfile/</url>
    <content><![CDATA[<p>当一个oracle实例启动的时候,这个实例的特性是通过初始化参数文件(initialization parameter file)中指定的参数获得的。初始化参数存储在文本格式的pfile或者二进制格式的spfile中，oracle 9i或更高的版本使用spfile,而之前的版本使用pfile。</p>
<a id="more"></a>
<p><strong>spflie比pfile有很多优点：</strong></p>
<ul>
<li>  可以用RMAN来备份spfile,但是不能备份pfile</li>
<li>  减少了人为的错误。spfile由服务器来管理，任何参数改变被接受前都会经过严格的检查</li>
<li>  消除了配置问题，如果远程启动oracle服务器，不再需要一个本地的pfile</li>
</ul>
<p><strong>spfile与pfile的不用点</strong></p>
<p>pfile是一个静态的客户端文本文件，可以使用标准的文本编辑器如vim或emacs来编辑。这个文件通常是保存在服务器上的，然而如果你想远程启动oracle服务器，则你需要pfile的一个本地拷贝，DBA通常称此文件为INIT.ORA文件。</p>
<p>然而spfile(Server Parameter File)是一直存在于服务器端的二进制文件，只能使用“ALTER SYSTEM SET”命令来修改。使用spfile,不再需要一个pfile的本地拷贝来远程启动数据库。试图编辑spfile会使其损坏，从而使数据库无法启动。</p>
<p><strong>如何知道数据库使用spfile还是pfile</strong></p>
<p>1、执行以下查询<br>SQL&gt; SELECT DECODE(value, NULL, ‘PFILE’, ‘SPFILE’) “Init File Type”<br> FROM sys.v_$parameter WHERE name = ‘spfile’;</p>
<p>2、查看spfile参数值<br>SQL&gt;show parameters spfile</p>
<p>如果有值说明使用spfile启动，反之pfile</p>
<p>3、还可以使用V$SPPARAMETER视图来确定使用的是spfile还是pfile,如果所有参数的value列都是null,那么使用的是pfile,否则是spfile。</p>
<p><strong>查看参数设置</strong></p>
<p>可以使用以下方法查看参数设置,无论参数是通过pfile或者spfile来设置的</p>
<ul>
<li>  从sqlplus里面使用”SHOW PARAMETERS”命令,比如SQL&gt;show parameter sga_target;</li>
<li>  通过V$PARAMETER视图查看当前实际的参数值</li>
<li>  通过V$PARAMETER2视图查看当前实际的参数值,”List Values”多行显示</li>
<li>  通过V$SPPARAMETER视图，查看server parameter file的当前值</li>
</ul>
<p><strong>使用spfile或pfile启动数据库</strong></p>
<p>oracle按以下顺序搜索合适的初始化参数文件：</p>
<ul>
<li>  尝试使用$ORACLE_HOME/dbs (Unix) or ORACLE_HOME/database (Windows)路径下的spfile${ORACLE_SID}.ora文件</li>
<li>  尝试使用$ORACLE_HOME/dbs (Unix) or ORACLE_HOME/database (Windows)路径下的spfile.ora文件</li>
<li>  尝试使用$ORACLE_HOME/dbs (Unix) or ORACLE_HOME/database (Windows)路径下的init${ORACLE_SID}.ora文件</li>
</ul>
<p>前两个是spfile，最后一个是pfile,${ORACLE_SID}部分一定要大写。</p>
<p>也可以为startup命令的pfile语句指定一个pfile来替代默认的初始化参数文件<br>SQL&gt; STARTUP PFILE=’/path/to/pfile’</p>
<p>注意并没有”STARTUP SPFILE=”这样一个命令，也就是并不能直接指定一个spfile来启动数据库，但可以通过以下方法来使用非默认的spfile启动数据库：</p>
<p>1、创建一个只有一行的pfile,这一行用来指定spfile参数,参数的值即为一个非默认的spfile，比如创建一个pfile /u01/oracle/dbs/spf_init.ora只包含下面的行<br>SPFILE = /u01/oracle/dbs/test_spfile.ora</p>
<p>2、用上一步创建的初始化参数文件启动实例<br>STARTUP PFILE = /u01/oracle/dbs/spf_init.ora</p>
<p>这样就可以间接的用非默认的spfile来启动实例了，这个spfile必须位于数据库服务器上。这样也不需要客户机器维护一个客户端的初始化参数文件，当客户端机器发现初始化参数文件包含一个spfile参数，它就会告诉服务器指定的spfile从哪里读取。</p>
<p><strong>在pfile和spfile之间转换</strong></p>
<p>可以很容易的在pfile和spfile之间进行转行，以SYSDBA或SYSOPER角色执行一下命令：<br>SQL&gt; CREATE PFILE FROM SPFILE;<br>SQL&gt; CREATE SPFILE FROM PFILE;</p>
<p>也可以指定非缺省的pfile或spfile位置，可以二者都指定非缺省的位置，比如：<br>SQL&gt; CREATE SPFILE=’/oradata/spfileORCL.ora’ from PFILE=’/oradata/initORCL.ora’;</p>
<p><strong>参数文件备份</strong></p>
<p>如果设置”CONFIGURE CONTROLFILE AUTOBACKUP”为”ON”（该参数默认值为”OFF”）,RMAN会在备份控制文件的同时备份参数文件，RMAN不能备份pfile,比如</p>
<p>RMAN&gt; CONFIGURE CONTROLFILE AUTOBACKUP ON;</p>
<p>使用如下的命令恢复参数文件：<br>RMAN&gt; RESTORE CONTROLFILE FROM AUTOBACKUP;</p>
<p><strong>改变spfile参数值</strong></p>
<p>pfile可以用任何文本编辑器进行编辑，spfile是二进制文件，可以使用”ALTER SYSTEM SET”和”ALTER SYSTEM RESET”命令来改变spfile参数值，格式如下<br>SQL&gt; ALTER SYSTEM SET parameter_name=value SCOPE=MEMORY SPFILE BOTH;</p>
<p>SCOPE参数值的含义如下：<br>MEMORY - 只设置当前实例。如果使用pfile启动数据库，这是默认的行为。<br>SPFILE - 更新spfile,参数值将会在数据库下一次启动后生效。<br>BOTH - 设置当前实例，并更新spfile。如果使用spfile启动数据库，这是默认的行为。</p>
<p>另一种改变spfile参数的方法是将spfile转换到pfile,用文本编辑器编辑参数，然后再转换回spfile启动数据库，步骤如下：<br>1、导出spfile到pfile。<br>SQL&gt;CREATE PFILE=’pfilename’ FROM SPFILE =’spfilename’;</p>
<p>2、使用文本编辑器编辑导出的pfile</p>
<p>3、关闭然后使用pfile启动数据库<br>SQL&gt; STARTUP PFILE=pfile_name;</p>
<p>4、重新创建spfile<br>SQL&gt;CREATE SPFILE=’spfilename’ FROM PFILE=’pfilename’;</p>
<p>5、关闭然后不使用参数启动数据库<br>SQL&gt;STARTUP</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>pg_dump,pg_dumpall,pg_restore与psql</title>
    <url>/2016/08/07/pg-dumppg-dumpallpg-restore-psql/</url>
    <content><![CDATA[<a id="more"></a>
<p>pg_dump可以转储数据库为一个sql脚本文件或其他归档格式文件，比如pg_restore使用的归档格式。</p>
<p>pg_dump默认输出普通的sql脚本，指定-F –format=format来指定pg_restore支持的格式，比如-Fc或-Ft</p>
<p>pg_dumpall内部使用pg_dump来转储数据库，只输出文本格式的sql脚本文件。</p>
<p>在转储的同时可以进行bzip2压缩，比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pg_dumpall -U user -h localhost -c --<span class="keyword">if</span>-exists --role=postgres bzip2 &gt; db.sql.bz2</span><br></pre></td></tr></table></figure>
<p>-c选项指定在重建数据库对象之前插入清理语句(drop)。</p>
<p>sql脚本文件只能使用psql来执行，如果使用pg_restore，则会有如下错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">pg_restore: \[archiver\] input file appears to be a text format dump. Please use psql</span><br></pre></td></tr></table></figure>

<p>其他格式则需要使用pg_restore来恢复。</p>
<p>恢复pg_dumpall转储的sql脚本时，使用超级用户postgres来恢复：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql -f reis_2016_08_07.sql &gt; <span class="keyword">import</span>.log</span><br><span class="line">psql:reis_2016_08_07.sql:<span class="number">24</span>: ERROR: current user cannot be dropped</span><br><span class="line">psql:reis_2016_08_07.sql:<span class="number">33</span>: ERROR: role <span class="string">&quot;postgres&quot;</span> already exists</span><br></pre></td></tr></table></figure>
<p>有错误提示不能drop掉postgres用户和postgres用户已经存在，在sql脚本中有这样两行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">DROP ROLE IF EXISTS postgres;</span><br><span class="line">CREATE ROLE postgres;</span><br></pre></td></tr></table></figure>

<p>因为当前用户正是postgres,所以会有这样的错误，忽略掉即可。</p>
<p>References:<br>[1]<a href="http://www.postgres.cn/news/viewone/1/244">Postgresql 转存恢复数据经验</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>以服务方式部署pgadmin4</title>
    <url>/2020/02/03/pgadmin4-server-deployment/</url>
    <content><![CDATA[<a id="more"></a>
<p>在debian buster系统上以服务方式部署pgadmin4</p>
<p><strong>配置</strong></p>
<p>/usr/share/pgadmin4/web目录下添加config_local.py文件，内容如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">LOG_FILE = <span class="string">&#x27;/var/log/pgadmin/pgadmin4.log&#x27;</span></span><br><span class="line">SQLITE_PATH = <span class="string">&#x27;/var/lib/pgadmin/pgadmin4.db&#x27;</span></span><br><span class="line">SESSION_DB_PATH = <span class="string">&#x27;/var/lib/pgadmin/sessions&#x27;</span></span><br><span class="line">STORAGE_DIR = <span class="string">&#x27;/var/lib/pgadmin/storage&#x27;</span></span><br></pre></td></tr></table></figure>

<p>然后执行:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># python3 setup.py</span><br></pre></td></tr></table></figure>
<p>配置过程中输入用户登录认证信息，email和password，访问服务时需要提供</p>
<p><strong>运行</strong></p>
<p>使用gunicorn来运行python服务，先安装gunicorn</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install gunicorn3</span><br></pre></td></tr></table></figure>

<p>启动服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo gunicorn3 --bind <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">80</span> \\</span><br><span class="line"> --workers=<span class="number">1</span> \\</span><br><span class="line"> --threads=<span class="number">25</span> \\</span><br><span class="line"> --chdir /usr/share/pgadmin4/web \\</span><br><span class="line"> pgAdmin4:app</span><br></pre></td></tr></table></figure>

<p>然后打开浏览器，输入服务所在的ip地址即可。</p>
<p>References:<br>[1]<a href="https://www.pgadmin.org/docs/pgadmin4/latest/server_deployment.html">Server Deployment</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>pgadmin4无法启动错误</title>
    <url>/2020/02/04/pgadmin4-start-error/</url>
    <content><![CDATA[<a id="more"></a>
<p>pgadmin4无法启动，有类似错误</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">AttributeError: <span class="string">&#x27;module&#x27;</span> object has no attribute <span class="string">&#x27;GSSException&#x27;</span></span><br></pre></td></tr></table></figure>

<p>是因为python3-paramiko与python3-gssapi冲突，启动python3,import paramiko会报错：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Python <span class="number">3.7</span><span class="number">.3</span> (<span class="keyword">default</span>, Apr <span class="number">3</span> <span class="number">2019</span>, <span class="number">05</span>:<span class="number">39</span>:<span class="number">12</span>) </span><br><span class="line">\[GCC <span class="number">8.3</span><span class="number">.0</span>\] on linux</span><br><span class="line">Type <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> or <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">import</span> paramiko</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line"> File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> File <span class="string">&quot;/usr/lib/python3/dist-packages/paramiko/__init__.py&quot;</span>, line <span class="number">22</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> <span class="keyword">from</span> paramiko.transport <span class="keyword">import</span> SecurityOptions, Transport</span><br><span class="line"> File <span class="string">&quot;/usr/lib/python3/dist-packages/paramiko/transport.py&quot;</span>, line <span class="number">38</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> <span class="keyword">from</span> paramiko.auth_handler <span class="keyword">import</span> AuthHandler</span><br><span class="line"> File <span class="string">&quot;/usr/lib/python3/dist-packages/paramiko/auth_handler.py&quot;</span>, line <span class="number">72</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> <span class="keyword">from</span> paramiko.ssh_gss <span class="keyword">import</span> GSSAuth, GSS_EXCEPTIONS</span><br><span class="line"> File <span class="string">&quot;/usr/lib/python3/dist-packages/paramiko/ssh_gss.py&quot;</span>, line <span class="number">55</span>, <span class="keyword">in</span> &lt;<span class="built_in">module</span>&gt;</span><br><span class="line"> GSS_EXCEPTIONS = (gssapi.GSSException,)</span><br><span class="line">AttributeError: <span class="built_in">module</span> <span class="string">&#x27;gssapi&#x27;</span> has no attribute <span class="string">&#x27;GSSException&#x27;</span></span><br></pre></td></tr></table></figure>

<p>临时的解决办法就是卸载掉python3-gssapi</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt remove python3-gssapi</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>PHP PDO select语句结果行数计算</title>
    <url>/2012/11/12/php-select-rowcount/</url>
    <content><![CDATA[<p>PDO有一个函数PDOStatement::rowCount返回上一个SQL语句影响的行数。</p>
<a id="more"></a>
<p>rowCount函数对于DELETE, INSERT, 或者UPDATE语句的结果是正确的,但对于select语句则与数据库的实现相关。有些数据库在执行select语句时会将结果集全部读入内存,但对于数量巨大的结果集,这样显然是低效的。大部分的数据库则只会返回结果集的一部分,当需要时再返回其余的结果集,这样无论是内存占用和执行效率都是优化的。对于后一种情况,则rowCount无法返回正确的SELECT语句结果集的行数。</p>
<p>获取正确的SELECT结果的行数有几种方法</p>
<p>1、<strong>使用fetchAll函数</strong></p>
<p>$q = $db-&gt;query(“SELECT …”);<br>$rows = $q-&gt;fetchAll();<br>$rowCount = count($rows);</p>
<p>2、<strong>使用sql count函数</strong></p>
<p>$q = $db-&gt;query(“SELECT count(*) from db;”);<br>$rows = $q-&gt;fetch();<br>$rowCount = $rows[0];</p>
<p>显然第二种方法更有效率</p>
]]></content>
      <categories>
        <category>lang</category>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>生成PKI公私密钥对及数字证书</title>
    <url>/2014/01/22/pki-key-pair-certificate/</url>
    <content><![CDATA[<p>PKI体系是数字证书的基础。</p>
<a id="more"></a>
<p>有些情形只需要公私密钥对就够了, 不需要数字证书,比如私有的SSH服务。但是对于一些要求身份认证的情形,则需要对公钥进行数字签名形成数字证书。</p>
<p><strong>公私密钥对(key pair)</strong></p>
<p>有两种常见的工具来生成RSA公私密钥对,ssh-keygen和openssl genrsa。其实ssh-keygen底层也是使用openssl提供的库来生成密钥。</p>
<p><em>ssh-keygen</em></p>
<p>生成2048位RSA密钥对,1024已经不算安全了,现在至少要使用2048位的密钥。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -b <span class="number">2048</span> -t rsa -f foo_rsa</span><br><span class="line"></span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved <span class="keyword">in</span> foo_rsa.</span><br><span class="line">Your public key has been saved <span class="keyword">in</span> foo_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">b8:c4:5f:2a:<span class="number">94</span>:fd:b9:<span class="number">56</span>:9d:5b:fd:<span class="number">96</span>:<span class="number">02</span>:5a:7e:b7 user@yoga</span><br><span class="line">The key<span class="string">&#x27;s randomart image is:</span></span><br><span class="line"><span class="string">+--\[ RSA 2048\]----+</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> . + </span></span><br><span class="line"><span class="string"> * S . . ..</span></span><br><span class="line"><span class="string"> o o + +. o o</span></span><br><span class="line"><span class="string"> o o *.. oo</span></span><br><span class="line"><span class="string"> . ..o o.oo</span></span><br><span class="line"><span class="string"> .. . oE.</span></span><br><span class="line"><span class="string">+-----------------+</span></span><br></pre></td></tr></table></figure>
<p>-b 指定密钥位数<br>-t 指定密钥类型rsa,dsa或者ecdsa。一般常用的就是rsa,据说椭圆曲线ecdsa安全又高效,不过没用过。</p>
<p>如果密钥对用于ssh,那么习惯上私钥命名为id_rsa,对应的公钥就是id_rsa.pub,然后可以使用ssh-copy-id把密钥追加到远程主机的.ssh/authorized_key文件里。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-copy-id -i ~<span class="regexp">/.ssh/i</span>d_rsa.pub user@host</span><br></pre></td></tr></table></figure>

<p>默认生成的密钥对是RFC 4716/SSH2格式,可以转到PEM格式公其他程序使用:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -f id_rsa.pub -e -m pem</span><br><span class="line">-----BEGIN RSA PUBLIC KEY-----</span><br><span class="line">...</span><br><span class="line">-----END RSA PUBLIC KEY-----</span><br></pre></td></tr></table></figure>

<p>-m 指定转换后的格式,支持RFC4716(RFC 4716/SSH2 public or private key),PKCS8(PEM PKCS8 public key)或PEM(PEM public key)</p>
<p><em>genrsa</em></p>
<p>生成2048位rsa私钥:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl genrsa -des3 -out foo_rsa <span class="number">2048</span></span><br><span class="line">Generating RSA private key, <span class="number">2048</span> bit long modulus</span><br><span class="line">...........+++</span><br><span class="line">.................................+++</span><br><span class="line">e is <span class="number">65537</span> (<span class="number">0x10001</span>)</span><br><span class="line">Enter pass phrase <span class="keyword">for</span> foo_rsa:</span><br><span class="line">Verifying - Enter pass phrase <span class="keyword">for</span> foo_rsa:</span><br></pre></td></tr></table></figure>

<p>-des3 用于指定使用三重des加密的私钥访问口令(passphase),每次使用私钥时需要提供正确的口令。</p>
<p>生成的PEM编码格式的私钥类似这个样子:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat foo_rsa</span><br><span class="line">-----BEGIN RSA PRIVATE KEY-----</span><br><span class="line">Proc-Type: <span class="number">4</span>,ENCRYPTED</span><br><span class="line">DEK-Info: DES-EDE3-CBC,12C561CAE7D35804</span><br><span class="line"></span><br><span class="line">D/6eomJUqvrCQwOpGuzyF7+NaJmP6xzgFeS30792BX58qk10EtWCNIsa+0HW0+Jp</span><br><span class="line">...</span><br><span class="line">-----END RSA PRIVATE KEY-----</span><br></pre></td></tr></table></figure>

<p>以上生成的只是私钥,可以进一步根据私钥推导出对应公钥,为什么可以推导出公钥?参见[3]</p>
<blockquote>
<p>在Openssl中RSA是内存结构。如果内存结构中有rsa-&gt;n,rsa-&gt;e时，该RSA是公钥RSA。RSA的私钥只要有是rsa-&gt;n, rsa-&gt;d 就可以了。但是，往往在应用中,RSA的私钥是也包括rsa-&gt;p,rsa-&gt;q,rsa-&gt;dmp1,rsa-&gt;dmq1,rsa-&gt;iqmp，你想想,d,n,p,q,p-1,q-1以及(p-1)*(q-1)都有了，推导出e太难吗？人们常说不能从私钥导出公钥，是指产生RSA后，抛弃掉p,q的情况的,没有p,q是无法从公钥中算出私钥的，也无法从私算出公钥的。题外话，公钥是公开的，不必费心思去计算了。</p>
</blockquote>
<p>是的,公钥本身就是对外公开,只要私钥还在就没什么大不了的。</p>
<p>推导出对应的公钥:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl rsa -<span class="keyword">in</span> foo_rsa -pubout &gt; foo_rsa.pub</span><br></pre></td></tr></table></figure>

<p>也可以使用ssh-keygen来导出公钥:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -f foo_rsa -y &gt; foo_rsa.pub</span><br></pre></td></tr></table></figure>

<p>这样导出来的公钥是SSH2格式的。</p>
<p><strong>自签数字证书</strong></p>
<p>有了密钥对,还可以进一步申请数字证书。但向CA申请数字证书是要花钱的,so so,如果没有十分的必要,玩个不用建CA的简单自签吧。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl req -<span class="keyword">new</span> -outform PEM -out foo_rsa.cert -key foo_rsa -inform PEM -days <span class="number">365</span> -x509</span><br><span class="line"></span><br><span class="line">You are about to be asked to enter information that will be incorporated</span><br><span class="line">into your certificate request.</span><br><span class="line">What you are about to enter is what is called a Distinguished Name or a DN.</span><br><span class="line">There are quite a few fields but you can leave some blank</span><br><span class="line">For some fields there will be a <span class="keyword">default</span> value,</span><br><span class="line">If you enter <span class="string">&#x27;.&#x27;</span>, the field will be left blank.</span><br><span class="line">-----</span><br><span class="line">Country Name (<span class="number">2</span> letter code) \[AU\]:California</span><br><span class="line">string is too long, it needs to be less than <span class="number">2</span> bytes long</span><br><span class="line">Country Name (<span class="number">2</span> letter code) \[AU\]:US</span><br><span class="line">State or Province Name (full name) \[Some-State\]:California</span><br><span class="line">Locality Name (eg, city) \[\]:Los Angeles</span><br><span class="line">Organization Name (eg, company) \[Internet Widgits Pty Ltd\]:Some Ltd.</span><br><span class="line">Organizational Unit Name (eg, section) \[\]:</span><br><span class="line">Common Name (e.g. server FQDN or YOUR name) \[\]:domain.tld</span><br><span class="line">Email Address \[\]:admin@domain.tld</span><br></pre></td></tr></table></figure>
<p>参数:<br>-new 产生一个新的证书请求,会提示用户输入一些相关的信息。如果没有指定-key参数,会生成一个新的RSA私钥。<br>-days 申请证书的有效期<br>-outform 输出证书的编码格式,PEM或DER,默认PEM<br>-key 用户私钥<br>-inform 用户私钥格式,PEM或DER,默认PEM<br>-x509 输出一个自签的证书而不是产生一个证书请求文件。这通常用于产生一个测试证书或者一个自签根CA证书(root CA Cert)。如果要添加扩展需要通过配置文件指定。除非指定-set-serial选项,否则使用0作为证书序列号</p>
<p>输入一些信息后就可以生成自签的证书foo_rsa.cert了。</p>
<p>还以一并生成私钥并生成证书,不用提前生成密钥了,不过命令行就更复杂了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl req -<span class="keyword">new</span> -outform PEM -out bar_rsa.cert -newkey rsa:<span class="number">2048</span> </span><br><span class="line"> -nodes -keyout bar_rsa -keyform PEM -days <span class="number">365</span> -x509</span><br></pre></td></tr></table></figure>
<p>这里有几个新参数:<br>-newkey rsa:nbits 产生一个新的RSA私钥用于生成证书,私钥的位数用nbits指定<br>-nodes 新产生的私钥不使用des加密的口令,nodes是no des之意。</p>
<p>更详细的用法参考man req。</p>
<p><strong>自建CA中心</strong></p>
<p>自建CA中心,你就可以做CA了,可以签署一系列的数字证书,除了没人内置你的CA root证书之外,一切都不会有问题。<br>不用担心,CA的根证书也都是自签的,只不过信任度有差异而已:-)</p>
<p>CA的配置文件在/etc/ssl/openssl.cnf,里面指定了建立CA中心需要使用的目录结构和文件。使用默认配置:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ mkdir -p ~<span class="regexp">/demoCA/</span>&#123;crl,private,newcerts&#125;</span><br><span class="line">$ touch ~<span class="regexp">/demoCA/</span>&#123;serial,crlnumber,index.txt&#125;</span><br><span class="line">$ touch ~<span class="regexp">/demoCA/</span>private/.rand</span><br><span class="line">$ echo <span class="number">01</span> &gt; ~<span class="regexp">/demoCA/</span>serial</span><br></pre></td></tr></table></figure>

<p>将CA的私钥foo_rsa拷贝到demoCA/private/cakey.pem,或直接生成到这个目录,默认配置下名字必须为cakey.pem。</p>
<p><em>生成证书申请文件CSR:</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl req -<span class="keyword">new</span> -days <span class="number">365</span> -key ~<span class="regexp">/demoCA/</span>private/cakey.pem -out ca.csr</span><br></pre></td></tr></table></figure>

<p>这里提供的是私钥,回答一些问题就可以生成PEM格式编码的证书请求文件ca.csr了。</p>
<p><em>自签CA根证书</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl ca -selfsign -<span class="keyword">in</span> ca.csr</span><br><span class="line"></span><br><span class="line">Using configuration <span class="keyword">from</span> /usr/lib/ssl/openssl.cnf</span><br><span class="line">Check that the request matches the signature</span><br><span class="line">Signature ok</span><br><span class="line">The commonName field needed to be supplied and was missing</span><br></pre></td></tr></table></figure>
<p>因为生成证书请求是没有填写任何信息,所以有最后一句的提示。生成的CA根证书为demoCA/cacert.pem,这样你也成为CA认证中心了:-)。/usr/lib/ssl/openssl.cnf是符号链接,链接到/etc/ssl/openssl.cnf。</p>
<p>这是<strong>使用自己的私钥为自己的公钥进行数字签名生成数字证书</strong>,其实<strong>所有的CA都是这么干的</strong>。</p>
<p><em>签署其他证书</em></p>
<p>有了CA根证书,就可以使用这个根证书来签署其他数字证书了。<br>和签署CA根证书过程基本一样，只是最后签署证书就不要自签了,因为要用CA根证书签署:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl ca -<span class="keyword">in</span> userreq.csr -out usercert.cert</span><br></pre></td></tr></table></figure>
<p>userreq.csr 为数字证书申请文件<br>usercert.cert 为使用CA根证书签署后的数字证书</p>
<p><strong>ssh-keygen证书</strong></p>
<p>ssh-keygen也可以生成证书,但是openssh的证书与X.509证书是不同的,它更简单。ssh-keygen支持用户和主机两种证书。这种证书只是在ssh环境下做用户和主机的认证之用。我们常用的还是X.509证书,关于openssh证书的详细信息参见man ssh-keygen CERTIFICATES节。</p>
<p>Refereneces:<br>[1]<a href="http://rhythm-zju.blog.163.com/blog/static/310042008015115718637/">基于 OpenSSL 的 CA 建立及证书签发</a><br>[2]<a href="http://www.haiyun.me/archives/openssl-ca-cert.html">Openssl生成根证书、服务器证书并签核证书</a><br>[3]<a href="http://blog.csdn.net/ifree_/article/details/10952331">openssl genrsa 能够单独生成私钥还能推导出公钥的原因</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>postfix邮件系统之基础配置</title>
    <url>/2014/01/03/postfix-fundmental-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>电子邮件系统结构图</strong><br>图片来自网络</p>
<p><img src="/downloads/email.png" alt="email architecture"></p>
<p><strong>基本概念</strong><br>电子邮件系统有几个基本的概念:</p>
<ul>
<li>  MUA<br>邮件用户代理(Mail User Agent),邮件系统的客户端,用户用来收发邮件的软件,常见的有linux下的mail,mutt,windows平台下的outlook express等。</li>
<li>  MSA<br>邮件提交代理(Mail Submmission Agent),MSA居于MUA和MTA之间,MSA一般使用587端口向MTA提交邮件。</li>
<li>  MTA<br>邮件传输代理(Mail Transfer Agent),负责邮件的存储和转发,是邮件系统的核心,一般也称之为邮件服务器,常见的有postfix,sendmail,qmail,exim4等。MTA之间使用25端口交换邮件信息。</li>
<li>  MDA<br>邮件投递代理(Mail Dlivery Agent),MTA接收到自己管理的域上用户的邮件后,使用MDA将邮件投递给本地用户。常见的MDA有maildrop,procmail等。</li>
<li>  MRA<br>邮件访问代理(Mail Retrieval Agent),将用户连接到系统邮件，使用POP3或IMAP协议收取邮件,比如fetchmail等。</li>
</ul>
<p>通常这些代理角色分的并不是很清楚,也不太容易区分。经常一个程序实现多个代理角色。对这几个代理角色更详尽的描述见<a href="http://dev.mutt.org/trac/wiki/MailConcept/Flow">这里</a>。</p>
<p>一封电子邮件在各个代理之间的流动大体是这样的:<br>MUA → MSA → MTA → … → MTA → MDA → MRA → MUA</p>
<p><strong>安装</strong></p>
<h1 id="apt-get-install-postfix-postfix-mysql"><a href="#apt-get-install-postfix-postfix-mysql" class="headerlink" title="apt-get install postfix postfix-mysql"></a>apt-get install postfix postfix-mysql</h1><p><strong>基本配置</strong><br>postfix主配置文件有两个/etc/postfix/main.cf和master.cf</p>
<p>main.cf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">myhostname = mail.openwares.net #指定主机名</span><br><span class="line">mydomain = openwares.net #指定域名</span><br><span class="line">myorigin = $mydomain #本邮件服务器所发送邮件的域名后缀</span><br><span class="line"></span><br><span class="line">#本地投递的域名,所有发送给user@mydestination的邮件都在本地交付</span><br><span class="line">mydestination = localhost.localdomain localhost </span><br><span class="line"></span><br><span class="line">#为来自哪些网络的客户转发邮件(forward,relay),默认为邮件服务器所连接的子网,如果邮件服务器连接在广域网上,</span><br><span class="line">#那么默认设置就太open了。</span><br><span class="line">mynetworks = <span class="number">127.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">8</span> \[::ffff:<span class="number">127.0</span><span class="number">.0</span><span class="number">.0</span>\]/<span class="number">104</span> \[::<span class="number">1</span>\]/<span class="number">128</span> </span><br><span class="line">relay_domains = #拒绝为陌生人转发邮件</span><br><span class="line">relayhost = #直接通过互联网发送邮件</span><br><span class="line">inet_interfaces = all #postfix监听的接口</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>理解虚拟域</strong><br>postfix有两种域,一种是<strong>本地域</strong>, 另一种就是虚拟域。</p>
<p>本地域: </p>
<p> 本地域一般包括postfix运行的机器上的主机名和ip地址,main.cf中用mydestination指名本地域。本地域上的所有用户都有对应的unix账户。如果采用mbox邮箱格式,则用户的邮箱是/var/mail目录下的用户名同名文件，如果采用Maildir邮箱格式,比如在main.cf中设置home_mailbox = Maildir/,则用户的邮箱就是用户主目录的Maildir目录。</p>
<p>虚拟域:</p>
<p> 除了本地域之外,postfix还可以管理其他域,这就是虚拟域。虚拟域分为两种,一种是<strong>虚拟别名域</strong>,另一种是<strong>虚拟邮箱域</strong>。</p>
<ul>
<li>  虚拟别名域<br>使用virtual_alias_domain指定虚拟别名域,然后通过虚拟别名映射virtual_alias_maps将,虚拟域的用户帐号映射到本地unix账户或者远程mail地址</li>
<li>  虚拟邮箱域<br>使用virtual_mailbox_domains指定虚拟邮箱域,通过virtual_mailbox_maps等配置参数为虚拟域的用户映射邮箱地址。虚拟邮箱域的账户不必有对应的unix系统账户。</li>
</ul>
<p>一个域要么是本地域,要么是虚拟域;一个虚拟域要么是虚拟别名域,要么是虚拟邮箱域。也就是<strong>本地域,虚拟别名域,虚拟邮箱域是互斥的</strong>。</p>
<p>那么一个postfix邮件系统要添加一个额外的域,有这么几种选择,几个实例如下：</p>
<ul>
<li>  加入本地域<br>很简单,直接将域名添加到mydestination中即可。这样有两个缺点：<br>第一，所有本地域上的同名用户都对应同一个unix系统账户,也就是<a href="mailto:&#105;&#x6e;&#x66;&#x6f;&#64;&#x64;&#111;&#109;&#x61;&#x69;&#x6e;&#x31;&#46;&#116;&#x6c;&#100;">&#105;&#x6e;&#x66;&#x6f;&#64;&#x64;&#111;&#109;&#x61;&#x69;&#x6e;&#x31;&#46;&#116;&#x6c;&#100;</a>和info@domain2.tld的所有邮件都将发给unix系统用户info。<br>第二，所有的用户必须有对应的unix系统用户,如果用户很多,管理起来比较麻烦。</li>
<li>加入虚拟别名域<br>/etc/postfix/main.cf:<figure class="highlight"><table><tr><td class="code"><pre><span class="line"> virtual_alias_domains = example.com</span><br><span class="line"> virtual_alias_maps = hash:<span class="regexp">/etc/</span>postfix/virtual</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"> /etc/postfix/virtual:</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line"> postmaster@example.com postmaster</span><br><span class="line"> info@example.com joe</span><br><span class="line"> sales@example.com jane</span><br><span class="line"> # Uncomment entry below to implement a catch-all address</span><br><span class="line"> # @example.com jim #example.com域上的所有其他用户的邮件都发送给jim,这样可能会有垃圾邮件的困扰</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>也可以将虚拟别名域上的用户映射到远程账户,只是作为转发之用。</p>
<ul>
<li>加入虚拟邮箱域<br>/etc/postfix/main.cf:<figure class="highlight"><table><tr><td class="code"><pre><span class="line"> virtual_mailbox_domains = example.com </span><br><span class="line"> virtual_mailbox_base = /var/mail/vhosts #指定虚拟邮箱域内所有用户邮箱相对的基本目录</span><br><span class="line"> virtual_mailbox_maps = hash:<span class="regexp">/etc/</span>postfix/vmailbox</span><br><span class="line"> virtual_minimum_uid = 100 #邮箱文件(mbox)或目录(Mailbox)的最小owner id</span><br><span class="line"> virtual_uid_maps = static:5000 #静态映射邮箱所有者uid</span><br><span class="line"> #静态映射邮箱所有者gid。uid和gid也可以指定查找表,通过邮件地址来查找对应的gid或uid</span><br><span class="line"> virtual_gid_maps = <span class="keyword">static</span>:<span class="number">5000</span> </span><br><span class="line"> virtual_alias_maps = hash:/etc/postfix/virtual #虚拟邮箱域也可以使用别名映射</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"> /etc/postfix/vmailbox:</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line"> #mbox邮箱格式,完整的邮箱地址为/<span class="keyword">var</span>/mail/vhosts/example.com/info</span><br><span class="line"> info@example.com example.com/info </span><br><span class="line"> #Maildir邮箱格式,完整的邮箱地址为/<span class="keyword">var</span>/mail/vhosts/example.com/sales/</span><br><span class="line"> sales@example.com example.com/sales/ </span><br><span class="line"> # Comment out the entry below to implement a catch-all.</span><br><span class="line"> # @example.com example.com/catchall</span><br><span class="line"> #...virtual mailboxes for more domains...</span><br></pre></td></tr></table></figure>
/etc/postfix/virtual:<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postmaster@example.com postmaster #虚拟邮箱域用户映射到本地unix用户</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>postfix支持丰富的查找表类型, hash,ldap,mysql等,一般使用数据库比较方便。</p>
<p><strong>虚拟邮箱域mysql数据库配置</strong><br>这里使用mysql数据库来设置openwares.net虚拟邮箱域</p>
<p><em>创建数据库</em></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mysql&gt; CREATE DATABASE mail;</span><br><span class="line">mysql&gt; GRANT ALL ON mail.* TO <span class="string">&#x27;postfix&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> IDENTIFIED BY <span class="string">&#x27;postfix&#x27;</span>;</span><br><span class="line">mysql&gt; GRANT ALL ON mail.* TO <span class="string">&#x27;postfix&#x27;</span>@<span class="string">&#x27;localhost.localdomain&#x27;</span> IDENTIFIED BY <span class="string">&#x27;postfix&#x27;</span>;</span><br><span class="line">mysql&gt; FLUSH PRIVILEGES;</span><br><span class="line">mysql&gt; USE mail;</span><br><span class="line">mysql&gt; CREATE TABLE users (</span><br><span class="line">email varchar(<span class="number">80</span>) NOT NULL,</span><br><span class="line">password varchar(<span class="number">20</span>) NOT NULL,</span><br><span class="line">PRIMARY KEY (email)</span><br><span class="line">);</span><br><span class="line">mysql&gt; quit;</span><br></pre></td></tr></table></figure>

<p><em>创建postfix配置文件</em><br>/etc/postfix/mysql_virtual_mailboxes.cf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">user = postfix</span><br><span class="line">password = postfix</span><br><span class="line">dbname = mail</span><br><span class="line">query = SELECT CONCAT(SUBSTRING_INDEX(email,<span class="string">&#x27;@&#x27;</span>,-<span class="number">1</span>),<span class="string">&#x27;/&#x27;</span>,SUBSTRING_INDEX(email,<span class="string">&#x27;@&#x27;</span>,<span class="number">1</span>),<span class="string">&#x27;/&#x27;</span>) FROM users WHERE email=<span class="string">&#x27;%s&#x27;</span></span><br><span class="line">hosts = <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span></span><br></pre></td></tr></table></figure>

<p>query语句从user表动态构建出用户对应的Maildir目录,格式为domain.tld/username/</p>
<p>/etc/postfix/main.cf中添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">virtual_mailbox_domains = openwares.net</span><br><span class="line">virtual_mailbox_maps = mysql:<span class="regexp">/etc/</span>postfix/mysql_virtual_mailboxes.cf</span><br><span class="line">virtual_mailbox_base = <span class="regexp">/var/m</span>ail/vmail</span><br><span class="line">virtual_minimum_uid = <span class="number">5000</span></span><br><span class="line">virtual_uid_maps = <span class="keyword">static</span>:<span class="number">5000</span></span><br><span class="line">virtual_gid_maps = <span class="keyword">static</span>:<span class="number">5000</span></span><br></pre></td></tr></table></figure>
<p><em>创建虚拟邮箱文件夹的所有者</em></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># groupadd -g 5000 vmail</span><br><span class="line"># useradd -g vmail -u 5000 vmail -d /var/mail/vmail -m</span><br></pre></td></tr></table></figure>
<p>在users表里添加用户</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mysql&gt; insert into users values (<span class="string">&#x27;test@openwares.net&#x27;</span>, <span class="string">&#x27;password&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>就可以使用<a href="mailto:&#x74;&#x65;&#115;&#x74;&#64;&#x6f;&#x70;&#101;&#110;&#x77;&#x61;&#x72;&#101;&#x73;&#x2e;&#110;&#x65;&#x74;">&#x74;&#x65;&#115;&#x74;&#64;&#x6f;&#x70;&#101;&#110;&#x77;&#x61;&#x72;&#101;&#x73;&#x2e;&#110;&#x65;&#x74;</a>邮箱了。</p>
<p><strong>别名设置</strong></p>
<p>/etc/aliases为postfix的本地别名数据库,可以为本地收件人重定向邮件，这种重定向由本地交付代理(local delivery agent)处理。可以添加一个重定向将root重定向到自己的用户,从而所有的系统邮件都会发给你。比如在文件中添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">root: yourname</span><br></pre></td></tr></table></figure>
<p>修改/etc/aliases之后,需要执行命令</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># newaliases</span><br></pre></td></tr></table></figure>
<p>使修改生效。</p>
<p><strong>TLS加密</strong></p>
<p>如果不开启TLS,则邮件客户端与服务器之间是明文传输的,包括邮件内容和smtp认证的用户名和密码都容易被中间节点截获。因此如果需要更安全的电子邮件系统,则需要为postfix配置TLS加密。</p>
<p>启用TLS,需要为服务器创建私钥和数字证书(签名的公钥),公私钥必须是PEM格式,并且私钥不能添加passphrase。<br>数字证书需要受信任的证书颁发机构(CA)签发才被别人认可,虽然自签也能使用,但不一定为大多数的客户端所支持。<br>当前免费的CA机构有<a href="www.cacert.org">CACert</a>和<a href="www.startssl.com">StartSSL</a>,但被支持的程度还都不高,CACert在开源世界得到广泛支持。</p>
<p>生成自签X.509证书</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd /etc/postfix</span><br><span class="line">$ openssl req -<span class="keyword">new</span> -outform PEM -out smtpd.cert -newkey rsa:<span class="number">2048</span> -nodes -keyout smtpd.key -keyform PEM -days <span class="number">365</span> -x509</span><br></pre></td></tr></table></figure>

<p>一般使用RSA证书就可以了。有了证书后,在main.cf中添加如下设置:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">smtpd_tls_cert_file = /etc/postfix/smtpd.cert #证书</span><br><span class="line">smtpd_tls_key_file = /etc/postfix/smtpd.key #私钥 </span><br><span class="line">smtpd_tls_security_level = may # may 不强制客户端使用TLS, encrypt 则强制客户端使用TLS</span><br><span class="line">#smtpd_use_tls = yes #这是已经废弃的参数,新版本postfix不再使用</span><br></pre></td></tr></table></figure>

<p>通常来讲未机密服务和加密服务使用不同的端口号,比如http使用80,https使用443。smtp使用25,smtps使用465。<br>但是使用两个端口有些太浪费了,smtp支持STARTSSL,也就是先在25端口上连接,需要加密连接服务时,可以通过STARTSSL将普通连接升级到SSL加密连接。</p>
<p>SMTP最初是设计来传输(transfer)邮件而不是提交(submission)邮件的,因此又有了另一个端口587用于消息提交(message submission)。MSA(Mail Submmission Agent)使用这个端口向MTA(Mail Tansfer Agent)提交邮件。</p>
<p>postfix也可以通过配置直接使用465端口提供加密连接,而不是使用STARTSSL。部分客户端依赖于这种方式,但这种方式是不鼓励使用的。<br>postfix使用wrapper来支持smtps。</p>
<p><strong>配额quota</strong><br>可以使用<a href="http://vda.sourceforge.net/">VDA</a>添加配额支持,需要给postfix打补丁。</p>
<p><strong>UPDATE(01/24/2014):</strong><br>在user表中添加一个用户帐号后,用户的虚拟邮箱目录是尚未建立的,只有当用户收到第一封邮件时,postfix才会为用户建立maildir目录。之后才能使用imap登录用户邮箱,否则imap会有错误提示:</p>
<p>Jan 24 10:33:29 www imapd-ssl: <a href="mailto:&#120;&#120;&#120;&#64;&#x6f;&#112;&#x65;&#x6e;&#119;&#x61;&#114;&#101;&#x73;&#x2e;&#x6e;&#101;&#116;">&#120;&#120;&#120;&#64;&#x6f;&#112;&#x65;&#x6e;&#119;&#x61;&#114;&#101;&#x73;&#x2e;&#x6e;&#101;&#116;</a>: No such file or directory</p>
<p>所以新增邮箱用户后,立马向其发送一个welcome邮件吧。</p>
<p>参考:<br><a href="http://www.postfix.org/BASIC_CONFIGURATION_README.html">Postfix Basic Configuration</a><br><a href="http://www.postfix.org/VIRTUAL_README.html">Postfix Virtual Domain Hosting Howto</a><br><a href="http://www.postfix.org/DATABASE_README.html">Postfix Lookup Table Overview</a><br><a href="http://www.howtoforge.com/virtual-users-and-domains-with-postfix-courier-mysql-and-squirrelmail-ubuntu-12.04-lts">Virtual Users And Domains With Postfix, Courier, MySQL And SquirrelMail (Ubuntu 12.04 LTS)</a><br><a href="http://www.postfix.org/TLS_README.html">Postfix TLS Support</a><br><a href="https://www.fastmail.fm/help/technology_ssl_vs_tls_starttls.html">SSL vs TLS vs STARTTLS</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>postfix邮件系统之imap配置</title>
    <url>/2014/01/03/postfix-imap-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>安装</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install courier-imap courier-authlib-mysql</span><br></pre></td></tr></table></figure>
<p><strong>配置</strong></p>
<p>编辑/etc/courier/authdaemonrc</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">authmodulelist=<span class="string">&quot;authmysql&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>编辑/etc/courier/authmysqlrc,内容如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">MYSQL_SERVER localhost</span><br><span class="line">MYSQL_USERNAME postfix</span><br><span class="line">MYSQL_PASSWORD postfix</span><br><span class="line">MYSQL_PORT <span class="number">3306</span></span><br><span class="line">MYSQL_DATABASE mail</span><br><span class="line">MYSQL_USER_TABLE users</span><br><span class="line">#MYSQL_CRYPT_PWFIELD password # 加密密码</span><br><span class="line">MYSQL_CLEAR_PWFIELD password # 非加密密码</span><br><span class="line">MYSQL_UID_FIELD 5000 # 虚拟邮箱域目录所有者uid</span><br><span class="line">MYSQL_GID_FIELD <span class="number">5000</span></span><br><span class="line">MYSQL_LOGIN_FIELD email #用户名</span><br><span class="line">MYSQL_HOME_FIELD &#x27;/var/mail/vmail&#x27; #虚拟邮箱域邮箱基本目录</span><br><span class="line"># 用户Maildir目录</span><br><span class="line">MYSQL_MAILDIR_FIELD CONCAT(SUBSTRING_INDEX(email,<span class="string">&#x27;@&#x27;</span>,-<span class="number">1</span>),<span class="string">&#x27;/&#x27;</span>,SUBSTRING_INDEX(email,<span class="string">&#x27;@&#x27;</span>,<span class="number">1</span>),<span class="string">&#x27;/&#x27;</span>) </span><br><span class="line">#MYSQL_NAME_FIELD</span><br></pre></td></tr></table></figure>
<p><strong>SSL/TLS加密</strong></p>
<p>未启用SSL/TLS加密时,客户端与imap服务器的所有通讯都是以明文传输的,包括认证用户名和密码。因为如果需要安全的imap服务,则需要启用SSL/TLS加密。</p>
<p>安装courier-imap-ssl</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install courier-imap-ssl</span><br></pre></td></tr></table></figure>
<p>安装过程中为会localhost自签一对证书,放置在/etc/courier/imapd.pem文件中,如果正式使用,最好还是去申请CA签署的证书。</p>
<p><em>为imap服务的域名imap.openwares.net生成自签证书</em>:</p>
<p>编辑/etc/courier/imapd.cnf:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CN=imap.openwares.net #CN为Canonical Name缩写</span><br></pre></td></tr></table></figure>
<p>删除掉安装时为localhost自签的证书</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># rm -f /etc/courier/imapd.pem</span><br></pre></td></tr></table></figure>
<p>重新为imap.openwares.net生成证书</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># mkimapdcert</span><br></pre></td></tr></table></figure>
<p>重新启动ssl imapd</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># /etc/init.d/courier-imap-ssl restart</span><br></pre></td></tr></table></figure>
<p>将未加密imap服务删除</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># /etc/init.d/courier-imap stop</span><br><span class="line"># rm /etc/init.d/courier-imap</span><br></pre></td></tr></table></figure>

<p>未启用SSL/TLS加密的imapd使用知名端口143,启用加密后imapd使用知名端口993。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL初步</title>
    <url>/2012/10/04/postgres-first/</url>
    <content><![CDATA[<p>mysql已纳入oracle囊中,PostgreSQL才是开源数据库的未来,而且PostgresQL比mysql更优秀。</p>
<a id="more"></a>
<p><strong>安装</strong></p>
<p>#apt-get install postgresql postgresql-client</p>
<p><strong>登录</strong></p>
<p>psql是PostgreSQL的交互式管理控制台,就像MySQL的mysql,Oracle的sqlplus</p>
<p>PostgreSQL默认安装的管理员账户名字为postgres,其有对应的linux系统账户postgres,但是这个系统账户是锁定的,无法使用密码登录该账户,这是为了系统安全。不要试图修改密码启用postgres系统账户。</p>
<p>可以这样登录PostgreSQL<br>$sudo su - postgres<br>$psql</p>
<p>或者<br>$sudo -u postgres psql</p>
<p>这样会进入psql控制台<br>psql (9.1.5)<br>Type “help” for help.</p>
<p>postgres=#</p>
<p>输入\q可以退出psql控制台</p>
<p>这种登录方式使用的是peer认证,PostgreSQL会获取当前linux用户,然后匹配认证配置文件/etc/postgresql/[version]/[cluster]/pg_hba.conf文件,如果匹配成功则会让用户登录。<br>hba是host-based authentication的缩写。</p>
<p>这种登录方式与oracle的OS认证登录方式类似<br>$ sqlplus / as sysdba;</p>
<p>也可以使用密码认证方式登录PostgreSQL,首先要为PostgreSQL管理的管理员账户postgres设置密码,注意这里不是指linux系统用户postgres</p>
<p>有两种方法为postgres设置密码,一种是使用SQL,另一种是使用psql命令</p>
<p>使用SQL:<br>postgres=# ALTER USER postgres WITH PASSWORD ‘passwd’;</p>
<p>使用psql命令：<br>postgres=# \password postgres<br>Enter new password: </p>
<p>设置好密码后可以这样登录<br>$ psql -U postgres -h localhost<br>Password for user postgres:<br>这种方式使用的是MD5认证方式,而不是PEER认证方式,匹配了pg_hba.conf中的不同的行。</p>
<p><strong>管理</strong></p>
<p>psql控制台下可以create database,create user,create table,alter …等等日常管理工作。详细用法参见PostgresQL手册。</p>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/9.3/static/auth-pg-hba-conf.html">The pg_hba.conf File</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL 11 连续归档备份</title>
    <url>/2019/10/16/postgresql-11-continuous-archiving/</url>
    <content><![CDATA[<a id="more"></a>
<p>主配置路径/etc/postgresql/11/main/postgresql.conf<br>连续归档备份主要涉及三个参数</p>
<p><strong>参数配置</strong></p>
<p>wal_level<br>默认值为replica，支持WAL归档，replication以及hot standby，所以此参数保持默认值即可。</p>
<p>archive_mode<br>归档模式，默认为off，关闭状态，还有两个选项值on和always。on表示打开归档模式，always表示在日志恢复和replication状态下，仍然会将恢复的日志继续进行归档，所以一般设置为on就可以了。</p>
<p>archive_command<br>归档命令,指定一个shell命令字符串来保存WAL文档，其中%p代表归档文件路径，%f代表归档文件的名字，不包含路径。归档命令返回0表示归档成功，非0表示归档失败，服务器会保留未归档的WAL日志文档，直到重新归档成功，或者服务器耗尽存储空间，进入panic关闭状态。<br>不要将WAL归档日志存储在本机，可以挂载NFS或其他远程文件系统来存储日志，也可以使用scp拷贝到远程服务器，总之archive_command十分灵活。<br>下面的命令写入挂载在本地/mnt/wals目录的远程NFS文件系统</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">archive_command=<span class="string">&#x27;test ! -f /mnt/wals/%f &amp;&amp; cp %p /mnt/wals/%f&#x27;</span></span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">要注意archive_command是以运行postgresql数据库的postgres用户来执行的，要注意权限问题，所以/mnt/wals目录postgres用户要有写入权限。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">wal_keep_segments</span></span><br><span class="line"><span class="string">指定在pg_wal目录下保留的wal日志数量。如果replication使用log ship方式可以防止standby跟不上primary产生wal log的速度导致standby需要的日志被循环覆盖而失效。如果流复制replication时使用复制槽则不会存在这个问题，只要wal log没有被standby apply则primay永远不会删除这些wal log,此参数是没有影响的。还有就是pg_basebackup时如果同时备份需要的wal log则，需要设置此参数以防止需要备份的wal log被循环覆盖。</span></span><br><span class="line"><span class="string">这是设置为100</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">wal_keep_segments = <span class="number">100</span></span><br></pre></td></tr></table></figure>

<p>修改wal_level、archive_mode、wal_keep_segments需要重新启动postgresql才能生效。</p>
<p>查看归档设置是否生效:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql</span><br><span class="line">psql (<span class="number">11.5</span> (Debian <span class="number">11.5</span>-<span class="number">1</span>+deb10u1))</span><br><span class="line">Type <span class="string">&quot;help&quot;</span> <span class="keyword">for</span> help.</span><br><span class="line"></span><br><span class="line">postgres=# select name, setting from pg_catalog.pg_settings where name like &#x27;archive%&#x27; or name = &#x27;wal_level&#x27;;</span><br><span class="line"> name setting </span><br><span class="line">-----------------+----------------------------------------------</span><br><span class="line"> archive_command test ! -f /mnt/wals/%f &amp;&amp; cp %p /mnt/wals/%f</span><br><span class="line"> archive_mode on</span><br><span class="line"> archive_timeout <span class="number">0</span></span><br><span class="line"> wal_level replica</span><br><span class="line">(<span class="number">4</span> rows)</span><br></pre></td></tr></table></figure>

<p>手动切换WAL日志测试归档是否成功:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_current_wal_lsn();</span><br><span class="line"> pg_current_wal_lsn </span><br><span class="line">--------------------</span><br><span class="line"> <span class="number">0</span>/<span class="number">1659450</span></span><br><span class="line">(<span class="number">1</span> row)</span><br><span class="line"></span><br><span class="line">postgres=# select pg_switch_wal();</span><br><span class="line"> pg_switch_wal </span><br><span class="line">---------------</span><br><span class="line"> <span class="number">0</span>/<span class="number">1659468</span></span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<p>查看/mnt/wals目录下是否有了新归档的WAL日志文件</p>
<p><strong>基础备份</strong></p>
<p>开启归档后，应该立即进行一次基础备份，基础备份加上WAL日志可以完整的恢复整个数据库集群。<br>这里使用pg_basebackup在本地服务器进行基础备份，使用postgresql用户进行操作，要注意输出文件写入权限问题</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres sh -c <span class="string">&#x27;pg_basebackup -l 20191019 -RPv -Ft -D - gzip -c &gt; baseback20191019.tgz&#x27;</span></span><br></pre></td></tr></table></figure>
<p>出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">pg_basebackup: cannot stream write-ahead logs <span class="keyword">in</span> tar mode to stdout</span><br><span class="line">Try <span class="string">&quot;pg_basebackup --help&quot;</span> <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure>
<p>这是因为pg_basebackup有一个参数<code>-X --wal-method</code>默认设置为s，但此方法与tar格式写入stdout不兼容,可见postgresql源代码</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (format == <span class="string">&#x27;t&#x27;</span> &amp;&amp; includewal == STREAM_WAL &amp;&amp; strcmp(basedir, <span class="string">&quot;-&quot;</span>) == <span class="number">0</span>)</span><br><span class="line"> &#123;</span><br><span class="line"> pg_log_error(<span class="string">&quot;cannot stream write-ahead logs in tar mode to stdout&quot;</span>);</span><br><span class="line"> fprintf(stderr, _(<span class="string">&quot;Try \\&quot;</span>%s --help\\<span class="string">&quot; for more information.\\n&quot;</span>),</span><br><span class="line"> progname);</span><br><span class="line"> exit(<span class="number">1</span>);</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>

<p><code>-X --wal-method</code>参数可以使pg_basebackup直接包含恢复需要的WAL日志文档，形成一个完整的直接用于恢复的备份，不需要再单独拷贝归档日志文件。但是要注意，wal_keep_segments参数要设置的大一些，防止在备份期间生成的归档日志被循环覆盖，这样基本备份会失败。每个WAL日志有16MB大小，wal_keep_segments设置数乘以16MB就是服务器保存这些wal log需要使用的额外存储空间。<br>当然<code>-X --wal-method</code>参数也可以设置为n，这样恢复时需手动管理自基础备份以来的生成的WAL日志。</p>
<p>在postgres用户的主目录/var/lib/postgresql或postgres可以写的其他目录下执行基础备份完整的命令：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo -u postgres sh -c <span class="string">&#x27;pg_basebackup -l 20191019 -RPv -Ft --wal-method=f -D - gzip -c &gt; baseback20191019.tgz&#x27;</span></span><br><span class="line">pg_basebackup: initiating base backup, waiting <span class="keyword">for</span> checkpoint to complete</span><br><span class="line">pg_basebackup: checkpoint completed</span><br><span class="line">pg_basebackup: write-ahead log start point: <span class="number">0</span>/<span class="number">6000028</span> on timeline <span class="number">1</span></span><br><span class="line"><span class="number">40157</span>/<span class="number">40157</span> kB (<span class="number">100</span>%), <span class="number">1</span>/<span class="number">1</span> tablespace </span><br><span class="line">pg_basebackup: write-ahead log end point: <span class="number">0</span>/60000F8</span><br><span class="line">pg_basebackup: base backup completed</span><br></pre></td></tr></table></figure>
<p>pg_basebackup备份时会生成一个.backup文件标识出保证此次备份完整性所需要的最后一个WAL日志，使用此次基础备份恢复系统时，不再需要之前的WAL日志。生成的备份文档内也有一个文件叫做backup_label，与此文件内容相同。<br>此文件的内容类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">START WAL LOCATION: <span class="number">0</span>/<span class="number">6000028</span> (file <span class="number">000000010000000000000006</span>)</span><br><span class="line">STOP WAL LOCATION: <span class="number">0</span>/60000F8 (file <span class="number">000000010000000000000006</span>)</span><br><span class="line">CHECKPOINT LOCATION: <span class="number">0</span>/<span class="number">6000060</span></span><br><span class="line">BACKUP METHOD: streamed</span><br><span class="line">BACKUP FROM: master</span><br><span class="line">START TIME: <span class="number">2019</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">20</span>:<span class="number">20</span>:<span class="number">44</span> CST </span><br><span class="line">LABEL: <span class="number">20191019</span></span><br><span class="line">START TIMELINE: <span class="number">1</span></span><br><span class="line">STOP TIME: <span class="number">2019</span>-<span class="number">10</span>-<span class="number">19</span> <span class="number">20</span>:<span class="number">20</span>:<span class="number">45</span> CST </span><br><span class="line">STOP TIMELINE: <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>也可以远程使用pg_basebackup制作基础备份，pg_basebackup使用复制协议，因此需要配置pg_hba.conf文件以允许replication连接</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">host replication all <span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span> </span><br></pre></td></tr></table></figure>

<p>还需要设置postgresql.conf文件中的max_wal_senders参数以允许至少一个session连接来进行备份，postgresql 11默认设置为10，够用了。</p>
<p>References:<br>[1]<a href="https://www.postgresql.org/docs/11/continuous-archiving.html">25.3. Continuous Archiving and Point-in-Time Recovery (PITR)</a><br>[2]<a href="https://www.postgresql.org/docs/11/runtime-config-wal.html">19.5. Write Ahead Log</a><br>[3]<a href="https://www.postgresql.org/docs/11/runtime-config-replication.html">19.6. Replication</a><br>[4]<a href="https://www.postgresql.org/docs/11/app-pgbasebackup.html">pg_basebackup</a><br>[5]<a href="https://www.postgresql.org/docs/11/functions-admin.html">9.26. System Administration Functions</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL 11数据库参数优化</title>
    <url>/2019/10/08/postgresql-11-server-optimisation/</url>
    <content><![CDATA[<a id="more"></a>
<p>服务器资源状况：<br>32GB内存<br>4路8核心CPU，逻辑核心32颗</p>
<p>postgresql.conf配置文件部分参数：</p>
<p><strong>shared_buffers</strong><br>设置为系统内存的40%，过多无益</p>
<p><strong>work_mem</strong><br>单个查询排序所用内存，work_mem*所有用户数的全部查询数=占用系统内存，因此如果并发用户很多，此参数不宜设置多大，比如设置为128MB，如果同时有10个并发查询，则会占用1280MB系统内存</p>
<p><strong>maintenance_work_mem</strong><br>维护类工作使用的内存，比如VACUUM, CREATE INDEX, and ALTER TABLE ADD FOREIGN KEY等，因为每一个数据库session同时只能执行一个此类操作，因为可以将其设置的大一点儿，可以提高此类操作的性能。</p>
<p><strong>effective_cache_size</strong><br>用于query planner估算系统可用内存，并不是真正的分配内存，可以设置为系统内存的1/2到3/4大小。</p>
<p>调优参数汇总:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">shared_buffers = 12GB</span><br><span class="line">work_mem = 128MB</span><br><span class="line">maintenance_work_mem = 2GB</span><br><span class="line">effective_cache_size = 24GB</span><br><span class="line">max_connections = <span class="number">2000</span></span><br><span class="line">max_prepared_transactions = <span class="number">2000</span></span><br></pre></td></tr></table></figure>


<p>References:<br>[1]<a href="https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server">Tuning Your PostgreSQL Server</a><br>[2]<a href="https://pgtune.leopard.in.ua/#/">PGTune</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL 11 流复制Hot Standby HA</title>
    <url>/2019/10/16/postgresql-11-streaming-replication-ha/</url>
    <content><![CDATA[<a id="more"></a>
<p>PostgreSQL 11 on Debian buster使用带有复制槽的流复制实现高可用只读热备库</p>
<p><strong>主库端操作</strong></p>
<p>1、主库参数配置<br>配置文件/etc/postgresql/11/main/postgresql.conf</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># wal_level = replica #默认配置即可</span><br><span class="line"># max_wal_senders = 10 #默认配置即可</span><br><span class="line">wal_keep_segments = 100 #虽然使用复制槽，但仍然防御性设置此参数，防止建立备库的过程中需要的wal log被循环覆盖</span><br><span class="line"># max_replication_slots = 10 # 默认配置即可</span><br></pre></td></tr></table></figure>

<p>2、主库复制用户认证配置</p>
<p>使用超级用户postgres或者新建一个具有replication权限的用户作为备库连接到主库进行复制的用户<br>创建用于复制的用户repl_usr</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# create role repl_usr with login replication password &#x27;repl_passwd&#x27;;</span><br><span class="line">CREATE ROLE</span><br></pre></td></tr></table></figure>
<p>修改/etc/postgresql/11/main/pg_hba.conf文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">host replication repl_usr <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">0</span> md5</span><br></pre></td></tr></table></figure>
<p>postgres用户默认没有启用密码，只能本地peer方式访问，如果需要远程使用此用户，需要先启用密码访问。</p>
<p>3、创建复制槽<br>名字设定为repl_slot_1</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# SELECT * FROM pg_create_physical_replication_slot(&#x27;repl_slot_1&#x27;);</span><br><span class="line">slot_name lsn </span><br><span class="line">-------------+-----</span><br><span class="line"> repl_slot_1 </span><br><span class="line">(<span class="number">1</span> row)</span><br><span class="line">postgres=# SELECT slot_name, slot_type, active FROM pg_replication_slots;</span><br><span class="line"> slot_name slot_type active </span><br><span class="line">-------------+-----------+--------</span><br><span class="line"> repl_slot_1 physical f</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>

<p><strong>备库端操作</strong></p>
<p>1、使用基础备份恢复数据库作为备库</p>
<p>a. 停止备库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop postgresql</span><br></pre></td></tr></table></figure>

<p>b. 删除备库现有集群数据<br>将备库postgresql集群数据目录下的所有文件删除，删除debian默认安装postgresql集群数据：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># rm -rf /var/lib/postgresql/11/main/*</span><br></pre></td></tr></table></figure>

<p>c. 恢复基础备份</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres tar zxvf baseback20191019.tgz -C /<span class="keyword">var</span>/lib/postgresql/<span class="number">11</span>/main/</span><br></pre></td></tr></table></figure>
<p>一定要注意恢复的数据文件的属主是运行PostgreSQL服务的系统用户，debian系统上为postgres,还应该保持原来的权限。<br>这里使用的基础备份包含了备份完成时所有需要的WAL日志，所以可以不配置restore_command进行日志恢复，而且wal_keep_segments设置了较大的数值，基础备份之后生成的WAL日志可以通过流复制从master获取。</p>
<p>2、参数配置<br>配置文件/etc/postgresql/11/main/postgresql.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># hot_standby = on #默认配置</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string">配置文件/var/lib/postgresql/11/main/recovery.conf</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">standby_mode = <span class="string">&#x27;on&#x27;</span></span><br><span class="line">primary_conninfo = <span class="string">&#x27;host=192.168.3.6 port=5432 user=repl_usr password=repl_passwd&#x27;</span></span><br><span class="line">primary_slot_name = <span class="string">&#x27;repl_slot_1&#x27;</span></span><br></pre></td></tr></table></figure>
<p>3、启动备库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl start postgresql.service</span><br></pre></td></tr></table></figure>

<p><strong>检查复制状态</strong></p>
<p>1、主库端<br>检查复制槽状态</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# SELECT slot_name, slot_type, active FROM pg_replication_slots;</span><br><span class="line"> slot_name slot_type active </span><br><span class="line">-------------+-----------+--------</span><br><span class="line"> repl_slot_1 physical t</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<p>可以看到复制槽repl_slot_1已经处于活动状态。</p>
<p>当前WAL日志的位置：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_current_wal_lsn();</span><br><span class="line"> pg_current_wal_lsn </span><br><span class="line">--------------------</span><br><span class="line"> <span class="number">0</span>/D000140</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>

<p>复制状态：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# \\x</span><br><span class="line">Expanded display is on.</span><br><span class="line">postgres=# select * from pg_stat_replication;</span><br><span class="line">-\[ RECORD <span class="number">1</span> \]----+------------------------------</span><br><span class="line">pid <span class="number">1567</span></span><br><span class="line">usesysid <span class="number">16386</span></span><br><span class="line">usename repl_usr</span><br><span class="line">application_name walreceiver</span><br><span class="line">client_addr <span class="number">192.168</span><span class="number">.3</span><span class="number">.7</span></span><br><span class="line">client_hostname </span><br><span class="line">client_port <span class="number">58492</span></span><br><span class="line">backend_start <span class="number">2019</span>-<span class="number">10</span>-<span class="number">20</span> <span class="number">17</span>:<span class="number">36</span>:<span class="number">05</span><span class="number">.768654</span>+<span class="number">08</span></span><br><span class="line">backend_xmin </span><br><span class="line">state streaming</span><br><span class="line">sent_lsn <span class="number">0</span>/D000140</span><br><span class="line">write_lsn <span class="number">0</span>/D000140</span><br><span class="line">flush_lsn <span class="number">0</span>/D000140</span><br><span class="line">replay_lsn <span class="number">0</span>/D000140</span><br><span class="line">write_lag </span><br><span class="line">flush_lag </span><br><span class="line">replay_lag </span><br><span class="line">sync_priority <span class="number">0</span></span><br><span class="line">sync_state <span class="keyword">async</span></span><br></pre></td></tr></table></figure>

<p>2、备库端<br>最后一个收到的WAL日志</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_last_wal_receive_lsn();</span><br><span class="line"> pg_last_wal_receive_lsn </span><br><span class="line">-------------------------</span><br><span class="line"> <span class="number">0</span>/D000140</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://www.postgresql.org/docs/11/high-availability.html">Chapter 26. High Availability, Load Balancing, and Replication</a><br>[2]<a href="https://www.postgresql.org/docs/11/hot-standby.html">26.5. Hot Standby</a><br>[3]<a href="https://www.postgresql.org/docs/11/warm-standby-failover.html">Failover</a><br>[4]<a href="https://blog.51cto.com/heyiyi/1917655">PostgreSQL Switchover vs. Failover</a><br>[5]<a href="https://www.cnblogs.com/lottu/p/7490759.html">PostgreSQL主备切换</a><br>[6]<a href="https://blog.csdn.net/qq_43303221/article/details/85777529">PostgreSQL 流复制的主备切换</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql checkpoints相关参数</title>
    <url>/2016/10/10/postgresql-checkpoints-parameters/</url>
    <content><![CDATA[<a id="more"></a>
<p>数据库日志中出现警告：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">10</span> <span class="number">03</span>:<span class="number">04</span>:<span class="number">29</span> CST \[<span class="number">26586</span>-<span class="number">131</span>\] LOG: checkpoints are occurring too frequently (<span class="number">17</span> seconds apart)</span><br><span class="line"><span class="number">2016</span>-<span class="number">10</span>-<span class="number">10</span> <span class="number">03</span>:<span class="number">04</span>:<span class="number">29</span> CST \[<span class="number">26586</span>-<span class="number">132</span>\] HINT: Consider increasing the configuration parameter <span class="string">&quot;checkpoint_segments&quot;</span>.</span><br></pre></td></tr></table></figure>

<p>checkpoint_segments参数按默认设置3过小了，这里有几个相互关联的参数，有时间好好看看。</p>
<p>References:<br>[1]<a href="http://mysql.taobao.org/monthly/2015/09/06/">PgSQL · 特性分析 · 谈谈checkpoint的调度</a><br>[2]<a href="http://www.weixinkd.com/n/8244035">PostgreSQL 中 checkpoint 和 WAL 日志量的关系以及优化</a><br>[3]<a href="http://blog.csdn.net/sszgg2006/article/details/26826501">postgresql之checkpoint(检查点)</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL客户端认证</title>
    <url>/2014/04/18/postgresql-client-authentication/</url>
    <content><![CDATA[<a id="more"></a>
<p>客户端认证是由文件pg_hba.conf来配置的,通常pg_hba.conf存放在数据库集群的数据目录中,当然也可以放在其他地方,比如debian就放在了/etc/postgresql/[version]/[cluser]/目录下。</p>
<p>当使用用户名映射时,还需要一个用户名映射配置文件,这个文件的存放位置与pg_hba.conf一样,可以在集群的数据目录中, 也可以放置在其他目录中。</p>
<p>无论客户端以何种方式来登录数据库，都要有一个客户端可以访问的数据库用户或叫角色存在。如果是本地认证,则服务器会验证发起请求的客户端的系统用户名,系统用户名可能与数据库角色相同，也可能不同。</p>
<p><strong>pg_hba.conf配置</strong></p>
<p>配置格式如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#request_mode db_name db_role address mask method options </span><br><span class="line">local database user auth-method \[auth-options\]</span><br><span class="line">host database user address auth-method \[auth-options\]</span><br><span class="line">hostssl database user address auth-method \[auth-options\]</span><br><span class="line">hostnossl database user address auth-method \[auth-options\]</span><br><span class="line">host database user IP-address IP-mask auth-method \[auth-options\]</span><br><span class="line">hostssl database user IP-address IP-mask auth-method \[auth-options\]</span><br><span class="line">hostnossl database user IP-address IP-mask auth-method \[auth-options\]</span><br></pre></td></tr></table></figure>

<p>local认证方法使用unix domain socket进行连接,其他认证方法通过TCP/IP连接,带有ssl后缀的认证方式使用SSL连接，带有nossl后缀的认证方式不使用SSL连接,host则既可以使用SSL连接,也可以不使用。</p>
<p>一个客户端请求只会匹配pg_hba.conf中与连接类型，数据库，数据库用户和地址等信息匹配的第一行，无论登录成功与否都不会再去匹配其他行。</p>
<ul>
<li><p>  database<br>指定要访问的数据库。all匹配所有的数据库，sameuser表示如果请求的数据库名与角色名相同则匹配。replication表示允许replication连接请求,此时不指定任何特定的数据库。可以用逗号分隔来指定多个数据库。</p>
</li>
<li><p>  user<br>指定访问数据库使用的数据库角色名,all匹配所有存在的数据库角色。</p>
</li>
<li><p>  address<br>声明这条记录匹配的客户端机器的地址。可以是主机名或者ip地址。ip地址可以以常用的两种方式指定。0.0.0.0/0代表全部IPv4地址,::/0代表全部Ipv6地址。</p>
</li>
<li><p>  auth-method</p>
</li>
<li><p>  trust<br>无条件的允许连接。这个方法允许任何人用任意一个PostgreSQL用户登录到PostgreSQL数据库。</p>
</li>
<li><p>  peer<br>从操作系统获取操作系统的用户名，然后检查它是否和请求的数据库角色名相匹配。这只对本地连接有效。可以使用用户名映射,使系统用户名映射到不同的数据库角色。<br>这种登录方式与oracle的OS认证登录方式类似</p>
</li>
<li><p>  md5<br>要求客户端提供一个MD5加密的口令进行认证。</p>
</li>
<li><p>  password<br>要求客户提供一个未加密的密码进行身份验证。不安全。</p>
</li>
<li><p>  krb5<br>使用Kerberos V5来进行认证用户。这只对TCP/IP连接有效。</p>
</li>
<li><p>  ident<br>使用ident服务器认证用户。</p>
</li>
<li><p>  ldap<br>用LDAP服务器进行认证</p>
</li>
<li><p>  radius<br>用RADIUS服务器进行认证</p>
</li>
<li><p>  cert<br>用SSL客户端证书进行认证</p>
</li>
<li><p>  pam<br>使用PAM认证。</p>
</li>
<li><p>  [auth-options]<br>以name=value的形式为这些认证方法指定一些选项。比较常用的是指定用户名映射,格式为map=map-name,map-name指定pg_ident.conf文件中的一条命名用户名映射记录。</p>
</li>
</ul>
<p><strong>pg_ident.conf配置</strong><br>用于系统用户名到数据库角色名的映射。格式如下</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#map-name system-username database-username</span><br><span class="line">admin john postgres</span><br></pre></td></tr></table></figure>
<p>为某个认证方法指定map=admin选项后,john就可以以postgres数据库角色来访问数据库。peer认证默认要求system-username与database-username必须一致，可以使用用户名映射来改变这一默认行为。</p>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/9.3/static/auth-pg-hba-conf.html">The pg_hba.conf File</a><br>[2]<a href="http://www.postgresql.org/docs/9.3/static/auth-username-maps.html">User Name Maps</a><br>[3]<a href="http://www.postgresql.org/docs/9.3/static/auth-methods.html">Authentication Methods</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>兼容PostgreSQL的分布式NewSQL数据库CockroachDB</title>
    <url>/2019/10/15/postgresql-compatible-distributed-newsql-database-cockroachdb/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="https://www.cockroachlabs.com/docs/stable/">CockroachDB Docs</a><br>[2]<a href="https://blog.wolfogre.com/posts/setup-of-cockroachdb-cluster/">用于生产环境的 CockroachDB 集群搭建教程</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL约束</title>
    <url>/2013/10/29/postgresql-constaint/</url>
    <content><![CDATA[<p>约束用于保证数据的完整性和正确性。</p>
<a id="more"></a>
<p><strong>检查约束Check Constraints</strong></p>
<p>检查约束允许指定特定列的值必须满足一个布尔表达式。比如：<br>[sql]<br>CREATE TABLE products (<br> product_no integer,<br> name text,<br> price numeric CHECK (price &gt; 0)<br>);<br>[/sql]<br>也可以为检查约束指定名字，这样错误信息会看起来更清楚，也方便修改约束。<br>[sql]<br>CREATE TABLE products (<br> product_no integer,<br> name text,<br> price numeric CONSTRAINT positive_price CHECK (price &gt; 0)<br>);<br>[/sql]</p>
<p>检查约束也可以引用多个列，如：<br>[sql]<br>CREATE TABLE products (<br> product_no integer,<br> name text,<br> price numeric CHECK (price &gt; 0),<br> discounted_price numeric CHECK (discounted_price &gt; 0),<br> CHECK (price &gt; discounted_price)<br>);<br>[/sql]<br>在上面这里例子中，前两个是列约束写法，最后一个是表约束写法。一个列约束总是可以用表约束来表达，但反过来却不一定，因为列约束只能引用一个字段而且要附加在引用的字段后面，而表约束则可以引用多个字段。列约束只能引用列约束所在的字段。表约束的顺序没有要求，但最好位于所有引用列的后面，这样看起来更清晰。</p>
<p>PostgeSQL对写法没有太多的要求，最好以与其他数据库兼容的方式来写。甚至可以这样写：<br>[sql]<br>CREATE TABLE products (<br> product_no integer,<br> name text,<br> price numeric CHECK (price &gt; 0),<br> discounted_price numeric,<br> CHECK (discounted_price &gt; 0 AND price &gt; discounted_price)<br>);<br>[/sql]<br>应该注意，无论检查表达式返回true还是null,检查约束都是满足的。如果需要列非空，还需要附加非空约束。</p>
<p><strong>非空约束Not-Null Constraints</strong></p>
<p>非空约束指示一个列不能为null,如：<br>[sql]<br>CREATE TABLE products (<br> product_no integer NOT NULL,<br> name text NOT NULL,<br> price numeric<br>);<br>[/sql]</p>
<p>非空约束只能使用列约束语法，非空约束与如下的检查约束功能是一样的：<br>CHECK (column_name IS NOT NULL)<br>但是使用非空约束更有效率，非空约束的缺点是不能指定约束的名字。</p>
<p>一个列可以有多个约束，顺着往下写就是了，顺序无关。<br>[sql]<br>CREATE TABLE products (<br> product_no integer NOT NULL,<br> name text NOT NULL,<br> price numeric NOT NULL CHECK (price &gt; 0)<br>);<br>[/sql]</p>
<p><strong>唯一约束Unique Constraints</strong></p>
<p>唯一约束用于保证一个字段或一组字段的组合值在一个表中是唯一的。</p>
<p>列约束语法示例：<br>[sql]<br>CREATE TABLE products (<br> product_no integer UNIQUE,<br> name text,<br> price numeric<br>);<br>[/sql]<br>表约束语法示例：<br>[sql]<br>CREATE TABLE products (<br> product_no integer,<br> name text,<br> price numeric,<br> UNIQUE (product_no)<br>);<br>[/sql]</p>
<p>也可以约束多个字段<br>[sql]<br>CREATE TABLE example (<br> a integer,<br> b integer,<br> c integer,<br> CONSTRAINT must_be_different UNIQUE (a, c)<br>);<br>[/sql]</p>
<p>null值有些不同，因为null是未知的，所以两个null不被认为是相等的。所以唯一约束作用于组合字段时，可以有重复的组合字段记录，只要有一个字段的值是null就可以，这符合SQL标准。然后有些数据库却不这样处理，比如oracle，只要组合字段中非空的字段重复就认为违反了唯一约束。</p>
<p>单一字段约束可以插入多个值为null的重复记录，组合字段如果所有的字段都为null,也可以插入多个重复的记录。</p>
<p><strong>主键约束Primary Keys</strong></p>
<p>主键约束就是唯一约束和非空约束的组合。<br>[sql]<br>CREATE TABLE products (<br> product_no integer UNIQUE NOT NULL,<br> name text,<br> price numeric<br>);<br>[/sql]<br>[sql]<br>CREATE TABLE products (<br> product_no integer PRIMARY KEY,<br> name text,<br> price numeric<br>);<br>[/sql]<br>两种写法接受的数据是一样的，但还是有区别的。一个表只能有一个主键约束，但可以有多个非空约束和唯一约束，或者二者的组合。<br>每一个表最好有一个主键。</p>
<p>主键约束也适用于多个字段，如：<br>[sql]<br>CREATE TABLE example (<br> a integer,<br> b integer,<br> c integer,<br> PRIMARY KEY (a, c)<br>);<br>[/sql]</p>
<p>还要注意，虽然主键约束可以保证唯一和非空，但主键的取值是不受限制的，比如用integer做主键，那么所有的整数都是可以做主键的，0和负数也可以，所以有时候还要根据需要，在主键上添加检查约束，比如主键只能是大于0的整数。</p>
<p><strong>外键约束Foreign Keys</strong><br>见<a href="https://openwares.net/database/postgresql_foreinkey_constraint.html">PostgreSQL外键约束</a></p>
<p><strong>排斥约束Exclusion Constraints</strong><br>这是PostgreSQL独有的约束，是不可移植的。</p>
<p>参考：<br><a href="http://www.postgresql.org/docs/9.3/static/ddl-constraints.html">Data Definition</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL连续归档备份</title>
    <url>/2015/12/04/postgresql-continuous-archiving-pitr/</url>
    <content><![CDATA[<a id="more"></a>
<p>pg_dump/pg_dumpall属于一致性逻辑备份，可以用其进行跨PostgreSQL版本，跨系统平台的数据迁移。用于常规备份则其速度和灵活性略显不足。</p>
<p>而连续归档模式则类似于oracle的rman备份方式，可用于大型数据库的增量备份和恢复，以及用于搭建高可用standby镜像备份。</p>
<p><strong>设置归档</strong></p>
<p>PostgreSQL默认处于非归档模式。开启归档模式，主要涉及到三个参数：wal_level,archive_mode和archive_command</p>
<p>wal_level参数默认为mininal,设置此参数为archive或者之上的级别都可以打开归档。<br>当postgresql需要传输归档日志时，会调用archive_command指定的shell命令。归档文件传输成功时，shell命令要返回0，此时，postgresql会认为归档文件已经传输成功，因此可以删除或者重新循环利用归档文件。当shell命令返回非0值时，postgresql会保留所有未成功传输的归档日志，并不断尝试重新传输，直到成功。如果归档命令一直不成功，pg_xlog目录会持续增长，有耗尽服务器存储空间的可能，此时postgresql会PANIC关闭，直到释放存储空间。</p>
<p>将归档WAL日志存储在本机上是风险极高，不被推荐的。postgresql通过archive_command提供了存储WAL日志的灵活性，可以将归档日志存储到挂装的NFS目录，磁带，刻录到光盘，也可以将WAL日志通过ssh/scp传输到异机保存。</p>
<p>要注意，archive_command将以运行PostgreSQL的系统用户的身份运行。debian系统里，这个系统用户是postgres。</p>
<p>修改/etc/postgresql/$PG_VERISON/main/postgresql.conf文件以启动归档:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">wal_level = archive</span><br><span class="line">archive_mode = on</span><br><span class="line">#archive_command = <span class="string">&#x27;test ! -f /mnt/server/archivedir/%f &amp;&amp; cp %p /mnt/server/archivedir/%f&#x27;</span></span><br><span class="line">archive_command = <span class="string">&#x27;ssh arc_svr test ! -f /path/to/archive/%f &amp;&amp; scp %p arc_svr:/path/to/archive/%f&#x27;</span></span><br></pre></td></tr></table></figure>

<p>arc_svr是用于存储WAL日志的ssh服务器别名<br>然后重新启动postgresql</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service postgresql restart</span><br></pre></td></tr></table></figure>

<p>手动切换WAL日志,看配置是否正确，WAL是否正确传输了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql -c <span class="string">&#x27;select pg_switch_xlog()&#x27;</span></span><br><span class="line">pg_switch_xlog </span><br><span class="line">----------------</span><br><span class="line"> <span class="number">1</span>/6A0006A8</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>

<p>查看归档目录下出现了归档WAL日志文件。</p>
<p><strong>使用pg_start_backup进行基础备份</strong></p>
<ol>
<li><p> 确保postgesql运行于归档模式</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select name, setting from pg_catalog.pg_settings where name like &#x27;archive%&#x27; or name = &#x27;wal_level&#x27;;</span><br><span class="line"> name setting </span><br><span class="line">-----------------+---------------------------------------------------------------------------</span><br><span class="line"> archive_command ssh node5 test ! -f /<span class="keyword">var</span>/backups/postgresql/archive/%f &amp;&amp; scp %p node5:<span class="regexp">/var/</span>backups/postgresql/archive/%f</span><br><span class="line"> archive_mode on</span><br><span class="line"> archive_timeout <span class="number">0</span></span><br><span class="line"> wal_level archive</span><br><span class="line">(<span class="number">4</span> rows)</span><br></pre></td></tr></table></figure></li>
<li><p> 使用超级用户执行pg_start_backup</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_start_backup(&#x27;basebackup-20151205&#x27;);</span><br><span class="line"> pg_start_backup </span><br><span class="line">-----------------</span><br><span class="line"> <span class="number">1</span>/6F000028</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<p>basebackup-20151205是一个标签，用户自行指定用于标识本次基础备份。pg_start_backup会创建一个备份标签文件(backup label file),文件内保存有此次基本备份的相关信息。</p>
</li>
<li><p> 使用文件系统备份工具备份整个集群的数据文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres tar cjvf /<span class="keyword">var</span>/backups/postgresql/base/<span class="number">20151205.</span>tbz2 -P \\</span><br><span class="line">--exclude=<span class="regexp">/var/</span>lib/postgresql/<span class="number">9.4</span>/main/postmaster.pid \\</span><br><span class="line">--exclude=<span class="regexp">/var/</span>lib/postgresql/<span class="number">9.4</span>/main/postmaster.opts \\</span><br><span class="line">--exclude=<span class="regexp">/var/</span>lib/postgresql/<span class="number">9.4</span>/main/pg_xlog \\</span><br><span class="line">--exclude=<span class="regexp">/var/</span>lib/postgresql/<span class="number">9.4</span>/main/pg_replslot \\</span><br><span class="line">--warning=no-file-changed --warning=no-file-removed \\</span><br><span class="line">/<span class="keyword">var</span>/lib/postgresql/<span class="number">9.4</span>/main </span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>备份时需要排除掉postmaster.pid和postmaster.opts文件，以及pg_xlog和pg_replslot目录。</p>
<p>生成的基础备份应该与归档WAL日志采用一样的存储策略，存储到异机保存，并可以进一步保存到永久介质保存，比如磁带或者CDROM。<br>4.  以超级用户身份执行pg_stop_backup</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_stop_backup();</span><br><span class="line">NOTICE: pg_stop_backup complete, all required WAL segments have been archived</span><br><span class="line"> pg_stop_backup </span><br><span class="line">----------------</span><br><span class="line"> <span class="number">1</span>/6F1A64F8</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<p>pg_stop_backup会将备份期间活动的WAL日志文件归档，一旦这些日志完成归档，则整个备份过程就结束了。<br>pg_stop_backup会生成一个.backup文件标识出保证此次备份完整性所需要的最后一个WAL日志，使用此次基础备份恢复系统时，不再需要之前的WAL日志。<br>比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-rw------- <span class="number">1</span> admin admin <span class="number">306</span> Dec <span class="number">5</span> <span class="number">21</span>:<span class="number">37</span> 00000001000000010000006F<span class="number">.00000028</span>.backup</span><br><span class="line">-rw------- <span class="number">1</span> admin admin 16M Dec <span class="number">5</span> <span class="number">21</span>:<span class="number">37</span> 00000001000000010000006F</span><br></pre></td></tr></table></figure>
<p>说明此次备份所需的归档WAL日志文件从00000001000000010000006F往后即可，包含此文件和对应的.backup文件。<br>backup文件的内容类似如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">START WAL LOCATION: <span class="number">1</span>/6F000028 (file 00000001000000010000006F)</span><br><span class="line">STOP WAL LOCATION: <span class="number">1</span>/6F1A64F8 (file 00000001000000010000006F)</span><br><span class="line">CHECKPOINT LOCATION: <span class="number">1</span>/6F000028</span><br><span class="line">BACKUP METHOD: pg_start_backup</span><br><span class="line">BACKUP FROM: master</span><br><span class="line">START TIME: <span class="number">2015</span>-<span class="number">12</span>-<span class="number">05</span> <span class="number">21</span>:<span class="number">03</span>:<span class="number">03</span> CST </span><br><span class="line">LABEL: basebackup-<span class="number">20151205</span></span><br><span class="line">STOP TIME: <span class="number">2015</span>-<span class="number">12</span>-<span class="number">05</span> <span class="number">21</span>:<span class="number">37</span>:<span class="number">58</span> CST </span><br></pre></td></tr></table></figure>

<p><strong>使用pg_basebackup进行基础备份</strong></p>
<p>pg_basebackup使用复制协议，因此需要配置pg_hba.conf文件以允许replication连接,无论本地还是通过网络。<br>比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">local replication postgres peer </span><br><span class="line">host replication postgres <span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span> md5 </span><br></pre></td></tr></table></figure>

<p>还需要设置postgresql.conf文件中的max_wal_senders参数以允许至少一个session连接来进行备份。<br>修改两个参数文件后，重新启动postgresql。</p>
<p>然后执行以下命令:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres pg_basebackup -RPv　-D baseback20151205-<span class="number">1</span></span><br><span class="line">transaction log start point: <span class="number">1</span>/<span class="number">72000028</span> on timeline <span class="number">1</span></span><br><span class="line"><span class="number">498974</span>/<span class="number">498974</span> kB (<span class="number">100</span>%), <span class="number">1</span>/<span class="number">1</span> tablespace </span><br><span class="line">transaction log end point: <span class="number">1</span>/<span class="number">72000430</span></span><br><span class="line">pg_basebackup: base backup completed</span><br></pre></td></tr></table></figure>

<p>这会生成一个备份目录，其目录结构与数据库集群的目录结构一致。如果要将数据打包到一个bz2文件，可以执行如下命令:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd /<span class="keyword">var</span>/lib/postgresql</span><br><span class="line">$ sudo -u postgres sh -c <span class="string">&#x27;pg_basebackup -RPv -Ft -D - bzip2 &gt; baseback20151205-1.tbz2&#x27;</span></span><br></pre></td></tr></table></figure>

<p>pg_basebackup命令同样会在备份中生成backup_label文件和.backup归档日志文件。<br>其.backup文件内容类似如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">START WAL LOCATION: <span class="number">1</span>/7C000028 (file 00000001000000010000007C)</span><br><span class="line">STOP WAL LOCATION: <span class="number">1</span>/7C000998 (file 00000001000000010000007C)</span><br><span class="line">CHECKPOINT LOCATION: <span class="number">1</span>/7C000550</span><br><span class="line">BACKUP METHOD: streamed</span><br><span class="line">BACKUP FROM: master</span><br><span class="line">START TIME: <span class="number">2015</span>-<span class="number">12</span>-<span class="number">05</span> <span class="number">22</span>:<span class="number">52</span>:<span class="number">23</span> CST </span><br><span class="line">LABEL: pg_basebackup base backup</span><br><span class="line">STOP TIME: <span class="number">2015</span>-<span class="number">12</span>-<span class="number">05</span> <span class="number">22</span>:<span class="number">53</span>:<span class="number">20</span> CST </span><br></pre></td></tr></table></figure>

<p>可以远程使用pg_basebackup来进行基础备份。</p>
<p>pg_basebackup的详细参数见man pg_basebackup或参考[2]。</p>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/current/static/continuous-archiving.html">24.3. Continuous Archiving and Point-in-Time Recovery (PITR)</a><br>[2]<a href="http://www.postgresql.org/docs/9.4/static/app-pgbasebackup.html">pg_basebackup</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL数据库</title>
    <url>/2013/11/05/postgresql-database-manager/</url>
    <content><![CDATA[<p>每一个运行的PostgeSQL服务实例管理一个或多个数据库。数据库是用于分级组织SQL对象的顶层对象。</p>
<a id="more"></a>
<p><strong>概览</strong></p>
<p>数据库是SQL对象(也叫数据库对象)的命名集合。一般来讲，一个数据库对象，比如表，函数等，属于且仅属于一个数据库。然而，也存在一些系统对象(system catalogs),比如pg_database属于整个集群,可以被集群的每个数据库访问。</p>
<p>更准确的说，一个数据库是包含表，函数等对象的模式(schema)的集合,因此完整的层级是这样的：</p>
<p>集群(server) -&gt; 数据库(database) -&gt; 模式(schema) -&gt; 表，函数等对象(table,funcations,etc)</p>
<p>如果多个项目或者用户是相互关联的，并且会相互访问彼此的资源，它们应该放到同一个数据库的不同模式里。模式(schema)只是一个单纯的逻辑结构，谁能访问某个模式由权限系统来管理。</p>
<p><strong>创建数据库</strong></p>
<p><em>语法</em><br>[sql]<br>CREATE DATABASE name<br> [ [ WITH ] [ OWNER [=] user_name ]<br> [ TEMPLATE [=] template ]<br> [ ENCODING [=] encoding ]<br> [ LC_COLLATE [=] lc_collate ]<br> [ LC_CTYPE [=] lc_ctype ]<br> [ TABLESPACE [=] tablespace_name ]<br> [ CONNECTION LIMIT [=] connlimit ] ]<br>[/sql]</p>
<p>要创建数据库，必须要有超级用户权限或者有CREATEDB权限。默认情况下，新创建的数据库克隆系统数据库template1，可以通过TEMPLATE参数指定一个不同的数据库克隆源。特别地，指定TEMPLATE template0，可以创建一个未受到任何污染的纯净的数据库，仅仅包行当前版本PostgreSQL预定义的标准对象。</p>
<p>因为需要连接到数据库服务器才能执行CREATE DATABASE命令，那么任意一个节点的第一个数据库是如何建立的呢？第一个数据库总是由initdb命令在初始化数据存储区的时候创建的。这个数据库叫做postgres,因此<strong>要创建第一个用户数据库的时候你应该连接到postgres数据库</strong>。</p>
<p>第二个数据库template1， 也是在数据库集群初始化时被创建的。每创建一个新的数据库时，实际上就是克隆了 template1 数据库。这就意味着你对 template1 做的任何修改都会传播到所有随后创建的数据库。正因如此，应该避免在 template1 数据库中创建任何对象，除非你想将它们传播到后面创建的所有数据库中。</p>
<p><em>参数</em></p>
<ul>
<li>  name<br>将要创建的数据库的名字</li>
<li>  user_name<br>将拥有新创建数据库的角色名字。默认情况下，新创建数据库的拥有者为执行命令的用户。为其他用户创建数据库，你必须是其他用户直接或间接的成员，或者是超级用户。</li>
<li>  template<br>从哪个数据库克隆出新数据库，默认为template1</li>
<li>  encoding<br>新数据库使用的字符集。默认使用模板数据库的字符集。最常用的为UTF8,可以使用的<a href="http://www.postgresql.org/docs/9.3/static/multibyte.html#MULTIBYTE-CHARSET-SUPPORTED">字符集</a>。</li>
<li>  lc_collate<br>本地排序规则，lc为locale之意</li>
<li>  lc_ctype<br>语言符号及其分类</li>
<li>  tablespace_name<br>新数据库关联的表空间的名字，默认使用模板数据库的表空间。此数据库中创建的对象默认使用此表空间，除非明确指定要使用的表空间。</li>
<li>  connlimit<br>并发连接限制，默认为无限制。</li>
</ul>
<p>还可以使用shell命令createdb来创建数据库，详见CREATEDB(1)。<br>[sql]<br>$ createdb dbname<br>[/sql]<br>createdb没有任何魔法，仅仅是连接到postgres数据库，发出CREATE DATABASE命令。如果不提供任何参数，CREATEDB将创建一个与当前系统用户名相同的数据库。</p>
<p><em>注意</em></p>
<ul>
<li>  不能在一个事务块中执行CREATE DATABASE语句。</li>
<li>  如果出现像这样的错误’could not initialize database directory’,可能是因为表空间的权限不足，磁盘满，或者其他文件系统错误。</li>
<li>  创建数据库前如果源模板数据库已经有其他连接存在，CREATE DATABASE会失败，否则，到模板数据库的新连接会被锁定，直到CREATE DATABASE命令完成</li>
<li>  选择的字符集编码必须与选择的locale设置lc_collate和lc_ctype兼容</li>
</ul>
<p><strong>查看数据库</strong></p>
<p>使用SQL语句<br>[sql]<br>SELECT datname FROM pg_database;<br>[/sql]<br>或者使用psql命令<br>[sql]<br>=&gt; \l<br>[/sql]</p>
<p><strong>删除数据库</strong></p>
<p>[sql]<br>DROP DATABASE name;<br>[/sql]</p>
<p>只有数据库的所有者，或者超级用户可以删除数据库。删除数据库会删除数据库中包括的所有对象。数据库的删除是不可恢复的。<br>你不能使用 DROP DATABASE 删除与你连接的数据库。不过，你可以联接到其他数据库去执行，包括template1数据库，template1也是你删除集群中最后一个用户数据库的唯一方法。</p>
<p>也可以使用shell命令删除数据库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dropdb dbname</span><br></pre></td></tr></table></figure>
<p><a href="http://www.postgresql.org/docs/9.3/static/managing-databases.html">Chapter 21. Managing Databases</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql数据库存储结构升级</title>
    <url>/2015/01/08/postgresql-database-upgrade/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果使用brew升级postgresql到新版时，数据库存储结构升级了，那么原来的数据库就不能在新版本下运行了,/usr/local/var/postgres/server.log里会有错误提示。</p>
<p>有以下升级方式:</p>
<p>1、使用pg_dump备份旧版数据库，将原来的数据库目录整个干掉，重新初始化一个新库，最后使用pg_restore恢复数据。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># rm -rf /usr/local/var/postgres</span><br><span class="line">$ initdb -D /usr/local/<span class="keyword">var</span>/postgres</span><br></pre></td></tr></table></figure>

<p>2、使用pg_upgrade命令升级数据库</p>
<p>详细的升级方法见参考[1]和[2]。</p>
<p>References:<br>[1]<a href="http://david-chen-blog.logdown.com/posts/169428-postgresql-upgrade-to-93">升级 PostgreSQL 到 9.3 小记</a><br>[2]<a href="http://stackoverflow.com/questions/24379373/how-to-upgrade-postgres-from-9-3-to-9-4-without-losing-data">postgresql upgrade</a><br>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL dblink</title>
    <url>/2016/11/11/postgresql-dblink/</url>
    <content><![CDATA[<a id="more"></a>
<p>dblink是postgresql内置的一个扩展模块，支持从当前postgresql数据库连接到其他postgresql数据库来存取数据。<br>除dblink外，还可以使用postgres_fdw来访问外部postgresql,二者功能基本一致，但postgres_fdw更优。</p>
<p>dblink有一系列的函数，支持连接外部postgresql,执行select,insert,update,delete等语句，以及在外部数据库中执行命令。</p>
<p><strong>创建</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; CREATE EXTENSION dblink;</span><br></pre></td></tr></table></figure>
<p>会创建dblink相关的函数</p>
<p><strong>使用</strong></p>
<p>dblink的语法：<br>[sql]<br>dblink(text connname, text sql [, bool fail_on_error]) returns setof record<br>dblink(text connstr, text sql [, bool fail_on_error]) returns setof record<br>[/sql]<br>dblink函数可以使用已有的连接，或者直接提供连接字符串来访问外部服务器</p>
<p>下面的语句直接提供连接串来访问外部postgresql的表：<br>[sql]<br>=&gt; select id, land_using_type from dblink(‘host=192.168.0.9 dbname=pgdbname user=pguser password=passwd’,<br>‘select id, land_using_type from reg.tb_relevant_cert where cert_type=1’)<br>as t1 (id integer, land_using_type varchar(50));<br>[/sql]</p>
<p>使用dblink访问外部表数据，必须指定alias,下面是个综合的用法，用外部postgresql数据库的表更新本地表的数据：<br>[sql]<br>=&gt; update reg.tb_relevant_cert c set land_using_type=t2.land_using_type<br>from<br>(select id, land_using_type from dblink(‘host=192.168.0.9 dbname=pgdbname user=pguser password=passwd’,<br>‘select id, land_using_type from reg.tb_relevant_cert where cert_type=1’)<br>as t1 (id integer, land_using_type varchar(50))<br>) as t2<br>where c.id=t2.id;<br>[/sql]</p>
<p><strong>创建视图</strong></p>
<p>每次写dblink比较麻烦，可以创建一个视图来简化此项工作:<br>[sql]<br>=&gt; CREATE VIEW view_tbl_foo AS<br>select * from dblink(‘host=192.168.0.9 dbname=pgdbname user=pguser password=passwd’,<br>‘select id, land_using_type from reg.tb_relevant_cert where cert_type=1’)<br>as t1 (id integer, land_using_type varchar(50));<br>[/sql]</p>
<p>然后访问就比较简单了：<br>[sql]<br>=&gt; SELECT * FROM view_tbl_foo;<br>[/sql]</p>
<p>References:<br>[1]<a href="https://www.postgresql.org/docs/9.6/static/dblink.html">F.10. dblink</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>查询PostgreSQL默认表空间</title>
    <url>/2013/11/06/postgresql-default-tablespace/</url>
    <content><![CDATA[<p>查询数据对应的默认表空间</p>
<a id="more"></a>
<p>继续使用<a href="https://openwares.net/database/postgresql_tablespace_database_user_schema_table-2.html">数据库组织管理</a>post里的示例<br>[sql]<br>foo=&gt; SELECT d.datname, t.spcname FROM pg_database d, pg_tablespace t WHERE d.dattablespace = t.oid;<br> datname spcname<br>———–+————<br> template1 pg_default<br> template0 pg_default<br> postgres pg_default<br> foo ts_foo<br>(4 rows)<br>[/sql]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgresQL终止活动连接/会话</title>
    <url>/2014/10/30/postgresql-drop-active-connections/</url>
    <content><![CDATA[<a id="more"></a>
<p>执行建库脚本时需要drop数据库,那么问题来了,脚本出现如下错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR: database <span class="string">&quot;reis&quot;</span> is being accessed by other users</span><br><span class="line">DETAIL: There are <span class="number">5</span> other sessions using the database.</span><br><span class="line">ERROR: tablespace <span class="string">&quot;ts_reis&quot;</span> is not empty</span><br><span class="line">ERROR: role <span class="string">&quot;reis&quot;</span> cannot be dropped because some objects depend on it</span><br><span class="line">DETAIL: owner <span class="keyword">of</span> database reis</span><br><span class="line">owner <span class="keyword">of</span> tablespace ts_reis</span><br></pre></td></tr></table></figure>
<p>也就是该库上还有会话存在,drop请求被拒绝。那么把活动连接drop掉就可以了吧。</p>
<p>可以使用pg_terminate_backend()函数和pg_stat_activity视图来终止数据库上的活动连接。<br>先查看下pg_stat_activity视图的详细信息：<br>[sql]<br>$ psql -U postgres -h localhost -d postgres<br>postgres=# \d pg_stat_activity ;</p>
<p>View “pg_catalog.pg_stat_activity”<br> Column Type Modifiers<br>——————+————————–+———–<br> datid oid<br> datname name<br> pid integer<br> usesysid oid<br> usename name<br> application_name text<br> client_addr inet<br> client_hostname text<br> client_port integer<br> backend_start timestamp with time zone<br> xact_start timestamp with time zone<br> query_start timestamp with time zone<br> state_change timestamp with time zone<br> waiting boolean<br> state text<br> query text </p>
<p>[/sql]</p>
<p>\d+ 命令可以获取表或视图更详细的信息。</p>
<p>然后就有了下面的sql语句来终止活动连接：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SELECT </span><br><span class="line"> pg_terminate_backend(pid) </span><br><span class="line">FROM </span><br><span class="line"> pg_stat_activity </span><br><span class="line">WHERE </span><br><span class="line"> -- 不终止当前连接</span><br><span class="line"> pid &lt;&gt; pg_backend_pid()</span><br><span class="line"> -- 只终止target_database上的连接</span><br><span class="line"> AND datname = <span class="string">&#x27;target_database&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>世界一下子就清净了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL导出数据到CSV文件</title>
    <url>/2016/06/14/postgresql-export-to-csv/</url>
    <content><![CDATA[<a id="more"></a>
<p>postgresql支持在表和文件之间拷贝数据，可以使用PostgreSQL扩展的SQL函数COPY或者psql内部命令\copy来做这件事。</p>
<p>导出数据的格式：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">COPY table_name (query) TO <span class="string">&#x27;filename&#x27;</span> PROGRAM <span class="string">&#x27;command&#x27;</span> STDOUT \[ WITH OPTIONS \];</span><br></pre></td></tr></table></figure>

<p>导入数据的格式：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">COPY table_name (query) FROM <span class="string">&#x27;filename&#x27;</span> PROGRAM <span class="string">&#x27;command&#x27;</span> STDIN \[ WITH OPTIONS \];</span><br></pre></td></tr></table></figure>

<p>更详细的格式描述见[1]</p>
<p><strong>COPY函数</strong></p>
<p>COPY函数在服务器上执行，如果输出到文件，要注意postgresql服务器进程有没有对指定目录的执行权限，比如:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">=# COPY (SELECT * FROM base.tb_dictionary WHERE ...) TO &#x27;/tmp/designusage.csv&#x27; WITH CSV DELIMITER &#x27;,&#x27;;</span><br></pre></td></tr></table></figure>

<p>将查询结果输出到临时目录下的指定文件。debian系统postgresql系统进程用户postgres的主目录是/var/lib/postgresql,也可以将文件输出到此目录。<br>如无写权限，会提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR: could not open file <span class="string">&quot;...&quot;</span> <span class="keyword">for</span> writing: Permission denied</span><br></pre></td></tr></table></figure>

<p><strong>\copy命令</strong></p>
<p>psql命令\copy在客户端执行，如果输出到文件是输出到客户端的文件系统，要注意当前执行psql的用户权限。比如：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">=# \\copy (SELECT * FROM base.tb_dictionary WHERE ...) TO &#x27;/tmp/designusage.csv&#x27; WITH CSV DELIMITER &#x27;,&#x27;</span><br></pre></td></tr></table></figure>

<p>如果要输出列名，可以指定HEADER选项，HEADER只用于CSV格式。<br>可以写到临时目录，也可以写到当前用户的主目录。</p>
<p>其实\copy命令实际上是使用了COPY FROM STDIN或者COPY TO STDOUT，然会通过STDIN或STDOUT与文件交互。</p>
<p>所以可以这样:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ psql -c <span class="string">&quot;COPY (SELECT * FROM base.tb_dictionary WHERE ...) TO STDOUT WITH CSV DELIMITER &#x27;,&#x27; &quot;</span> -U role -h host dbname &gt; <span class="keyword">export</span>.csv</span><br></pre></td></tr></table></figure>

<p>使用COPY函数输出到STDOUT，然后重定向到文件。</p>
<p>References:<br>[1]<a href="https://www.postgresql.org/docs/current/static/sql-copy.html">copy data between a file and a table</a><br>[2]<a href="http://blogs.harvard.edu/dlarochelle/2011/12/11/outputing-to-csv-in-postgresql/">Outputting to CSV in Postgresql</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql的FDW</title>
    <url>/2016/11/10/postgresql-fdw/</url>
    <content><![CDATA[<a id="more"></a>
<p>SQL/MED(SQL Management of External Data)是SQL与外部数据交互的标准，postgresql对此的支持就是FDW(Foreign Data Wrapper)，可以支持各种各样的外部数据，从关系数据库、NoSQL数据库到文件，几乎涵盖了常见的各种数据源。有通用的支持关系数据库的FDW,比如JDBC_FDW,ODBC_FDW,也有针对特定数据库的FDW,比如postgres_fdw,oracle_fdw,mysql_fdw，也有对csv,json文件等的支持,file_fdw,josn_fdw。</p>
<p>postgresql的FDW不但支持查询，现在还可以支持insert,update,delete等操作，还可以下推(pushdown)where,group by,sort,join等。</p>
<p>References:<br>[1]<a href="https://wiki.postgresql.org/wiki/Fdw">Foreign data wrappers</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL外键约束</title>
    <url>/2013/10/29/postgresql-foreinkey-constraint/</url>
    <content><![CDATA[<p>外键约束用来实现表与表之间的参照完整性(referential integrity)。</p>
<a id="more"></a>
<p>外键约束是指一个引用表(referencing table)中的一个或多个引用字段(referencing column)必须与另一个被引用表(referenced table)中相应的被引用字段(referenced column)匹配，而且类型和值都必须匹配。</p>
<p>被引用表(referenced table)中的被引用列(referenced column)必须是一个非延迟的唯一约(unique key)束或者主键约束(primary key)。</p>
<p>比如我们有一个产品表<br>[sql]<br>CREATE TABLE products (<br> product_no integer PRIMARY KEY,<br> name text,<br> price numeric<br>);<br>[/sql]</p>
<p>另外还有一个订单表，我们需要保证订单表中只能包含实际存在产品的订单，否则是没意义的垃圾数据。因此我们可以定义一个订单表到产品表的外键约束。<br>列约束写法：<br>[sql]<br>CREATE TABLE orders (<br> order_id integer PRIMARY KEY,<br> product_no integer REFERENCES products (product_no),<br> quantity integer<br>);<br>[/sql]</p>
<p>也可以用表约束的方式这样写：<br>[sql]<br>CREATE TABLE orders (<br> order_id integer PRIMARY KEY,<br> product_no integer,<br> CONSTRAINT order_product_fk FOREIGN KEY (product_no) REFERENCES products (product_no),<br> quantity integer<br>);<br>[/sql]</p>
<p>列约束与表约束的主要区别是列约束只能定义单一字段，而表约束则可以组合多个列。<br>列约束和表约束都可以用CONSTRAINT _constraint_name_为约束命名。</p>
<p>这样以来，就不可能在orders表中创建一条订单记录，记录的product_no非空但其值没有出现在products的product_no字段的值中。</p>
<p>在这里orders叫引用表(referencing table),而products表叫被引用表(referenced table),orders表的字段product_no叫引用列(referencing column)，而products表的product_no叫被引用列(referenced column)。</p>
<p>orders表还可以这样写：<br>[sql]<br>CREATE TABLE orders (<br> order_id integer PRIMARY KEY,<br> product_no integer REFERENCES products,<br> quantity integer<br>);<br>[/sql]<br>这样默认引用products表的主键字段，但最好不要这样用。</p>
<p>外键约束也可以引用多个字段，这时就只能使用表约束的写法了，比如：<br>[sql]<br>CREATE TABLE t1 (<br> a integer PRIMARY KEY,<br> b integer,<br> c integer,<br> FOREIGN KEY (b, c) REFERENCES other_table (c1, c2)<br>);<br>[/sql]</p>
<p>一个表可以有多个外键约束。上面的例子可能还会需要一个订单包含多个产品，可以这样：<br>[sql]<br>CREATE TABLE products (<br> product_no integer PRIMARY KEY,<br> name text,<br> price numeric<br>);</p>
<p>CREATE TABLE orders (<br> order_id integer PRIMARY KEY,<br> shipping_address text,<br> …<br>);</p>
<p>CREATE TABLE order_items (<br> product_no integer REFERENCES products,<br> order_id integer REFERENCES orders,<br> quantity integer,<br> PRIMARY KEY (product_no, order_id)<br>);<br>[/sql]</p>
<p>注意最后一张表中，主键和外键重叠了，这是允许的。</p>
<p>如果一个产品被引用后我们想删除这条产品记录，会怎样呢？阻止删除？关联的订单一起删除?还是其他？</p>
<p>下面的例子，我们阻止删除已经被订单(最终是通过订单项order_items)引用的产品记录，然而如果删除一个订单，其所有的订单项全部会被级联删除。</p>
<p>[sql]<br>CREATE TABLE products (<br> product_no integer PRIMARY KEY,<br> name text,<br> price numeric<br>);</p>
<p>CREATE TABLE orders (<br> order_id integer PRIMARY KEY,<br> shipping_address text,<br> …<br>);</p>
<p>CREATE TABLE order_items (<br> product_no integer REFERENCES products ON DELETE RESTRICT,<br> order_id integer REFERENCES orders ON DELETE CASCADE,<br> quantity integer,<br> PRIMARY KEY (product_no, order_id)<br>);<br>[/sql]</p>
<p>外键约束之表约束写法完整语法：<br>[ CONSTRAINT <em>constraint_name_ ] FOREIGN KEY ( _column_name</em> [, … ] ) REFERENCES <em>reftable</em> [ ( <em>refcolumn</em> [, … ] ) ] [ MATCH <em>matchtype</em> ] [ ON DELETE <em>action</em> ] [ ON UPDATE <em>action</em> ]</p>
<p><strong>[ ON DELETE <em>action</em> ] [ ON UPDATE <em>action</em> ]</strong></p>
<p>当删除被引用行或者更新被引用列时，对于引用表或引用列,不同的action有不同的行为。可用的action如下：</p>
<ul>
<li>  NO ACTION<br>如果违反外键约束会产生一个错误。如果约束被延迟，那么到事务结束检查约束时如果仍然因为存在一个引用行而违反外键约束，则仍会产生错误。这是默认值。其他的动作action都不能被延迟。</li>
<li>  RESTRICT<br>违反外键约束会产生一个错误。</li>
<li>  CASCADE<br>级联删除或更新。分别删除一个引用行或者更新一个引用列的值。</li>
<li>  SET NULL<br>设置引用列(referencing column(s))的值为null</li>
<li>  SET DEFAULT<br>设置引用列为其缺省值。如果缺省值不是null,那么仍然需要被引用表中有一条记录的被引用字段的值与之匹配，否则操作会失败。</li>
</ul>
<p><strong>[ MATCH <em>matchtype</em> ]</strong></p>
<p>当向引用表的引用列(referencing column(s))插入数据时，根据给定的匹配规则matchtype匹配被引用表的被引用列的值。匹配规则如下：</p>
<ul>
<li>  MATCH FULL<br>不允许多列外键约束中的任何一个为null,除非他们全部为null，这样不要求被引用表中有与其匹配的数据。</li>
<li>  MATCH PARTIAL<br>此特性尚未实现</li>
<li>  MATCH SIMPLE<br>这是默认值。允许外键约束中的任何一列为null,只要外键约束中的一列为null,则不要求与被引用表相匹配。</li>
</ul>
<p><strong>外键约束也可以引用自身表中的字段。</strong></p>
<p>参考：<br><a href="http://www.postgresql.org/docs/9.3/static/ddl-constraints.html">Constraints</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL高可用之log-shiping based hot standby</title>
    <url>/2015/12/08/postgresql-ha-log-shiping-based-hot-standby/</url>
    <content><![CDATA[<a id="more"></a>
<p>传统的备份恢复问题在于恢复时间过长，恢复时间有时候是无法接受的。因此有了高可用(High Availability)的概念。</p>
<p>高可用的实现方式多种多样，PostgreSQL内置支持基于WAL日志文件传输或流复制的方式来实现warm/hot standby备库从而实现数据库的高可用性。</p>
<p>这一篇文章只讲基于日志文件传输方式的warm/hot standby配置。<br>hot standby与warm standby的区别在于，hot standby在日志恢复的同时还可以提供只读查询，而warm standby只能进行日志恢复。</p>
<p><strong>先决条件</strong></p>
<p>主备库硬件可以不同，但硬件架构必须相同，字长也必须相同。PostgreSQL的主版本号必须相同，小版本号可以不同。<br>但是推荐主备库使用完全相同的版本号。</p>
<p>主备库升级时，要先升级备库，因为新版本的程序会兼容旧版本传输过来的wal日志，但反过来却不一定。</p>
<p><strong>搭建warm standby备库</strong></p>
<p>首先参考”<a href="https://openwares.net/database/postgresql_restore_using_continuous_archiving_backup.html">PostgreSQL使用连续归档备份恢复数据库</a>“在主库上进行一次基础备份，然后将其在备机上恢复。</p>
<p>然后recovery.conf文件中除了restore_comman参数之外，再打开standby_mode参数：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">restore_command = <span class="string">&#x27;cp /var/backups/postgresql/archive/%f %p&#x27;</span></span><br><span class="line">standby_mode = <span class="string">&#x27;on&#x27;</span></span><br><span class="line">#archive_cleanup_command = ’pg_archivecleanup /path/to/archive %r’</span><br></pre></td></tr></table></figure>

<p>如果需要清理standby不再需要的归档日志，可以配置archive_cleanup_command。不过一般来讲，为了备份的目的，归档日志应该dump到永久存储介质之后再行删除。</p>
<p>可以看到，此处与前文恢复数据库的主要区别既在于在recovery.conf中打开了standby_mode参数。这样以来，备库就会一直处于WAL归档日志恢复循环之中，直到主库失败,备库通过failover升级为主库，或者通过switchover升级为主库。</p>
<p>还可以在recovery.conf文件通过trigger_file参数指定一个触发文件，当standby服务器检测到这个文件时，就会结束恢复模式进入正常操作模式。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">trigger_file = <span class="string">&#x27;/var/lib/postgresql/trigger&#x27;</span></span><br></pre></td></tr></table></figure>
<p>此参数在standby_mode为off时无效。即使设置了此参数，仍然可以使用pg_ctl promote命令来结束恢复模式，从而可以升级为master数据库。</p>
<p><strong>提升为hot standby备库</strong></p>
<p>warm standby是不可查询的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql</span><br><span class="line">psql: FATAL: the database system is starting up</span><br></pre></td></tr></table></figure>

<p>在warm standby备库的基础上，主备库只需做少许参数配置即可升级到hot standby模式。</p>
<p>主库端postgresql.conf文件中：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">wal_level = hot_standby</span><br></pre></td></tr></table></figure>
<p>然后重新启动主库，并切换归档日志，从而使下一个归档日志具有hot standby信息:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service postgresql restart</span><br><span class="line">$ sudo -u postgres psql -c <span class="string">&quot;select pg_switch_xlog()&quot;</span></span><br></pre></td></tr></table></figure>

<p>备库端postgresql.conf文件中:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">hot_standby = on</span><br></pre></td></tr></table></figure>

<p>然后重新启动备库即可。</p>
<p>如果启动备库时有类似如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">FATAL: hot standby is not possible because max_connections = <span class="number">100</span> is a lower setting than on the master server (its value was <span class="number">500</span>)</span><br><span class="line">FATAL: hot standby is not possible because max_prepared_transactions = <span class="number">0</span> is a lower setting than on the master server (its value was <span class="number">50</span>)</span><br></pre></td></tr></table></figure>

<p>需要将standby上的max_connections，max_prepared_transactions参数设置为大于或等于master上对应参数的值，然后再重新启动。</p>
<p>启动成功后日志中会有类似的输出:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">09</span> <span class="number">21</span>:<span class="number">53</span>:<span class="number">19</span> CST \[<span class="number">23100</span>-<span class="number">3</span>\] LOG: entering standby mode</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">09</span> <span class="number">21</span>:<span class="number">53</span>:<span class="number">19</span> CST \[<span class="number">23100</span>-<span class="number">4</span>\] LOG: restored log file <span class="string">&quot;0000000100000001000000A9&quot;</span> <span class="keyword">from</span> archive</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">09</span> <span class="number">21</span>:<span class="number">53</span>:<span class="number">19</span> CST \[<span class="number">23100</span>-<span class="number">5</span>\] LOG: redo starts at <span class="number">1</span>/A9000090</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">09</span> <span class="number">21</span>:<span class="number">53</span>:<span class="number">19</span> CST \[<span class="number">23100</span>-<span class="number">6</span>\] LOG: restored log file <span class="string">&quot;0000000100000001000000AA&quot;</span> <span class="keyword">from</span> archive</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">09</span> <span class="number">21</span>:<span class="number">53</span>:<span class="number">19</span> CST \[<span class="number">23100</span>-<span class="number">7</span>\] LOG: consistent recovery state reached at <span class="number">1</span>/AB000000</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">09</span> <span class="number">21</span>:<span class="number">53</span>:<span class="number">19</span> CST \[<span class="number">23099</span>-<span class="number">1</span>\] LOG: database system is ready to accept read only connections</span><br></pre></td></tr></table></figure>

<p>可用使用以下命令进一步确认备库处于日志恢复状态:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo -u postgres psql -c <span class="string">&quot;select pg_is_in_recovery()&quot;</span></span><br><span class="line"> pg_is_in_recovery </span><br><span class="line">-------------------</span><br><span class="line"> t</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<p>此命令在主库上执行会返回false。</p>
<p>可以在主库上修改数据库并切换归档，然后查询备库，检查数据是否有一样的变化。因为备库是基于日志文件传输的，所以如果不强制切换归档，备库要等到主库日志切换之后才能看到修改。</p>
<p>流复制有更高的实时性，从而数据丢失的风险更低。</p>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/current/static/recovery-config.html">Chapter 26. Recovery Configuration</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL高可用之streaming replication based hot standby</title>
    <url>/2015/12/10/postgresql-ha-streaming-replication-based-hot-standby/</url>
    <content><![CDATA[<a id="more"></a>
<p>前面讲了基于日志文件传输的warm/hot standby配置，但日志文件传输的最大问题在于延迟。</p>
<p>单个日志文件要空间满了或者到了归档超时时间才会传输然后应用到备库，每个日志文件有16MB大小。这会造成较大的延迟，如果主库当机，则数据损失会较大。如果缩小归档超时时间，又会造成大量的空间浪费。</p>
<p>基于流复制则解决了这些问题。备库会连接到主库，不用等待WAL日志文件填满就可以立即传输完成的WAL记录到备库。<br>流复制默认是异步的，这样主库和备库之间会有微小的延迟，极端情况下可能会有极少的数据丢失。</p>
<p>流复制不依赖于归档模式archive_mode和归档日志。但是部署流复制的同时，开启归档也是有必要的。不能把鸡蛋放到一个篮子里。基于日志文件传输或流复制的高可用warm/hot standby配置仍然很难防范主库误删除数据的问题。</p>
<p>基于流复制同样可以实现warm或者hot standby配置。</p>
<p><strong>流复制hot standby配置步骤</strong></p>
<ol>
<li> 主库复制用户认证配置<br>使用超级用户postgres或者新建一个超级用户作为备库连接到主库进行复制的用户，修改pg_hba.conf文件:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">host replication postgres <span class="number">192.168</span><span class="number">.0</span><span class="number">.0</span>/<span class="number">24</span> md5</span><br></pre></td></tr></table></figure></li>
<li> 主库postgresql.conf配置<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">wal_level = hot_standby</span><br><span class="line">max_wal_senders = <span class="number">5</span></span><br><span class="line">wal_keep_segments = <span class="number">30</span></span><br></pre></td></tr></table></figure>
max_wal_senders参数要比standby备库的数量再多一些，防止某些备库连接中断但尚未完全释放连接，如果参数设置过小，重新连接时可能会失败。<br>流复制模式下，pg_xlog目录下的WAL日志文件会循环利用，如果备库应用日志跟不上主库产生日志的速度，或者备库故障导致无法应用主库的日志，此时，主库的日志可能会被覆盖，从而导致备库需要重新建立。<br>当然如果同时做了归档备份，并且备库能访问到WAL日志归档目录，则备库会从归档备份目录来获取所需要的归档日志。</li>
</ol>
<p>wal_keep_segments这个参数只能根据实际情况来估算，并不会很精确。参数设置小了，有可能需要的日志会被覆盖,设置大了会占用主库大量的存储空间。<br>流复制槽可以解决WAL日志循环覆盖的问题，只要备库没有应用主库的WAL日志，则这些日志会一直保存，直到备库不再需要这些日志。设置流复制槽时，如果备库一直下线，则需要注意主库的存储空间是否充裕。<br>3.  使用基础备份搭建备库<br>详见前文所述。<br>4.  备库端配置<br>postgresql.conf文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">hot_standby = on</span><br></pre></td></tr></table></figure>
<p>recovery.conf文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">standby_mode = <span class="string">&#x27;on&#x27;</span></span><br><span class="line">primary_conninfo = <span class="string">&#x27;host=192.168.0.80 port=5432 user=postgres password=pass&#x27;</span></span><br><span class="line">trigger_file = <span class="string">&#x27;/var/lib/postgresql/trigger&#x27;</span></span><br></pre></td></tr></table></figure>
<ol start="5">
<li> 启动备库<br>日志中有类似如下文本:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">LOG: started streaming WAL <span class="keyword">from</span> primary at <span class="number">1</span>/B0000000 on timeline <span class="number">1</span></span><br></pre></td></tr></table></figure></li>
<li> 复制信息查看<br>主库端：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_current_xlog_location();</span><br><span class="line"> pg_current_xlog_location </span><br><span class="line">--------------------------</span><br><span class="line"> <span class="number">1</span>/B0142910</span><br><span class="line">(<span class="number">1</span> row)</span><br><span class="line">postgres=# \\x</span><br><span class="line">Expanded display is on.</span><br><span class="line">postgres=# select * from pg_stat_replication;</span><br><span class="line">-\[ RECORD <span class="number">1</span> \]----+-----------------------------</span><br><span class="line">pid <span class="number">11471</span></span><br><span class="line">usesysid <span class="number">19670</span></span><br><span class="line">usename reis</span><br><span class="line">application_name walreceiver</span><br><span class="line">client_addr <span class="number">192.168</span><span class="number">.0</span><span class="number">.5</span></span><br><span class="line">client_hostname </span><br><span class="line">client_port <span class="number">44247</span></span><br><span class="line">backend_start <span class="number">2015</span>-<span class="number">12</span>-<span class="number">10</span> <span class="number">22</span>:<span class="number">04</span>:<span class="number">45.47403</span>+<span class="number">08</span></span><br><span class="line">backend_xmin </span><br><span class="line">state streaming</span><br><span class="line">sent_location <span class="number">1</span>/B01572F0</span><br><span class="line">write_location <span class="number">1</span>/B01572F0</span><br><span class="line">flush_location <span class="number">1</span>/B01572F0</span><br><span class="line">replay_location <span class="number">1</span>/B0157268</span><br><span class="line">sync_priority <span class="number">0</span></span><br><span class="line">sync_state <span class="keyword">async</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>备库端:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_last_xlog_receive_location();</span><br><span class="line"> pg_last_xlog_receive_location </span><br><span class="line">-------------------------------</span><br><span class="line"> <span class="number">1</span>/B0170B90</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>

<p><strong>配置复制槽</strong></p>
<ol>
<li> 主库端<br>创建流复制槽:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_create_physical_replication_slot(&#x27;slot_1&#x27;);</span><br><span class="line">ERROR: replication slots can only be used <span class="keyword">if</span> max_replication_slots &gt; <span class="number">0</span></span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>所以要修改postgresql.conf文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">max_replication_slots = <span class="number">5</span> </span><br></pre></td></tr></table></figure>
<p>重启后，重新创建复制槽即可。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select pg_create_physical_replication_slot(&#x27;slot_1&#x27;);</span><br><span class="line"> pg_create_physical_replication_slot </span><br><span class="line">-------------------------------------</span><br><span class="line"> (slot_1,)</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<ol start="2">
<li> 备库端<br>recovery.conf文件:<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">primary_slot_name = <span class="string">&#x27;slot_1&#x27;</span></span><br></pre></td></tr></table></figure>
重新启动备库</li>
<li> 主库端检查复制槽状态<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# select * from pg_replication_slots;</span><br><span class="line"> slot_name plugin slot_type datoid database active xmin catalog_xmin restart_lsn </span><br><span class="line">-----------+--------+-----------+--------+----------+--------+------+--------------+-------------</span><br><span class="line"> slot_1 physical t <span class="number">1</span>/B1021F18</span><br><span class="line">(<span class="number">1</span> row)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
复制槽slot_1已经启用。启用复制槽后参数wal_keep_segments就没用了。</li>
</ol>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/current/static/warm-standby.html">25.2.5. Streaming Replication</a><br>[2]<a href="http://www.postgresql.org/docs/current/static/warm-standby.html">25.2.2. Standby Server Operation</a><br>[3]<a href="http://www.cnblogs.com/mchina/archive/2012/05/26/2518350.html">PostgreSQL Hot Standby</a><br>[4]<a href="http://my.oschina.net/hippora/blog/380416">postgresql高可用性之备库(二)</a><br>[5]<a href="https://www.postgresql.org/docs/9.4/static/warm-standby-failover.html">25.3. Failover</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql扩展oracle_fdw</title>
    <url>/2016/11/09/postgresql-oracle-fdw/</url>
    <content><![CDATA[<a id="more"></a>
<p>postgresql通过fdw(Foreign Data Wrapper)插件来支持各种各种的外部数据，外部文件和关系数据库都可以，通过插件oracle_fdw可以从postgresq来访问oracle数据库。</p>
<p><strong>安装</strong></p>
<p>安装postgresql开发库</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install postgresql-server-dev-all</span><br></pre></td></tr></table></figure>

<p><a href="https://openwares.net/linux/debian_amd64_install_oracle_10g_instant_client.html">安装oracle instant client</a>，并配置好oracle环境变量，特别是ORACLE_HOME<br>特别注意要建几个符号链接：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd /opt/oracle/instantclient_12_1</span><br><span class="line">$ sudo ln -sf libclntsh.so<span class="number">.12</span><span class="number">.1</span> libclntsh.so</span><br><span class="line">$ sudo ln -sf libclntshcore.so<span class="number">.12</span><span class="number">.1</span> libclntshcore.so</span><br><span class="line">$ sudo ln -sf libocci.so<span class="number">.12</span><span class="number">.1</span> libocci.so</span><br></pre></td></tr></table></figure>

<p>下载oracle_fdw源代码，解压，编译，安装：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//github.com/laurenz/oracle_fdw/archive/ORACLE_FDW_1_5_0.tar.gz</span></span><br><span class="line">$ tar zxvf ORACLE_FDW_1_5_0.tar.gz</span><br><span class="line">$ cd ORACLE_FDW_1_5_0</span><br><span class="line">$ make</span><br><span class="line">$ sudo make install</span><br><span class="line">/bin/mkdir -p <span class="string">&#x27;/usr/lib/postgresql/9.4/lib&#x27;</span></span><br><span class="line">/bin/mkdir -p <span class="string">&#x27;/usr/share/postgresql/9.4/extension&#x27;</span></span><br><span class="line">/bin/mkdir -p <span class="string">&#x27;/usr/share/postgresql/9.4/extension&#x27;</span></span><br><span class="line">/bin/mkdir -p <span class="string">&#x27;/usr/share/doc/postgresql-doc-9.4/extension&#x27;</span></span><br><span class="line">/usr/bin/install -c -m <span class="number">755</span> oracle_fdw.so <span class="string">&#x27;/usr/lib/postgresql/9.4/lib/oracle_fdw.so&#x27;</span></span><br><span class="line">/usr/bin/install -c -m <span class="number">644</span> oracle_fdw.control <span class="string">&#x27;/usr/share/postgresql/9.4/extension/&#x27;</span></span><br><span class="line">/usr/bin/install -c -m <span class="number">644</span> oracle_fdw--<span class="number">1.1</span>.sql oracle_fdw--<span class="number">1.0</span>--<span class="number">1.1</span>.sql <span class="string">&#x27;/usr/share/postgresql/9.4/extension/&#x27;</span></span><br><span class="line">/usr/bin/install -c -m <span class="number">644</span> README.oracle_fdw <span class="string">&#x27;/usr/share/doc/postgresql-doc-9.4/extension/&#x27;</span></span><br></pre></td></tr></table></figure>

<p>查看插件是否安装成功：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sql=&gt; select * <span class="keyword">from</span> pg_available_extensions ;</span><br><span class="line">...</span><br><span class="line">oracle_fdw <span class="number">1.1</span> (<span class="literal">null</span>) foreign data wrapper <span class="keyword">for</span> Oracle access</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以看到已经安装了插件oracle_fdw</p>
<p><strong>创建扩展</strong></p>
<p>确保运行postgresql的用户(一般为postgres)可以使用sqlplus正确链接到oracle数据库(其实只要当前系统用户正确连接到oracle即可)</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sqlplus orauser/password@oradb</span><br></pre></td></tr></table></figure>

<p>创建oracle_fdw</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql</span><br><span class="line">postgres=# create extension oracle_fdw ;</span><br><span class="line">ERROR: could not load library <span class="string">&quot;/usr/lib/postgresql/9.4/lib/oracle_fdw.so&quot;</span>: libclntsh.so<span class="number">.12</span><span class="number">.1</span>: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>

<p>检查$LD_LIBRARY_PATH设置无误，但仍然找不到libclntsh.so.12.1，只好修改ld配置文件<br>添加/etc/ld.so.conf.d/oracle.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># oracle instant client</span><br><span class="line">/opt/oracle/instantclient_12_1/</span><br></pre></td></tr></table></figure>

<p>然后刷新ld缓存,</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ldconfig</span><br></pre></td></tr></table></figure>
<p>重新创建oracle_fdw扩展成功。<br>为什么ldconfig可以而$LD_LIBRARY_PATH不行呢？因为</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">If you manually start the server, it will inherit the environment setting <span class="keyword">from</span> your shell.</span><br><span class="line">But <span class="keyword">if</span> PostgreSQL is started <span class="keyword">from</span> a startup script, e.g. when the machine is booted,</span><br><span class="line">you will not have the environment setting, and things will suddenly stop working.</span><br><span class="line"></span><br><span class="line">That<span class="string">&#x27;s why I recommended to set the variables in the PostgreSQL startup script.</span></span><br><span class="line"><span class="string">As I said before, using ldconfig is much better</span></span><br></pre></td></tr></table></figure>
<p>更详细参见参考[2]</p>
<p><strong>创建外部服务器、用户映射和外部表</strong></p>
<p>创建外部oracle服务器<br>首先确保运行postgresql服务的用户(一般为postgres)可以通过sqlplus正确连接到配置的oracle数据库实例，比如此处的orcl</p>
<p>注意：要确保tnsname.ora文件位于默认的$ORACLE_HOME/network/admin目录下，指定$TNS_ADMIN环境变量是没用的。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postgres=# CREATE SERVER oradb FOREIGN DATA WRAPPER oracle_fdw OPTIONS (dbserver &#x27;oradb&#x27;);</span><br></pre></td></tr></table></figure>

<p>查看创建的外部服务器：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postgres=# select * from pg_foreign_server ;</span><br></pre></td></tr></table></figure>

<p>还需要创建一个postgresql用户到oracle用户的映射表</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postgres=# CREATE USER MAPPING FOR pguser SERVER oradb OPTIONS (user &#x27;orauser&#x27;, password &#x27;orapwd&#x27;);</span><br></pre></td></tr></table></figure>

<p>删除用户映射:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postgres=# DROP USER MAPPING FOR postgres SERVER oradb;</span><br></pre></td></tr></table></figure>

<p>如果不想在postgresql数据库中保存oracle的密码，可以将user后面的内容置空，从而使用外部密码方式。</p>
<p>创建外部表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres=# CREATE FOREIGN TABLE tb_ora_test (</span><br><span class="line"> id integer OPTIONS (key <span class="string">&#x27;true&#x27;</span>) NOT NULL,</span><br><span class="line"> text character varying(<span class="number">30</span>),</span><br><span class="line"> floating double precision NOT NULL</span><br><span class="line"> ) SERVER oradb OPTIONS (schema <span class="string">&#x27;ORASCHEMA&#x27;</span>, table <span class="string">&#x27;ORATAB&#x27;</span>);</span><br></pre></td></tr></table></figure>
<p>外部表的字段来自于指定的oracle表，字段数量可以少于oracle表的字段数量，也可以多于oracle表的字段数量，但多出来的字段只会返回空值。<br>然后就可以通过查询外部表来访问到oracle数据库表的内容，除了select,也可以insert,update,delete原始oracle表的内容。</p>
<p>授权其他用户使用外部oracle服务器</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postgres=# GRANT USAGE ON FOREIGN SERVER oradb TO pguser;</span><br></pre></td></tr></table></figure>


<p>References:<br>[1]<a href="http://laurenz.github.io/oracle_fdw/">PostgreSQL Foreign Data Wrapper for Oracle</a><br>[2]<a href="http://xahlee.info/UnixResource_dir/_/ldpath.html">Why LD_LIBRARY_PATH is bad</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL密码文件</title>
    <url>/2013/11/07/postgresql-passwd-file/</url>
    <content><![CDATA[<p>可以在用户主目录下建立一个密码文件~/.pgpass,用于存储角色的登录密码一遍自动登录数据库集群。</p>
<a id="more"></a>
<p>用脚本自动访问数据库时，无论通过管道，还是expect都无法自动登录到PostgreSQL数据库，所以只有使用密码文件~/.pgpass这一条路。</p>
<p>其文件格式为</p>
<p>hostname:port:database:username:password</p>
<p>除了password域，其他域都可以为指定*，PostgreSQL会使用搜索到的最匹配的第一条记录。</p>
<p>standby服务器上，database域指定为replication匹配到主服务器的流复制连接。database域大部分情形下无用，因为所有的角色默认都有connect到集群所有服务器上的权限。</p>
<p>这个文件的权限必须为0600,否则PostgreSQL拒绝使用这个文件。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL性能诊断与处理</title>
    <url>/2016/11/23/postgresql-performance-issues/</url>
    <content><![CDATA[<a id="more"></a>
<p>CPU负载居高不下，可以从这几方面入手查找原因，一个比较大的可能是有查询在长期占用CPU资源。</p>
<p><strong>查看当前连接数</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT count(*) FROM pg_stat_activity;</span><br><span class="line">=&gt; select client_addr, count(*) <span class="keyword">from</span> pg_stat_activity group by client_addr;</span><br></pre></td></tr></table></figure>

<p>可以查看总的连接数，以及每个客户端的连接数，判断是否有客户端泄露连接。</p>
<p><strong>查看连接状态</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT state, count(*) FROM pg_stat_activity GROUP BY state;</span><br></pre></td></tr></table></figure>

<p>连接有以下几种状态：</p>
<ul>
<li>  idle<br>连接对应的后端进程处于空闲状态</li>
<li>  actvie<br>连接对应的后端进程正在执行查询</li>
<li>  idle in transaction<br>连接对应的后端进程在一个事务中，但当前并没有执行查询</li>
<li>  idle in transaction (aborted)<br>在一个事务中，但是事务中的语句出现了错误，事务没有正确回滚</li>
<li>  fastpath function call<br>正在执行fastpath函数调用</li>
<li>  disabled<br>后端进程被配置为禁止跟踪</li>
</ul>
<p><strong>等待锁的连接</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT count(distinct pid) FROM pg_locks WHERE granted = <span class="literal">false</span>;</span><br></pre></td></tr></table></figure>

<p>查看是否有连接在等待排它锁导致效率低下</p>
<p><strong>查看事务最大执行时间</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT max(now() -xact_start) FROM pg_stat_activity WHERE state IN (<span class="string">&#x27;idle in transaction&#x27;</span>,<span class="string">&#x27;active&#x27;</span>); </span><br></pre></td></tr></table></figure>
<p>查看当前所有事务中最长事务的执行时间，一般来讲事务应该在数秒内结束，数分钟已经是很长的事务了。如果有事务的执行时间达到了小时的级别，那一定是出现了错误，但是事务还在占用系统资源，应该将其干掉。</p>
<p><strong>查看事务执行时间</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT pid, xact_start FROM pg_stat_activity ORDER BY xact_start ASC;</span><br></pre></td></tr></table></figure>
<p>以事务的起始时间为顺序，如果某事务的运行时间过长，比如达到了小时级别，应该查清原因，然后搞掉它。</p>
<p><strong>杀掉后端进程</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT pg_cancel_backend(<span class="number">1234</span>);</span><br></pre></td></tr></table></figure>

<p>1234就是pg_stat_activity表里的pid,也是postgres进程的系统进程pid，不要用操作系统命令去搞死进程，要用postgresql提供的命令。</p>
<p>References:<br>[1]<a href="https://www.postgresql.org/docs/9.6/static/monitoring-stats.html">28.2. The Statistics Collector</a><br>[2]<a href="https://jee-appy.blogspot.in/2016/10/debug-postgresql-performance-issues.html">Debug Slow Performance &amp; High Resource Utilisation Issue in PostgreSQL</a><br>[3]<a href="https://jee-appy.blogspot.com/2016/10/find-and-kill-long-running-process-in.html">Find and Kill Long Running Process in PostgreSQL</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL作业调度代理pgAgent安装及配置</title>
    <url>/2014/05/26/postgresql-pgagent-setup/</url>
    <content><![CDATA[<p>pgAgent是PostgreSQL的作业调度代理。</p>
<a id="more"></a>
<p><strong>安装pgAgent</strong></p>
<h1 id="apt-get-install-pgagent"><a href="#apt-get-install-pgagent" class="headerlink" title="apt-get install pgagent"></a>apt-get install pgagent</h1><p><strong>安装pgAgent数据库</strong></p>
<p>pgAgent需要一些数据库表和其他对象的支持,因此需要先安装pgAgent数据库。pgagen包中已经包含了创建pgAgent数据库的脚本，有两个文件，分别是:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/usr/share/pgadmin3/pgagent.sql</span><br><span class="line">/usr/share/pgadmin3/pgagent_upgrade.sql</span><br></pre></td></tr></table></figure>

<p>以数据库管理员身份连接到系统数据库postgres,分别执行这两个脚本,会创建一个新的schema pgagent。pgagent的详细参数见man pgagent。</p>
<p>pgagent需要一个标准的postgresql连接字符串连接到数据库，比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">/path/to/pgagent hostaddr=localhost dbname=postgres user=postgres</span><br></pre></td></tr></table></figure>

<p>因为安全原因，不能直接将密码写入连接字符串，因为那样任何人使用ps命令就可以看到密码。所以使用~/.pgpass文件为数据库用户提供密码。</p>
<p><strong>创建pgagent用户和.pgpass文件</strong></p>
<p>pgAgent将以pgagent用户的身份运行，因此首先创建pgagent用户</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># adduser --shell=/bin/bash pgagent</span><br></pre></td></tr></table></figure>

<p>然后在pgagent用户的主目录下新建.pgpass文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#hostname:port:database:username:password</span><br><span class="line">*:*:*:postgres:postgres</span><br></pre></td></tr></table></figure>

<p>将.pgpass的访问权限设置为0600</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ chmod <span class="number">0600</span> .pgpass</span><br></pre></td></tr></table></figure>

<p>有一点儿应该注意，用户pgagent连接数据库时的用户必须支持使用MD5密码认证才行,具体详见pg_hba.conf配置。</p>
<p><strong>pgAgent init script</strong></p>
<p>/usr/bin/pgagent需要作为守护程序运行，它会周期性的查询postgresql数据库，然后执行用户设定的jobs。<br>pgagent包并没有带init脚本，因此写了下面的init脚本,使pgagent可以作为Daemon程序自动运行。代码如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">set -e</span><br><span class="line"></span><br><span class="line">#</span><br><span class="line"># Starts / stops the pgagent daemon</span><br><span class="line">#</span><br><span class="line"># /etc/init.d/pgagent</span><br><span class="line"></span><br><span class="line">### BEGIN INIT INFO</span><br><span class="line"># Provides: pgagent</span><br><span class="line"># Required-Start:$local_fs $remote_fs $network $time postgresql</span><br><span class="line"># Required-Stop:$local_fs $remote_fs $network $time</span><br><span class="line"># Should-Start:$syslog</span><br><span class="line"># Should-Stop:$syslog</span><br><span class="line"># Default-Start:2 3 4 5</span><br><span class="line"># Default-Stop:0 1 6</span><br><span class="line"># Short-Description:pgagent Postgresql Job Service</span><br><span class="line">### END INIT INFO</span><br><span class="line"></span><br><span class="line"># For SELinux we need to use &#x27;runuser&#x27; not &#x27;su&#x27;</span><br><span class="line"><span class="keyword">if</span> \[ -x /sbin/runuser \]</span><br><span class="line">then</span><br><span class="line"> SU=runuser</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line"> SU=su</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">DBNAME=$&#123;DBNAME-postgres&#125;</span><br><span class="line">DBUSER=$&#123;DBUSER-postgres&#125;</span><br><span class="line">DBHOST=$&#123;DBHOST-localhost&#125;</span><br><span class="line">DBPORT=$&#123;DBPORT-<span class="number">5432</span>&#125;</span><br><span class="line">LOGFILE=$&#123;LOGFILE-<span class="regexp">/var/</span>log/pgagent.log&#125;</span><br><span class="line">pidfile=<span class="string">&quot;/var/run/pgagent.pid&quot;</span></span><br><span class="line"></span><br><span class="line">RETVAL=<span class="number">0</span></span><br><span class="line">NAME=<span class="string">&quot;pgagent&quot;</span></span><br><span class="line">PROG=<span class="string">&quot;/usr/bin/pgagent&quot;</span></span><br><span class="line"></span><br><span class="line"># Override defaults from /etc/default/pgagent file,if file is present:</span><br><span class="line">\[ -f /etc/<span class="keyword">default</span>/pgagent \] &amp;&amp; . /etc/<span class="keyword">default</span>/pgagent</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">echo_success</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line"> echo <span class="string">&quot;Success.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="title">echo_failure</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line"> echo <span class="string">&quot;Failure.&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">start</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line"> # Make sure that pgagent is not already running:</span><br><span class="line"> <span class="keyword">if</span> \[ -e <span class="string">&quot;$&#123;pidfile&#125;&quot;</span> \]</span><br><span class="line"> then</span><br><span class="line"> echo <span class="string">&quot;$&#123;NAME&#125; is already running&quot;</span></span><br><span class="line"> exit <span class="number">0</span></span><br><span class="line"> fi</span><br><span class="line"></span><br><span class="line"> echo <span class="string">&quot;Starting $&#123;NAME&#125; service... &quot;</span></span><br><span class="line"></span><br><span class="line"> <span class="keyword">if</span> \[ ! -e <span class="string">&quot;$&#123;LOGFILE&#125;&quot;</span> \]; then</span><br><span class="line"> touch $&#123;LOGFILE&#125;</span><br><span class="line"> chown root:pgagent $&#123;LOGFILE&#125;</span><br><span class="line"> chmod g+rw $&#123;LOGFILE&#125; </span><br><span class="line"> fi</span><br><span class="line"></span><br><span class="line"> $SU - pgagent -c <span class="string">&quot;$PROG -s $LOGFILE hostaddr=$DBHOST dbname=$DBNAME user=$DBUSER&quot;</span></span><br><span class="line"> RETVAL=$?</span><br><span class="line"> <span class="keyword">if</span> \[ $RETVAL -eq <span class="number">0</span> \]</span><br><span class="line"> then</span><br><span class="line"> echo_success</span><br><span class="line"> touch $pidfile</span><br><span class="line"> echo \<span class="string">`pidof pgagent\` &gt; $pidfile</span></span><br><span class="line"><span class="string"> else</span></span><br><span class="line"><span class="string"> echo_failure</span></span><br><span class="line"><span class="string"> return -1</span></span><br><span class="line"><span class="string"> fi</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">stop()&#123;</span></span><br><span class="line"><span class="string"> echo $&quot;Stopping <span class="subst">$&#123;NAME&#125;</span> service... &quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> if \[ ! -e &quot;$pidfile&quot; \]; then</span></span><br><span class="line"><span class="string"> echo &quot;<span class="subst">$&#123;NAME&#125;</span> is not running.&quot;</span></span><br><span class="line"><span class="string"> exit 0</span></span><br><span class="line"><span class="string"> else</span></span><br><span class="line"><span class="string"> pid=\`cat $pidfile\`</span></span><br><span class="line"><span class="string"> kill $pid true</span></span><br><span class="line"><span class="string"> rm $pidfile</span></span><br><span class="line"><span class="string"> echo_success</span></span><br><span class="line"><span class="string"> return 0</span></span><br><span class="line"><span class="string"> fi</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">status() &#123;</span></span><br><span class="line"><span class="string"> if \[ ! -f &quot;<span class="subst">$&#123;pidfile&#125;</span>&quot; \]; then</span></span><br><span class="line"><span class="string"> echo &quot;<span class="subst">$&#123;NAME&#125;</span> is not running.&quot;</span></span><br><span class="line"><span class="string"> else</span></span><br><span class="line"><span class="string"> echo &quot;<span class="subst">$&#123;NAME&#125;</span> is running.&quot;</span></span><br><span class="line"><span class="string"> fi</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#</span></span><br><span class="line"><span class="string">case &quot;$1&quot; in</span></span><br><span class="line"><span class="string"> start)</span></span><br><span class="line"><span class="string"> start</span></span><br><span class="line"><span class="string"> ;;</span></span><br><span class="line"><span class="string"> stop)</span></span><br><span class="line"><span class="string"> stop</span></span><br><span class="line"><span class="string"> ;;</span></span><br><span class="line"><span class="string"> reloadrestart)</span></span><br><span class="line"><span class="string"> stop</span></span><br><span class="line"><span class="string"> start</span></span><br><span class="line"><span class="string"> ;;</span></span><br><span class="line"><span class="string"> status)</span></span><br><span class="line"><span class="string"> status</span></span><br><span class="line"><span class="string"> ;;</span></span><br><span class="line"><span class="string"> *)</span></span><br><span class="line"><span class="string"> echo $&quot;Usage: $0 &#123;startstoprestartreloadstatus&#125;&quot;</span></span><br><span class="line"><span class="string">esac</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">exit $?</span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>
<p>使用这个脚本需要新建pgagent用户来运行daemon程序，并且要在pgagent的用户主目录下添加.pgpass文件。</p>
<p>如需要更改pgagent运行时的选项，在/etc/default/pgagent文件添加选项，覆盖默认值即可。</p>
<p>在各个运行级对应的启动脚本目录下创建符号连接</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># update-rc.d pgagent defaults</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://www.pgadmin.org/docs/1.18/pgagent.html">pgAgent</a><br>[2]<a href="http://www.wurenny.com/2013/12/18/14">RHEL5为postgresql安装独立作业插件：pgAgent手记</a></p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>PostgreSQL权限</title>
    <url>/2013/11/06/postgresql-privilige/</url>
    <content><![CDATA[<p>PostgreSQL权限系统</p>
<a id="more"></a>
<p>当一个对象被创建时，它被赋予一个所有者，这通常就是执行CREATE语句的角色。对于大多数对象，在初始状态，只有对象的所有者(和超级用户)才能对对象做任何事情。允许其他角色使用这个对象，必须赋予其适当的权限。</p>
<p>有许多不同种类的权限SELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER, CREATE, CONNECT, TEMPORARY, EXECUTE, 和 USAGE.不同的对象类型有不同的权限种类。</p>
<p>修改或者移除对象始终是对象所有者的权限。</p>
<p>使用ALTER命名可以为对象赋予一个新的所有者。超级用户总是可以这样做，而普通角色只有是当前对象的所有者(或者所有者角色的成员)，并且是新所有者角色的成员，才可以这样做。</p>
<p><strong>赋予权限</strong></p>
<p>赋予权限使用GRANT语句,比如<br>[sql]<br>GRANT UPDATE ON tb_accounts TO joe;<br>[/sql]<br>使用ALL来赋予角色对象类型具有的所有权限，特殊的用户PUBLIC用来给系统所有的用户赋予权限。</p>
<p>PostgreSQL为PUBLIC赋予某些类型对象的默认权限。对于tables, columns, schemas和tablespaces，没有默认权限赋予PUBLIC角色。对于其他类型，PUBLIC被赋予如下的默认权限：</p>
<ul>
<li>  数据库的CONNECT和CREATE TEMP TABLE权限</li>
<li>  函数的EXECUTE权限</li>
<li>  语言的USAGE权限</li>
</ul>
<p>对象的所有者可以剥夺默认的或显式赋予的权限。并且，初始默认权限可以使用ALTER DEFAULT PRIVILEGES来改变。</p>
<p>CONNECT权限只适用于数据库。</p>
<p>详细的授权语法见<a href="http://www.postgresql.org/docs/9.3/static/sql-grant.html">GRANT</a></p>
<p><strong>查询权限</strong></p>
<p>使用psql命令\z或\dp查询表，视图或者序列的访问权限</p>
<p><strong>撤销权限</strong></p>
<p>使用REVOKE语句<br>[sql]<br>REVOKE ALL ON tb_accounts FROM PUBLIC;<br>[/sql]</p>
<p>(对象所有者的)特殊权限，比如DROP,GRANT和REVOKE，是由对象所有者隐式拥有的，并且不能被赋予或剥夺。但是对象所有者可以选择撤销它自己在所拥有的对象上的普通权限。</p>
<p>通常，只有对象的所有者(或者超级用户)可以授予或者剥夺其他角色对其所拥有对象的权限。然而，可以通过WITH GRANT OPTION赋予接受权限的角色有能力为其他角色赋予当前对象的权限。如果GRANT OPTION随后被剥夺，那么所有直接或间接得到GRANT OPTION的角色都将失去其对当前的GRANT权限。</p>
<p>参考：</p>
<p>[1]<a href="http://www.postgresql.org/docs/9.3/static/ddl-priv.html">5.6. Privileges</a><br>[2]<a href="http://www.postgresql.org/docs/9.3/static/sql-grant.html">GRANT</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql reset xlog</title>
    <url>/2016/11/26/postgresql-reset-xlog/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>切记：永远不要手工删除postgresql数据库目录下的文件。</strong></p>
<p>一个测试库，因为开启了归档，而归档命令又失败了，导致归档日志暴涨，把根文件系统撑爆了，因为只是测试库，所以没在意，从配置文件中关了归档，<br>直接去pg_xlog目下手工干掉了所有的归档日志，然后问题就来了。</p>
<p>重新启动postgresql服务失败，错误日志：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">47</span>:<span class="number">53</span> CST \[<span class="number">24422</span>-<span class="number">1</span>\] LOG: database system was shut down at <span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">42</span>:<span class="number">38</span> CST</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">47</span>:<span class="number">53</span> CST \[<span class="number">24422</span>-<span class="number">2</span>\] LOG: invalid primary checkpoint record</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">47</span>:<span class="number">53</span> CST \[<span class="number">24422</span>-<span class="number">3</span>\] LOG: invalid secondary checkpoint record</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">47</span>:<span class="number">53</span> CST \[<span class="number">24422</span>-<span class="number">4</span>\] PANIC: could not locate a valid checkpoint record</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">47</span>:<span class="number">53</span> CST \[<span class="number">24421</span>-<span class="number">1</span>\] LOG: startup process (PID <span class="number">24422</span>) was terminated by signal <span class="number">6</span>: Aborted</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">47</span>:<span class="number">53</span> CST \[<span class="number">24421</span>-<span class="number">2</span>\] LOG: aborting startup due to startup process failure</span><br></pre></td></tr></table></figure>
<p>检查点丢失了，只好reset log</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres ./pg_resetxlog /<span class="keyword">var</span>/lib/postgresql/<span class="number">9.4</span>/main/</span><br><span class="line">Transaction log reset</span><br></pre></td></tr></table></figure>

<p>如果不行，请加-f参数强制reset</p>
<p>然后再启动，提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">55</span>:<span class="number">24</span> CST \[<span class="number">27330</span>-<span class="number">1</span>\] LOG: database system was shut down at <span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">54</span>:<span class="number">28</span> CST</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">55</span>:<span class="number">24</span> CST \[<span class="number">27330</span>-<span class="number">2</span>\] PANIC: too many replication slots active before shutdown</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">55</span>:<span class="number">24</span> CST \[<span class="number">27330</span>-<span class="number">3</span>\] HINT: Increase max_replication_slots and <span class="keyword">try</span> again.</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">55</span>:<span class="number">24</span> CST \[<span class="number">27329</span>-<span class="number">1</span>\] LOG: startup process (PID <span class="number">27330</span>) was terminated by signal <span class="number">6</span>: Aborted</span><br><span class="line"><span class="number">2016</span>-<span class="number">11</span>-<span class="number">26</span> <span class="number">13</span>:<span class="number">55</span>:<span class="number">24</span> CST \[<span class="number">27329</span>-<span class="number">2</span>\] LOG: aborting startup due to startup process failure</span><br></pre></td></tr></table></figure>

<p>因为以前添加了复制槽，现在max_replication_slots又设置成了0，所以出错了，重新修改配置文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">archive_moe=archive</span><br><span class="line">max_replication_slots=<span class="number">5</span></span><br></pre></td></tr></table></figure>

<p>启动后删除replication slots:<br>[sql]<br>=&gt; select pg_drop_replication_slot(‘slotname’);<br>[/sql]</p>
<p>这样关闭归档参数就没问题了。</p>
<p>再一次，永远不要手工删除postgresql数据目录下的文件，归档日志太多撑爆了硬盘，postgresql panic，是因为归档命令或者复制槽出问题了，因此数据库无法自动清理wal日志。<br>如果故障无法排除，可以首先将pg_xlog目录下的文件拷贝到其他地方，然后使用pg_archivecleanup命令来清理归档日志。</p>
<p>迫不得已，实在每办法了，再reset log，但是这时的数据库状态是不对的，不应该再使用了。如果有其他备份，请恢复这些备份。<br>没有的话，可以先pg_dump,然后停止数据库，重新initdb初始化数据库,然后再pg_restore。</p>
<p>References:<br>[1]<a href="http://dba.stackexchange.com/questions/80317/how-can-i-solve-postgresql-problem-after-deleting-wal-files">How can I solve postgresql problem after deleting wal files?</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL使用连续归档备份恢复数据库</title>
    <url>/2015/12/06/postgresql-restore-using-continuous-archiving-backup/</url>
    <content><![CDATA[<a id="more"></a>
<p>当数据库因为各种原因损坏时，连续归档备份就派上用场了，不过这种恢复在对停机时间很苛刻的环境下并不是很合适。<br>如果数据库很大的话，恢复时间可能是不可接受的，这时候就应该配置高可用实时复制系统，比如配置warm/hot standby备用机。</p>
<p>此文中的$PG_VERISON代表postgresql的主次版本号，比如当前为9.4。</p>
<p><strong>数据恢复</strong></p>
<ol>
<li> 停止服务器<br>如果服务器还在运行中，应该先将其停止。如果硬件故障已无法开机，则可以在异机恢复。这里以异机恢复为例讲解。<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service postgresql stop</span><br></pre></td></tr></table></figure></li>
<li> 删除现有集群数据<br>将当前postgresql集群数据目录下的所有文件删除，删除debian默认安装postgresql集群数据：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rm -rf /<span class="keyword">var</span>/lib/postgresql/$PG_VERSION/main<span class="comment">/*</span></span><br></pre></td></tr></table></figure></li>
<li> 恢复基础备份<br>将最近的基础备份恢复到集群的数据目录：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres tar jxvf <span class="number">20151207.</span>tbz2 -C /<span class="keyword">var</span>/lib/postgresql/$PG_VERSION/main/</span><br></pre></td></tr></table></figure>
一定要注意恢复的数据文件的属主是运行PostgreSQL服务的系统用户，debian系统上为postgres,还应该保持原来的权限。</li>
<li> pg_xlog目录<br>如果进行基础备份时，pg_xlog目录下有未归档日志，恢复后应将目录下的所有文件删除，因为这些文件已经过时。如果没有pg_xlog目录则建立此目录，注意目录的属主和权限。<br>主服务器崩溃后如果尚未归档的WAL日志还能访问，则应将其拷贝到pg_xlog目录，以尽最大可能恢复数据。</li>
<li> 配置recovery.conf文件<br>如果使用pg_basebackup命令进行备份时使用了-R(–write-recovery-conf)参数,则恢复后的数据目录中已经有了一个recovery.conf文件。如果没有，则可以拷贝一个模板到数据目录：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres cp /usr/share/postgresql/$PG_VERSION/recovery.conf.sample /<span class="keyword">var</span>/lib/postgresql/$PG_VERSION/main/</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>然后修改文件中的restore_command为适当的shell脚本以在恢复时可以读取到归档的WAL日志：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">restore_command = <span class="string">&#x27;cp /var/backups/postgresql/archive/%f %p&#x27;</span></span><br></pre></td></tr></table></figure>

<p>因为此案例没有使用流复制，因此应该注释掉primary_conninfo参数。</p>
<p>恢复期间还应该修改pg_hba.conf文件或其他途径以阻止客户端连接。<br>6.  启动服务器，开始恢复</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service postgresql start</span><br></pre></td></tr></table></figure>
<p>当所有的归档WAL恢复完毕,无法读取到其他更新的归档日志后，恢复就会自动结束，并且recovery.conf会被更名为recovery.done,防止意外重新进入restore过程。<br>恢复完毕后，可以允许客户端连接到服务器。<br>注意，恢复的最后阶段，日志中会出现No such file or directory字样的提示，这是正常的，因为恢复过程已经无法读取到其他的归档日志文件或时间线history文件。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">5</span>\] LOG: consistent recovery state reached at <span class="number">1</span>/<span class="number">86008798</span></span><br><span class="line">cp: cannot stat ‘/<span class="keyword">var</span>/backups/postgresql/archive/<span class="number">000000010000000100000087</span>’: No such file or directory</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">6</span>\] LOG: redo done at <span class="number">1</span>/<span class="number">86008798</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">7</span>\] LOG: last completed transaction was at log time <span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">08</span>:<span class="number">57</span>:<span class="number">51.075265</span>+<span class="number">08</span></span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">8</span>\] LOG: restored log file <span class="string">&quot;000000010000000100000086&quot;</span> <span class="keyword">from</span> archive</span><br><span class="line">cp: cannot stat ‘/<span class="keyword">var</span>/backups/postgresql/archive/<span class="number">00000002</span>.history’: No such file or directory</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">9</span>\] LOG: selected <span class="keyword">new</span> timeline ID: <span class="number">2</span></span><br><span class="line">cp: cannot stat ‘/<span class="keyword">var</span>/backups/postgresql/archive/<span class="number">00000001</span>.history’: No such file or directory</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">10</span>\] LOG: archive recovery complete</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4906</span>-<span class="number">11</span>\] LOG: MultiXact member wraparound protections are now enabled</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4924</span>-<span class="number">1</span>\] LOG: autovacuum launcher started</span><br><span class="line"><span class="number">2015</span>-<span class="number">12</span>-<span class="number">07</span> <span class="number">09</span>:<span class="number">24</span>:<span class="number">42</span> CST \[<span class="number">4905</span>-<span class="number">1</span>\] LOG: database system is ready to accept connections</span><br></pre></td></tr></table></figure>

<p><strong>时间点恢复Point-in-Time Recovery (PITR)</strong></p>
<p>默认情况下，恢复过程会一直持续到最后一个可用的WAL归档日志。<br>但是也可以在recovery.conf中设置参数来控制恢复到的目标点，这四个参数recovery_target,recovery_target_name，recovery_target_time和recovery_target_xid可以用来指定恢复的目标点，但同时只能有一个生效，如果指定多个，则以最后一个为准。</p>
<p>这几个参数的含义如下：</p>
<ul>
<li>  recovery_target<br>该参数目前只有一个取值’immediate’,指示恢复应该在达到一直状态后尽快的结束。对于连续归档备份来说，基础备份结束时就处于一致状态。</li>
<li>  recovery_target_name<br>指定使用pg_create_restore_point()函数设定的恢复点名称。pg_create_restore_point()可以创建一个命名的恢复日志记录作为恢复目标，此函数只有超级用户可以访问。</li>
<li>  recovery_target_time<br>指定恢复所要到达的时间戳。注意，recovery_target_time 设置的时间格式,使用pg的now函数输出的格式。比如：<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">recovery_target_time = <span class="string">&#x27;2015-02-13 20:04:49.63197+08&#x27;</span> </span><br></pre></td></tr></table></figure></li>
<li>  recovery_target_xid<br>指定恢复过程要到达的事务id。要注意，事务id在事务开始时顺序赋值，但每个事务的完成不一定会遵循先后顺序，因此指定这个参数，只有那些在此事务id之前启动的事务会被恢复。</li>
</ul>
<p>还有几个参数会影响恢复目标的设定以及到达恢复目标时的动作：</p>
<ul>
<li>  recovery_target_inclusive<br>此参数只影响recovery_target_time和recovery_target_xid参数。当设定为true时，会包含恢复目标，而设定为false时，会恢复到恢复目标之前而不包含恢复目标。此参数默认为true。</li>
<li>  recovery_target_timeline<br>指定在一个特定的时间线上恢复。默认在与制作基础备份相同的时间线上恢复。设置为latest会在归档日志中最新的时间线上恢复。</li>
<li>  pause_at_recovery_target<br>指定当到达恢复目标是是否应该暂停，默认为true。此参数的意图是允许查询数据库来检查当前的恢复目标是否是想要的恢复点。<br>如果当前恢复目标并不是想要的，可以停止服务器，修改恢复目标设置，重新开始恢复数据库。<br>可以使用pg_xlog_replay_resume()函数来结束暂停继续恢复数据库，此时会一直恢复到最后的一致状态。</li>
</ul>
<p>没有指定恢复目标，或者没有处于hot_standby状态时，这个参数并不生效。</p>
<p><strong>恢复时间线timeline</strong></p>
<p>在做数据恢复时，如果能像时间旅行或者并行宇宙中那样来来回回随意穿梭就好了。比如，恢复一次之后，发现不满意，可以从头再来，直到找到满意的恢复点为止。</p>
<p>幸好，PostgreSQL支持时间线timeline，正好支持了这种“超能力”。如果没有时间线，每次恢复之后新产生的WAL日志极有可能会将部分之前的WAL日志覆盖，从而再也无法恢复到那些状态。</p>
<p>时间线是这样的，无论何时，一个恢复完成后，会创建一个新的时间线来标识此次恢复之后产生的WAL日志。时间线的id号是WAL日志文件名字的一部分，因此不会覆盖其他时间线上的WAL日志文件。</p>
<p>每次创建一个新的时间线时，PostgreSQL会创建一个新的时间线历史文件，后缀为.history。历史文件会标识此时间线是什么时候从那个时间线分支而来的。有了时间线历史文件，PostgreSQL就可以在含有多个时间线的归档文件中找到正确的WAL归档日志。</p>
<p>虽然时间线看起来的确很高能，但是无论如何也不可能恢复到制作基础备份之前的时间。</p>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/9.2/static/continuous-archiving.html">24.3. Continuous Archiving and Point-in-Time Recovery (PITR)</a><br>[2]<a href="http://www.postgresql.org/docs/current/static/recovery-target-settings.html">26.2. Recovery Target Settings</a><br>[3]<a href="http://my.oschina.net/hippora/blog/378415">postgresql在线备份与恢复(三)</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL模式(schema)</title>
    <url>/2013/11/05/postgresql-schema/</url>
    <content><![CDATA[<p>schema就是用于逻辑隔离不同数据库对象的名字空间，schema隶属于特定的数据库。</p>
<a id="more"></a>
<p>一个数据库可以包含一个或多个命名schema,然后schema可以包含表等其他对象。</p>
<p>schema也可以包含多种命名对象，包括数据类型(data types),函数(functions)和操作符(operators),相同的对象名可以存在与不同的schema里而不会冲突，不像数据库，schema是逻辑隔离，一个用户可以存取其所连接到数据库的任何schema里的对象，只要用户有相应的权限。</p>
<p>使用schema可能的原因有以下几个：</p>
<ul>
<li>  允许多个用户使用同一个数据库而互不干扰</li>
<li>  组织数据库对象到逻辑组，使其更容易管理</li>
<li>  第三方应用程序可以放进单独的schema，隔离其名字空间，不与其他对象名字冲突</li>
</ul>
<p>schema是操作系统目录的模拟，但是schema是不能嵌套的。schema就是namespace。</p>
<p><strong>创建schema</strong></p>
<p><em>语法</em><br>[sql]<br>CREATE SCHEMA schema_name [ AUTHORIZATION user_name ] [ schema_element [ … ] ]<br>CREATE SCHEMA AUTHORIZATION user_name [ schema_element [ … ] ]<br>CREATE SCHEMA IF NOT EXISTS schema_name [ AUTHORIZATION user_name ]<br>CREATE SCHEMA IF NOT EXISTS AUTHORIZATION user_name<br>[/sql]</p>
<p>CREATE SCHEMA语句在当前数据库中创建名字为schema_name的schema。</p>
<p><em>参数</em></p>
<ul>
<li>  schema_name<br>将要创建的schema的名字，在当前数据库中schema的名字不能冲突。如果忽略此参数，则以当前数据库用户的名字命名新创建的schema。schema的名字不能以pg_开头，这是系统保留的名字。</li>
<li>  user_name<br>拥有新创建schema的角色名字，如果不指定则为执行当前命令的数据库用户。如果为其他角色创建此schema，那么当前用户必须是那个角色的直接或间接角色成员，或者当前用户为超级用户。</li>
<li>  schema_element<br>创建schema名字空间下其他对象的SQL语句。与创建schema完毕后执行单独的SQL来创建对象是一样的，除了如果指定AUTHORIZATION,那么新创建的对象都有指定的角色拥有。建议分开创建schema包含的对象。</li>
<li>  IF NOT EXISTS<br>如果同名的schema已经存在，除了提示什么也不做。当指定此选项时，不能包含schema_element子命令。</li>
</ul>
<p><em>注意</em><br>要创建schema，调用该命令的用户必需在当前数据库上有 CREATE 权限。当然，超级用户可以绕开这个检查。</p>
<p>在新建的schema下建表<br>[sql]<br>CREATE TABLE myschema.mytable (<br> …<br>);<br>[/sql]</p>
<p><strong>查询schema</strong><br>SQL语句<br>[sql]<br>SELECT * FROM pg_namespace;<br>[/sql]<br>pg_namespace不只包含schema，还包含其他的名字空间。</p>
<p>或者psql命令<br>[sql]<br>=# \dn</p>
<p> List of schemas<br> Name Owner<br>————+———-<br> public postgres<br> testschema postgres<br>(2 rows)<br>[/sql]</p>
<p><strong>删除schema</strong></p>
<p>如果schema的子对象都已删除，schema已为空对象，可以用以下语句删除schema<br>[sql]<br>DROP SCHEMA myschema;<br>[/sql]</p>
<p>也可以这样删除schema及其子对象<br>[sql]<br>DROP SCHEMA myschema CASCADE;<br>[/sql]</p>
<p><strong>public schema</strong></p>
<p>每一个新建的数据库包含一个默认的public模式，数据库中所有没有显式或隐式指定schema的对象，都归属于public名字空间。<br>[sql]<br>CREATE TABLE products ( … );<br>[/sql]<br>与<br>[sql]<br>CREATE TABLE public.products ( … );<br>[/sql]<br>是一样的。</p>
<p><strong>schema搜索路径</strong></p>
<p>全限定的名字写起来冗长乏味，因此表经常通过一个没有名字空间限定的名字来使用，仅仅就是表的名字。系统通过一个搜索路径来决定到底使用的是哪一张表，搜索路径是schema的一个列表。搜索路径中第一个匹配的表即是要访问的表。如果搜索路径中没有匹配，会报告一个错误，即使在数据库的其他schema中有相匹配的表。</p>
<p>搜索路径中的第一个schema成为当前schema,也是CREATE命名没有指定schema时的默认schema。</p>
<p>查看当前的搜索路径：</p>
<p>[sql]<br>=&gt; SHOW search_path;</p>
<h2 id="search-path"><a href="#search-path" class="headerlink" title=" search_path "></a> search_path </h2><p> “$user”,public<br>(1 row)<br>[/sql]</p>
<p>默认情况下，搜索路径的第一个schema是与当前用户同名的schema,第二个则是public schema。</p>
<p>可以这样设置搜索路径：</p>
<p>[sql]<br>SET search_path TO myschema,public;<br>[/sql]</p>
<p>搜索路径同样适用于data types,function names和operator names。</p>
<p><strong>schema与权限</strong></p>
<p>默认情况下，用户不能访问不属于他的schema中的任何对象。要允许访问，schema的拥有者必须授予用户在这个schema上的USAGE权限。不同访问权限需要不同的授权。</p>
<p>一个用户也可以在其他schema里创建对象，这需要schema拥有者授予用户CREATE权限。默认情况下，每个人都有public schema上的CREATE和USAGE权限。这允许所有可以连接到指定数据库的用户，在public模式里创建对象。如果不允许这样，可以撤销默认的权限设置：</p>
<p>[sql]<br>REVOKE CREATE ON SCHEMA public FROM PUBLIC;<br>[/sql]</p>
<p>第一个小写的public是指 public schema,而第二个大写的PUBLIC是指所有可以连接到数据库的用户。第一个小写的public是个标示符，而第二个大写的PUBLIC则是关键字，所以用大小写予以区分。</p>
<p><strong>System Catalog Schema</strong></p>
<p>除了public和用户创建的schema，每一个数据库还包含一个pg_catalog schema,它包含了系统表所有的内建数据类型，函数和操作符。pg_catalog一直是schema搜索路径的一部分。虽然没有在搜索路径中显示指定，但它在搜索路径中的schema之前被隐式搜索。这保证了内建的名字总是可以被发现。只要不使用pg_开头的名字就不会与系统发生名字冲突。</p>
<p><strong>schema使用范式</strong></p>
<p>schema用来组织和管理数据库对象，有几个推荐的schema使用范式：</p>
<ul>
<li>  如果不创建任何schema，则所有用户隐式的使用public schema。这等同于根本不使用schema。这在数据库中只有一个或者极少的用户时推荐使用。</li>
<li>  可以为每一个用户创建一个与其用户名相同的schema。因为缺省的搜索路径的第一个schema是$user,与当前用户的名字相同。因此，如果每个用户有一个与其名字相同的单独的schema，则默认他们只能访问自己所属的schema。使用这种schema范式，可以撤销掉对public schema的访问许可，甚至把public schema直接移除，这样每个用户就真正的限定在了他们自己的schema里</li>
</ul>
<p>参考：<br><a href="http://www.postgresql.org/docs/9.3/static/ddl-schemas.html">Schemas</a><br><a href="http://www.postgresql.org/docs/9.3/static/sql-createschema.html">CREATE SCHEMA</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL Standby Server Operation</title>
    <url>/2015/12/10/postgresql-standby-server-operation/</url>
    <content><![CDATA[<a id="more"></a>
<p>当standby备库启动时,首先会调用restore_command来恢复所有可用的归档日志。</p>
<p>如果没有配置restore_command或者恢复了所有的归档日志restore_command失败之后，stanby备库会尝试pg_xlog目录下所有可用的WAL日志。</p>
<p>pg_xlog目录下没有WAL日志或者已有的WAL日志全部恢复完毕后，如果配置了流复制，standby会尝试连接到主库，开始进行流式复制。</p>
<p>如果失败，或者没有配置流式复制，或者连接中断，standby会重新开始一个新的恢复循环。</p>
<p>从WAL归档日志，到pg_xlog,再到流式复制的恢复循环会一直持续到服务器停止或者退出standby模式。</p>
<p>可以使用pg_ctl promote命令或者找到触发文件时，备库退出standby模式并切换到正常操作模式，可以接受正常的读写请求。<br>在failover完成之前，所有restore_command可以访问的以及pg_xlog目录下的WAL日志会被恢复，但是不会连接到主库进行流式恢复。</p>
<p>References:<br>[1]25.2.2. Standby Server Operation</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL流复制主备切换</title>
    <url>/2020/07/09/postgresql-stream-replication-switchover/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>一、判断主备角色</strong><br>有几个方法可以判断：<br>1、查看wal进程</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ps aux grep wal</span><br></pre></td></tr></table></figure>
<p>如果进程名有”postgres: 11/main: walwriter”字样，则为主库，walwriter为wal发送方。<br>如果进程名有”postgres: 11/main: walreceiver streaming 2A/ACAA1088”字样，则为备库，walreceiver为wal接收方。<br>2、pg_is_in_recovery函数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres psql</span><br><span class="line">postgres=# select pg_is_in_recovery();</span><br><span class="line">pg_is_in_recovery</span><br><span class="line">-------------------</span><br><span class="line"> f</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>
<p>显示f说明是主库，显示t说明为备库。<br>3、查看数据库控制信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres /usr/lib/postgresql/<span class="number">11</span>/bin/pg_controldata -D /<span class="keyword">var</span>/lib/postgresql/<span class="number">11</span>/main/</span><br><span class="line">g_control version number: <span class="number">1100</span></span><br><span class="line">Catalog version number: <span class="number">201809051</span></span><br><span class="line">Database system identifier: <span class="number">6745356148899875633</span></span><br><span class="line">Database cluster state: <span class="keyword">in</span> production</span><br><span class="line">pg_control last modified: Thu <span class="number">09</span> Jul <span class="number">2020</span> <span class="number">02</span>:<span class="number">40</span>:<span class="number">49</span> PM CST</span><br><span class="line">Latest checkpoint location: <span class="number">825</span>/245660D8</span><br><span class="line">Latest checkpoint<span class="string">&#x27;s REDO location: 825/245660A0</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>Database cluster state这行为in production说明位主库，为in archive recovery说明为备库。<br>4、通过recovery.conf 文件判断<br>一般的，备库才有recovery.conf，主库一般没有或是改名为recovery.done</p>
<p><strong>二、主备切换</strong><br>1、使用trigger文件切换</p>
<p>a. 在备库启动时在 recovery.conf 文件中加入一个触发文件的路径（新加则需要重启备库）</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">trigger_file=<span class="string">&#x27;/var/lib/postgresql/11/main/.postgresql.trigger&#x27;</span></span><br></pre></td></tr></table></figure>

<p>b. 关闭主库：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop postgresql@<span class="number">11</span>-main.service</span><br></pre></td></tr></table></figure>
<p>或者<br>先查看postgresql集群信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pg_lsclusters</span><br><span class="line">Ver Cluster Port Status Owner Data directory Log file</span><br><span class="line"><span class="number">11</span> main <span class="number">5432</span> online postgres /<span class="keyword">var</span>/lib/postgresql/<span class="number">11</span>/main /<span class="keyword">var</span>/log/postgresql/postgresql-<span class="number">11</span>-main.log</span><br></pre></td></tr></table></figure>
<p>然后执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo pg_ctlcluster <span class="number">11</span> main stop</span><br></pre></td></tr></table></figure>

<p>c.在备库上创建trigger文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo touch /<span class="keyword">var</span>/lib/postgresql/<span class="number">11</span>/main/.postgresql.trigger</span><br></pre></td></tr></table></figure>
<p>可以看到备库上的recovery文件已经成为done了,此时备库已经被激活为主库，可以直接做读写操作了<br>在新主库上创建复制槽</p>
<p>d. 原主库搭建为新备库<br>准备recovery.conf文件，primary_conninfo指向新主库，使用合适的复制槽，然后重新启动数据库即可。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">recovery_target_timeline=<span class="string">&#x27;latest&#x27;</span></span><br><span class="line">standby_mode = <span class="string">&#x27;on&#x27;</span></span><br><span class="line">primary_conninfo = <span class="string">&#x27;host=59.206.31.149 port=5432 user=xxxx password=xxxx&#x27;</span></span><br><span class="line">primary_slot_name = <span class="string">&#x27;repl_slot_2&#x27;</span></span><br></pre></td></tr></table></figure>
<p>这里必须添加recovery_target_timeline=’latest’，因为主备切换时timeline更新了。<br>注意pg_hba_conf中对replication的权限设定</p>
<p>2、使用pg_ctlcluster命令切换<br>a. 停止应用程序，关闭主库<br>b. 备库提升为主库<br>备库端执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo pg_ctlcluster <span class="number">11</span> main promote</span><br></pre></td></tr></table></figure>
<p>c. 老主库上配置recovery.conf文件，启动原主库为新的备库</p>
<p>References:<br>[1]<a href="https://www.postgresql.org/docs/11/warm-standby-failover.html">26.3. Failover</a><br>[2]<a href="https://blog.csdn.net/qq_43303221/article/details/85777529">PostgreSQL 流复制的主备切换</a><br>[3]<a href="https://blog.51cto.com/heyiyi/1917655">PostgreSQL Switchover vs. Failover</a><br>[4]<a href="https://www.cnblogs.com/lottu/p/7490759.html">PostgreSQL主备切换</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql停止归档</title>
    <url>/2019/04/06/postgresql-stop-archiving/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为存储归档文件的服务器硬件故障宕机，写入不成功导致postgresql无法归档。这时候可以临时修改配置文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">archive_command=<span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>然后reload postgresql</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service postgresql reload</span><br></pre></td></tr></table></figure>
<p>这时服务器不会发送归档日志文件，但是服务器在继续累积产生的WAL日志文档，直到提供一个合适的归档命令，重新开始归档，这样不会丢失WAL日志文档。</p>
<p>如果提供如下归档命令</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">archive_command=<span class="string">&#x27;/bin/true&#x27;</span></span><br></pre></td></tr></table></figure>
<p>这样归档进程总是认为归档成功，但实际上并没有真正写归档文件，但服务器上的WAL会被删除掉(与参数wal_keep_segments有关)，当硬件恢复或者换用其他硬件时，必须重新制作基础备份，因为WAL归档日志文件已经缺失了。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL外键表引用授权</title>
    <url>/2013/12/18/postgresql-table-grant/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为要引用schema base中的一张表tb_user,所以在sql文件中使用如下语句授权:<br>[sql]<br>\c reis base<br>GRANT REFERENCES ON tb_user TO general;<br>\c reis general<br>[/sql]</p>
<p>但仍然无法引用base.tb_user表,提示:</p>
<p>ERROR: permission denied for schema base</p>
<p>这里虽然对schema base下的对象tb_user有了参考的权限,但对schema本身却没有授予权限,所以出现这个错误提示。</p>
<p>所以先授权角色general有使用schema的权限就可以了。</p>
<p>[sql]<br>\c reis base<br>GRANT USAGE ON SCHEMA base TO general;<br>GRANT REFERENCES ON tb_user TO general;<br>\c reis general<br>[/sql]</p>
<p>对于schema对象,有两种权限可以授权其他角色。一个是CREATE,允许被授权的角色在当前schema内创建和修改对象。另一个权限是USAGE,允许被授权角色使用schema内的对象。</p>
<p><strong>参考:</strong><br><a href="http://www.postgresql.org/docs/9.3/static/sql-grant.html">GRANT的详细语法</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL表空间、数据库、角色(用户)、模式、表之间的关系以及数据库组织管理模式</title>
    <url>/2013/11/06/postgresql-tablespace-database-user-schema-table-2/</url>
    <content><![CDATA[<p>表空间、数据库、角色、模式及表之间的关系</p>
<a id="more"></a>
<p>表空间用于定义数据库对象在物理存储设备上的位置，不特定于某个单独的数据库。</p>
<p>数据库是数据库对象的物理集合，而schema则是数据库内部用于组织管理数据库对象的逻辑集合，<br>schema名字空间之下则是各种应用程序会接触到的对象，比如表，索引，数据类型，函数，操作符等。</p>
<p>角色(用户)则是数据库服务器(集群)全局范围内的权限控制系统，用于各种集群范围内所有的对象权限管理。<br>因此角色不特定于某个单独的数据库，但角色如果需要登录数据库管理系统则必须连接到一个数据库上。</p>
<p>角色可以拥有各种数据库对象。</p>
<h5 id="数据库管理模式"><a href="#数据库管理模式" class="headerlink" title="数据库管理模式"></a>数据库管理模式</h5><p>对于一个应用程序分很多相对独立的模块，每个模块有相对独立的数据结构，可以采用每个模块一个数据库用户及与其名字相同的schema来组织数据库，并且整个的物理数据库放在一个单独的表空间中。</p>
<p>使用这种数据库管理模式，可以撤销掉对public schema的访问许可，甚至把public schema直接移除，这样每个用户就真正的限定在了他们自己的schema里。</p>
<p>大致的数据库创建流程如下：</p>
<p><strong>创建数据库拥有者角色</strong></p>
<p>用超级用户postgres登录postgres数据库，然后创建角色foo<br>[sql]<br>$ psql -U postgres -h localhost<br>postgres=# CREATE ROLE foo CREATEDB CREATEROLE LOGIN PASSWORD ‘password’;<br>[/sql]</p>
<p><strong>创建表空间并将其所有权赋予新创建的用户</strong></p>
<p>创建表空间ts_foo并将其所有权赋予角色foo<br>[sql]<br>postgres=# CREATE TABLESPACE ts_foo OWNER foo LOCATION ‘/mnt/raid3805’;<br>[/sql]</p>
<p><strong>创建数据库</strong></p>
<p>使用新创建的用户foo登录postgres数据库，然后在ts_foo表空间上创建同名数据库foo<br>[sql]<br>$ psql -U foo -h localhost -d postgres<br>postgres=&gt; CREATE DATABASE foo TABLESPACE ts_foo;<br>[/sql]</p>
<p><strong>创建其他用户</strong></p>
<p>用新创建的角色foo登录foo数据库，然后创建其他用户bar，并为bar赋予数据库foo上的CREATE权限<br>[sql]<br>$ psql -U foo -h localhost<br>foo=&gt; CREATE ROLE bar LOGIN PASSWORD ‘password’;<br>foo=&gt; GRANT CREATE ON DATABASE foo TO bar;<br>[/sql]</p>
<p><strong>创建用户的schema</strong></p>
<p>使用角色bar登录数据库foo，然后创建角色bar拥有的schema bar<br>[sql]<br>$ psql -U bar -h localhost -d foo<br>foo=&gt; CREATE SCHEMA bar;<br>[/sql]</p>
<p><strong>bar用户创建其同名schema下的表对象</strong></p>
<p>[sql]<br>foo=&gt; CREATE TABLE foobar (id INTEGER);<br>[/sql]</p>
<p><strong>注意：</strong></p>
<p>shell命令psql连接到哪个数据库呢？情况是这样的：</p>
<p>如果只使用psql不提供任何参数，则psql试图连接到与当前发出命令的操作系统用户名同名的数据库，如果提供命令行参数-U指定要使用的登录角色名，那么psql试图去连接与登录名同名的数据库，如果提供了-d 命令行参数明确的指定要连接的数据库，则psql试图连接到这个指定的数据库。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>PostgreSQL表空间</title>
    <url>/2013/11/05/postgresql-tablespace/</url>
    <content><![CDATA[<p>PostgeSQL表空间允许数据库管理员定义存储数据库对象的文件在文件系统中的位置。一旦创建了表空间，当创建数据库对象时就可以引用这个表空间。</p>
<a id="more"></a>
<p>通过使用表空间，管理员可以控制PostgreSQL数据库的磁盘布局。这有两个好处：</p>
<ul>
<li>  如果PostgreSQL集群初始安装所在的分区或卷耗尽了空间，并且已经无法扩展，可以在另外的分区上面创建和使用一个新的表空间，直到系统重新被配置。</li>
<li>  表空间可以允许管理员根据已知的数据库对象使用模式优化系统性能。比如，一个频繁使用的index可以放在一个快速的，高可用的磁盘上，比如昂贵的固态硬盘。同时，存储很少使用或者对性能要求不高的归档数据的table，可以放在廉价低速的磁盘系统上。</li>
</ul>
<p><strong>创建表空间语法</strong><br>[sql]<br>CREATE TABLESPACE tablespace_name [ OWNER user_name ] LOCATION ‘directory’;<br>[/sql]</p>
<p>参数</p>
<ul>
<li><p>  _tablespace_name_ 表空间的名字，不能以pg_开头，这是为系统表空间保留的。</p>
</li>
<li><p>  _user_name_ 表空间所有者的名字，如果省略，缺省为执行命令的用户。只有数据库超级用户才可以创建表空间，但可以将其所有权赋予非超级用户。</p>
</li>
<li><p>  <em>directory</em> 表空间使用的路径，目录必须是空的，并且owner为PostgreSQL操作系统用户。Debian默认安装PostgreSQL的系统用户为postgres。目录必须是一个绝对路径。</p>
</li>
</ul>
<p>注意</p>
<ul>
<li><p>  只有支持符号链接的系统才能创建表空间</p>
</li>
<li><p>  CREATE TABLESPACE不能在一个事务块中执行</p>
</li>
</ul>
<p>示例<br>[sql]<br>postgres=# CREATE TABLESPACE ts_mydbspace LOCATION ‘/mnt/raid’;<br>[/sql]</p>
<p><strong>使用表空间</strong></p>
<p>只有数据库超级用户才可以创建表空间，但是创建之后，普通的数据库用户就可以使用它了，只要用户有相应的CREATE权限。比如：<br>[sql]<br>auser=&gt; CREATE TABLE foo(i int) TABLESPACE ts_mydbspace;<br>[/sql]</p>
<p>或者使用缺省表空间参数</p>
<p>[sql]<br>SET default_tablespace = ts_mydbspace;<br>CREATE TABLE foo(i int);<br>[/sql]</p>
<p>数据库创建时指定的表空间为其默认表空间，如果没有指定，则其默认表空间与生成该数据库的模板数据库的默认表空间是同一个。数据库关联的默认表空间用于存储该数据库的系统目录信息,它是在这个数据库内创建的表，索引，临时文件等的默认表空间，如果创建这些对象时没有用TABLESPACE语句或通过default_tablespace、temp_tablespaces指定表空间。</p>
<p><strong>查看表空间</strong></p>
<p>当PostgeSQL数据集群初始化时，自动创建两个表空间。pg_global用于存储共享的系统目录信息。pg_default是模板数据库template0和template1默认的数据库，从而也是其他数据库默认的表空间，除非CREATE DATABASE时显式指定默认表空间。</p>
<p>查看存在的表空间</p>
<p>[sql]<br>postgres=# SELECT spcname FROM pg_tablespace;</p>
<h2 id="spcname"><a href="#spcname" class="headerlink" title=" spcname "></a> spcname </h2><p> pg_default<br> pg_global<br>(2 rows)<br>[/sql] </p>
<p>或者使用psql命令\db</p>
<p>[sql]<br>postgres=# \db</p>
<p> List of tablespaces<br> Name Owner Location<br>————+———-+———-<br> pg_default postgres<br> pg_global postgres<br>(2 rows)<br>[/sql]</p>
<p><a href="http://www.postgresql.org/docs/9.3/static/manage-ag-tablespaces.html">21.6. Tablespaces</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL防止更新丢失(覆盖)</title>
    <url>/2014/01/10/postgresql-updata-lost/</url>
    <content><![CDATA[<p>所有的数据库都会遇到更新丢失(覆盖)的问题。</p>
<a id="more"></a>
<p>更新丢失(覆盖)的详细描述见<a href="https://openwares.net/database/transaction_isolation_level.html">数据库事务隔离级别</a>。</p>
<p>发生更新丢失(覆盖)问题的关键在于”读取,计算,写回”这个过程中,当前事务使用了过期的(stale)数据,没有将其他并发事务对数据的修改纳入到计算结果中,从而在写回时将其他事务的更新覆盖了。</p>
<p><strong>防止更新丢失(覆盖)的方法</strong></p>
<ul>
<li>  悲观锁</li>
</ul>
<p>事务中对需要修改的结果集加行锁,常用的就是select for update,或者lock table对整个表加锁。加锁之后,当前事务未处理完成之前,其他所有需要访问锁定行的事务都必须等待。这虽然能解决更新丢失(覆盖)的问题,但很明显会影响数据库的并发性能。</p>
<p>如果并发事务冲突的几率很高,则采用悲观锁可以减少事务回滚并重试的开销。</p>
<ul>
<li>  乐观锁</li>
</ul>
<p>乐观锁不锁定任何行,当更新数据时再做检查数据是否已经发生了变化。多版本并发控制MVCC(Multiversion concurrency control)可以实现乐观锁。<br>PostgreSQL使用MVCC实现并发控制。PostgreSQL的默认事务隔离级别为读已提交(Read Commited),在这个级别上会发生不可重复读现象,这个隔离级别是无法防止更新丢失(覆盖)的。</p>
<p>但是在可重复读(Repeatable Read)事务隔离级别,可以完全防止更新丢失(覆盖)的问题,如果当前事务读取了某行,这期间其他并发事务修改了这一行并提交了,然后当前事务试图更新该行时,PostgreSQL会提示:<br>ERROR: could not serialize access due to concurrent update<br>事务会被回滚,只能重新开始。</p>
<p>由于使用的是MVCC机制的乐观锁,内部有版本号(这个字段名字叫xmin)来控制并发,所以不会对数据集上锁,对性能的影响是很小的。但如果并发事务冲突的几率比较大,那么事务回滚的开销就比较大了。</p>
<p>总的来说,如果并发事务冲突的几率很低那么应该选择乐观锁,对于PostgreSQL来说,将事务隔离级别提高到Repeatable Read即可。如果事务并发冲突的几率很高,那么可以谨慎的使用悲观锁。</p>
<p>还有一种防止更新丢失(覆盖)的方法叫条件更新,也就是在更新时指定where子句,检测指定的条件是否已经变化来决定是否进行更新。这不是一种通用的解决方案,只能根据业务逻辑来选择特定的检测条件,并不能防止这些检测条件之外的可能存在的更新丢失问题。而且有些情况下可能很难选择合适的更新检测条件,比如一个银行账户,关键的字段有账户号和余额,很难通过WHERE条件来检测当前事务执行期间是否有其他并发事务已经修改了余额并做了提交。所以这种方法只在特定的逻辑环境下有一定的用途。</p>
<p><strong>PostgreSQL可重复读隔离级小实验</strong></p>
<p>先建一张表,并插入一条记录:<br>[sql]<br>create table sometable (id integer, whatever varchar(20));<br>insert into sometable values(1,’initial’);<br>[/sql]</p>
<p>下面演示两个事务并发的几种情况,左边为事务A,右边为事务B。</p>
<p>第一种情况:</p>
<p>[sql gutter=”false”]<br>begin transaction isolation level repeatable read ;<br>select whatever from sometable where id=1;<br> begin transaction isolation level repeatable read;<br> update sometable set whatever=’second’ where id=1;<br> commit;<br>update sometable set whatever=’first’ where id=1;<br>&lt;ERROR:could not serialize access due to concurrent update&gt;</p>
<p>[/sql]</p>
<p>第二种情况:<br>[sql gutter=”false”]<br>begin transaction isolation level repeatable read ;<br> begin transaction isolation level repeatable read;<br> update sometable set whatever=’second’ where id=1;<br>update sometable set whatever=’first’ where id=1;<br><blocked><br> commit;<br>&lt;ERROR:could not serialize access due to concurrent update&gt;</p>
<p>[/sql]</p>
<p>第三种情况:<br>[sql gutter=”false”]<br>begin transaction isolation level repeatable read ;<br> begin transaction isolation level repeatable read;<br> update sometable set whatever=’second’ where id=1;<br> commit;<br>update sometable set whatever=’first’ where id=1;<br>commit; </p>
<p>[/sql]</p>
<p>为什么第三种情况下,两个并发事务全部成功完成了,B事务的更新丢失了吗?答案是没有。所有的三种情形都没有更新丢失发生。<br>在可重复读隔离级下,事务第一次读取数据时,同样是读取的已经提交的数据,只要是在当前读取动作之前的提交都会看到。也就是说,并不是在开始repeatable read隔离级的那个时点上,事务能访问到的数据已经固定了,而是在事务访问特定的行时,从那个时点起,事务每次访问该行都会返回同样版本的数据,无论其他事务如何修改这一行。</p>
<p>那么第三种情况就容易理解了,A事务之前并没有访问任何行,当A事务要修改id=1的行时,它实际上获取到的是该行最新的版本,也就是B事务已经修改提交的版本。所以这是很正常的,没有更新丢失的问题,因为A事务看到了id=1这一行的最新版本。</p>
<p>通过下面的第四个实验可以清楚看到repeatable read隔离级读取到了其他事务在后来更新提交的数据。</p>
<p>[sql gutter=”false”]<br>update sometable set whatever=’initial’ where id=1; </p>
<p>begin transaction isolation level repeatable read ;<br> begin transaction isolation level repeatable read;<br> update sometable set whatever=’second’ where id=1;<br> commit;<br>select whatever from sometable where id=1;<br>whatever </p>
<hr>
<p>second<br>(1 row) </p>
<p>update sometable set whatever=’first’ where id=1;<br>commit;<br>[/sql]</p>
<p>可以看到事务A在第一个访问id=1的行时读取到了后来的并发事务B更新并提交的数据,然后事务A也正确的更新这一行并成功提交。</p>
<p>在可重复读(Repeatable Read)事务隔离级别下,完全不用担心更新丢失(覆盖)的问题,而且对性能的影响也是很小的。</p>
<p>PostgreSQL真的是太酷了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL角色(用户)</title>
    <url>/2013/11/05/postgresql-user-role/</url>
    <content><![CDATA[<p>PostgreSQL数据库系统中，用户是角色的别名。</p>
<a id="more"></a>
<p>PostgreSQL使用角色的概念来管理数据库访问权限。一个角色可以被认为是一个数据库用户，也可以认为是一组数据库用户，这取决于角色是如何被配置的。</p>
<p>角色可以拥有数据库对象，比如database,table,并且可以通过把在这些对象上拥有的权限赋予其他角色来控制谁可以访问这些对象。更进一步，可以将一个角色的成员关系(把当前角色当作组角色，把其他角色当作当前角色的成员)赋予另一个角色，可以使其成员角色使用组角色的访问权限。</p>
<p>角色包含用户和组的概念。PostgreSQL 8.1之前，用户和组是不同的实体，但现在它们都是角色。<strong>任何角色可以充当一个用户，组，或者兼而有之。</strong></p>
<p><strong>数据库角色</strong></p>
<p>数据库角色和操作系统用户概念上是完全分开的。实践上，在二者之间使用统一的名字可能是便利的，但这不是必须的。<strong>数据库角色是跨数据库集群全局通用的，不是针对每一个单独的数据库。</strong></p>
<p><em>创建角色语法</em></p>
<p>完整语法<br>[sql]<br>CREATE ROLE name [ [ WITH ] option [ … ] ]</p>
<p>where option can be:</p>
<p> SUPERUSER NOSUPERUSER<br> CREATEDB NOCREATEDB<br> CREATEROLE NOCREATEROLE<br> CREATEUSER NOCREATEUSER<br> INHERIT NOINHERIT<br> LOGIN NOLOGIN<br> REPLICATION NOREPLICATION<br> CONNECTION LIMIT connlimit<br> [ ENCRYPTED UNENCRYPTED ] PASSWORD ‘password’<br> VALID UNTIL ‘timestamp’<br> IN ROLE role_name [, …]<br> IN GROUP role_name [, …]<br> ROLE role_name [, …]<br> ADMIN role_name [, …]<br> USER role_name [, …]<br> SYSID uid<br>[/sql]</p>
<p>主要参数</p>
<ul>
<li>  name<br>角色名字</li>
<li>  CREATEDB NOCREATEDB<br>是否允许创建数据库,缺省值是NOCREATEDB</li>
<li>  INHERIT NOINHERIT<br>是否继承组角色，默认是继承。如果设置为NOINHERIT，则必须用SET ROLE指明要使用的组角色。</li>
<li>  LOGIN NOLOGIN<br>是否允许角色登录</li>
<li>  PASSWORD <em>password</em><br>指定登录密码</li>
<li>  IN ROLE _role_name_<br>新创建的角色作为成员加入已经存在的一个或多个角色</li>
<li>  ROLE role_name<br>将已经存在的一个或多个角色作为新创建角色的成员</li>
</ul>
<p><strong>修改或撤销角色</strong></p>
<p>使用ALTER ROLE修改角色属性，使用DROP ROLE撤销角色。</p>
<p><strong>使用shell命令创建或撤销角色</strong><br>PostgreSQL提供了SHELL命令createuser和dropuser来创建或撤销角色，它们是SQL语句的包装，支持SQL语句支持的所有属性，具体用法见 CREATEUSER(1)和 DROPUSER(1)</p>
<p><strong>查看存在的角色</strong></p>
<p>SQL语句<br>[sql]<br>SELECT rolname FROM pg_roles;<br>[/sql]</p>
<p>或者psql命令<br>[sql]<br>postgres=# \du<br>[/sql]</p>
<p><a href="http://www.postgresql.org/docs/9.3/static/user-manag.html">Chapter 20. Database Roles</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>postgresql预写日志(Write-Ahead Logging)</title>
    <url>/2015/11/03/postgresql-write-ahead-logging/</url>
    <content><![CDATA[<a id="more"></a>
<p>postgresql WAL日志是为了保证数据的完整性，基本上是与oracle的redo log十分类似的东西。<br>WAL也是在线复制备份，时间点恢复等高级特性的基石。</p>
<p>References:<br>[1]<a href="http://www.postgresql.org/docs/9.4/static/wal-intro.html">29.2. Write-Ahead Logging (WAL)</a><br>[2]<a href="http://www.moeding.net/archives/37-PostgreSQL-WAL-vs.-Oracle-Redo-Log.html">PostgreSQL WAL vs. Oracle Redo Log</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL分布式事务配置</title>
    <url>/2016/09/15/postgresql-xa-config/</url>
    <content><![CDATA[<a id="more"></a>
<p>XA是open group提出的分布式事务处理规范，JTA支持XA规范，JTA只规定了接口，有些应用容器提供实现，也有一些三方的开源实现可用，比如Atomikos。</p>
<p>如果PostgreSQL参与分布式事务(XA)处理，则需要在配置文件postgres.conf中设置max_prepared_transactions参数，此参数用于指定分布式事务中两步提交准备事务的最大数量。默认值为0，此时不支持分布式事务。</p>
<p>max_prepared_transactions参数值不应该小于max_connections参数值，这样每一个session都可以至少有一个可用的准备事务。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">max_connections = <span class="number">100</span></span><br><span class="line">max_prepared_transactions = <span class="number">100</span></span><br></pre></td></tr></table></figure>

<p>如果有standby服务器，则standby服务器上这两个参数值都不能小于master服务器上的相应值。</p>
<p>References:<br>[1]<a href="https://www.atomikos.com/Documentation/ConfiguringPostgreSQL">Configuring PostgreSQL for XA</a><br>[2]<a href="https://www.postgresql.org/docs/9.4/static/sql-prepare-transaction.html">PREPARE TRANSACTION</a><br>[3]<a href="https://www.postgresql.org/docs/9.4/static/runtime-config-resource.html">18.4. Resource Consumption</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu系统为ppp接口配置IPv6隧道(IPv6-in-IPv4 tunnel)</title>
    <url>/2010/01/03/ppp-ipv6-tunnel/</url>
    <content><![CDATA[<p>linux最早的IPv6/IPng支持代码始于kernel 2.1.8，November 1996，也算是历史悠久了，而IPv6在1998年8月10日成为IETF的草案标准。<br>　　Ubuntu 9.10默认是开启IPv6协议的，也就是说我们的主机是IPv4/IPv6双栈主机。可以通过检查/proc/net/if_inet6这个文件是否存在来确定内核是否支持IPv6，如果这个文件不存在，那么你的系统极有可能是通过可加载模块来支持IPv6的。虽然kernel是支持IPv6了，但现在的网络条件下，除了教育网直接支持IPv6外，其他网络用户还是无法直接访问IPv6网站的，也就是说我们的主机成了IPv6孤岛，只能通过IPv6-in-IPv4隧道协议来访问IPv6资源。</p>
<a id="more"></a>
<p>有多种多样的方式来实现这种隧道，这里只介绍其中的一种站内自动隧道寻址协议ISATAP(Intra-Site Automatic Tunnel Addressing Protocol)，这是一种点对点隧道协议(point-to-point tunneling)。<br>　　使用ISATAP需要知道ISATAP隧道路由器的IPv4地址，IPv6地址及其网络前缀和本地的IPv4地址。可以使用教育网提供的隧道路由器，比如<a href="http://ipv6.sjtu.edu.cn/news/041231.php">上海交大</a>，下面就以这个隧道路由器为例来设置本地ppp接口。<br>　　IPv6提供了2001:和2002:开头的地址用于IPv6-in-IPv4隧道，ISATAP一般使用2001:开头的IPv6地址.<br>建立隧道的脚本build_ipv6_tunnel如下：<br>1 #!/bin/bash<br>2<br>3 ipv4_addr=`ifconfig ppp0  **grep** **’**inet addr**’**  cut -d**’**:**’** -f 2cut -d**’** **’** -f 1`<br>4 ip tunnel add sit1 mode sit remote 202.120.58.150 <strong>local</strong> ${ipv4_addr}<br>5 ifconfig sit1 up<br>6 ifconfig sit1 add 2001:da8:8000:d010:0:5efe:${ipv4_addr}/64<br>7 ip -6 route add ::/0 via 2001:da8:8000:d010::1 metric 1 dev sit1<br>　　ipv4_addr就是本地ppp接口获取的IPv4地址，隧道路由器的IPv4地址为202.120.58.150，IPv6地址为2001:da8:8000:d010::1,其IPv6地址网络前缀为2001:da8:8000:d010::/64,而本地IPv6地址的host部分为0:5efe:${ipv4_addr},这样两部分(64位网络部分和64位主机部分)合并在一起就构成了本地IPv6地址2001:da8:8000:d010:0:5efe:${ipv4_addr}/64。这里是静态设置的本地IPv6地址，ISATAP也支持动态配置客户端IPv6地址。<br>　　mode sit处的sit是简单互联网转换Simple Internet Transition的缩写，当然接口名字可以随意取，不一定非要叫做sit1，但据说不能用sit0,我没测试。<br>　　拆除隧道的脚本delete_ipv6_tunnel如下：<br>1 #!/bin/bash<br>2<br>3 ip -6 route del ::/0 via 2001:da8:8000:d010::1 dev sit1<br>4 ip link <strong>set</strong> sit1 down<br>5 ip tunnel del sit1<br>　　将build_ipv6_tunnel置于目录/etc/ppp/ip-up.d/下，delete_ipv6_tunnel置于目录/etc/ppp/ip-down.d/下，就可以随ppp0接口的建立和拆除而自动的建立和拆除隧道了。<br>　　现在访问<a href="http://www.ipv6.org,如果看到类似“you/">http://www.ipv6.org,如果看到类似“You</a> are using IPv6 from 2001:da8:8000:d010:0:5efe:xxxx:xxxx“的信息，说明IPv6已经正常工作了。<br>　　如果能找到Ipv6反向代理，那就可以用IPv6来访问一些平常不能访问的站点了，比如twitter，详见”<a href="http://internet.solidot.org/article.pl?sid=09/12/09/0347210&tid=48">用IPv6反向代理访问Twitter</a>“</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>prometheus grafana alertmanager 监控报警基本配置</title>
    <url>/2019/11/14/prometheus-grafan-alertmanager-config/</url>
    <content><![CDATA[<a id="more"></a>
<p>此配置主要用于监控主机状态,prometheus还可以监控各种服务的状态,只要使用相应的exporter即可。</p>
<p><strong>prometheus</strong></p>
<p>监控节点安装prometheus,被监控节点只需安装prometheus-node-exporter</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install prometheus</span><br></pre></td></tr></table></figure>
<p>/etc/prometheus/prometheus.yml文件中添加被监控节点</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">- job_name: node</span><br><span class="line"> # If prometheus-node-exporter is installed, grab stats about the local</span><br><span class="line"> # machine by default.</span><br><span class="line"> static_configs:</span><br><span class="line"> # 被监控节点,默认</span><br><span class="line"> - targets: \[<span class="string">&#x27;localhost:9100&#x27;</span>\]</span><br><span class="line"> labels:</span><br><span class="line"> hostname: <span class="string">&#x27;vmin&#x27;</span></span><br><span class="line"> # 被监控节点</span><br><span class="line"> - targets: \[<span class="string">&#x27;10.100.0.31:9100&#x27;</span>\]</span><br><span class="line"> labels:</span><br><span class="line"> hostname: <span class="string">&#x27;vmsvr02&#x27;</span></span><br></pre></td></tr></table></figure>
<p>添加主机名标签，方便管理。<br>通过监控主机的9090端口访问prometheus,<code>http://ip_of_monitor:9090/</code></p>
<p><strong>alertmanager</strong><br>在监控主机安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install prometheus-alertmanager</span><br></pre></td></tr></table></figure>

<p>添加节点监控规则文件/etc/prometheus/node-alert.rules:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># hostStatsAlert</span><br><span class="line">groups:</span><br><span class="line">- name: hostStatsAlert</span><br><span class="line"> rules:</span><br><span class="line"> - alert: InstanceDown</span><br><span class="line"> expr: up == <span class="number">0</span></span><br><span class="line"> <span class="keyword">for</span>: 1m</span><br><span class="line"> labels:</span><br><span class="line"> severity: page</span><br><span class="line"> annotations:</span><br><span class="line"> summary: <span class="string">&quot;Instance &#123;&#123;$labels.instance&#125;&#125; down&quot;</span></span><br><span class="line"> description: <span class="string">&quot;&#123;&#123;$labels.instance&#125;&#125; of job &#123;&#123;$labels.job&#125;&#125; has been down for more than 5 minutes.&quot;</span></span><br><span class="line"> - alert: hostCpuUsageAlert</span><br><span class="line"> expr: sum(avg without (cpu)(irate(node_cpu_seconds_total&#123;mode!=<span class="string">&#x27;idle&#x27;</span>&#125;\[5m\]))) by (instance) &gt; <span class="number">0.85</span></span><br><span class="line"> <span class="keyword">for</span>: 1m</span><br><span class="line"> labels:</span><br><span class="line"> severity: page</span><br><span class="line"> annotations:</span><br><span class="line"> summary: <span class="string">&quot;Instance &#123;&#123; $labels.instance &#125;&#125; CPU usgae high&quot;</span></span><br><span class="line"> description: <span class="string">&quot;&#123;&#123; $labels.instance &#125;&#125; CPU usage above 85% (current value: &#123;&#123; $value &#125;&#125;)&quot;</span></span><br><span class="line"> - alert: hostMemUsageAlert</span><br><span class="line"> expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes)/node_memory_MemTotal_bytes &gt; <span class="number">0.85</span></span><br><span class="line"> <span class="keyword">for</span>: 1m</span><br><span class="line"> labels:</span><br><span class="line"> severity: page</span><br><span class="line"> annotations:</span><br><span class="line"> summary: <span class="string">&quot;Instance &#123;&#123; $labels.instance &#125;&#125; MEM usgae high&quot;</span></span><br><span class="line"> description: <span class="string">&quot;&#123;&#123; $labels.instance &#125;&#125; MEM usage above 85% (current value: &#123;&#123; $value &#125;&#125;)&quot;</span></span><br><span class="line"> - alert: filesystemUsageAlert</span><br><span class="line"> expr: <span class="number">100</span> - ((node_filesystem_avail_bytes&#123;mountpoint=<span class="string">&quot;/&quot;</span>,fstype=~<span class="string">&quot;ext4xfs&quot;</span>&#125; * <span class="number">100</span>) / node_filesystem_size_bytes &#123;mountpoint=<span class="string">&quot;/&quot;</span>,fstype=~<span class="string">&quot;ext4xfs&quot;</span>&#125;) &gt; <span class="number">85</span></span><br><span class="line"> <span class="keyword">for</span>: 1m</span><br><span class="line"> labels:</span><br><span class="line"> severity: page</span><br><span class="line"> annotations:</span><br><span class="line"> summary: <span class="string">&quot;Instance &#123;&#123; $labels.instance &#125;&#125; root DISK usgae high&quot;</span></span><br><span class="line"> description: <span class="string">&quot;&#123;&#123; $labels.instance &#125;&#125; root DISK usage above 85% (current value: &#123;&#123; $value &#125;&#125;)&quot;</span></span><br></pre></td></tr></table></figure>
<p>此规则文件主要监测主机在线状态，cpu、memory和filesystem使用率</p>
<p>/etc/prometheus/prometheus.yml引用此规则文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rule_files:</span><br><span class="line"> - <span class="string">&quot;node-alert.rules&quot;</span></span><br></pre></td></tr></table></figure>

<p>alertmanager配置邮件报警/etc/prometheus/alertmanager.yml:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="built_in">global</span>:</span><br><span class="line"> # The smarthost and SMTP sender used for mail notifications.</span><br><span class="line"> smtp_smarthost: <span class="string">&#x27;smtp.163.com:25&#x27;</span></span><br><span class="line"> smtp_from: <span class="string">&#x27;abc@163.com&#x27;</span></span><br><span class="line"> smtp_auth_username: <span class="string">&#x27;abc@163.com&#x27;</span></span><br><span class="line"> smtp_auth_password: <span class="string">&#x27;password&#x27;</span></span><br><span class="line">...</span><br><span class="line"> # A default receiver</span><br><span class="line"> receiver: team-X-mails</span><br><span class="line">...</span><br><span class="line">receivers:</span><br><span class="line">- name: <span class="string">&#x27;team-X-mails&#x27;</span></span><br><span class="line"> email_configs:</span><br><span class="line"> - to: <span class="string">&#x27;123@163.com&#x27;</span></span><br></pre></td></tr></table></figure>
<p>重新装载prometheus和alertmanager服务,停止一个被监控节点的监控服务，就可以收到报警邮件了。</p>
<p><strong>grafana</strong></p>
<p>可以使用grafana来展示prometheus监控信息<br>安装grafana</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install -y software-properties-common</span><br><span class="line">$ sudo add-apt-repository <span class="string">&quot;deb https://packages.grafana.com/oss/deb stable main&quot;</span></span><br><span class="line">$ wget -q -O - https:<span class="comment">//packages.grafana.com/gpg.key sudo apt-key add -</span></span><br><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install grafana</span><br></pre></td></tr></table></figure>

<p>通过http 3000端口来访问grafana，然后添加prometheus数据源，添加展示prometheus数据的dashboard</p>
<p>References:<br>[1]<a href="https://aeric.io/post/prometheus-alertmanager-config/">Prometheus Alertmanager 基本配置</a><br>[2]<a href="https://www.kancloud.cn/huyipow/prometheus/527563">alertmanager报警规则详解</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>打印指定DIV内容</title>
    <url>/2014/03/13/print-div/</url>
    <content><![CDATA[<a id="more"></a>
<p>window.print()函数会打印整个浏览器窗口的内容。如果只想打印页面的部分内容,可以在print css样式中隐藏不想打印的内容,但这样样式写起来会比较繁琐。可以将需要打印的内容放在一个div容器中,然后使用javascript生成一个新窗口,将div内容写入新窗口,最后打印整个新窗口就可以了,简单明了。</p>
<p>简单的样例代码:<br>[javascript]<br> $(‘#print_button’).click(function(){<br> var print_window = window.open(“print”,”_blank”);<br> var doc = print_window.document;<br> doc.write(‘<!DOCTYPE html><html><head><meta charset="utf-8" />‘);<br> doc.write(‘<title>打印申请书</title>‘);<br> doc.write(‘<link rel="stylesheet" href="css/normalize.css" />‘);<br> doc.write(‘<link rel="stylesheet" href="css/foo.css" />‘);<br> doc.write(‘<link rel="stylesheet" href="css/print.css" media="print"/>‘);<br> doc.write(‘</head><body>‘);<br> doc.write($(‘#foodiv’).html());<br> doc.write(“</body></html>“);<br> doc.close();<br> print_window.print();<br> print_window.close();<br> });<br>[/javascript]</p>
<p>点击打印按钮就可以打印指定div的内容了,div的内容使用print css指定打印样式。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>psql配置文件psqlrc</title>
    <url>/2016/06/15/psql-psqlrc/</url>
    <content><![CDATA[<a id="more"></a>
<p>psql启动时会先读取系统范围的psqlrc文件，然后读取用户主目录下的.psqlrc文件</p>
<p>下面是一个简单的配置：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-- 静默模式</span><br><span class="line">\\set QUIET ON</span><br><span class="line"></span><br><span class="line">-- 设置扩展显示</span><br><span class="line">\\x auto </span><br><span class="line"></span><br><span class="line">--以大写字母自动完成关键字</span><br><span class="line">\\set COMP_KEYWORD_CASE upper</span><br><span class="line"></span><br><span class="line">-- <span class="literal">null</span>显示为(<span class="literal">null</span>)</span><br><span class="line">\\pset <span class="literal">null</span> <span class="string">&#x27;(null)&#x27;</span></span><br><span class="line"></span><br><span class="line">-- 显示query执行时间</span><br><span class="line">\\timing</span><br><span class="line"></span><br><span class="line">-- 不同的数据库使用不同的命令历史文件</span><br><span class="line">\\set HISTFILE ~/.psql_history- :DBNAME</span><br><span class="line"></span><br><span class="line">-- 历史记录忽略重复的命令</span><br><span class="line">\\set HISTCONTROL ignoredups</span><br><span class="line"></span><br><span class="line">-- 更详细的错误报告</span><br><span class="line">\\set VERBOSITY verbose</span><br><span class="line"></span><br><span class="line">-- 关闭自动提交事务.</span><br><span class="line">\\set AUTOCOMMIT OFF</span><br><span class="line"></span><br><span class="line">-- 提示符<span class="number">1</span></span><br><span class="line">\\set PROMPT1 <span class="string">&#x27;%\[%033\[1m%\]%n@%/(%M)%R%\[%033\[0m%\]%#&#x27;</span></span><br><span class="line"></span><br><span class="line">--关闭静默模式</span><br><span class="line">\\unset QUIET</span><br></pre></td></tr></table></figure>

<p><strong>自动提交事务</strong></p>
<p>AUTOCOMMIT是默认打开的，当命令执行成功时会自动进行提交。在自动提交事务打开时，如果要显式手动提交，那么必须在执行命令或命令块之前执行BEGIN或START TRANSACTION命令执行完命令后再执行END或COMMIT来手动提交事务。<br>当关闭自动提交时，命令执行成功后需要手动END或COMMIT来提交。<br>关闭自动提交时，系统默默的在任何没有开启事务的语句前自动添加BEGIN或START TRANSACTION等事务开始语句。</p>
<p>自动提交关闭时，要用ABORT或ROLLBACK显式的撤销回滚事务，如果没有提交退出当前会话，则未提交事务会自动回滚。</p>
<p>**注意:**这里有一个坑,当关闭事务自动提交时,使用psql导入数据库时,可能会因为sql文件中没有提交语句而最后回滚,但没有错误提示,只是没有什么数据也没导入而已.比如,pg_dump/pg_dumpall导出的sql脚本文件就没有COMMIT语句,从而导入不会成功.</p>
<p><strong>提示符变量</strong></p>
<p><code>%[</code> 和 <code>%]</code> 之间的字符解释为终端控制字符序列。</p>
<p><code>%digits</code> 转换为八进制字符序列，比如 <code>%033</code> 转换为 <code>\033</code> ,所以 <code>%033[</code> 正好转换为终端转义控制序列起始字符 <code>\033[</code> ,后面紧跟的正是终端转义控制序列，可以指定字体的颜色，粗细等等属性。</p>
<p>设置图形模式的终端转义序列的结束字符为m,所以,\033[与m之间的字符为真正的终端转义控制序列，这语法真的很@&amp;^*(#!%</p>
<p>其实 <code>\033[</code> 即 <code>Esc[</code></p>
<p>完整详细的终端转义控制序列参见[4]</p>
<p>postgresql支持的提示符变量参见[1]</p>
<p>References:<br>[1]<a href="https://www.postgresql.org/docs/9.4/static/app-psql.html">psql</a><br>[2]<a href="https://robots.thoughtbot.com/an-explained-psqlrc">An Explained psqlrc</a><br>[3]<a href="https://github.com/thoughtbot/dotfiles/blob/master/psqlrc">psqlrc</a><br>[4]<a href="http://ascii-table.com/ansi-escape-sequences.php">ANSI Escape sequences</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>psql变量</title>
    <url>/2016/06/15/psql-variable/</url>
    <content><![CDATA[<a id="more"></a>
<p>psql 提供变量替换特性，类似于shell的变量。</p>
<p>psql的变量就是简单的名字/值对，名字只能有字母、数字和下划线组成。</p>
<p>使用\set命令来设置变量:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; \\set foo bar</span><br></pre></td></tr></table></figure>

<p>这样设置了变量foo,其值为bar。这样来显示变量的值:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; \\echo :foo</span><br><span class="line">bar</span><br></pre></td></tr></table></figure>

<p>使用\set只指定变量名，不指定值时，会设置该变量，只不过其值为空。</p>
<p>使用\unset命令来销毁变量：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; \\unset foo</span><br></pre></td></tr></table></figure>

<p>使用\set命令，不提供任何参数，显示全部的变量。<br>下面展示的是系统预置的变量:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; \\set</span><br><span class="line">AUTOCOMMIT = <span class="string">&#x27;on&#x27;</span></span><br><span class="line">PROMPT1 = <span class="string">&#x27;%/%R%# &#x27;</span></span><br><span class="line">PROMPT2 = <span class="string">&#x27;%/%R%# &#x27;</span></span><br><span class="line">PROMPT3 = <span class="string">&#x27;&gt;&gt; &#x27;</span></span><br><span class="line">VERBOSITY = <span class="string">&#x27;default&#x27;</span></span><br><span class="line">VERSION = <span class="string">&#x27;PostgreSQL 9.4.8 on x86_64-unknown-linux-gnu, compiled by gcc (Debian 4.9.2-10) 4.9.2, 64-bit&#x27;</span></span><br><span class="line">DBNAME = <span class="string">&#x27;reis&#x27;</span></span><br><span class="line">USER = <span class="string">&#x27;reis&#x27;</span></span><br><span class="line">HOST = <span class="string">&#x27;localhost&#x27;</span></span><br><span class="line">PORT = <span class="string">&#x27;5432&#x27;</span></span><br><span class="line">ENCODING = <span class="string">&#x27;UTF8&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>查看PostgreSQL版本</strong></p>
<p>因此获取postgresql版本就有了另外一种方法：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; \\echo :VERSION</span><br><span class="line">PostgreSQL <span class="number">9.4</span><span class="number">.8</span> on x86_64-unknown-linux-gnu, compiled by gcc (Debian <span class="number">4.9</span><span class="number">.2</span>-<span class="number">10</span>) <span class="number">4.9</span><span class="number">.2</span>, <span class="number">64</span>-bit</span><br></pre></td></tr></table></figure>

<p>另一种方法是:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; SELECT VERSION();</span><br><span class="line"> version </span><br><span class="line">-----------------------------------------------------------------------------------------------</span><br><span class="line"> PostgreSQL <span class="number">9.4</span><span class="number">.8</span> on x86_64-unknown-linux-gnu, compiled by gcc (Debian <span class="number">4.9</span><span class="number">.2</span>-<span class="number">10</span>) <span class="number">4.9</span><span class="number">.2</span>, <span class="number">64</span>-bit</span><br><span class="line">(<span class="number">1</span> row)</span><br></pre></td></tr></table></figure>

<p>二者结果是一样的。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>push到gerrit服务器时的unpack failed错误</title>
    <url>/2014/01/24/push-to-gerrit-unpack-failed/</url>
    <content><![CDATA[<a id="more"></a>
<p>向gerrit服务器提交代码时,发现如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git push origin HEAD:refs/<span class="keyword">for</span>/devel</span><br><span class="line"></span><br><span class="line">Counting objects: <span class="number">12</span>, done.</span><br><span class="line">Delta compression using up to <span class="number">4</span> threads.</span><br><span class="line">Compressing objects: <span class="number">100</span>% (<span class="number">2</span>/<span class="number">2</span>), done.</span><br><span class="line">Writing objects: <span class="number">100</span>% (<span class="number">2</span>/<span class="number">2</span>), <span class="number">297</span> bytes <span class="number">0</span> bytes/s, done.</span><br><span class="line">Total <span class="number">2</span> (delta <span class="number">1</span>), reused <span class="number">0</span> (delta <span class="number">0</span>)</span><br><span class="line">fatal: Unpack error, check server log </span><br><span class="line">remote: Resolving deltas: <span class="number">100</span>% (<span class="number">1</span>/<span class="number">1</span>)</span><br><span class="line">error: unpack failed: error Missing unknown 40febad12460dee95f917b2e7a95869e039b1038</span><br><span class="line">To ssh:<span class="comment">//cr/reis</span></span><br><span class="line"> ! \[remote rejected\] HEAD -&gt; refs/<span class="keyword">for</span>/devel (n/a (unpacker error))</span><br><span class="line">error: failed to push some refs to <span class="string">&#x27;ssh://cr/project&#x27;</span></span><br></pre></td></tr></table></figure>

<p>同时gerrit服务器端日志有如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ERROR com.google.gerrit.sshd.BaseCommand : Internal server error (user admin account <span class="number">1000000</span>)</span><br><span class="line"> during git-receive-pack <span class="string">&#x27;/xxx&#x27;</span></span><br><span class="line">com.google.gerrit.sshd.BaseCommand$Failure: fatal: Unpack error, check server log</span><br><span class="line"> at com.google.gerrit.sshd.commands.Receive.runImpl(Receive.java:<span class="number">162</span>)</span><br><span class="line"> ...</span><br><span class="line">Caused by: java.io.IOException: Unpack error on project <span class="string">&quot;reis&quot;</span>:</span><br><span class="line"> AdvertiseRefsHook: org.eclipse.jgit.transport.AdvertiseRefsHookChain@23c6488aclass </span><br><span class="line">org.eclipse.jgit.transport.AdvertiseRefsHookChain</span><br><span class="line"> ...</span><br><span class="line">Caused by: org.eclipse.jgit.errors.UnpackException: Exception <span class="keyword">while</span> parsing pack stream</span><br><span class="line"> ...</span><br><span class="line">Caused by: org.eclipse.jgit.errors.MissingObjectException: </span><br><span class="line">Missing unknown 40febad12460dee95f917b2e7a95869e039b1038</span><br><span class="line"> at org.eclipse.jgit.internal.storage.file.WindowCursor.open(WindowCursor.java:<span class="number">148</span>)</span><br></pre></td></tr></table></figure>

<p>是因为丢失了对象40febad12460dee95f917b2e7a95869e039b1038才提示这些错误。</p>
<p>为什么会丢失对象呢,因为测试的时候直接删除掉了repository,而这个repo还有打开的changes。虽然仓库被移除了,但是gerrit数据库里的记录还在。<br>已经merged和adandoned对象不会有问题。所以需要将这些orphan关闭掉。</p>
<p>连上gerrit数据库，然后将对应的changes关闭就可以了:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">=&gt; update changes set open=<span class="string">&#x27;N&#x27;</span>,status=<span class="string">&#x27;A&#x27;</span> where ...</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>PuTTY画线不正确的解决</title>
    <url>/2010/01/06/putty-drawline-issue/</url>
    <content><![CDATA[<p>　　PuTTY连上服务器运行iptraf，发现显示出现问题，本来应该是直线的地方，却出现了lmkjxq等字符，很难看。打开PuTTY配置，找到Connection-&gt;Data-&gt;Terminal details，把终端类型(Terninal-type string)由xterm改为linux，问题解决。<br>　　经过试验发现，如果不使用UTF-8编码，则终端类型xterm和linux画线都很正常，如果使用UTF-8，则只有使用终端类型linux是正常的，看来出现画线不正确应该是xterm这个终端类型对UTF-8编码的支持存在一些问题。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>PXE网络安装Debian</title>
    <url>/2010/01/17/pxe-install-debian/</url>
    <content><![CDATA[<p>近期收拾一台老本本IBM thinkpad 390X,虽有光驱，但已无法使用。网卡支持PXE(Preboot eXecution Environment)，于是以PXE方式启动安装Debian。<br>　　PXE网络安装或启动需要BOOTP(Bootstrap Protocol)和TFTP(Trivial File Transfer Protocol)服务支持。通过BOOTP服务获取本机IP和启动映像(boot image)所在的网络位置，通过TFTP服务来获取启动映像。DHCP(Dynamic Host Configuration Protocol)是一个更具弹性的，兼容BOOTP的动态主机配置协议，因此在局域网内安装TFTP和DHCP服务器即可。</p>
<a id="more"></a>
<p>1. 安装配置DHCP服务器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install dhcp3-server</span><br></pre></td></tr></table></figure>
<p>　　在/etc/dhcp3/dhcpd.conf文件内添加以下内容</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">allow booting;</span><br><span class="line">allow bootp;</span><br><span class="line"></span><br><span class="line">subnet <span class="number">192.168</span><span class="number">.1</span><span class="number">.0</span> netmask <span class="number">255.255</span><span class="number">.255</span><span class="number">.0</span> &#123; </span><br><span class="line"> #根据实际的局域网设置配置</span><br><span class="line"> range <span class="number">192.168</span><span class="number">.1</span><span class="number">.10</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.20</span>;</span><br><span class="line"> option routers <span class="number">192.168</span><span class="number">.1</span><span class="number">.2</span>;</span><br><span class="line"># option domain-name &quot;localdomain&quot;;</span><br><span class="line"> option domain-name-servers <span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">host tftpclient &#123;</span><br><span class="line"> #以实际的需要PXE方式引导的机器网卡MAC地址为准 </span><br><span class="line"> hardware ethernet <span class="number">00</span>:E0:<span class="number">00</span>:1A:5D:<span class="number">43</span>; </span><br><span class="line"> filename <span class="string">&quot;pxelinux.0&quot;</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="string">``</span><span class="string">`　　</span></span><br><span class="line"><span class="string">　　2. 安装配置TFTP服务器</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line">$ sudo apt-get install tftpd-hpa</span><br></pre></td></tr></table></figure>
<p>　　修改/etc/default/tftpd-hpa文件内的行RUN_DAEMON=”no”为RUN_DAEMON=”yes”,然后重新装载配置或启动inet服务<br>　　<br>　　3. 准备PXE启动映像<br>　　打开/etc/inetd.conf文件，找到tftp开头的行，最后的参数列是一个路径名，这个路径就是TFTP提供文件服务的根路径，Debian及衍生系统上一般为/var/lib/tftpboot。下载Debian PXE网络安装映像<a href="http://ftp.nl.debian.org/debian/dists/lenny/main/installer-i386/current/images/netboot/">netboot.tar.gz</a>并解压到/var/lib/tftpboot。</p>
<p>　　最后以PXE启动电脑就可以从网络开始安装了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>pyinstaller打包python应用程序</title>
    <url>/2015/06/02/pyinstaller-package-app/</url>
    <content><![CDATA[<a id="more"></a>
<p>py2exe已经好久不更新了,pyinstaller则是打包python程序更强大的工具。支持多平台打包，包括Linux,Mac,Solaris,AIX和Windows,而且使用十分简单。</p>
<p>虽然pyinstaller说是实验性的支持python 3,其实已经支持的很好了。</p>
<p><strong>安装</strong></p>
<p>linux平台</p>
<p>pyinstaller开发版已经支持python 3，使用pip3安装支持python 3的开发版pyinstaller</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo pip3 install https:<span class="comment">//github.com/pyinstaller/pyinstaller/archive/python3.zip</span></span><br></pre></td></tr></table></figure>

<p>windows平台</p>
<p>windows 平台需要根据目标python 版本先安装相应的<a href="http://sourceforge.net/projects/pywin32/">pywin32</a></p>
<p>然后下载<a href="https://github.com/pyinstaller/pyinstaller/archive/python3.zip,%E8%A7%A3%E5%8E%8B%E7%BC%A9%E5%90%8E%EF%BC%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BF%9B%E5%85%A5%E8%AF%A5%E7%9B%AE%E5%BD%95%E6%89%A7%E8%A1%8C">https://github.com/pyinstaller/pyinstaller/archive/python3.zip,解压缩后，命令行进入该目录执行</a>:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&amp;amp;gt; python setup.py install</span><br></pre></td></tr></table></figure>

<p><strong>打包python程序</strong><br>pyinstaller尚不支持跨平台打包应用程序。</p>
<p>打包应用程序十分简单:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ pyinstaller -F -w your_application_entry.py</span><br></pre></td></tr></table></figure>

<p>在当前目录生成一个新目录dist,生成的可执行文件就在该目录之下。</p>
<p>-F,–onefile 参数指定生成一个可执行文件。<br>-w, –windowed, –noconsole 参数指示不生成控制台窗口,主要针对Mac和Windows平台。</p>
<p>如果能在当前PATH中找到UPX，会使用UPX来压缩exe文件。</p>
<p>其他参数详见官方文档(参考[1])</p>
<p>References:<br>[1]<a href="http://pythonhosted.org/PyInstaller/">PyInstaller Manual</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>linux系统pypyodbc 1.3.3读取GB编码mdb文件中文字符乱码问题</title>
    <url>/2014/08/14/pypyodbc-gb-mdb-mess/</url>
    <content><![CDATA[<a id="more"></a>
<p>当前1.3.3版本的pypyodbc在linux系统上面已经可以读取有中文字符的mdb文件,不再出现异常,但是读取的中文字符却全是乱码。</p>
<p>下面是根据一些现象的合理推论:<br><strong>mdb文件来自于windows系统,其中的中文字符使用GB编码无疑,但linux系统上mdbtools提供的odbc驱动底层已经执行了编码转换,将GB码转换为unicode码，pypyodbc再一次进行转换所以出现了问题。</strong></p>
<p>pypyodbc.connect函数有一个参数unicode_results,在python3版本上默认为True,也就是返回unicode编码的结果集。<br>odbc底层驱动转换一次编码,pypyodbc再转换一次，悲剧不可避免的出现了。</p>
<p>因此设定connect函数的unicode_results为False,也就是原样返回结果集,然后结果集中的字段名和字段值都需要解码为unicode字符串：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ python3</span><br><span class="line">&gt;&gt;&gt; conn=pypyodbc.connect(<span class="string">&#x27;Driver=MDBTools;DBQ=/path/to/Record.mdb&#x27;</span>, unicode_results=False)</span><br><span class="line">&gt;&gt;&gt; conn.cursor().execute(<span class="string">&#x27;SELECT * FROM Build&#x27;</span>).fetchone()\[<span class="number">0</span>\].decode(<span class="string">&#x27;UTF-8&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>decode(‘UTF-8’)解码成功,说明mdbtools的odbc驱动返回的结果集已经是unicode编码格式。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>pypyodbc,unixODBC和mdbtools</title>
    <url>/2016/11/21/pypyodbc-unixodbc-mdbtools/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>pypyodbc</strong></p>
<p>pypyodbc是一个使用纯python实现的跨平台odbc模块，其利用了ctypes来访问底层的odbc驱动，支持python2和python3。<br>虽然跨平台，但其对linux/mac平台上的unixODBC支持存在问题，无法正确显示中文字段名和字段值。</p>
<p><strong>unixODBC</strong></p>
<p>unixODBC有几个函数的ansi版本和宽字符版本返回信息比较古怪。</p>
<p>首先说SQLDescribeCol，其ansi版本，也就是不带后缀W的版本，无论本地locale为何皆直接返回utf-8编码的字符，但是SQLDescribeColW版本在mac平台上返回utf-16编码的字符，linux平台对于中文字符返回的是用zero填充了每一个utf-8编码字节的神一样的编码</p>
<p>如下面所示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;\\xe5\\x00\\x9b\\x00\\xbe\\x00\\xe5\\x00\\xb9\\x00\\x85\\x00\\xe5\\x00\\x8f\\x00\\xb7\\x00\\x00\\x00&#x27;</span></span><br></pre></td></tr></table></figure>
<p>正确的应该是长这样的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;\\xe5\\x9b\\xbe\\xe5\\xb9\\x85\\xe5\\x8f\\xb7\\x00</span></span><br></pre></td></tr></table></figure>
<p>以utf-8解码后对应的中文字符是”图幅号”</p>
<p>而英文字符返回的是这样的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;B\\x00u\\x00i\\x00l\\x00d\\x00G\\x00e\\x00o\\x00C\\x00o\\x00d\\x00e\\x00\\x00&#x27;</span></span><br></pre></td></tr></table></figure>
<p>仔细看，这串字符实际上就是”BuildGeoCode”,当然也是utf-8编码无疑。返回的编码以’\x00\x00’作为结束符，它是utf-16吗？它是utf-8吗？<br>这都算天坑了吧，没这样玩的。</p>
<p>SqlGetData则只有一个版本，无论locale为何都是返回utf-8编码的字符。</p>
<p>针对这几点问题制作了一个补丁，放在了github上，准备给原作者发一个pull request。修改后的版本，connect函数无论unicode_results为True或False都可以正确的返回中文字符。</p>
<p>还有一个函数SQLGetInfo(W)，当使用SQL_DRIVER_NAME(值为6)调用时，无论调用哪个版本，都返回SQL_ERROR(值为-1)。</p>
<p><strong>mdbtools</strong><br>mdbtools是unixODBC上的mdb driver,当前只支持读操作，查询数据时尙不支持group by字句，select得到结果后自行排序吧。</p>
<p><strong>UPDATE:</strong><br>补丁已经迅速进入<a href="https://github.com/jiangwen365/pypyodbc">官方主线</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>python 添加模块搜索路径</title>
    <url>/2014/12/28/python-add-modules-path/</url>
    <content><![CDATA[<a id="more"></a>
<p>大约有这么几种方法：<br>1、<br>添加环境变量PYTHONPATH,python会添加此路径下的模块，在.bashrc文件中添加如下类似行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> PYTHONPATH=$PYTHONPATH:<span class="regexp">/usr/</span>local/lib/python2<span class="number">.7</span>/site-packages</span><br></pre></td></tr></table></figure>

<p>2、<br>在site-packages路径下添加一个路径配置文件,文件的扩展名为.pth,内容为要添加的路径即可</p>
<p>3、<br>sys.path.append()函数添加搜索路径,参数值即为要添加的路径。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python的KeyError异常</title>
    <url>/2013/11/22/python-keyerror-exception/</url>
    <content><![CDATA[<a id="more"></a>
<p>当请求字典对象里面没有的key时,python会抛出异常KeyError。</p>
<p>如果不想抛出异常而是当没有对应的键时提供一个默认值，可以使用字典对象的get()方法:<br>[python]<br>val = adict.get(‘nonexist_key’, ‘default_value’)<br>print(val) #default_value<br>print(adict[‘nonexist_key’]) #KeyError: ‘nonexist_key’<br>[/python]<br>get()方法值提供默认值，不会为字典对象添加key</p>
<p>如果在访问字典没有对应key时想添加这个key，并设置默认值，可以使用字典对象的setdefault(key, val)方法,这个方法会返回已经存在key的value，只有当key不存在时才添加key，并返回默认值。</p>
<p>[python]<br>val = adict.setdefault(‘nonexsit_key’, ‘default_value’)<br>print(adict[‘nonexsit_key’]) # ‘default_value’<br>[/python]</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>python获取操作系统平台、版本及架构</title>
    <url>/2013/11/14/python-os-version-platform/</url>
    <content><![CDATA[<a id="more"></a>
<p>platform模块提供了底层系统平台的相关信息</p>
<p><strong>系统架构</strong></p>
<p>32位还是64位<br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>import platform<br>platform.architecture()<br>(‘64bit’, ‘ELF’) # python 3.3.2+ 64 bits on debian jessie 64 bits<br>(‘32bit’, ‘WindowsPE’) # python 3.3.2 32 bits on windows 8.1 64 bits<br>(‘64bit’, ‘WindowsPE’) # python 3.3.2 64 bits on wndows 8.1 64 bits<br>(‘64bit’, ‘’) # python 3.4.1 64 bits on mac os x 10.9.4<br>[/python]<br>ELF和WindowsPE是可执行文件格式</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>操作系统</strong><br>linux,mac还是windows<br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.system()<br>‘Linux’ # python 3.3.2+ 64 bits on debian jessie 64 bits<br>‘Windows’ # python 3.3.2 32 bits on windows 8.1 64 bits<br>‘Windows’ # python 3.3.2 64 bits on windows 8.1 64 bits<br>‘Darwin’ # python 3.4.1 64 bits on mac os x 10.9.4<br>[/python]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>系统版本</strong><br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.version()<br>‘#1 SMP Debian 3.10.11-1 (2013-09-10)’ # python 3.3.2+ 64 bits on debian jessie 64 bits<br>‘6.2.9200’ # python 3.3.2 32 bits on windows 8.1 64 bits<br>‘6.2.9200’ # python 3.3.2 64 bits on windows 8.1 64 bits<br>‘Darwin Kernel Version 13.3.0: Tue Jun 3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64’ # python 3.4.1 64 bits on mac os x 10.9.4<br>[/python]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>CPU平台</strong><br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.machine()<br>‘x86_64’ # python 3.3.2+ 64 bits on debian jessie 64 bits<br>‘AMD64’ # python 3.3.2 32 bits on windows 8.1 64 bits<br>‘AMD64’ # python 3.3.2 64 bits on windows 8.1 64 bits<br>‘x86_64’ # python 3.4.1 64 bits on mac os x 10.9.4<br>[/python]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>linux发行版</strong><br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.dist()<br>(‘debian’, ‘jessie/sid’, ‘’) # python 3.3.2+ 64 bits on debian jessie 64 bits<br>[/python]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>节点名</strong><br>也就是机器名<br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.node()<br>‘work’ # python 3.3.2+ 64 bits on debian jessie 64 bits<br>‘work-xxx’ # python 3.3.2 32 bits on windows 8.1 64 bits<br>[/python]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>系统信息</strong><br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.uname()<br>uname_result(system=’Linux’, node=’work’, release=’3.10-3-amd64’, version=’#1 SMP Debian 3.10.11-1 (2013-09-10)’, machine=’x86_64’, processor=’’) # python 3.3.2+ 64 bits on debian jessie 64 bits</p>
</blockquote>
</blockquote>
</blockquote>
<p>uname_result(system=’Windows’, node=’work-xxx’, release=’8’, version=’6.2.9200’, machine=’AMD64’, processor=’Intel64 Family 6 Model 58 Stepping 9,<br>GenuineIntel’) # python 3.3.2 32 bits on windows 8.1 64 bits</p>
<p>uname_result(system=’Darwin’, node=’mba’, release=’13.3.0’, version=’Darwin Kernel Version 13.3.0: Tue Jun 3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64’, machine=’x86_64’, processor=’i386’) # python 3.4.1 64 bits on mac os x 10.9.4<br>[/python]</p>
<p><strong>python版本</strong><br>[python]</p>
<blockquote>
<blockquote>
<blockquote>
<p>platform.python_verison()<br>‘3.3.2+’ # python 3.3.2+ 64 bits on debian jessie 64 bits<br>‘3.3.3’ # python 3.3.2 32 bits on windows 8.1 64 bits<br>[/python]</p>
</blockquote>
</blockquote>
</blockquote>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>python队列</title>
    <url>/2016/04/10/python-queue/</url>
    <content><![CDATA[<a id="more"></a>
<p>python有两个队列实现，分别是queue.Queue和mulitiprocess.Queue。</p>
<p>queue.Queue是线程安全的，用于线程间数据同步，而mulitiprocess.Queue是用于多进程间数据通讯的。如果在多进程间使用queue.Queue是无法共享数据的，每个进程会有一个单独的队列副本。</p>
<p>因为queue.Queue用于多线程数据同步，而mulitiprocess.Queue用于多进程数据同步。</p>
<p>python3中线程队列的名字为queue,而python2中其名字为Queue。</p>
<p>python中的list和dict不是线程安全的。</p>
<p><strong>task_done与join</strong></p>
<p>queue.Queue有一个join方法可以阻塞当前线程，直到队列中所有的item都处理完成了，所以需要每处理一个队列的item,调用一次队列的task_done方法，当队里的所有元素都标记为处理过了，join方法会从等待中返回。</p>
<p>如果不调用join方法，也就无需调用task_done方法了。</p>
<p>mulitiprocess.Queue并没有join特性，如需要此特性，应该使用multiprocessing.JoinableQueue队列</p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python3 内建异常继承体系结构</title>
    <url>/2014/08/17/python3-builtin-exceptions/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">BaseException</span><br><span class="line"> +-- SystemExit</span><br><span class="line"> +-- KeyboardInterrupt</span><br><span class="line"> +-- GeneratorExit</span><br><span class="line"> +-- Exception</span><br><span class="line"> +-- StopIteration</span><br><span class="line"> +-- ArithmeticError</span><br><span class="line"> +-- FloatingPointError</span><br><span class="line"> +-- OverflowError</span><br><span class="line"> +-- ZeroDivisionError</span><br><span class="line"> +-- AssertionError</span><br><span class="line"> +-- AttributeError</span><br><span class="line"> +-- BufferError</span><br><span class="line"> +-- EOFError</span><br><span class="line"> +-- ImportError</span><br><span class="line"> +-- LookupError</span><br><span class="line"> +-- IndexError</span><br><span class="line"> +-- KeyError</span><br><span class="line"> +-- MemoryError</span><br><span class="line"> +-- NameError</span><br><span class="line"> +-- UnboundLocalError</span><br><span class="line"> +-- OSError</span><br><span class="line"> +-- BlockingIOError</span><br><span class="line"> +-- ChildProcessError</span><br><span class="line"> +-- ConnectionError</span><br><span class="line"> +-- BrokenPipeError</span><br><span class="line"> +-- ConnectionAbortedError</span><br><span class="line"> +-- ConnectionRefusedError</span><br><span class="line"> +-- ConnectionResetError</span><br><span class="line"> +-- FileExistsError</span><br><span class="line"> +-- FileNotFoundError</span><br><span class="line"> +-- InterruptedError</span><br><span class="line"> +-- IsADirectoryError</span><br><span class="line"> +-- NotADirectoryError</span><br><span class="line"> +-- PermissionError</span><br><span class="line"> +-- ProcessLookupError</span><br><span class="line"> +-- TimeoutError</span><br><span class="line"> +-- <span class="built_in">ReferenceError</span></span><br><span class="line"> +-- RuntimeError</span><br><span class="line"> +-- NotImplementedError</span><br><span class="line"> +-- <span class="built_in">SyntaxError</span></span><br><span class="line"> +-- IndentationError</span><br><span class="line"> +-- TabError</span><br><span class="line"> +-- SystemError</span><br><span class="line"> +-- <span class="built_in">TypeError</span></span><br><span class="line"> +-- ValueError</span><br><span class="line"> +-- UnicodeError</span><br><span class="line"> +-- UnicodeDecodeError</span><br><span class="line"> +-- UnicodeEncodeError</span><br><span class="line"> +-- UnicodeTranslateError</span><br><span class="line"> +-- Warning</span><br><span class="line"> +-- DeprecationWarning</span><br><span class="line"> +-- PendingDeprecationWarning</span><br><span class="line"> +-- RuntimeWarning</span><br><span class="line"> +-- SyntaxWarning</span><br><span class="line"> +-- UserWarning</span><br><span class="line"> +-- FutureWarning</span><br><span class="line"> +-- ImportWarning</span><br><span class="line"> +-- UnicodeWarning</span><br><span class="line"> +-- BytesWarning</span><br><span class="line"> +-- ResourceWarning</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>python3 http.server中wasm的mime类型配置</title>
    <url>/2018/11/26/python3-http-server-wasm-mime/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用WebAssembly.instantiateStreaming(fetch(‘add.wasm’), imports)以流方式获取wasmw文件时,chrome会抱怨:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Uncaught (<span class="keyword">in</span> promise) <span class="built_in">TypeError</span>: Failed to execute <span class="string">&#x27;compile&#x27;</span> on <span class="string">&#x27;WebAssembly&#x27;</span>: </span><br><span class="line">Incorrect response MIME type. Expected <span class="string">&#x27;application/wasm&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>查看server.py发现使用了mimetypes模块来管理mime types，调用mimetypes.init()方法时，会使用mimetypes.knownfiles文件中记载的mime types</p>
<p>查看knowfiles路径：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ python3</span><br><span class="line">&gt;&gt;&gt; <span class="keyword">import</span> mimetypes</span><br><span class="line">&gt;&gt;&gt; mimetypes.knownfiles</span><br><span class="line">\[<span class="string">&#x27;/etc/mime.types&#x27;</span>, <span class="string">&#x27;/etc/httpd/mime.types&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;/etc/httpd/conf/mime.types&#x27;</span>, <span class="string">&#x27;/etc/apache/mime.types&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;/etc/apache2/mime.types&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;/usr/local/etc/httpd/conf/mime.types&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;/usr/local/lib/netscape/mime.types&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;/usr/local/etc/httpd/conf/mime.types&#x27;</span>, </span><br><span class="line"><span class="string">&#x27;/usr/local/etc/mime.types&#x27;</span>\]</span><br></pre></td></tr></table></figure>

<p>MacOS上这些文件基本都不存在，添加文件/usr/local/etc/mime.types，其内容添加如下行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">application/wasm wasm</span><br></pre></td></tr></table></figure>

<p>重新启动http.server就好了，注意清除浏览器缓存再试。</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>python3输出utf-8编码的csv文件</title>
    <url>/2016/01/29/python3-utf8-csv/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果有中文字符，并且输出的csv文件没有BOM标志，M$ Excel打开会出现乱码。所以输出utf-8编码的csv时，为了兼容性要输出BOM.<br>很简单，只要在open函数中指定文件编码即可，无需额外的操作：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(<span class="string">&#x27;foobar.csv&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8-sig&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>

<p>因为指定的编码为utf-8-sig,sig就是signature,所以不但文件的编码为utf-8格式，同时还会自动输出utf-8的BOM标志0xEFBBBF。这样生成的csv可用用M$ Excel正确打开导入。</p>
<p>或者更简单点儿，指定encoding为’gb18030’。</p>
<p>References:<br>[1]<a href="http://www.cnblogs.com/findumars/p/3620078.html">UTF8最好不要带BOM，附许多经典评论</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>扩大qcow2格式kvm虚拟镜像磁盘大小</title>
    <url>/2013/03/14/qcow2-img-resize-expand/</url>
    <content><![CDATA[<p>缩写见以前的一篇文字”<a href="https://openwares.net/linux/shrink_kvm_qcow2_disk.html">缩小qcow2格式kvm虚拟镜像磁盘大小</a>“</p>
<a id="more"></a>
<p>相对于缩写qcow2镜像文件大小，扩大则简单的多</p>
<p>首先，qemu-img resize 命令增加镜像文件的大小，如<br>#qemu-img resize origin.qcow2 +20G</p>
<p>此时，对于虚拟客户机来说，只是硬盘增大了，但其文件系统并未扩展以使用新的硬盘空间，所以还需要使用分区工具来扩展客户机的文件系统</p>
<p>然后，挂载gparted iso镜像为虚拟机的光驱，并从光驱启动，使用gparted扩展客户机的文件系统至硬盘的空闲部分即可。<br>扩展完毕，用客户机的镜像文件启动，不同的客户操作系统有不同的反应，linux客户机直接就可以使用了，windows客户机可能会有一些提示，并要求重新启动云云。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>qemu monitor</title>
    <url>/2019/06/15/qemu-monitor/</url>
    <content><![CDATA[<a id="more"></a>
<p>qemu monitor可以监控guest的运行状态，还可以操纵guest的运行</p>
<p><strong>telnet访问</strong></p>
<p>qemu命令行上添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-monitor telnet:<span class="number">192.168</span><span class="number">.0</span><span class="number">.86</span>:<span class="number">1234</span>,server,nowait</span><br></pre></td></tr></table></figure>
<p>这样在qemu在host接口192.168.0.86端口1234上打开telnet监听，可以使用telnet连接monitor</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ telnet <span class="number">192.168</span><span class="number">.0</span><span class="number">.86</span> <span class="number">1234</span></span><br><span class="line">Trying <span class="number">192.168</span><span class="number">.0</span><span class="number">.86</span>...</span><br><span class="line">Connected to <span class="number">192.168</span><span class="number">.0</span><span class="number">.86</span>.</span><br><span class="line">Escape character is <span class="string">&#x27;^\]&#x27;</span>.</span><br><span class="line">QEMU <span class="number">3.1</span><span class="number">.0</span> monitor - type <span class="string">&#x27;help&#x27;</span> <span class="keyword">for</span> more information</span><br><span class="line">(qemu)</span><br></pre></td></tr></table></figure>

<p>注意，如果在qemu命令上quit会结束guest的运行，如果只是想退出telnet连接，应该按’^]‘，然后输入quit退出telnet，之后还可以再次连接qemu monitor</p>
<p><strong>raw socket访问</strong><br>命令行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-monitor tcp:<span class="number">192.168</span><span class="number">.0</span><span class="number">.86</span>:<span class="number">1234</span>,server,nowait</span><br></pre></td></tr></table></figure>
<p>然后可以这样连接</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nc <span class="number">192.168</span><span class="number">.0</span><span class="number">.86</span> <span class="number">1234</span></span><br><span class="line">QEMU <span class="number">3.1</span><span class="number">.0</span> monitor - type <span class="string">&#x27;help&#x27;</span> <span class="keyword">for</span> more information</span><br><span class="line">(qemu) </span><br></pre></td></tr></table></figure>

<p>again，在qemu命令行上quit，会结束guest的运行，如果只是退出nc的话crtl+c就可以了。</p>
<p>References:<br>[1]<a href="http://smilejay.com/2014/01/access-qemu-monitor-accross-network/">通过网络连接到QEMU MONITOR</a><br>[2]<a href="https://en.wikibooks.org/wiki/QEMU/Monitor">QEMU/Monitor</a><br>[3]<a href="https://www.linux-kvm.org/page/Migration">kvm guest live migration</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>qemu 3 &#39;-usbdevice&#39; is deprecated</title>
    <url>/2019/06/15/qemu-usbdevice-is-deprecated/</url>
    <content><![CDATA[<a id="more"></a>
<p>qemu 3.1 提示 </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&#x27;-usbdevice&#x27;</span> is deprecated, please use <span class="string">&#x27;-device usb-...&#x27;</span> instead</span><br></pre></td></tr></table></figure>

<p>使用主机usb设备可以这样写:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-machine usb=on</span><br><span class="line">-device usb-host,hostbus=<span class="number">2</span>,hostaddr=<span class="number">4</span></span><br></pre></td></tr></table></figure>

<p>一定不要忘了添加 <code>-machine usb=on</code>，不然</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">No <span class="string">&#x27;usb-bus&#x27;</span> bus found <span class="keyword">for</span> device <span class="string">&#x27;usb-host&#x27;</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>de</tag>
      </tags>
  </entry>
  <entry>
    <title>qt 5.7 qmake错误</title>
    <url>/2016/09/19/qt-5-7-qmake-error/</url>
    <content><![CDATA[<a id="more"></a>
<p>升级xcode 8.0后，编译qt程序时：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ qmake -project</span><br><span class="line">Project ERROR: Xcode not set up properly. You may need to confirm the license agreement by running /usr/bin/xcodebuild.</span><br><span class="line">/opt/Qt/<span class="number">5.7</span>/clang_64/mkspecs/features/mac/default_post.prf:<span class="number">35</span>: Variable QMAKE_XCODE_VERSION is not defined.</span><br></pre></td></tr></table></figure>

<p>修改文件Qt_install_folder/5.7/clang_64/mkspecs/features/mac/default_pre.prf<br>将</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">isEmpty($$list($$system(<span class="string">&quot;/usr/bin/xcrun -find xcrun 2&gt;/dev/null&quot;</span>))): \\</span><br></pre></td></tr></table></figure>
<p>更改为</p>
<p><code>js isEmpty($$list($$system(&quot;/usr/bin/xcrun -find xcodebuild 2&gt;/dev/null&quot;))): \\</code></p>
<p>也就是将find后面的xcrun改为xcodebuild</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>QT5.7安装</title>
    <url>/2016/09/13/qt5-7-install/</url>
    <content><![CDATA[<a id="more"></a>
<p>之前一直比较抵触Qt,当然就是因为它的授权问题。随着Qt对开源社区越来越友好，授权方式也做了很大的调整，现在授权已不是障碍。<br>Qt感觉上比GTK/GTK+还是要完善不少，整个的生态也更成熟。<br>最新版的Qt 5.7全面拥抱C++11标准，对于C++拥趸来讲当然是好事一桩。<br>虽然linus并不喜欢C++,但不妨碍C++成为一门伟大的语言。<br>开始学一下Qt,下一步要基于QCAD二次开发一个测绘类应用程序，还有很长的路要走。</p>
<p><strong>下载安装</strong></p>
<p>debian源里的Qt版本略低，从<a href="https://www.qt.io/download/">官方下载</a>最新的Qt5.7安装文件qt-opensource-linux-x64-5.7.0.run<br>添加执行权限，然后将Qt安装到/opt目录</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ chmod +x qt-opensource-linux-x64-<span class="number">5.7</span><span class="number">.0</span>.run</span><br><span class="line"># ./qt-opensource-linux-x64-5.7.0.run</span><br></pre></td></tr></table></figure>

<p>如果没有Qt账号，可以提前注册一个，也可以即时注册，安装目录选择/opt/Qt</p>
<p><strong>配置变量</strong></p>
<p>修改bashrc文件，添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># qt5.7</span><br><span class="line"><span class="keyword">export</span> QT_HOME=<span class="regexp">/opt/</span>Qt/<span class="number">5.7</span>/gcc_64</span><br><span class="line"><span class="keyword">export</span> PATH=$QT_HOME/bin:$PATH</span><br><span class="line"><span class="keyword">export</span> CPATH=$QT_HOME/include:$PATH</span><br><span class="line"><span class="keyword">export</span> LIBRARY_PATH=$QT_HOME/lib:$LIBRARY_PATH</span><br><span class="line"><span class="keyword">export</span> LD_LIBRARY_PATH=$QT_HOME/lib:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>

<p>然后source以下就可以了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ . .bashrc</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title>random: 7 urandom warning(s) missed due to ratelimiting</title>
    <url>/2019/10/15/random-7-urandom-warnings-missed-due-to-ratelimiting/</url>
    <content><![CDATA[<a id="more"></a>
<p>kvm上的debian虚拟客户机，升级操作系统到buster之后，重启内核启动缓慢:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[ <span class="number">3.126166</span>\] ppdev: user-space parallel port driver</span><br><span class="line">\[ <span class="number">138.280959</span>\] random: crng init done</span><br><span class="line">\[ <span class="number">138.280968</span>\] random: <span class="number">7</span> urandom warning(s) missed due to ratelimiting</span><br></pre></td></tr></table></figure>
<p>随机数产生存在问题，以下方法解决</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo apt-get install haveged</span><br><span class="line">sudo systemctl enable haveged</span><br><span class="line">sudo systemctl start haveged</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://unix.stackexchange.com/questions/461425/debian-testing-takes-a-long-time-to-load-crng-init-done">Debian Testing takes a long time to load. Crng init done [closed]</a><br>[2]<a href="https://www.linode.com/community/questions/17915/random-7-urandom-warnings-missed-due-to-ratelimiting">random: 7 urandom warning(s) missed due to ratelimiting</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>redis sentinel主从复制高可用安装配置</title>
    <url>/2019/09/30/redis-install-configuration/</url>
    <content><![CDATA[<a id="more"></a>
<p>redis sentinel与cluster是不同的，虽然都是分布式系统，sentinel只是实现高可用，而cluster则可以进一步实现数据分片和负载均衡。</p>
<p>sentinel配置至少需要三个节点。<br>后面采用如下的配置,三个独立的节点，数字代表节点编号，M代表Master，S代表Sentinel，R代表Replica</p>
<pre><code>   +----+
    M1 
    S1 
   +----+</code></pre>
<p>+—-+        +—-+<br> R2 —-+—- R3<br> S2           S3<br>+—-+         +—-+</p>
<p>Configuration: quorum = 2</p>
<p><strong>安装</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install redis-server redis-sentinel</span><br></pre></td></tr></table></figure>

<p><strong>redis-server配置</strong></p>
<p>配置文件为/etc/redis/redis.conf<br>所有的server节点注释掉bind本地回环地址这一行，并且将protect-mode设置为no</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#bind <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> ::<span class="number">1</span></span><br><span class="line">protect-mode no</span><br></pre></td></tr></table></figure>
<p>请注意网络安全风险，如果节点直连互联网，可以添加安全认证，或者只bind到内部网络地址<br>slave节点2和3需要添加replicaof配置项：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">replicaof ip_of_master <span class="number">6379</span></span><br></pre></td></tr></table></figure>

<p>diskless配置</p>
<p>如果redis只是用于存储session，可以无需持久化到硬盘，进一步提高性能</p>
<p>注释掉配置文件中的所有save行，replica参数设置如下即可：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># save 900 1</span><br><span class="line"># save 300 10</span><br><span class="line"># save 60 10000</span><br><span class="line">repl-diskless-sync yes</span><br><span class="line">repl-diskless-sync-delay <span class="number">0</span></span><br><span class="line">repl-disable-tcp-nodelay no</span><br></pre></td></tr></table></figure>

<p><strong>redis-sentinel配置</strong><br>配置文件为/etc/redis/sentinel.conf<br>注释掉</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#bind <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> ::<span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>请注意网络安全风险，如果节点直连互联网，可以添加安全认证，或者只bind到内部网络地址<br>sentinel monitor配置为</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sentinel monitor mymaster ip_of_master <span class="number">6379</span> <span class="number">2</span></span><br></pre></td></tr></table></figure>

<p>其他参数，比如down-after-milliseconds，failover-timeout，parallel-syncs等都使用系统默认值即可。</p>
<p>注意：sentinel启动时会自动生成sentinel myid用于在集群中标识本实例，生成后只要不删除会一直使用这个id，如果其他节点复制本节点的配置文件，注意要注释或删除掉已经生成的myid，因为sentinel集群中所有的实例要有不同的myid</p>
<p><strong>sentinel集群状态</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ redis-cli -p <span class="number">26379</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">26379</span>&gt; sentinel master mymaster</span><br><span class="line"> <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line"> <span class="number">2</span>) <span class="string">&quot;mymaster&quot;</span></span><br><span class="line"> <span class="number">3</span>) <span class="string">&quot;ip&quot;</span></span><br><span class="line"> <span class="number">4</span>) <span class="string">&quot;192.168.0.19&quot;</span></span><br><span class="line"> <span class="number">5</span>) <span class="string">&quot;port&quot;</span></span><br><span class="line"> <span class="number">6</span>) <span class="string">&quot;6379&quot;</span></span><br><span class="line"> <span class="number">7</span>) <span class="string">&quot;runid&quot;</span></span><br><span class="line"> <span class="number">8</span>) <span class="string">&quot;eb70c88ffcf007fd54032e85fc35e500dfbbb2a0&quot;</span></span><br><span class="line"> <span class="number">9</span>) <span class="string">&quot;flags&quot;</span></span><br><span class="line"><span class="number">10</span>) <span class="string">&quot;master&quot;</span></span><br><span class="line"><span class="number">11</span>) <span class="string">&quot;link-pending-commands&quot;</span></span><br><span class="line"><span class="number">12</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="number">13</span>) <span class="string">&quot;link-refcount&quot;</span></span><br><span class="line"><span class="number">14</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line"><span class="number">15</span>) <span class="string">&quot;last-ping-sent&quot;</span></span><br><span class="line"><span class="number">16</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="number">17</span>) <span class="string">&quot;last-ok-ping-reply&quot;</span></span><br><span class="line"><span class="number">18</span>) <span class="string">&quot;173&quot;</span></span><br><span class="line"><span class="number">19</span>) <span class="string">&quot;last-ping-reply&quot;</span></span><br><span class="line"><span class="number">20</span>) <span class="string">&quot;173&quot;</span></span><br><span class="line"><span class="number">21</span>) <span class="string">&quot;down-after-milliseconds&quot;</span></span><br><span class="line"><span class="number">22</span>) <span class="string">&quot;30000&quot;</span></span><br><span class="line"><span class="number">23</span>) <span class="string">&quot;info-refresh&quot;</span></span><br><span class="line"><span class="number">24</span>) <span class="string">&quot;2289&quot;</span></span><br><span class="line"><span class="number">25</span>) <span class="string">&quot;role-reported&quot;</span></span><br><span class="line"><span class="number">26</span>) <span class="string">&quot;master&quot;</span></span><br><span class="line"><span class="number">27</span>) <span class="string">&quot;role-reported-time&quot;</span></span><br><span class="line"><span class="number">28</span>) <span class="string">&quot;6058526968&quot;</span></span><br><span class="line"><span class="number">29</span>) <span class="string">&quot;config-epoch&quot;</span></span><br><span class="line"><span class="number">30</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line"><span class="number">31</span>) <span class="string">&quot;num-slaves&quot;</span></span><br><span class="line"><span class="number">32</span>) <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="number">33</span>) <span class="string">&quot;num-other-sentinels&quot;</span></span><br><span class="line"><span class="number">34</span>) <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="number">35</span>) <span class="string">&quot;quorum&quot;</span></span><br><span class="line"><span class="number">36</span>) <span class="string">&quot;2&quot;</span></span><br><span class="line"><span class="number">37</span>) <span class="string">&quot;failover-timeout&quot;</span></span><br><span class="line"><span class="number">38</span>) <span class="string">&quot;180000&quot;</span></span><br><span class="line"><span class="number">39</span>) <span class="string">&quot;parallel-syncs&quot;</span></span><br><span class="line"><span class="number">40</span>) <span class="string">&quot;1&quot;</span></span><br></pre></td></tr></table></figure>
<p>可以看到当前的master节点信息，num-slaves表明有几个replica，num-other-sentinels表明除本节点外有几个其他的sentinel节点。</p>
<p>relipa节点的信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">26379</span>&gt; sentinel slaves mymaster</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line"> <span class="number">2</span>) <span class="string">&quot;192.168.0.18:6379&quot;</span></span><br><span class="line"> <span class="number">3</span>) <span class="string">&quot;ip&quot;</span></span><br><span class="line"> <span class="number">4</span>) <span class="string">&quot;192.168.0.18&quot;</span></span><br><span class="line"> <span class="number">5</span>) <span class="string">&quot;port&quot;</span></span><br><span class="line"> <span class="number">6</span>) <span class="string">&quot;6379&quot;</span></span><br><span class="line"> <span class="number">7</span>) <span class="string">&quot;runid&quot;</span></span><br><span class="line"> <span class="number">8</span>) <span class="string">&quot;f8213930280bbf28202922474c045bb225ed0685&quot;</span></span><br><span class="line"> <span class="number">9</span>) <span class="string">&quot;flags&quot;</span></span><br><span class="line"> <span class="number">10</span>) <span class="string">&quot;slave&quot;</span></span><br><span class="line"> <span class="number">11</span>) <span class="string">&quot;link-pending-commands&quot;</span></span><br><span class="line"> <span class="number">12</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">13</span>) <span class="string">&quot;link-refcount&quot;</span></span><br><span class="line"> <span class="number">14</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line"> <span class="number">15</span>) <span class="string">&quot;last-ping-sent&quot;</span></span><br><span class="line"> <span class="number">16</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">17</span>) <span class="string">&quot;last-ok-ping-reply&quot;</span></span><br><span class="line"> <span class="number">18</span>) <span class="string">&quot;432&quot;</span></span><br><span class="line"> <span class="number">19</span>) <span class="string">&quot;last-ping-reply&quot;</span></span><br><span class="line"> <span class="number">20</span>) <span class="string">&quot;432&quot;</span></span><br><span class="line"> <span class="number">21</span>) <span class="string">&quot;down-after-milliseconds&quot;</span></span><br><span class="line"> <span class="number">22</span>) <span class="string">&quot;30000&quot;</span></span><br><span class="line"> <span class="number">23</span>) <span class="string">&quot;info-refresh&quot;</span></span><br><span class="line"> <span class="number">24</span>) <span class="string">&quot;3994&quot;</span></span><br><span class="line"> <span class="number">25</span>) <span class="string">&quot;role-reported&quot;</span></span><br><span class="line"> <span class="number">26</span>) <span class="string">&quot;slave&quot;</span></span><br><span class="line"> <span class="number">27</span>) <span class="string">&quot;role-reported-time&quot;</span></span><br><span class="line"> <span class="number">28</span>) <span class="string">&quot;6058776146&quot;</span></span><br><span class="line"> <span class="number">29</span>) <span class="string">&quot;master-link-down-time&quot;</span></span><br><span class="line"> <span class="number">30</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">31</span>) <span class="string">&quot;master-link-status&quot;</span></span><br><span class="line"> <span class="number">32</span>) <span class="string">&quot;ok&quot;</span></span><br><span class="line"> <span class="number">33</span>) <span class="string">&quot;master-host&quot;</span></span><br><span class="line"> <span class="number">34</span>) <span class="string">&quot;192.168.0.19&quot;</span></span><br><span class="line"> <span class="number">35</span>) <span class="string">&quot;master-port&quot;</span></span><br><span class="line"> <span class="number">36</span>) <span class="string">&quot;6379&quot;</span></span><br><span class="line"> <span class="number">37</span>) <span class="string">&quot;slave-priority&quot;</span></span><br><span class="line"> <span class="number">38</span>) <span class="string">&quot;100&quot;</span></span><br><span class="line"> <span class="number">39</span>) <span class="string">&quot;slave-repl-offset&quot;</span></span><br><span class="line"> <span class="number">40</span>) <span class="string">&quot;1250825725&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line"> <span class="number">2</span>) <span class="string">&quot;192.168.0.17:6379&quot;</span></span><br><span class="line"> <span class="number">3</span>) <span class="string">&quot;ip&quot;</span></span><br><span class="line"> <span class="number">4</span>) <span class="string">&quot;192.168.0.17&quot;</span></span><br><span class="line"> <span class="number">5</span>) <span class="string">&quot;port&quot;</span></span><br><span class="line"> <span class="number">6</span>) <span class="string">&quot;6379&quot;</span></span><br><span class="line"> <span class="number">7</span>) <span class="string">&quot;runid&quot;</span></span><br><span class="line"> <span class="number">8</span>) <span class="string">&quot;dc208df92659b72d94e5da0335cc6bc1b9fe814b&quot;</span></span><br><span class="line"> <span class="number">9</span>) <span class="string">&quot;flags&quot;</span></span><br><span class="line"> <span class="number">10</span>) <span class="string">&quot;slave&quot;</span></span><br><span class="line"> <span class="number">11</span>) <span class="string">&quot;link-pending-commands&quot;</span></span><br><span class="line"> <span class="number">12</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">13</span>) <span class="string">&quot;link-refcount&quot;</span></span><br><span class="line"> <span class="number">14</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line"> <span class="number">15</span>) <span class="string">&quot;last-ping-sent&quot;</span></span><br><span class="line"> <span class="number">16</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">17</span>) <span class="string">&quot;last-ok-ping-reply&quot;</span></span><br><span class="line"> <span class="number">18</span>) <span class="string">&quot;432&quot;</span></span><br><span class="line"> <span class="number">19</span>) <span class="string">&quot;last-ping-reply&quot;</span></span><br><span class="line"> <span class="number">20</span>) <span class="string">&quot;432&quot;</span></span><br><span class="line"> <span class="number">21</span>) <span class="string">&quot;down-after-milliseconds&quot;</span></span><br><span class="line"> <span class="number">22</span>) <span class="string">&quot;30000&quot;</span></span><br><span class="line"> <span class="number">23</span>) <span class="string">&quot;info-refresh&quot;</span></span><br><span class="line"> <span class="number">24</span>) <span class="string">&quot;6361&quot;</span></span><br><span class="line"> <span class="number">25</span>) <span class="string">&quot;role-reported&quot;</span></span><br><span class="line"> <span class="number">26</span>) <span class="string">&quot;slave&quot;</span></span><br><span class="line"> <span class="number">27</span>) <span class="string">&quot;role-reported-time&quot;</span></span><br><span class="line"> <span class="number">28</span>) <span class="string">&quot;6058766018&quot;</span></span><br><span class="line"> <span class="number">29</span>) <span class="string">&quot;master-link-down-time&quot;</span></span><br><span class="line"> <span class="number">30</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">31</span>) <span class="string">&quot;master-link-status&quot;</span></span><br><span class="line"> <span class="number">32</span>) <span class="string">&quot;ok&quot;</span></span><br><span class="line"> <span class="number">33</span>) <span class="string">&quot;master-host&quot;</span></span><br><span class="line"> <span class="number">34</span>) <span class="string">&quot;192.168.0.19&quot;</span></span><br><span class="line"> <span class="number">35</span>) <span class="string">&quot;master-port&quot;</span></span><br><span class="line"> <span class="number">36</span>) <span class="string">&quot;6379&quot;</span></span><br><span class="line"> <span class="number">37</span>) <span class="string">&quot;slave-priority&quot;</span></span><br><span class="line"> <span class="number">38</span>) <span class="string">&quot;100&quot;</span></span><br><span class="line"> <span class="number">39</span>) <span class="string">&quot;slave-repl-offset&quot;</span></span><br><span class="line"> <span class="number">40</span>) <span class="string">&quot;1250825169&quot;</span></span><br></pre></td></tr></table></figure>

<p>sentinel节点的信息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">26379</span>&gt; sentinel sentinels mymaster</span><br><span class="line"><span class="number">1</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line"> <span class="number">2</span>) <span class="string">&quot;779c2860c9f27aa416ad40df9f7213389b410350&quot;</span></span><br><span class="line"> <span class="number">3</span>) <span class="string">&quot;ip&quot;</span></span><br><span class="line"> <span class="number">4</span>) <span class="string">&quot;192.168.0.18&quot;</span></span><br><span class="line"> <span class="number">5</span>) <span class="string">&quot;port&quot;</span></span><br><span class="line"> <span class="number">6</span>) <span class="string">&quot;26379&quot;</span></span><br><span class="line"> <span class="number">7</span>) <span class="string">&quot;runid&quot;</span></span><br><span class="line"> <span class="number">8</span>) <span class="string">&quot;779c2860c9f27aa416ad40df9f7213389b410350&quot;</span></span><br><span class="line"> <span class="number">9</span>) <span class="string">&quot;flags&quot;</span></span><br><span class="line"> <span class="number">10</span>) <span class="string">&quot;sentinel&quot;</span></span><br><span class="line"> <span class="number">11</span>) <span class="string">&quot;link-pending-commands&quot;</span></span><br><span class="line"> <span class="number">12</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">13</span>) <span class="string">&quot;link-refcount&quot;</span></span><br><span class="line"> <span class="number">14</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line"> <span class="number">15</span>) <span class="string">&quot;last-ping-sent&quot;</span></span><br><span class="line"> <span class="number">16</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">17</span>) <span class="string">&quot;last-ok-ping-reply&quot;</span></span><br><span class="line"> <span class="number">18</span>) <span class="string">&quot;483&quot;</span></span><br><span class="line"> <span class="number">19</span>) <span class="string">&quot;last-ping-reply&quot;</span></span><br><span class="line"> <span class="number">20</span>) <span class="string">&quot;483&quot;</span></span><br><span class="line"> <span class="number">21</span>) <span class="string">&quot;down-after-milliseconds&quot;</span></span><br><span class="line"> <span class="number">22</span>) <span class="string">&quot;30000&quot;</span></span><br><span class="line"> <span class="number">23</span>) <span class="string">&quot;last-hello-message&quot;</span></span><br><span class="line"> <span class="number">24</span>) <span class="string">&quot;493&quot;</span></span><br><span class="line"> <span class="number">25</span>) <span class="string">&quot;voted-leader&quot;</span></span><br><span class="line"> <span class="number">26</span>) <span class="string">&quot;?&quot;</span></span><br><span class="line"> <span class="number">27</span>) <span class="string">&quot;voted-leader-epoch&quot;</span></span><br><span class="line"> <span class="number">28</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"><span class="number">2</span>) <span class="number">1</span>) <span class="string">&quot;name&quot;</span></span><br><span class="line"> <span class="number">2</span>) <span class="string">&quot;4c74e99d150700d256712c66f139372c42247073&quot;</span></span><br><span class="line"> <span class="number">3</span>) <span class="string">&quot;ip&quot;</span></span><br><span class="line"> <span class="number">4</span>) <span class="string">&quot;192.168.0.19&quot;</span></span><br><span class="line"> <span class="number">5</span>) <span class="string">&quot;port&quot;</span></span><br><span class="line"> <span class="number">6</span>) <span class="string">&quot;26379&quot;</span></span><br><span class="line"> <span class="number">7</span>) <span class="string">&quot;runid&quot;</span></span><br><span class="line"> <span class="number">8</span>) <span class="string">&quot;4c74e99d150700d256712c66f139372c42247073&quot;</span></span><br><span class="line"> <span class="number">9</span>) <span class="string">&quot;flags&quot;</span></span><br><span class="line"> <span class="number">10</span>) <span class="string">&quot;sentinel&quot;</span></span><br><span class="line"> <span class="number">11</span>) <span class="string">&quot;link-pending-commands&quot;</span></span><br><span class="line"> <span class="number">12</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">13</span>) <span class="string">&quot;link-refcount&quot;</span></span><br><span class="line"> <span class="number">14</span>) <span class="string">&quot;1&quot;</span></span><br><span class="line"> <span class="number">15</span>) <span class="string">&quot;last-ping-sent&quot;</span></span><br><span class="line"> <span class="number">16</span>) <span class="string">&quot;0&quot;</span></span><br><span class="line"> <span class="number">17</span>) <span class="string">&quot;last-ok-ping-reply&quot;</span></span><br><span class="line"> <span class="number">18</span>) <span class="string">&quot;483&quot;</span></span><br><span class="line"> <span class="number">19</span>) <span class="string">&quot;last-ping-reply&quot;</span></span><br><span class="line"> <span class="number">20</span>) <span class="string">&quot;483&quot;</span></span><br><span class="line"> <span class="number">21</span>) <span class="string">&quot;down-after-milliseconds&quot;</span></span><br><span class="line"> <span class="number">22</span>) <span class="string">&quot;30000&quot;</span></span><br><span class="line"> <span class="number">23</span>) <span class="string">&quot;last-hello-message&quot;</span></span><br><span class="line"> <span class="number">24</span>) <span class="string">&quot;454&quot;</span></span><br><span class="line"> <span class="number">25</span>) <span class="string">&quot;voted-leader&quot;</span></span><br><span class="line"> <span class="number">26</span>) <span class="string">&quot;?&quot;</span></span><br><span class="line"> <span class="number">27</span>) <span class="string">&quot;voted-leader-epoch&quot;</span></span><br><span class="line"> <span class="number">28</span>) <span class="string">&quot;0&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>redis-service优化配置</strong></p>
<p>1、TCP BACKLOG<br>/var/log/redis/redis-server.log中有警告:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">WARNING: The TCP backlog setting <span class="keyword">of</span> <span class="number">511</span> cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value <span class="keyword">of</span> <span class="number">128.</span></span><br></pre></td></tr></table></figure>
<p>查看当前配置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat /proc/sys/net/core/somaxconn</span><br><span class="line"><span class="number">128</span></span><br></pre></td></tr></table></figure>
<p>显然主机的tcp backlog设置过低了，不能很好的支持大量的并发连接，应该把对应的参数调高<br>系统参数文件/etc/sysctl.conf末尾添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">net.core.somaxconn = <span class="number">10240</span></span><br></pre></td></tr></table></figure>

<p>使其生效</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo sysctl -p</span><br></pre></td></tr></table></figure>

<p>/etc/redis/redis.conf文件中修改tcp-backlog为4096或更高，但不能超过系统参数设置，重启redis后生效。</p>
<p>2、overcommit_memory<br>/var/log/redis/redis-server.log中有警告:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">WARNING overcommit_memory is set to <span class="number">0</span>! Background save may fail under low memory condition. To fix <span class="built_in">this</span> issue add <span class="string">&#x27;vm.overcommit_memory = 1&#x27;</span> to /etc/sysctl.conf and then reboot or run the command <span class="string">&#x27;sysctl vm.overcommit_memory=1&#x27;</span> <span class="keyword">for</span> <span class="built_in">this</span> to take effect.</span><br></pre></td></tr></table></figure>
<p>一般在低内存条件时，此参数才会派上用场<br>系统参数文件/etc/sysctl.conf末尾添加：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">vm.overcommit_memory = <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>使其生效</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo sysctl -p</span><br></pre></td></tr></table></figure>

<p>3、关闭透明巨页<br>/var/log/redis/redis-server.log中有警告:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">WARNING you have Transparent Huge Pages (THP) support enabled <span class="keyword">in</span> your kernel. This will create latency and memory usage issues <span class="keyword">with</span> Redis. To fix <span class="built_in">this</span> issue run the command <span class="string">&#x27;echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled&#x27;</span> <span class="keyword">as</span> root, and add it to your /etc/rc.local <span class="keyword">in</span> order to retain the setting after a reboot. Redis must be restarted after THP is disabled.</span><br></pre></td></tr></table></figure>
<p>开启透明巨页会有些问题，可以通过grub传递内核参数来关闭透明巨页<br>/etc/default/grub文件中GRUB_CMDLINE_LINUX_DEFAULT中添加transparent_hugepage=never</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX_DEFAULT=<span class="string">&quot;quiet transparent_hugepage=never&quot;</span></span><br></pre></td></tr></table></figure>
<p>然后更新grub配置，重启生效</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo update-grub</span><br><span class="line">$ sudo reboot</span><br></pre></td></tr></table></figure>

<p>4、repl-backlog-size参数<br>这个参数是为replica保持数据的缓冲区大小，当replica离线时，使用此缓冲为其保存数据，当replica重新上线可以不用执行full sync，使用partial sync就可以了，默认设置为1MB，显然太小了，可以根据单位时间内业务数据多少、支持replica离线时间、内存大小等因素设置此参数，比如设置为16MB以上。</p>
<p>5、client-output-buffer-limit参数</p>
<p>References:<br>[1]<a href="https://redis.io/topics/replication">Replication</a><br>[2]<a href="https://redis.io/topics/sentinel">Redis Sentinel Documentation</a><br>[3]<a href="https://blog.csdn.net/angjunqiang/article/details/81190562">Redis Sentinel 与 Redis Cluster</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>减少qcow2虚拟磁盘文件实际占用的存储空间</title>
    <url>/2012/04/26/reduce-qcow2-image-size-kvm/</url>
    <content><![CDATA[<p>虚拟磁盘文件占用的空间会越来越大,就算从客户机里面删除了很多文件,但这些空间并未释放出来,qcow2文件仍然占用大量的主机存储空间。</p>
<a id="more"></a>
<p>虽然qcow2有一个特点,客户机需要时才分配存储空间,这工作的一直很好。但是当从客户机删除了很多文件,释放了很多空间时,从KVM主机端完全看不到qcow2虚拟磁盘文件有变小的迹象。这是因为现在的文件系统都有一个特点,删除文件时并没有真正的清除文件的内容,只是简单的做了标记,这样删除文件会很迅速,只有当用到这些空间时才重新写入新的数据。这也是反删除甚至反格式化软件存在的基础。所以要想缩小qcow2虚拟磁盘文件的大小,就要真正释放这些未使用的空间才可以。</p>
<p>不同的客户机类型有不同解决方式,基本思路就是用0填充未使用的客户机磁盘空间,然后用qemu-img转换磁盘镜像文件,转换后的磁盘镜像文件将只包含所有已使用的磁盘空间。</p>
<p><strong>linux客户机</strong></p>
<ol>
<li><p>使用dd命令将客户机未使用的磁盘空间用0填满<br> $dd if=/dev/zero of=~/junk<br> dd: writing to `/home/***/junk’: No space left on device<br> 然后<br> $rm junk<br> 关闭客户机</p>
</li>
<li><p>转换磁盘镜像文件<br> $qemu-img convert -O qcow2 debian.qcow2 debian_new.qcow2</p>
<p> 转换完成后可以看到debian_new.qcow2占用的KVM主机存储空间与客户机使用的磁盘空间基本是一致的。然后用新的磁盘镜像文件debian_new.qcow2启动客户机即可。</p>
</li>
</ol>
<p><strong>windows客户机</strong></p>
<ol>
<li><p> 删除不需要的文件,清理系统垃圾,然后整理磁盘碎片</p>
</li>
<li><p>下载<a href="http://technet.microsoft.com/en-us/sysinternals/bb897443">SDelete</a>,借助sdelete用0来填充未使用硬盘空间</p>
<p> 查看sdelete帮助<br> C:\&gt;sdelete<br> SDelete - Secure Delete v1.6<br> Copyright (C) 1999-2010 Mark Russinovich<br> Sysinternals - <a href="http://www.sysinternals.com/">www.sysinternals.com</a></p>
<p> usage: sdelete.exe [-p passes] [-s] [-q] …<br>  sdelete.exe [-p passes] [-z-c] [drive letter] …<br>  -a Remove Read-Only attribute<br>  -c Clean free space<br>  -p passes Specifies number of overwrite passes (default is 1)<br>  -q Don’t print errors (Quiet)<br>  -s or -r Recurse subdirectories<br>  -z Zero free space (good for virtual disk optimization)</p>
<p> 用0填充C分区空闲区域<br> C:\&gt;sdelete -z c</p>
<p> 关闭客户机</p>
</li>
<li><p>最后在KVM主机上转换qcow2磁盘镜像文件</p>
<p> $qemu-img convert -O qcow2 windows.qcow2 windows_new.qcow2<br> 转换完成后可以看到windows_new.qcow2占用的KVM主机存储空间与客户机使用的磁盘空间基本是一致的。然后用新的磁盘镜像文件windows_new.qcow2启动客户机即可。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>拒绝用户登录:/bin/false和/usr/sbin/nologin</title>
    <url>/2014/01/15/refuse-login/</url>
    <content><![CDATA[<a id="more"></a>
<p>要拒绝系统用户登录,可以将其shell设置为/usr/sbin/nologin或者/bin/false</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># usermod -s --shell /usr/sbin/nologin username</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># usermod -s -shell /bin/false username</span><br></pre></td></tr></table></figure>
<p><strong>/bin/false</strong></p>
<p>/bin/false什么也不做只是返回一个错误状态,然后立即退出。将用户的shell设置为/bin/false,用户会无法登录,并且不会有任何提示。</p>
<p><strong>/usr/sbin/nologin</strong></p>
<p>nologin会礼貌的向用户显示一条信息,并拒绝用户登录:</p>
<p>This account is currently not available. </p>
<p>有一些软件,比如一些ftp服务器软件,对于本地非虚拟账户,只有用户有有效的shell才能使用ftp服务。这时候就可以使用nologin使用户即不能登录系统,还能使用一些系统服务,比如ftp服务。/bin/false则不行,这是二者的重要区别之一。</p>
<p><strong>/etc/nologin</strong></p>
<p>如果存在/etc/nologin文件,则系统只允许root用户登录,其他用户全部被拒绝登录,并向他们显示/etc/nologin文件的内容。</p>
<p><strong>锁定用户账户</strong></p>
<p>锁定用户账户</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># passwd -l --lock username</span><br></pre></td></tr></table></figure>

<p>#解锁用户账户</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># passwd -u --unlock username</span><br></pre></td></tr></table></figure>
<p><strong>删除用户密码</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># passwd -d --delete username</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>依赖，关联，聚合与组合，继承与实现</title>
    <url>/2013/11/10/relationships/</url>
    <content><![CDATA[<a id="more"></a>
<p>依赖，关联，聚合与组合这四种关系从弱到强，依次为依赖-&GT;关联-&GT;聚合-&GT;组合</p>
<p><strong>依赖关系</strong>表示一个类依赖于另一个类的定义，依赖总是单向的。一般表现为被依赖类是依赖类的某个方法调用的参数，或某个方法的局部变量。<br>比如人可以买汽车，也可以买别墅，买这个行为依赖汽车，也依赖别墅，但关系十分弱。这里buy表达的就是依赖关系。</p>
<p>依赖用带箭头的虚线表示。</p>
<p><strong>关联关系</strong>表示一个类依赖于另一个类来实现自身的功能，这种依赖可以是单向的也可以是双向的。一般表现为被依赖类是依赖类的实例变量，但两个类之间没有整体和部分的关系，两个类是平行的。比如人买了汽车，可以开车。这里drive表达的就是关联关系。</p>
<p>关联用带箭头的实线表示。可以指定关联的数量关系。</p>
<p><strong>聚合关系</strong>是一种强关联关系，是整体和组成部分之间的关系，一般也表现为类的实例变量，但是整体和组成部分的生命周期是独立的，也就是个体可以不依赖与整体而独立存在。比如汽车与轮胎的关系，轮胎可以脱离汽车而存在。</p>
<p>聚合用一端为空心菱形，另一端为箭头的实线表示，可以指定关联的数量关系。</p>
<p><strong>组合关系</strong>是比聚合关系更强的关系，整体负责组成部分的生命周期， 二者的生命周期是一致的，组成部分不能脱离整体而存在。一般也表现为类的实例变量。比如人和其四肢的关系。</p>
<p>组合用一端为实心菱形，另一端为箭头的实线表示，可以指定关联的数量关系。</p>
<p>另外还有两个常见的关系是<strong>继承</strong>和<strong>实现</strong>,<strong>继承</strong>使用空心箭头表示继承的方向，用实线连接。<strong>实现</strong>也使用空心箭头表示继承的方向，只是改用虚线连接。<br><strong>以上关系具体的图例见参考[1]。</strong></p>
<p>References:<br>[1]<a href="http://www.uml.org.cn/oobject/200901041.asp">UML图示</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>uml</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 9.10 删除link-local 路由表项</title>
    <url>/2009/12/21/remove-link-local-route-entry/</url>
    <content><![CDATA[<p>route -n 时你总能看到这样一条路由</p>
<p>Destination Gateway Genmask Flags Metric Ref Use Iface<br>169.254.0.0 0.0.0.0 255.255.0.0 U 1000 0 0 eth0</p>
<p>由RFC3330 可知 169.254.0.0/16 为本地链路地址</p>
<p>“169.254.0.0/16 - This is the “link local” block. It is allocated for<br> communication between hosts on a single link. Hosts obtain these<br> addresses by auto-configuration, such as when a DHCP server may not<br> be found.”</p>
<p>当系统配置为使用动态地址，而找不到DHCP服务器时，系统会为本机设置一个169.254.X.X的地址。<br>这个路由表项是有zeroconf 协议Daemon 程序添加的,我们一般是用不到的</p>
<p>只是注释掉/etc/networks 里面的link-local 项是无法去掉该路由表项的,/etc/networks 与/etc/hosts<br>文件的作用差不多,是用来关联网络号(数字格式)和网络名(字符格式)的,注释掉该条目后,只是169.254.0.0<br>无法解析为网络名link-local了.</p>
<p>可以用以下命令来删除zeroconf 相关的程序包<br>sudo apt-get remove avahi-autoipd –purge<br>下次启动机器后这条路由就不会自动出现了.</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>规则表达式regex的posix标准,gnu扩展以及兼容性问题</title>
    <url>/2014/09/20/regex-posix-gnu-compatibility/</url>
    <content><![CDATA[<a id="more"></a>
<p>regex(Regular Expression)的posix标准是unix平台共同遵守的,而gnu对regex做了大量扩展,使regex更好用,但不是所有的平台都支持gnu扩展。</p>
<p>Mac OS X平台就只支持posix标准而不支持gnu扩展,因此使用gnu扩展的脚本在Mac OS X平台上运行时就会遇到兼容性问题。</p>
<p>比如匹配所有空白字符的<code>\s</code>就是gnu扩展,如果要在Mac OS X上匹配所有空白字符要使用<code>[[:space:]]</code>。</p>
<p>下面是几个常见的GNU扩展对应的posix表达:<br>\w - [[:alnum:]_]<br>\W - [^[:alnum:]_]<br>\s - [[:space:]]<br>\S - [^[:space:]]</p>
<p>更多详细信息见参考文档。</p>
<p>References:<br>[1]<a href="http://www.regular-expressions.info/posix.html">POSIX Basic Regular Expressions</a><br>[2]<a href="http://www.regular-expressions.info/posixbrackets.html">POSIX Bracket Expressions</a><br>[3]<a href="http://www.regular-expressions.info/gnu.html">GNU Regular Expression Extensions</a><br>[4]<a href="http://people.freebsd.org/~lofi/reference.html">Regular Expressions Reference Sheet</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>移除C语言源代码中未被使用的函数/代码</title>
    <url>/2018/11/30/remove-unused-function-code-from-c-sourcecode/</url>
    <content><![CDATA[<a id="more"></a>
<p>怎么找到C源程序中没有被引用的function/死代码?<br>GCC的CFLAGS -Wall -Wextra只能报告未使用的变量，而函数要到代码全部链接完成，才能知道哪些是没有被任何代码引用的，为时已晚。</p>
<p>在编译链接时可以组合使用CFLAGS: -ffunction-sections -fdata-sections 和 LDFLAGS: -Wl,-gc-sections在目标文件里移除未使用的代码，那么如何在源文件里找到这些函数呢？</p>
<p>一个相当简单的办法，编译完成后，对比ELF目标文件和所有obj对象文件中符号表中符号的差异，就这一知道哪些函数在最终的目标文件中被移除了，也就是无用的函数。</p>
<p>首先编译代码：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cc foo.c -o foo -fdata-sections -ffunction-sections -Wl,--gc-sections -save-temps</span><br></pre></td></tr></table></figure>

<p>注意要使用参数-save-temps保留中间文件，要用到是*.o对象文件<br>注意要保留符号表，不要strip all<br>gcc的<code>--gc-sections</code>在clang中对应的是<code>-dead_strip</code></p>
<p>然后使用这个脚本<a href="https://github.com/PetersSharp/C-code---Find-Unused-functions/blob/master/find-unused-function.sh">find-unused-function.sh</a>通过比较符号表找出从未被使用的函数名字</p>
<p>在工程目录下执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ./find-unused-<span class="keyword">function</span>.sh foo .</span><br></pre></td></tr></table></figure>

<p>生成的./DebugSymbol/symbols.unused-binary文件中记载了未被使用的函数名称。</p>
<p>References:<br>[1]<a href="https://github.com/PetersSharp/C-code---Find-Unused-functions">C-code—Find-Unused-functions</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Debian关闭AMD显卡KMS设置</title>
    <url>/2011/06/23/reset-amd-kms/</url>
    <content><![CDATA[<p>linux的内核模式设置KMS(Kernel Mode Setting)是一个很好的特性,从系统启动很早的阶段就给用户一个高分辨率的显示环境</p>
<a id="more"></a>
<p>这对intel的卡子来说很完美,但A卡多少有些杯具,自从xserver-xorg-video-radeon版本1:6.12.192-2开始,linux默认开启了A卡的KMS,在一块radeon hd 6450上安装最新的debian testing,安装完成重新启动后,过了grub就花屏了,无法进入控制台,原因就是AMD开源驱动默认开启了KMS,但对这个卡的支持有问题，所以只有关闭了KMS才能进入控制台。</p>
<p>用rescuecd引导系统进入控制台,然后挂装根分区<br>#mount -t ext4 /dev/sda1 /mnt<br>#cd /mnt/etc/modprobe.d/<br>查看一下是否有radeon-kms.conf这个文件,如果没有就新建该文件,输入一下内容<br>options radeon modeset=0</p>
<p>重新启动就可以进入console了，不过分辨率真的惨不忍睹,而AMD卡的VESA模式又那么怪异,竟然不支持1920x1080x24这种VESA模式，好吧，反正大部分时间都在X下，但是启动的时候就不那么美观了。</p>
<p>通过grub命令行来关闭KMS貌似行不通，没有测试成功。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Restful API 设计</title>
    <url>/2015/10/21/restful-api-design/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="http://www.ruanyifeng.com/blog/2014/05/restful_api.html">RESTful API 设计指南</a><br>[2]<a href="http://blog.jobbole.com/41233/">RESTful API 设计最佳实践</a><br>[3]<a href="http://novoland.github.io/%E8%AE%BE%E8%AE%A1/2015/08/17/Restful%20API%20%E7%9A%84%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.html">Restful API 的设计规范</a><br>[4]<a href="http://blog.xiayf.cn/2014/09/06/experience-about-restful-api/">RESTful API设计的一点经验</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>解决debian amd64 flash播放爆音</title>
    <url>/2011/07/10/resolve-debian-flash-audio/</url>
    <content><![CDATA[<p>debian tesing amd64系统，播放flash时总有严重的爆音,使用alsa和pulseaudio都有同样的问题</p>
<a id="more"></a>
<p>google得知是flash的memcpy实现有bug,导致播放某些flash时出现严重的爆音,adobe是没指望了,可以通过替换so文件来绕过这个bug。</p>
<p>firefox的启动程序是一个脚本,可以which firefox来看下其所在的位置，一般应该在这个位置/usr/bin/firefox，我是自己安装的，其位置在/opt/firefox/firefox。</p>
<p>打开脚本文件firefox，在其第一个非注释行前加入下面这行</p>
<p>export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libc/memcpy-preload.so</p>
<p>保存退出，重新启动firefox就可以了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Restful API 安全</title>
    <url>/2015/10/21/restful-api-security/</url>
    <content><![CDATA[<a id="more"></a>
<p>restful是一种轻量级的web service实现方式。restful并不是标准，也没有对应的软件实体，只是基于http协议的一种指导性的设计方法或原则。</p>
<p>当下流行的open api大部分采用restful的方式实现,但restful并不限于此。普通的web app,移动app,以及系统之间的web service集成都可以采用restful的方式。</p>
<p>restful和http一样是无状态的,也就是单次请求之间并无任何联系，每次请求必须携带全部的状态信息。</p>
<p>对于受保护的资源，restful同样面临认证(authentication)和授权(authorization)的问题。</p>
<p>restful在不同的使用情景下有其相适宜的认证和授权方式。</p>
<p><strong>第三方授权</strong></p>
<p>现在火热的开放平台就是典型的三方授权模式。OAuth(Open Authorization)就是用于三方授权的协议，当前版本为2.0。<br>OAuth协议重在授权，应用程序无需知道资源拥有者的身份凭证，只需用户授权一定的资源访问权限，获取相应的Access Token就可以在授权范围内访问用户的资源。这种授权是有期限的，而且用户可以随时撤销。</p>
<p>OAuth授权整个流程涉及到用户，资源服务器，认证服务器和第三方应用这四个角色。资源服务器和认证服务器只是概念上的区分，物理上可以存在于同一个服务器。</p>
<p>Access Token就是与一个与用户相关的一个随机数，认证服务器记录了此Access Token所拥有的访问权限。第三方应用访问用户资源时携带Access Token,经过权限检查可以访问被授权的资源。</p>
<p><strong>web应用</strong></p>
<p>前后分离的web应用程序,后端可以采用restful方式向前端提供api接口。这种模式，使用传统的session方式即可满足要求。也可以采用token的方式，用户使用身份凭证通过系统身份认证后，服务端颁发一个随机的token,以后每次访问api时，参数中携带此token即可。token可以设置有效期，过期以后重新认证颁发新的token。</p>
<p>其实传统的session使用的sessionid就是token。无论使用cookie,url重写还是隐藏表单域,无非都是将服务器颁发的sessionid再重新发送给服务器进行认证。sessionid就是会话令牌。</p>
<p>session用于认证，授权则由应用程序自行处理，比如基于角色的权限系统等。</p>
<p>传统的session方式最大的风险在于session劫持,https可以大大缓解这一风险，可以杜绝中间人攻击。</p>
<p><strong>web接口</strong></p>
<p>restful方式实现web　service供其他应用使用。这种情形下通过颁发app id(access key/pulic key)和app secret(secret key/private key)，并对请求进行签名的方式来保证api的安全，防止有人篡改请求和非授权访问。如果签名中添加timestamp可以进一步防范重放攻击(replay attack)。</p>
<p>此处的access key用户标示用户的身份，客户端必须妥善保存其secret key,这是服务端认证客户端唯一可靠保证。<br>access key类似传统的用户名，而secret key则是两端共享的私密秘钥，以随机数生成算法生成一个较长的随机字符串即可。</p>
<p>客户请求api时，将请求的动作类型(get,post,put或delete)、uri、请求参数(包括access key)、timestamp使用secret key进行签名，使用HMAC-SHA256等摘要算法。将计算好的摘要同其他请求参与一同发送给服务器。服务端根据access key查找其对应的secret key,然后使用相同的算法重新计算摘要。如果重新计算的摘要与请求传送过来的摘要一致，则可以信任此次请求。添加时间戳的主要目的是用于防范重放攻击。</p>
<p><strong>签名算法</strong></p>
<p>下面是一个签名算法的例子。</p>
<p>算法描述如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">signature = HMAC-SHA256(secrey_key，　string_to_sign);</span><br><span class="line"></span><br><span class="line">string_to_sign = http_verb + <span class="string">&quot;&amp;&quot;</span> + uri + <span class="string">&quot;&amp;&quot;</span> + request_parameters_sorted;</span><br><span class="line"></span><br><span class="line">request_parameters_sorted = <span class="string">&quot;key1=value1&amp;key2=value2&amp;..keyn=valuen&quot;</span>;</span><br></pre></td></tr></table></figure>

<p>比如以post方式访问<a href="https://foo.com/bar/test%E6%8E%A5%E5%8F%A3,%E8%AF%B7%E6%B1%82%E5%8F%82%E6%95%B0%E4%B8%BA">https://foo.com/bar/test接口,请求参数为</a>:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;first_name&quot;</span> : <span class="string">&quot;kitty&quot;</span>,</span><br><span class="line"> <span class="string">&quot;last_name&quot;</span> : <span class="string">&quot;san&quot;</span>,</span><br><span class="line"> <span class="string">&quot;age&quot;</span>　: <span class="number">8</span>,</span><br><span class="line"> <span class="string">&quot;gender&quot;</span> : <span class="string">&quot;female&quot;</span>,</span><br><span class="line"> <span class="string">&quot;app_id&quot;</span> : <span class="string">&quot;xdfe323423fsvdsefew&quot;</span>,</span><br><span class="line"> <span class="string">&quot;timestamp&quot;</span> : <span class="string">&quot;2015-10-21 12:06:06&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>获取当前的UTC时间戳为: 2015-10-21 12:06:06</p>
<p>将请求参数的key以字典序排序得到:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;age&quot;</span>　: <span class="number">8</span>, </span><br><span class="line"> <span class="string">&quot;app_id&quot;</span> : <span class="string">&quot;xdfe323423fsvdsefew&quot;</span>,</span><br><span class="line"> <span class="string">&quot;first_name&quot;</span> : <span class="string">&quot;kitty&quot;</span>,</span><br><span class="line"> <span class="string">&quot;gender&quot;</span> : <span class="string">&quot;female&quot;</span>,</span><br><span class="line"> <span class="string">&quot;last_name&quot;</span> : <span class="string">&quot;san&quot;</span>,</span><br><span class="line"> <span class="string">&quot;timestamp&quot;</span> : <span class="string">&quot;2015-10-21 12:06:06&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将排序后的参数拼接得到request_parameters_sorted：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">request_parameters_sorted = <span class="string">&quot;age=8&amp;app_id=xdfe323423fsvdsefew&amp;first_name=kitty&amp;gender=female&amp;last_name=san&amp;timestamp=2015-10-21 12:06:06&quot;</span>;</span><br></pre></td></tr></table></figure>


<p>然后得到将要签署的字符串string_to_sign</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">string_to_sign = <span class="string">&quot;post&amp;/bar/test&amp;age=8&amp;app_id=xdfe323423fsvdsefew&amp;first_name=kitty&amp;gender=female&amp;last_name=san&amp;timestamp=2015-10-21 12:06:06&quot;</span></span><br></pre></td></tr></table></figure>


<p>最后得到signature</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">signature = HMAC-SHA256(<span class="string">&#x27;your_secret_key&#x27;</span>, <span class="string">&quot;post&amp;/bar/test&amp;age=8&amp;app_id=xdfe323423fsvdsefew&amp;first_name=kitty&amp;gender=female&amp;last_name=san&amp;timestamp=2015-10-21 12:06:06&quot;</span>);</span><br></pre></td></tr></table></figure>

<p>计算完签名后，将签名作为请求参数之一一起发送给服务端，参数的名称为signature。服务器端接收到请求后以相同算法重新计算签名进行核对即可。服务器端计算签名时要去掉signature参数。</p>
<p>所有的字符都使用UTF-8编码。直接对原始请求参数进行签名即可，无需进行url编码。服务器端接收到的也是原始请求参数，这样计算签名更简单。</p>
<p><strong>防范重放攻击</strong></p>
<p>因为请求中携带了请求发出时的时间戳，服务器可以设置一个合理的请求认证时间窗口，比如10分钟，在当前时间前后10分钟之内的请求都可以视为合法请求。这只是减少了被重放攻击的可能性，但并未完全杜绝重放攻击。如果请求在服务器时间窗内被截获重放，则只靠时间戳是无能为力的。</p>
<p>因此，需要附加另外的机制来防止重放攻击。服务端可以记录每次请求的时间戳和签名，每次请求到达是，先验证请求是否在时间窗口范围内，如果超出时间范围则直接拒绝。如果在时间窗口内，则查询请求记录，如果没有对应的请求记录，则满足此次请求，并将此次请求的时间戳和签名记录下来，并清理掉不在当前时间窗口内的所有请求。</p>
<p>时间戳加记录请求的方式可以完全杜绝重放攻击，而且可以保持一个很小的请求记录表。因为在当前时间窗口外的请求可以随时被清理掉。</p>
<p><strong>请求速率限制</strong></p>
<p>如有需要可以对api请求的速率或次数进行限制。</p>
<p><strong>非对称秘钥加密签名</strong></p>
<p>也可以使用RSA非对称秘钥进行数字签名。</p>
<p>服务端生成RSA公私密钥对和客户端的access key,将私钥和access key交付客户端应用。服务端保存access key和客户公钥。</p>
<p>请求签名时，客户端不再使用HMAC签名算法，而是使用普通的摘要算法，比如SHA256，但此时传送的摘要使用客户私钥进行加密后再随请求参数一起传递。因为谁都可以计算SHA256摘要，所以需要用私钥进行加密保护。</p>
<p>服务端接收到请求后，使用同样的算法计算SHA256摘要，然后使用客户的公钥解密随请求一起发的、客户端计算的、加密后的摘要，如果服务端重新计算的摘要与解密后的摘要相同，则认为请求是合法。</p>
<p>无论使用对称秘钥还是非对称秘钥进行签名，秘钥都要妥善保存，这是整个签名认证算法的基石。</p>
<p><strong>无论何种情形，对于restful api的安全而言，https/ssl加密都是十分有必要的。</strong></p>
<p><strong>注意:使用access key与secret key并对api签名调用的方式，并不适合web前端或者移动app使用。因为web前端无法保密secret key,而将secret key保存在android或ios app中也是无法保证安全的，很容易将secret key从app中破解出来。只有将secret key保存在后端才能保证安全。并且secret key是针对客户端发放的，而不应该是针对每一个客户端的user发放的。</strong> </p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>64位运算中的REX指令前缀</title>
    <url>/2009/06/28/rex-prefix-64bits/</url>
    <content><![CDATA[<p>64bits CPU引入了REX指令前缀。<br>REX前缀的主要功能有以下几点：</p>
<ul>
<li><p>  指定通用寄存器和SSE寄存器，当然主要是来指定扩展的寄存器，如R8-R15寄存器等</p>
</li>
<li><p>  指定64位操作数</p>
</li>
<li><p>  指定扩展控制寄存器</p>
</li>
</ul>
<p>一直以来都不知道这个REX缩写词是由哪个或哪几个单词缩写来的，今天突然想明白了，REX应该就是Register EXtension，因为REX的主要功能就是用来索引扩展寄存器的。</p>
<p>关于REX前缀更详细的介绍，请参考<a href="http://www.intel.com/products/processor/manuals/">Intel® 64 and IA-32 Architectures Software Developer’s Manuals</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>为rm命令增加回收站功能</title>
    <url>/2011/03/11/rm-to-trash/</url>
    <content><![CDATA[<p>rm是个强大的命令,特别是rm -rf有时候强大到让你欲哭无泪,当你想清除当前目录下的所有文件和目录时,很简单</p>
<a id="more"></a>
<p>$sudo rm -rf ./*  </p>
<p>这没什么,但是,但是如果不小心打成这样<br>$sudo rm -rf /*  </p>
<p>兄弟,请节哀！<br>还有其他各种各样的杯具,比如打开了很多窗口,有本地机器还有远程的几台服务器,本来想从这台机器执行rm -rf命令,却错误的输入到了其他机器的终端窗口,总之rm太危险了,特别是带有-rf参数时一定要慎之又慎,但老虎也有打盹的时候啊,所以为什么不给rm一剂后悔药呢,嗯,就是它,trash-cli</p>
<p>trash-cli就是带有回收站(Trash)功能的命令行删除工具,其主要特点有</p>
<ul>
<li>  兼容rm命令行接口,可以alias rm为trash-cli</li>
<li>  为删除的每一个文件记录原始路径,删除时间和文件访问权限</li>
<li>  兼容GNOME和KDE桌面的trash,实现桌面和terminal操作的统一</li>
<li>  实现了FreeDesktop.org Trash Specification</li>
<li>  支持除home文件系统以外的其他文件系统,比如不同的分区或移动设备分区</li>
</ul>
<p><strong>安装trash-cli</strong></p>
<p>Ubuntu和Debian仓库里面的版本太低了,而且有严重的bug,去官方网站下载最新版本的trash-cli,然后执行以下命令完成安装</p>
<p>1 $tar xvfz trash-cli-0.11.3-r315.tar.gz <br>2 $cd trash-cli-0.11.3-r315<br>3 $sudo python setup.py install  </p>
<p><strong>配置trash-cli替代rm</strong></p>
<p>$vim ~/.bashrc  </p>
<p>增添一行<br>rm=<strong>‘**trash-put</strong>‘**  </p>
<p>以后用rm删除文件的时候,文件会被移动到<del>/.local/share/Trash/files文件夹下,另一个文件夹</del>/.local/share/Trash/info下保存了被删除文件的相关信息</p>
<p><strong>trash-cli命令介绍</strong></p>
<ul>
<li>  trash-put 删除文件</li>
</ul>
<p>$trash-put foo<br>foo文件会被放入回收站(trashcan)</p>
<ul>
<li><p>  trash-list 列出回收站里面的文件</p>
</li>
<li><p>  restore-trash 恢复指定的文件</p>
</li>
</ul>
<p>1 $restore-trash<br>2 …<br>3 …<br>4 What file to restore <strong>[**0..n</strong>]**:  </p>
<p>restore-trash会列出回收站里面的所有文件,每个文件前面有一个编号，从0开始,根据提示输入要恢复的文件的编号即可</p>
<ul>
<li><p>  trash-empty 清空回收站</p>
</li>
<li><p>  trash-empty days 删除回收站里面超过指定天数的文件</p>
</li>
</ul>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>rman-06214无法删除废弃的归档日志</title>
    <url>/2016/05/16/rman-06214-delte-obsolete-archivelog/</url>
    <content><![CDATA[<a id="more"></a>
<p>rman备份脚本出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN-<span class="number">06207</span>: WARNING: <span class="number">380</span> objects could not be deleted <span class="keyword">for</span> DISK channel(s) due</span><br><span class="line">RMAN-<span class="number">06208</span>: to mismatched status. Use CROSSCHECK command to fix status</span><br><span class="line">RMAN-<span class="number">06210</span>: List <span class="keyword">of</span> Mismatched objects</span><br><span class="line">RMAN-<span class="number">06211</span>: ==========================</span><br><span class="line">RMAN-<span class="number">06212</span>: <span class="built_in">Object</span> Type Filename/Handle</span><br><span class="line">RMAN-<span class="number">06213</span>: --------------- ---------------------------------------------------</span><br><span class="line">RMAN-<span class="number">06214</span>: Archivelog D:\\ARCHIVED_LOG\\ARC24290_0749146507<span class="number">.001</span></span><br></pre></td></tr></table></figure>

<p>然后手动执行crosscheck并重新删除:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; crosscheck archivelog all;</span><br><span class="line">RMAN&gt; <span class="keyword">delete</span> obsolete;</span><br></pre></td></tr></table></figure>

<p>提示由于恢复目录中没有归档日志的信息，无法删除。列出的归档日志是早已经物理删除掉、无用的日志。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; <span class="keyword">delete</span> expired archivelog all;</span><br></pre></td></tr></table></figure>
<p>也无法删除</p>
<p>最后，强制删除废弃的归档日志，<code>force</code>关键字会忽略掉错误将其干掉。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RAMN&gt; <span class="keyword">delete</span> force obsolete;</span><br></pre></td></tr></table></figure>

<p>删除成功。</p>
<p>===<br>[erq]</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>rman configure命令</title>
    <url>/2019/10/01/rman-configure%E5%91%BD%E4%BB%A4/</url>
    <content><![CDATA[<a id="more"></a>
<p>rman备份时出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN-<span class="number">03009</span>: failure <span class="keyword">of</span> Control File and SPFILE Autobackup command on ORA_DISK_1 channel at <span class="number">10</span>/<span class="number">01</span>/<span class="number">2019</span> <span class="number">00</span>:<span class="number">31</span>:<span class="number">53</span></span><br><span class="line">ORA-<span class="number">19504</span>: failed to create file <span class="string">&quot;\\\\192.168.0.82\\SHARE\\TT\\CTL_C-1276927241-20191001-00&quot;</span></span><br><span class="line">ORA-<span class="number">27056</span>: could not <span class="keyword">delete</span> file</span><br><span class="line">OSD-<span class="number">04029</span>: unable to get file attributes</span><br><span class="line">O/S-<span class="built_in">Error</span>: (OS <span class="number">53</span>) 找不到网络路径。</span><br></pre></td></tr></table></figure>
<p>是因为rman配置了控制文件自动备份，但是设置的自动备份路径早已经失效了<br>所以需要关闭控制文件自动备份配置，并恢复默认设置：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; CONFIGURE CONTROLFILE AUTOBACKUP OFF;</span><br><span class="line">RMAN&gt; CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK CLEAR;</span><br></pre></td></tr></table></figure>

<p>CLEAR用于恢复默认设置，比如控制文件自动备份的默认设置是OFF，所以也可以这样关闭控制文件自动备份：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; CONFIGURE CONTROLFILE AUTOBACKUP CLEAR;</span><br></pre></td></tr></table></figure>

<p>查看全部配置选项：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">RMAN&gt; SHOW ALL;</span><br><span class="line">RMAN configuration parameters are:</span><br><span class="line">CONFIGURE RETENTION POLICY TO REDUNDANCY <span class="number">1</span>;</span><br><span class="line">CONFIGURE BACKUP OPTIMIZATION ON;</span><br><span class="line">CONFIGURE DEFAULT DEVICE TYPE TO DISK; # default</span><br><span class="line">CONFIGURE CONTROLFILE AUTOBACKUP OFF; # default</span><br><span class="line">CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO &#x27;%F&#x27;; # default</span><br><span class="line">CONFIGURE DEVICE TYPE DISK PARALLELISM 1 BACKUP TYPE TO BACKUPSET; # default</span><br><span class="line">CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default</span><br><span class="line">CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # default</span><br><span class="line">CONFIGURE CHANNEL DEVICE TYPE DISK MAXPIECESIZE <span class="number">30</span> G;</span><br><span class="line">CONFIGURE MAXSETSIZE TO UNLIMITED; # default</span><br><span class="line">CONFIGURE ENCRYPTION FOR DATABASE OFF; # default</span><br><span class="line">CONFIGURE ENCRYPTION ALGORITHM &#x27;AES128&#x27;; # default</span><br><span class="line">CONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # default</span><br><span class="line">CONFIGURE SNAPSHOT CONTROLFILE NAME TO &#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\DB_1\\DATABASE\\SNCFORCL.ORA&#x27;; # default</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://www.juliandyke.com/Research/RMAN/ConfigureCommand.php">RMAN Configure Command</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>Database</category>
      </categories>
  </entry>
  <entry>
    <title>使用恢复目录catalog备份目标数据库</title>
    <url>/2012/03/21/rman-catalog-database/</url>
    <content><![CDATA[<p>默认情况下,rman使用目标数据库的控制文件存储备份恢复需要的相关信息,显然这很不安全。</p>
<a id="more"></a>
<p>一般目标控制数据库控制文件丢失,恢复起来就相当的麻烦。所以使用rman的恢复目录来存储备份恢复信息更安全一些，这玩意儿就是catalog。</p>
<p>目录数据库平台:oracle 10.2.0.4 64bits on debian amd64,实例名db_catalog<br>目标数据库平台:oracle 10.2.0.4 64bits on windows 2003 r2 sp2 x64,实例名db_target<br> <strong>1、为恢复目录(catalog)创建表空间</strong></p>
<p>$sqlplus sys/passwd@db_catalog as sysdba;<br>SQL&gt;create tablespace rman_ts datafile ‘/u01/app/oracle/product/10.2.0/oradata/db_catalog/rman_ts01.dbf’ size 50m;</p>
<p>Tablespace created.</p>
<p><strong>2、创建rman使用的schema,并授予适当的权限</strong></p>
<p>$sqlplus sys/passwd@db_catalog as sysdba;<br>SQL&gt;create user rman_usr identified by rman_usr default tablespace rman_ts temporary tablespace temp quota unlimited on rman_ts;</p>
<p>User created.</p>
<p>SQL&gt;grant recovery_catalog_owner to rman_usr;</p>
<p>Grant succeeded.</p>
<p>SQL&gt;grant connect,resource to rman_usr;</p>
<p>Grant succeeded.</p>
<p><strong>3、创建恢复目录catalog</strong></p>
<p>$rman catalog rman_usr/rman_usr@db_catalog;<br>RMAN&gt; create catalog tablespace rman_ts;</p>
<p>recovery catalog created</p>
<p><strong>4、在恢复目录中注册目标数据库</strong></p>
<p>$rman catalog rman_usr/rman_usr@db_catalog target sys/passwd@db_target;<br>RMAN&gt; register database;</p>
<p>database registered in recovery catalog<br>starting full resync of recovery catalog<br>full resync complete</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>使用rman从windows x64向linux amd64平台迁移oracle 10g 10.2.0.4</title>
    <url>/2020/04/29/rman-convert-database-from-windows-x64-to-linux-amd6-for-oracle-10g-10-2-0-4/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用rman convert database将oracle 10g 10.2.0.4 for windows x64环境下的数据库转换到oracle 10g 10.2.0.4 for linux x64环境下。</p>
<p>**注意:**无法使用standby备库来进行转换。</p>
<p><strong>1、以只读方式打开数据库</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; shutdown immediate</span><br><span class="line">SQL&gt; startup mount</span><br><span class="line">SQL&gt; alter database open read only;</span><br></pre></td></tr></table></figure>

<p><strong>2、检查可转换性和标示外部对象。</strong></p>
<p>使用DBMS_TDB.CHECK_DB检查数据库状态，是否可以顺利转换到目标平台：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; set serveroutput on</span><br><span class="line">SQL&gt; declare</span><br><span class="line">    db_ready boolean;</span><br><span class="line">  begin</span><br><span class="line">    <span class="comment">/* db_ready is ignored, but with SERVEROUTPUT set to ON any </span></span><br><span class="line"><span class="comment">     * conditions preventing transport will be output to console */</span></span><br><span class="line">    db_ready := dbms_tdb.check_db(<span class="string">&#x27;Linux x86 64-bit&#x27;</span>, dbms_tdb.skip_none);</span><br><span class="line">  end;</span><br><span class="line"> /</span><br></pre></td></tr></table></figure>
<p>DBMS_TDB.CHECK_DB返回TRUE表示可以转换到目标平台，返回FALSE则不可以，同时会输出不可已转换的原因。</p>
<p>使用DBMS_TDB.CHECK_EXTERNAL标识外部对象。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; set serveroutput on</span><br><span class="line">SQL&gt; declare</span><br><span class="line">     external boolean;</span><br><span class="line">  begin</span><br><span class="line">    <span class="comment">/* value of external is ignored, but with SERVEROUTPUT set to ON</span></span><br><span class="line"><span class="comment">     * dbms_tdb.check_external displays report of external objects</span></span><br><span class="line"><span class="comment">     * on console */</span></span><br><span class="line">    external := dbms_tdb.check_external;</span><br><span class="line">  end;</span><br><span class="line"> /</span><br></pre></td></tr></table></figure>
<p>如果有外部对象会在输出中显示出来。</p>
<p><strong>3、转换数据库</strong></p>
<p>可以在源数据库，也可以在目标数据库进行数据文件的转换。这里选择在目标数据库进行数据文件转换，这样可以减少源数据库的停止服务时间。</p>
<p>在源数据库执行rman convert database:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target sys/passwd@dbinst</span><br><span class="line">RMAN&gt; CONVERT DATABASE ON TARGET PLATFORM</span><br><span class="line"> CONVERT SCRIPT <span class="string">&#x27;D:\\rman\\convertscript.rman&#x27;</span></span><br><span class="line"> TRANSPORT SCRIPT <span class="string">&#x27;D:\\rman\\transportscript.sql&#x27;</span></span><br><span class="line"> <span class="keyword">new</span> database <span class="string">&#x27;orcl&#x27;</span></span><br><span class="line"> FORMAT <span class="string">&#x27;D:\\rman\\%U&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>命令执行完成会生成一个transport脚本用于在目标平台上创建数据库，一个pfile文件包含源数据库相同的参数配置，还生成一个convert脚本用于在目标平台上转换数据文件。</p>
<p><strong>注意：</strong>在windows平台上只能使用windows系统路径名，包括FORMAT参数使用的路径，在linux平台上做数据库转换时，根据linux平台上oracle数据库的目录结构布局来相应修改生成的convertscript.rman，pfile和transportscript.sql。</p>
<p><strong>3.1 convertscript.rman</strong><br>生成的转换脚本类似如下： </p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RUN &#123;</span><br><span class="line"></span><br><span class="line"> CONVERT DATAFILE <span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\DB_1\\DATABASE\\DIGITALSCANDATA.DAT&#x27;</span> </span><br><span class="line"> FROM PLATFORM <span class="string">&#x27;Microsoft Windows x86 64-bit&#x27;</span> </span><br><span class="line"> FORMAT <span class="string">&#x27;D:\\RMAN\\DATA_D-ORCL_I-1276927241_TS-DIGITALSCANDATA_FNO-38_HDV216EA&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> CONVERT DATAFILE <span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\DB_1\\DATABASE\\DIGITALSCANDATA01.DAT&#x27;</span> </span><br><span class="line"> FROM PLATFORM <span class="string">&#x27;Microsoft Windows x86 64-bit&#x27;</span> </span><br><span class="line"> FORMAT <span class="string">&#x27;D:\\RMAN\\DATA_D-ORCL_I-1276927241_TS-DIGITALSCANDATA_FNO-39_HEV216EA&#x27;</span>;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>根据目标平台文件系统布局，修改为：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RUN &#123;</span><br><span class="line"></span><br><span class="line"> CONVERT DATAFILE <span class="string">&#x27;/mnt/data/database/DIGITALSCANDATA.DAT&#x27;</span> </span><br><span class="line"> FROM PLATFORM <span class="string">&#x27;Microsoft Windows x86 64-bit&#x27;</span> </span><br><span class="line"> FORMAT <span class="string">&#x27;/u01/oradata/orcl/DATA_D-ORCL_I-1276927241_TS-DIGITALSCANDATA_FNO-38_HDV216EA&#x27;</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> CONVERT DATAFILE <span class="string">&#x27;/mnt/data/database/DIGITALSCANDATA01.DAT&#x27;</span> </span><br><span class="line"> FROM PLATFORM <span class="string">&#x27;Microsoft Windows x86 64-bit&#x27;</span> </span><br><span class="line"> FORMAT <span class="string">&#x27;/u01/oradata/orcl/DATA_D-ORCL_I-1276927241_TS-DIGITALSCANDATA_FNO-39_HEV216EA&#x27;</span>;</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>/mnt/data/database目录下为从源库直接拷贝过来待转换的数据文件，转换完成的数据文件存储到/u01/oradata/orcl/目录下。</p>
<p><strong>3.2 pfile</strong><br>生成的INIT文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># Please change the values of the following parameters:</span><br><span class="line"></span><br><span class="line"> control_files = <span class="string">&quot;D:\\RMAN\\CF_D-ORCL_ID-1276927241_00V216EA&quot;</span></span><br><span class="line"></span><br><span class="line"> db_recovery_file_dest = <span class="string">&quot;D:\\RMAN\\flash_recovery_area&quot;</span></span><br><span class="line"></span><br><span class="line"> db_recovery_file_dest_size= <span class="number">2147483648</span></span><br><span class="line"></span><br><span class="line"> audit_file_dest = <span class="string">&quot;D:\\RMAN\\ADUMP&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>相应修改为：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># Please change the values of the following parameters:</span><br><span class="line"></span><br><span class="line"> control_files = <span class="string">&quot;/u01/oradata/orcl/CF_D-ORCL_ID-1276927241_00V216EA&quot;</span></span><br><span class="line"></span><br><span class="line"> db_recovery_file_dest = <span class="string">&quot;/u01/app/oracle/flash_recovery_area&quot;</span></span><br><span class="line"></span><br><span class="line"> db_recovery_file_dest_size= <span class="number">2147483648</span></span><br><span class="line"></span><br><span class="line"> audit_file_dest = <span class="string">&quot;/u01/app/oracle/admin/orcl/adump&quot;</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><strong>3.3 transportscript.sql</strong><br>生成的建库脚本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-- The following commands will create a <span class="keyword">new</span> control file and use it</span><br><span class="line">-- to open the database.</span><br><span class="line">-- Data used by Recovery Manager will be lost.</span><br><span class="line">-- The contents <span class="keyword">of</span> online logs will be lost and all backups will</span><br><span class="line">-- be invalidated. Use <span class="built_in">this</span> only <span class="keyword">if</span> online logs are damaged.</span><br><span class="line"></span><br><span class="line">-- After mounting the created controlfile, the following SQL</span><br><span class="line">-- statement will place the database <span class="keyword">in</span> the appropriate</span><br><span class="line">-- protection mode:</span><br><span class="line">-- ALTER DATABASE SET STANDBY DATABASE TO MAXIMIZE PERFORMANCE</span><br><span class="line"></span><br><span class="line">STARTUP NOMOUNT PFILE=<span class="string">&#x27;D:\\RMAN\\INIT_00V216EA_1_0.ORA&#x27;</span></span><br><span class="line">CREATE CONTROLFILE REUSE SET DATABASE <span class="string">&quot;ORCL&quot;</span> RESETLOGS FORCE LOGGING ARCHIVELOG</span><br><span class="line"> MAXLOGFILES <span class="number">16</span></span><br><span class="line"> MAXLOGMEMBERS <span class="number">3</span></span><br><span class="line"> MAXDATAFILES <span class="number">100</span></span><br><span class="line"> MAXINSTANCES <span class="number">8</span></span><br><span class="line"> MAXLOGHISTORY <span class="number">14616</span></span><br><span class="line">LOGFILE</span><br><span class="line"> GROUP <span class="number">1</span> <span class="string">&#x27;D:\\RMAN\\ARCH_D-ORCL_ID-1276927241_S-517_T-1_A-1017328065_00V216EA&#x27;</span> SIZE 50M,</span><br><span class="line"> GROUP <span class="number">2</span> <span class="string">&#x27;D:\\RMAN\\ARCH_D-ORCL_ID-1276927241_S-515_T-1_A-1017328065_00V216EA&#x27;</span> SIZE 50M,</span><br><span class="line"> GROUP <span class="number">3</span> <span class="string">&#x27;D:\\RMAN\\ARCH_D-ORCL_ID-1276927241_S-516_T-1_A-1017328065_00V216EA&#x27;</span> SIZE 50M</span><br><span class="line">DATAFILE</span><br><span class="line"> <span class="string">&#x27;D:\\RMAN\\DATA_D-ORCL_I-1276927241_TS-SYSTEM_FNO-1_IKV216EF&#x27;</span>,</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>相应修改为:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">STARTUP NOMOUNT PFILE=<span class="string">&#x27;/u01/app/oracle/admin/orcl/pfile/INIT_00V216EA_1_0.ORA&#x27;</span></span><br><span class="line">CREATE CONTROLFILE REUSE SET DATABASE <span class="string">&quot;ORCL&quot;</span> RESETLOGS FORCE LOGGING ARCHIVELOG</span><br><span class="line"> MAXLOGFILES <span class="number">16</span></span><br><span class="line"> MAXLOGMEMBERS <span class="number">3</span></span><br><span class="line"> MAXDATAFILES <span class="number">100</span></span><br><span class="line"> MAXINSTANCES <span class="number">8</span></span><br><span class="line"> MAXLOGHISTORY <span class="number">14616</span></span><br><span class="line">LOGFILE</span><br><span class="line"> GROUP <span class="number">1</span> <span class="string">&#x27;/u01/oradata/orcl/ARCH_D-ORCL_ID-1276927241_S-517_T-1_A-1017328065_00V216EA&#x27;</span> SIZE 50M,</span><br><span class="line"> GROUP <span class="number">2</span> <span class="string">&#x27;/u01/oradata/orcl/ARCH_D-ORCL_ID-1276927241_S-515_T-1_A-1017328065_00V216EA&#x27;</span> SIZE 50M,</span><br><span class="line"> GROUP <span class="number">3</span> <span class="string">&#x27;/u01/oradata/orcl/ARCH_D-ORCL_ID-1276927241_S-516_T-1_A-1017328065_00V216EA&#x27;</span> SIZE 50M</span><br><span class="line">DATAFILE</span><br><span class="line"> <span class="string">&#x27;/u01/oradata/orcl/DATA_D-ORCL_I-1276927241_TS-SYSTEM_FNO-1_IKV216EF&#x27;</span>,</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><strong>3.4 实施转换</strong></p>
<p>首先，将源数据库的数据文件全部拷贝到目标数据库（因为只拷贝数据文件，可以从standby备库拷贝），然后根据数据文件所在的路径相应的修改convert脚本，然后使用rman执行转换脚本，转换后的数据文件存储在format指定的位置。</p>
<p>目标平台必须要有一个已经存在的数据库，因为rman需要连接到target数据库才能工作：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target / nocatalog</span><br><span class="line">RMAN&gt; @CONVERTSCRIPT.RMAN</span><br></pre></td></tr></table></figure>

<p>然后，根据目标平台环境修改生成的pfile文件参数<br>最后，执行transportscript.sql生成目标数据库。使用utlirp.sql和utlrp.sql脚本重新编译目标平台数据的PL/SQL模块。<br>先关闭已有的数据库，oracle实例每次只能启动一个数据库：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sqlplus / <span class="keyword">as</span> sysdba;</span><br><span class="line">SQL&gt; @TRANSPORTSCRIPT.SQL</span><br></pre></td></tr></table></figure>
<p>脚本最后最自动调用utlirp.sql和utlrp.sql编译模块。</p>
<p>其中遇到了错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">27102</span>: out <span class="keyword">of</span> memory</span><br><span class="line">Linux-x86_64 <span class="built_in">Error</span>: <span class="number">28</span>: No space left on device</span><br></pre></td></tr></table></figure>
<p>是因为内核参数kernel.shmall设置为了2097152，oracle最大只能使用2097152*4096=8GB的系统内存，而INIT文件中设置的SGA大小超过了10GB，重新设置kernel.shmall为4194304可以最大允许16GB，问题解决。</p>
<p>数据库的sys用户是由本地密码文件验证的，数据库转换时并没有涉及到sys用户，因此需要本地重新为sys用户新建一个密码文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID password=passwd_for_sys force=y</span><br></pre></td></tr></table></figure>

<p>至此，数据库转换完成，最后以OPEN RESETLOGS方式打开新数据库。</p>
<p>References:<br>[1]<a href="https://docs.oracle.com/cd/B19306_01/backup.102/b14191/dbxptrn.htm#BRADV05432">15 RMAN Cross-Platform Transportable Databases and Tablespaces</a><br>[2]<a href="https://blog.csdn.net/qq_34556414/article/details/80188533">使用RMAN Convert Database命令实现跨平台的数据库迁移</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>rman删除控制文件拷贝(control file copy)</title>
    <url>/2012/04/20/rman-delete-control-file-copy/</url>
    <content><![CDATA[<p>rman备份日志出现了如下警告：</p>
<a id="more"></a>
<p> Deleting the following obsolete backups and copies:<br>Type                 Key    Completion Time    Filename/Handle  </p>
<hr>
<p>Control File Copy     25208  25-JAN-12          D:\CONTROL01.CTL  </p>
<p>RMAN-06207: WARNING: 1 objects could not be deleted for DISK channel(s) due<br>RMAN-06208:          to mismatched status.  Use CROSSCHECK command to fix status<br>RMAN-06210: List of Mismatched objects<br>RMAN-06211: ==========================<br>RMAN-06212:   Object Type   Filename/Handle<br>RMAN-06213: ————— —————————————————<br>RMAN-06214: Datafile Copy   D:\CONTROL01.CTL </p>
<p>看文件日期和路径,发现是配置dataguard环境时通过以下SQL语句为standby生成的控制文件</p>
<p>SQL&gt;alter database create standby controlfile as ‘d:\control01.ctl’;</p>
<p>此文件早已物理删除,但数据库的控制文件中仍然留有此文件的信息。通过RMAN日志可以看出,此文件为控制文件的copy,而不是backup,所以rman针对backup的命令无法删除此文件。</p>
<p><strong>关于copy</strong></p>
<p>oracle 9i及早期版本的rman有两个命令backup和copy用来备份数据文件。backup命令将数据文件合并到一个备份片,并以特有的格式保存。而copy命令则一对一产生数据文件的拷贝。从10g开始,copy命令已经过时,不再推荐使用,其功能被合并到增强的backup命令中,通过在backup命令中添加BACKUP AS COPY来执行拷贝功能。</p>
<p><strong>RMAN中删除控制文件copy</strong></p>
<ol>
<li><p>首先物理删除copy文件,这里早已经删除了,用以下命令查看控制文件copy</p>
<p> RMAN&gt; list copy of controlfile;</p>
<p> List of Control File Copies<br> Key S Completion Time Ckp SCN Ckp Time Name</p>
<hr>
<p> 25208 A 25-JAN-12 1705616069 25-JAN-12 D:\CONTROL01.CTL</p>
</li>
</ol>
<ol start="3">
<li><p>crosscheck控制文件拷贝<br> RMAN&gt; crosscheck copy of controlfile;</p>
<p> starting full resync of recovery catalog<br> full resync complete<br> released channel: ORA_DISK_1<br> allocated channel: ORA_DISK_1<br> channel ORA_DISK_1: sid=70 devtype=DISK<br> validation failed for control file copy<br> control file copy filename=D:\CONTROL01.CTL recid=1 stamp=773453607<br> Crosschecked 1 objects</p>
</li>
</ol>
<ol start="5">
<li><p>删除控制文件copy<br> RMAN&gt; delete copy of controlfile;</p>
<p> released channel: ORA_DISK_1<br> allocated channel: ORA_DISK_1<br> channel ORA_DISK_1: sid=70 devtype=DISK</p>
<p> List of Control File Copies<br> Key S Completion Time Ckp SCN Ckp Time Name</p>
<hr>
<p> 25208 X 25-JAN-12 1705616069 25-JAN-12 D:\CONTROL01.CTL</p>
<p> Do you really want to delete the above objects (enter YES or NO)? YES<br> deleted control file copy<br> control file copy filename=D:\CONTROL01.CTL recid=1 stamp=773453607<br> Deleted 1 objects</p>
</li>
</ol>
<ol start="7">
<li><p>重新查看控制文件copy<br> RMAN&gt; list copy of controlfile;<br> RMAN&gt;</p>
<p> 可以看到已经没有控制文件copy存在了</p>
</li>
</ol>
<p>copy 命令支持archivelog, controlfile, database, datafile, spfile, tablespace这几个选项。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>RMAN DUPLICATE创建DataGuard物理备库</title>
    <url>/2012/08/07/rman-duplicate-create-standby/</url>
    <content><![CDATA[<p>Oracle推荐使用rman来创建物理备库,可以在不影响主库的情况下,轻松完成物理备库的创建。</p>
<a id="more"></a>
<p>这里只记叙物理备库与主库位于不用的主机,并且数据库的目录结构一致的情况,这应该也是Dataguard环境比较常见的部署方式,这种方式也比较简单。</p>
<p>系统运行环境为windows 2003 server 64bits + oracle 10g 10.2.0.4 64bits。<br> <strong>一、创建物理备库实例(物理备库端)</strong></p>
<p>1、安装oracle 10g</p>
<p>只安装软件,不创建数据库。</p>
<p>2、创建空闲实例</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CMD&gt; oradim -<span class="keyword">new</span> -sid orcl</span><br></pre></td></tr></table></figure>

<p>此处指定的实例名为orcl,同时会创建系统服务OracleServiceorcl和OracleJobSchedulerorcl。<br>之后即可使用sqlplus / as sysdba连接到这个空闲实例。</p>
<p>3、创建standby的初始化参数文件</p>
<p>从主库创建pfile根据物理备库的实际情况进行相应修改即可</p>
<p>主库端执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; create pfile=<span class="string">&#x27;d:\\INITorcl.ora&#x27;</span> <span class="keyword">from</span> spfile;</span><br></pre></td></tr></table></figure>

<p>将生成的INITorcl.ora拷贝到物理备机的$ORACLE_HOME/database目录下,并做相应修改,参见<a href="https://openwares.net/database/oracle_10g_windows_x64_dataguard.html">Oracle 10g DataGuard手记之基础配置</a></p>
<p>然后通过针对standby修改的INITorcl.ora为物理备库生成spfile</p>
<p>备库端执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CMD&gt; sqlplus / <span class="keyword">as</span> sysdba;</span><br><span class="line">SQL&gt; create spfile <span class="keyword">from</span> pfile; <span class="comment">//也可以指定pfile的详细位置pfile=&#x27;/path/to/pfile&#x27;,此处使用的默认位置和默认文件名</span></span><br></pre></td></tr></table></figure>

<p>4、创建物理备库<a href="https://openwares.net/database/oracle_passwd_file.html">密码文件</a></p>
<p>备库必须通过Oracle NEt并以SYSDBA权限访问,因此密码文件是必须的,因为不能使用OS认证。</p>
<p>备库端执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CMD&gt; orapwd file=PWDorcl.ora password=yourpasswd</span><br></pre></td></tr></table></figure>

<p>这会在备库的$ORACLE_HOME/database目录下生成密码文件PWDorcl.ora</p>
<p>也可以直接从主库$ORACLE_HOME/database目录下将PWDorcl.ora拷贝到物理备库相应的目录下，这样更简单。</p>
<p>5、启动备库到nomount</p>
<p>备库端：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CMD&gt; sqlplus / <span class="keyword">as</span> sysdba;</span><br><span class="line">SQL&gt; startup nomount</span><br></pre></td></tr></table></figure>

<p>因为此时尚没有控制文件和数据文件,因此只能启动到nomount状态</p>
<p>如果已经mount了，可以执行以下sql命令切换到nomount状态：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database dismount;</span><br></pre></td></tr></table></figure>

<p>这是可能会有错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">02778</span>: Name given <span class="keyword">for</span> the log directory is invalid</span><br></pre></td></tr></table></figure>
<p>这是因为dump文件存储路径尚未建立,根据你参数文件的设置建立相关的dump路径,这里建立了这几个路径</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\&#123;adump,bdump,cdump,udump&#125;</span><br></pre></td></tr></table></figure>

<p>然后再执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; startup nomount</span><br></pre></td></tr></table></figure>

<p>还有可能会有错误提示:<br>ORA-01261: Parameter db_recovery_file_dest destination string cannot be translated<br>ORA-01263: Name given for file destination directory is invalid<br>OSD-04018: Unable to access the specified directory or device.<br>O/S-Error: (OS 2) 系统找不到指定的文件。<br>这是因为参数db_recovery_file_dest指向的路径没有建立起来,这里根据参数文件创建目录<br>E:\oracle\product\10.2.0\flash_recovery_area</p>
<p>6、配置监听文件,创建监听服务<br>可以从主库拷贝$ORACLE_HOME/NETWORK/ADMIN/目录下的文件tnsname.ora,listener.ora,sqlnet.ora到备库相同的位置,并作相应的修改,特别要注意主机名部分。<br>只安装默认没有创建监听服务,lsnrctl命令可以在没有监听服务时自动创建监听服务</p>
<p>备库端：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CMD&gt; lsnrctl</span><br><span class="line">LSNRCTL&gt; status</span><br><span class="line">Connecting to (ADDRESS=(PROTOCOL=tcp)(HOST=)(PORT=<span class="number">1521</span>))</span><br><span class="line">TNS-<span class="number">12541</span>: TNS:no listener</span><br><span class="line"> TNS-<span class="number">12560</span>: TNS:protocol adapter error</span><br><span class="line"> TNS-<span class="number">00511</span>: No listener</span><br><span class="line"> <span class="number">64</span>-bit Windows <span class="built_in">Error</span>: <span class="number">61</span>: Unknown error</span><br></pre></td></tr></table></figure>

<p>启动监听:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">LSNRCTL&gt; start</span><br><span class="line">Starting tnslsnr: please wait...</span><br><span class="line"></span><br><span class="line">Failed to open service &lt;OracleOraDb10g_home1TNSListener&gt;, error <span class="number">1060.</span></span><br><span class="line">TNSLSNR <span class="keyword">for</span> <span class="number">64</span>-bit Windows: Version <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> - Production</span><br><span class="line">Log messages written to E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\db_1\\network\\log\\listener.log</span><br><span class="line">Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=localdb)(PORT=<span class="number">1521</span>)))</span><br><span class="line"></span><br><span class="line">Connecting to (ADDRESS=(PROTOCOL=tcp)(HOST=)(PORT=<span class="number">1521</span>))</span><br><span class="line">STATUS <span class="keyword">of</span> the LISTENER</span><br><span class="line">------------------------</span><br><span class="line">Alias LISTENER</span><br><span class="line">Version TNSLSNR <span class="keyword">for</span> <span class="number">64</span>-bit Windows: Version <span class="number">10.2</span><span class="number">.0</span><span class="number">.4</span><span class="number">.0</span> - Production</span><br><span class="line">Start <span class="built_in">Date</span> <span class="number">07</span>-AUG-<span class="number">2012</span> <span class="number">15</span>:<span class="number">32</span>:<span class="number">42</span></span><br><span class="line">Uptime <span class="number">0</span> days <span class="number">0</span> hr. <span class="number">0</span> min. <span class="number">7</span> sec</span><br><span class="line">Trace Level off</span><br><span class="line">Security ON: Local OS Authentication</span><br><span class="line">SNMP OFF</span><br><span class="line">Listener Log File E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\db_1\\network\\log\\listener.log</span><br><span class="line">Listening Endpoints Summary...</span><br><span class="line"> (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=localdb)(PORT=<span class="number">1521</span>)))</span><br><span class="line">The listener supports no services</span><br><span class="line">The command completed successfully</span><br></pre></td></tr></table></figure>

<p>这样会建立起tns监听系统服务OracleOraDb10g_home1TNSListener</p>
<p>7、提前创建控制文件所在的目录<br>参数文件中有记载的控制文件详细路径，参数名称为*.control_files。物理备库需要根据此参数的设置提前建立好控制文件所需要的上层各级目录,比如提前建立好如下目录层次:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\oradata\\orcl</span><br></pre></td></tr></table></figure>
<p>否则执行duplicate命令时会出现如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN-<span class="number">00571</span>: ===========================================================</span><br><span class="line">RMAN-<span class="number">00569</span>: =============== ERROR MESSAGE STACK FOLLOWS ===============</span><br><span class="line">RMAN-<span class="number">00571</span>: ===========================================================</span><br><span class="line">RMAN-<span class="number">03002</span>: failure <span class="keyword">of</span> Duplicate Db command at </span><br><span class="line">RMAN-<span class="number">05501</span>: aborting duplication <span class="keyword">of</span> target database</span><br><span class="line">RMAN-<span class="number">03015</span>: error occurred <span class="keyword">in</span> stored script Memory Script</span><br><span class="line">RMAN-<span class="number">06026</span>: some targets not found - aborting restore</span><br><span class="line">RMAN-<span class="number">06024</span>: no backup or copy <span class="keyword">of</span> the control file found to restore</span><br></pre></td></tr></table></figure>

<p><strong>二、RMAN全备主库并为备库生成控制文件</strong></p>
<p>1、对主库执行全备份<br>RMAN正常全备主库,可以使用也可以不使用恢复目录,最重要一点,在物理备库上要可以以相同的路径访问到主库的全备份。可以在备库上建立相同的备份文件存放路径,然后通过ftp等方式将主库全备份拷贝至备库主机相同位置。也可以使用NFS等网络路径,这样可以避免在主备库之间拷贝全备份。<br>比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; BACKUP DATABASE FORMAT <span class="string">&#x27;\\\\cifs_server\\RMAN\\bak_%U&#x27;</span> </span><br><span class="line"> INCLUDE CURRENT CONTROLFILE FOR STANDBY </span><br><span class="line"> PLUS ARCHIVELOG FORMAT <span class="string">&#x27;\\\\cifs_server\\RMAN\\ARC_%U&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>2、创建物理备库控制文件</p>
<p>有多种方式为物理备库生成控制文件。</p>
<ul>
<li><p>备份主库时同时为备库生成控制文件</p>
<p>  通过使用INCLUDE CURRENT CONTROLFILE FOR STANDBY语句,可以在备份集中生成备库的控制文件,类似如下：</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; BACKUP DATABASE FORMAT <span class="string">&#x27;D:\\RMAN\\bak_%U&#x27;</span> </span><br><span class="line"> INCLUDE CURRENT CONTROLFILE FOR STANDBY </span><br><span class="line"> PLUS ARCHIVELOG FORMAT <span class="string">&#x27;D:\\RMAN\\ARC_%U&#x27;</span>;</span><br></pre></td></tr></table></figure>


</li>
</ul>
<ul>
<li><p>使用RMAN COPY命令</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt; COPY CURRENT CONTROLFILE FOR STANDBY TO <span class="string">&#x27;D:\\RMAN\\control01.ctl&#x27;</span>;</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用alter database语句</p>
<p>  sqlplus登录主库端执行</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; alter database create standby controlfile <span class="keyword">as</span> <span class="string">&#x27;d:\\rman\\control01.ctl&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>  然后rman连接target(主库)和catalog恢复目录(如果使用的话),然后执行</p>
  <figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN&gt;CATALOG CONTROLFILECOPY <span class="string">&#x27;d:\\rman\\control01.ctl&#x27;</span>;</span><br></pre></td></tr></table></figure>

<p>  这样RMAN就知道去那里找物理备库的控制文件了。</p>
</li>
</ul>
<p><strong>注意:物理备库中控制文件所在路径必须提前建立起来。</strong></p>
<p><strong>三、创建物理备库</strong></p>
<p>1、用RMAN连接主库、物理备库和恢复目录,使用target关键字连接主库,使用auxiliary关键字连接待创建的物理备库,catalog关键字连接恢复目录数据库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rman target sys/passwd@primarydb auxiliary sys/passwd@standbydb catalog user/passwd@catalogdb</span><br><span class="line">...</span><br><span class="line">connected to target database: ORCL (DBID=<span class="number">1276927241</span>)</span><br><span class="line">connected to recovery catalog database</span><br><span class="line">connected to auxiliary database: ORCL (not mounted)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>然后执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rman&gt; duplicate target database <span class="keyword">for</span> standby nofilenamecheck;</span><br></pre></td></tr></table></figure>

<p>因为是异机相同目录结构复制到备库,所以必须指定参数nofilenamecheck,不然rman会晕菜。<br>如果不指定dorecover选项,则不进行日志恢复,物理备库创建完成后打开日志恢复自然就可以同步到主库一致的状态了。<br>如果RMAN数据库备份有增量备份，则应该打开DORECOVER选项以便恢复增量备份集。</p>
<p>如果指定了DORECOVER选项,可能会遇到如下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">RMAN-<span class="number">06026</span>: some targets not found - aborting restore </span><br><span class="line">RMAN-<span class="number">06024</span>: no backup or copy <span class="keyword">of</span> the control file found to restore</span><br></pre></td></tr></table></figure>

<p>具体原因和解决办法参见[2].</p>
<p>备库创建完成后rman将其置于mounted状态。</p>
<p>2、创建备库时并不会将主库的online redo log files和standby redo log files拷贝到备库,但是控制文件中包含了这些信息。</p>
<p>“因为在备份前主库创建了standby redo log，备库是根据主库的信息创建的，一开始它是包含了主库的standby redo log信息，如果主库设置的日志传送方式是LGWR，当主库发生日志切换时，备库的RFS会尝试使用standby redo log来存储主库传送过来的日志，因为此时备库实际上是不存在standby redo log的，所以备库会报错。当备库尝试打开字典信息的所有standby redo log失败以后，备库会自动把日志传送方式转为ARCN，并同时清除数据字典中的standby redo log信息。”参见<a href="http://space6212.itpub.net/post/12157/299427">DG使用中遇到的几个错误</a>。</p>
<p>因此如果需要开启实时redo apply的话,需要手动提前<a href="https://openwares.net/database/oracle_10g_windows_x64_dataguard.html">添加standby redo log文件</a>,如下:<br>备库端:<br>[sql]<br>SQL&gt;alter database add standby logfile group 4 (‘E:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\STDBYREDO01.LOG’) size 50M;<br>Database altered.<br>SQL&gt;alter database add standby logfile group 5 (‘E:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\STDBYREDO02.LOG’) size 50M;<br>Database altered.<br>SQL&gt;alter database add standby logfile group 6 (‘E:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\STDBYREDO03.LOG’) size 50M;<br>Database altered.<br>SQL&gt;alter database add standby logfile group 7 (‘E:\ORACLE\PRODUCT\10.2.0\ORADATA\ORCL\STDBYREDO04.LOG’) size 50M;<br>Database altered.<br>[/sql]<br>然后就可以打开realtime redo apply了,如下打开实时日志应用:<br>备库端:<br>[sql]<br>SQL&gt;ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION;<br>[/sql]</p>
<p>3、此时会后台日志文件中会报如下错误</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">19527</span>: physical standby redo log must be renamed</span><br></pre></td></tr></table></figure>
<p>物理standby并不需要在线redo日志,因为其并不以读写方式打开。但当物理standby要switch over成为主库时是必须要使用在线redo log的,在switch over之前,oracle会清除online redo log文件,为了加快switch over进度,oracle会在开启日志应用之时提前将物理standby的online redo log文件clear。oracle为了防止意外清除了主库的online redo log文件,即使物理standby与主库不在同一台主机上,只要其路径相同则必须明确的设置log_file_name_convert参数,这样才能避免此错误提示。<br>因此可以通过alter system set log_file_name_convert更改此参数设置或者在备库初始化文件中添加此参数并重新生成spfile启动数据库</p>
<p>pfile中添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">*.log_file_name_convert=<span class="string">&#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\redo01.log&#x27;</span>,<span class="string">&#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\redo01.log&#x27;</span>,<span class="string">&#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\redo02.log&#x27;</span>,<span class="string">&#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\redo02.log&#x27;</span>,<span class="string">&#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\redo03.log&#x27;</span>,<span class="string">&#x27;E:\\oracle\\product\\10.2.0\\oradata\\orcl\\redo03.log&#x27;</span></span><br></pre></td></tr></table></figure>
<p>4、检查下两边的日志同步情况<br>[sql]<br>SQL&gt;select sequence# from v$archived_log where applied=’YES’;<br>[/sql]</p>
<p>如果oracle后台日志出现类似错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">00313</span>: open failed <span class="keyword">for</span> members <span class="keyword">of</span> log group <span class="number">4</span> <span class="keyword">of</span> thread <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>只要将对应的日志组clear就可以了：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt;ALTER DATABASE RECOVER MANAGED STANDBY DATABASE CANCEL; #如果正在应用redo日志，需要先取消</span><br><span class="line">SQL&gt;ALTER DATABASE CLEAR LOGFILE GROUP <span class="number">4</span>;</span><br></pre></td></tr></table></figure>

<p>物理备库创建完成。</p>
<p>备注:如果重新启动物理备库，只能以mount方式打开，否则会出现错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; startup</span><br><span class="line">ORACLE instance started.</span><br><span class="line"></span><br><span class="line">Total System Global Area <span class="number">1.9327E+10</span> bytes</span><br><span class="line">Fixed Size <span class="number">2198344</span> bytes</span><br><span class="line">Variable Size <span class="number">2273014968</span> bytes</span><br><span class="line">Database Buffers <span class="number">1.7046E+10</span> bytes</span><br><span class="line">Redo Buffers <span class="number">6488064</span> bytes</span><br><span class="line">Database mounted.</span><br><span class="line">ORA-<span class="number">16004</span>: backup database requires recovery</span><br><span class="line">ORA-<span class="number">01196</span>: file <span class="number">1</span> is inconsistent due to a failed media recovery session</span><br><span class="line">ORA-<span class="number">01110</span>: data file <span class="number">1</span>: <span class="string">&#x27;E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\SYSTEM01.DBF&#x27;</span></span><br></pre></td></tr></table></figure>

<p>关闭后重新以mount方式打开即可：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">SQL&gt; shutdown immediate;</span><br><span class="line">SQL&gt; startup mount;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://docs.oracle.com/cd/B19306_01/server.102/b14239/rcmbackp.htm#i639101">Creating a Standby Database with Recovery Manager</a><br>[2]<a href="http://www.dba-oracle.com/t_rman_06026.htm">RMAN-06026 tips</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>rman中obsolete和expired的区别</title>
    <url>/2015/03/18/rman-obsolete-expired-diff/</url>
    <content><![CDATA[<a id="more"></a>
<p>obsolete是过期的备份，是指超过备份集保留策略(retention policy)的备份。</p>
<p>而expired是指无效的备份，比如已经从存储介质上物理删除，但rman的信息中仍然有这些备份的信息，这些备份被crosscheck命令标记为无效的。</p>
<p>[sql]<br>delete obsolete; //删除过期的备份<br>crosscheck archivelog all;<br>delete expired archivelog all; //删除无效的归档日志<br>crosscheck backup;<br>delete expired backup; //删除无效的备份集<br>[/sql]</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>只读表空间的备份和恢复</title>
    <url>/2016/05/11/rman-readonly-tablespaces/</url>
    <content><![CDATA[<a id="more"></a>
<p>查询表空间状态：<br>[sql]<br>sql&gt; select tablespace_name,status from dba_tablespaces;<br>[/sql]</p>
<p>修改表空间状态为READ ONLY：<br>[sql]<br>sql&gt; alter tablespace tablespace_name read only;<br>[/sql]</p>
<p>表空间置为READ ONLY之后，不再发生任何变化，只需保存一份有效的备份即可，可以使用RMAN，也可以使用OS直接拷贝数据文件来备份只读表空间。</p>
<p>之后日常备份时就可以skip readonly来忽略掉只读表空间的备份，加速备份速度。</p>
<p>但恢复数据库时记得要check readonly,即使没有只读表空间，恢复仍然会成功，但open数据库会出现错误。</p>
<p>如果不使用check readonly，记得要将只读表空间的数据文件拷贝到相应的位置之后再recover数据库。</p>
<p>References:<br>[1]<a href="http://www.cnblogs.com/Richardzhu/articles/2890833.html">Oracle Read-only Tablespace(只读表空间)</a><br>[2]<a href="http://blog.csdn.net/xcl168/article/details/20297247">(09)常被人遗忘的只读表空间</a><br>[3]<a href="https://docs.oracle.com/cd/B19306_01/backup.102/b14192/recov002.htm">Database Backup and Recovery Basics</a><br>[4]<a href="http://blog.csdn.net/leshami/article/details/6646492">只读表空间的备份与恢复</a><br>[5]<a href="http://gavinsoorma.com/2009/08/read-only-tablespace-restore-and-recovery/">READ ONLY Tablespace Restore and Recovery</a><br>[6]<a href="http://kubilaykara.blogspot.com/2008/02/backing-up-restoring-and-recovering.html">Backing up, Restoring and Recovering Read Only tablespaces with RMAN</a><br>[7]<a href="https://hemantoracledba.blogspot.com/2010/05/read-only-tablespaces-and-backup.html">Read Only Tablespaces and BACKUP OPTIMIZATION</a><br>[8]<a href="http://www.xifenfei.com/2011/04/rman%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4.html">Rman管理命令</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>rman远程备份</title>
    <url>/2012/04/17/rman-remote-backup/</url>
    <content><![CDATA[<p>rman自身是不支持远程备份的,它只支持备份到目标服务器可以直接存取的路径上。</p>
<a id="more"></a>
<p><strong>rman备份环境</strong></p>
<p>恢复目录系统环境为debian wheezy amd64 + oracle 10g 10.2.0.4 64bits,目标数据库系统环境为windows 2003 r2 sp2 x64 + oracle 10g 10.2.0.4 64bits。恢复目录所在服务器mount了一个共享大容量光纤SAS盘阵。目标数据库的备份数据要远程备份到盘阵,一个安全性,一个是容量问题。</p>
<p><strong>有这么几种方式可以实现此目标。</strong></p>
<p>NFS</p>
<p>首先想到NFS,NFS在unix/linux世界是使用十分广泛的共享文件系统,安装设置也很简单。windows平台有个SFU(Services for Unix)提供NFS客户端和服务器功能,可以通过安装此包设置为客户端来存取远端NFS服务器。但经测试表明32bits windows可以正常存取远端NFS服务器,但64bits windows无法安装SFU。而且SFU可能是已经被放弃的软件包。所以只好放弃此种方式。</p>
<p>FTP</p>
<p>linux提供FTP服务,windows端通过某些软件将FTP路径虚拟为一个本地磁盘供RMAN存取。虽然可行,但这方面软件成熟和让人放心的尚未找到,没有经过太多的实践检验。</p>
<p>SAMBA/CIFS</p>
<p>最后才考虑samba,因为这玩意儿虽然成熟,但安全问题也是多多。不过没办法,最终选择此方案。</p>
<p><strong>debian安装配置samba服务</strong></p>
<p>#apt-get install samba</p>
<p>配置文件/etc/samba/smb.conf内容</p>
<p>[global]<br>workgroup = WORKGROUP<br>guest account = nobody<br>security = share</p>
<p>[rman]<br>comment = rman backup destination<br>path = /mnt/data/rman_bak<br>guest ok = yes<br>writable = yes<br>share modes = yes<br>hosts allow = 127.0.0.1 192.168.0.0/24</p>
<p>将printer相关参数全部注释掉,其他参数默认即可。<br>guest账户映射到nobody用户,为rman远程备份设置共享名rman,只允许部分网段访问此共享,也可以限制到具体的哪台主机,比如127.0.0.1。</p>
<p>修改共享目录的属主和权限<br>#chown nobody:nogroup /mnt/data/rman_bak<br>#chmod 777 /mnt/data/rman_bak</p>
<p>然后rman备份时直接将备份片路径设置为\\ip\rman就可以了。在windows中做网络驱动器映射时,rman会提示无法创建备份片文件,不知为何？<br> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>rman恢复目录中注销(unregister)目标数据库</title>
    <url>/2014/10/18/rman-unregister-database/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果不再需要使用rman来管理目标数据库,或者目标数据库已经崩溃,可以从rman恢复目录注销掉目标数据库。这样只会从恢复目录中移除目标数据库备份相关的元数据，物理备份不会被删除。</p>
<p><strong>连接目标数据库</strong></p>
<p>最简单的就是连上目标数据库和恢复目录，然后执行unregister database<br>[sql]<br>$ rman target user/passwd@tgt catalog user/passwd@catlog;<br>RMAN&gt; unregister database;<br>database name is “orcl” and DBID is 1276927241<br>Do you really want to unregister the database (enter YES or NO)?<br>[/sql]</p>
<p><strong>不连接目标数据库</strong></p>
<p>如果目标数据库已经崩溃,无法再连接时,可以通过指定目标数据库的DBID或者直接使用名字来注销数据库。</p>
<p>如果不知道目标数据库的DBID或名字,先通过rman数据库的rc_database视图(rc指recovery catalog)来查询相关信息。谨记rman恢复目录可以同时为多个目标数据库提供服务。<br>[sql]<br>$ sqlplus user/passwd@catlog;<br>SQL&gt; select * from rc_database;<br> DB_KEY DBINC_KEY DBID NAME RESETLOGS_CHANGE# RESETLOGS_TIME</p>
<hr>
<p> 10161 41305 1276927241 ORCL 1981608693 28-JUL-12<br>[/sql]</p>
<p>使用DBID<br>[sql]<br>$ rman catalog user/passwd@catlog;<br>RMAN&gt; set dbid=1276927241;<br>executing command: SET DBID<br>database name is “ORCL” and DBID is 1276927241<br>RMAN&gt; unregister database;<br>database name is “ORCL” and DBID is 1276927241<br>Do you really want to unregister the database (enter YES or NO)?<br>[/sql]</p>
<p>直接使用目标数据库名字<br>[sql]<br>$ rman catalog user/passwd@catlog;<br>RMAN&gt; unregister database orcl;<br>database name is “ORCL” and DBID is 1276927241<br>Do you really want to unregister the database (enter YES or NO)? YES<br>database unregistered from the recovery catalog<br>[/sql]</p>
<p><strong>移除恢复目录</strong></p>
<p>如果rman恢复目录不再使用,可以drop掉:<br>[sql]<br>$ rman catalog user/passwd@catlog;<br>RMAN&gt; drop catalog;<br>[/sql]</p>
<p>References:<br>[1]<a href="http://www.oracledistilled.com/oracle-database/backup-and-recovery/remove-a-database-from-a-rman-recovery-catalog/">Remove a Database from a RMAN Recovery Catalog</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>webmail之roundcubemail安装配置</title>
    <url>/2014/01/04/roundcubemail-setup/</url>
    <content><![CDATA[<p>roundcubemail是一个不错的webmail,十分轻量,安装配置十分简单,比horde简单多了。</p>
<a id="more"></a>
<p><strong>安装</strong></p>
<p>直接<a href="http://roundcube.net/download/">下载</a>最新的版本,解压到www/roundcubemail目录</p>
<p>然后设置nginx虚拟主机:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"> listen <span class="number">80</span>; </span><br><span class="line"> server_name mail.openwares.net;</span><br><span class="line"> root /home/mopyman/public_html/roundcubemail;</span><br><span class="line"> index index.php;</span><br><span class="line"> access_log /<span class="keyword">var</span>/log/nginx/mail.openwares.net_access.log;</span><br><span class="line"> error_log /<span class="keyword">var</span>/log/nginx/mail.openwares.net_error.log;</span><br><span class="line"></span><br><span class="line"> include php-fpm.conf;</span><br><span class="line"> include errpage.conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改roundcube/temp和roundcube/logs目录访问权限,让www-data用户可写</p>
<p><strong>配置</strong></p>
<p>直接访问<a href="http://your_roundcubemail_domain/installer%E6%A0%B9%E6%8D%AE%E6%8F%90%E7%A4%BA%E4%B8%80%E6%AD%A5%E6%AD%A5%E9%85%8D%E7%BD%AE,%E6%9C%80%E5%90%8E%E5%B0%86%E7%94%9F%E6%88%90%E7%9A%84main.inc.php%E5%92%8Cdb.inc.php">http://your_roundcubemail_domain/installer根据提示一步步配置,最后将生成的main.inc.php和db.inc.php</a><br>上传到www/roundcubemail/config目录下就可以了。</p>
<p><strong>配置访问ssl imap</strong></p>
<p>只要修改config/main.inc.php中的参数<br>$rcmail_config[‘default_host’] = ‘ssl://mail.openwares.net:993’;<br>就可以了,一定不要用tls://这种格式,虽然配置文件说可以,但实际上会无法访问imap。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>RTL8723AU 蓝牙驱动</title>
    <url>/2014/11/15/rtl8723au-bluetooth-driver/</url>
    <content><![CDATA[<a id="more"></a>
<p>原来RTL8723AU芯片上的蓝牙功能驱动也已经有了，还是那个热心的Larry W. Finger搞的，github地址在<a href="https://github.com/lwfinger/rtl8723au_bt">https://github.com/lwfinger/rtl8723au_bt</a></p>
<p>安装也很简单：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ git clone https:<span class="comment">//github.com/lwfinger/rtl8723au_bt</span></span><br><span class="line">$ cd rtl8723au_bt</span><br><span class="line">$ make</span><br><span class="line"># make install</span><br><span class="line"># modprobe rtk_btusb</span><br></pre></td></tr></table></figure>

<p>然后就可以了</p>
<p><strong>UPDATE(08/01/2015):</strong><br>hci_recv_fragment函数从kernel 3.18起被删除了，当前仓库的master分支尚未修改以支持此状况，但kernel分支已经支持。因此应该切换到kernel分支再行编译安装。<br>并且，模块的名字变成了btusb, so:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ git checkout kernel</span><br><span class="line">...</span><br><span class="line"># modprobe btusb</span><br></pre></td></tr></table></figure>
<p>就可以了。</p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>RTL8723AU驱动 for Debian Jessie kernel 3.9</title>
    <url>/2013/06/22/rtl8723au-driver-for-debian-jessie-kernel-39/</url>
    <content><![CDATA[<p>Debian 当前testing Jessie终于更新到kernel 3.9</p>
<a id="more"></a>
<p>更新后，yoga 13的触摸屏终于可以驱动了，但是内置wifi模块仍然驱动不起来，因为RTL8723AU的驱动还没有进入主线内核。RealTEK的动作可真够慢的，这本子已经用了马上半年了。</p>
<p>这无线模组的设备ID为0bda:1724<br>$ lsusb<br>…<br>Bus 001 Device 005: ID 0bda:1724 Realtek Semiconductor Corp.<br>…</p>
<p>幸好<a href="http://www.lwfinger.net/">Larry W. Finger</a>通过与realrek交涉，<a href="https://lkml.org/lkml/2013/4/1/280">拿到了尚未公开的内部驱动</a>，并在github上将<a href="https://github.com/lwfinger/rtl8723au">RTL8723AU的驱动</a>公布出来。</p>
<p>Larry W. Finger虽然并没有此硬件设备，但对此驱动十分热心，正在着手将其推到内核主线，这就是开源的魅力。此芯片还有bluetooth功能，不过驱动尚未准备好，Larry W. Finger也打算与realtek共同努力解决对蓝牙的支持。期待下个内核版本rtl8723au的驱动能进入主线。</p>
<p><strong>驱动安装</strong></p>
<p>安装内核头文件</p>
<h1 id="apt-get-install-build-essential-linux-headers-3-9-1-amd64"><a href="#apt-get-install-build-essential-linux-headers-3-9-1-amd64" class="headerlink" title="apt-get install build-essential linux-headers-3.9-1-amd64"></a>apt-get install build-essential linux-headers-3.9-1-amd64</h1><p>$ git clone <a href="http://github.com/lwfinger/rtl8723au.git">http://github.com/lwfinger/rtl8723au.git</a></p>
<p>用新内核启动</p>
<p>$ cd ~/rtl8723au<br>$ make &amp;&amp; sudo make install</p>
<h1 id="modprobe-8723au"><a href="#modprobe-8723au" class="headerlink" title="modprobe 8723au"></a>modprobe 8723au</h1><h1 id="ifconfig"><a href="#ifconfig" class="headerlink" title="ifconfig"></a>ifconfig</h1><p>就可以看到wlan设备了，信号还不错哈。<br>蓝牙还不行。</p>
<p><strong>UPDATE(1/5/2014):</strong></p>
<p>偶然看了一眼,没想到编译后的内核模块ko文件这么大,8723au.ko竟然有23M之巨。看来strip一下十分有必要,那么在# make install之前，先执行以下命令剥除ko文件的符号。</p>
<h1 id="make-strip"><a href="#make-strip" class="headerlink" title="make strip"></a>make strip</h1><p>这样8723.ko文件就只有1.4M大了,对于内核模块来说,这尺寸也不算小了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>rTorrent配置</title>
    <url>/2019/10/09/rtorrent-configuration/</url>
    <content><![CDATA[<a id="more"></a>
<p>[1]是官方新版rTorrent的配置模板，使用0.9.*支持的语法</p>
<p>References:<br>[1]<a href="https://github.com/rakshasa/rtorrent/wiki/CONFIG-Template">rTorrent Configuration Template</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>rtorrent下载magnet资源</title>
    <url>/2016/12/04/rtorrent-magnet-download/</url>
    <content><![CDATA[<a id="more"></a>
<p>rtorrent原生支持magnet链接，主界面上按enter键，出现<code>&quot;load.normal&quot;</code>提示符，输入magnet链接，回车即可。</p>
<p>如果想要magnet自动添加到watch文件夹，可以用下面这个脚本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">watch_folder=~<span class="regexp">/downloads/</span>.watch</span><br><span class="line">cd $watch_folder</span><br><span class="line">\[\[ <span class="string">&quot;$1&quot;</span> =~ xt=urn:btih:(\[^&amp;/\]+) \]\] exit;</span><br><span class="line">echo <span class="string">&quot;d10:magnet-uri$&#123; #1&#125;:$&#123;1&#125;e&quot;</span> &gt; <span class="string">&quot;meta-$&#123;BASH_REMATCH\[1\]&#125;.torrent&quot;</span></span><br></pre></td></tr></table></figure>
<p>将脚本保存为一个文件，并添加可执行权限，然后将其作为magnet的协议处理器即可。</p>
<p>也可以从文件中读取magnet喂给rtorrent:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">watch_folder=~<span class="regexp">/downloads/</span>.watch</span><br><span class="line">cd $&#123;watch_folder&#125; exit # set your watch directory here</span><br><span class="line"></span><br><span class="line">cnt=<span class="number">1</span></span><br><span class="line">cat <span class="string">&quot;$&#123;1&#125;&quot;</span> <span class="keyword">while</span> read i </span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">\[\[ <span class="string">&quot;$i&quot;</span> =~ xt=urn:btih:(\[^&amp;/\]+) \]\] exit</span><br><span class="line">echo <span class="string">&quot;d10:magnet-uri$&#123; #i&#125;:$&#123;i&#125;e&quot;</span> &gt; <span class="string">&quot;$&#123;cnt&#125;.torrent&quot;</span></span><br><span class="line">cnt=$\[cnt+<span class="number">1</span>\]</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p>存储magnet链接的文件作为命令行参数传递给脚本，文件中每个magnet链接作为单独的一行。</p>
<p>References:<br>[1] <a href="https://wiki.archlinux.org/index.php/RTorrent#Saving_magnet_links_as_torrent_files_in_watch_folder">Saving magnet links as torrent files in watch folder</a><br>[2]<a href="http://www.aneasystone.com/archives/2015/05/how-does-magnet-link-work.html">磁力链接是如何实现下载的？</a><br>[3]<a href="https://zh.wikipedia.org/zh-cn/%E7%A3%81%E5%8A%9B%E9%93%BE%E6%8E%A5">磁力链接</a><br>[4]<a href="https://zh.wikipedia.org/zh-cn/%E5%88%86%E6%95%A3%E5%BC%8F%E9%9B%9C%E6%B9%8A%E8%A1%A8">分布式散列表</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>debian samba去掉默认打印机共享</title>
    <url>/2012/09/11/samba-remove-printers/</url>
    <content><![CDATA[<p>samba默认配置即使没有使用打印机共享,客户端也会看到”打印机和传真”图标</p>
<a id="more"></a>
<p>很简单的就可以去掉它,在/etc/smaba/smd.conf的[global]加入如下语句即可:</p>
<p>disable spoolss = yes</p>
<p>这样客户端就不会看到打印机共享了</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>通过串行控制台访问kvm客户机</title>
    <url>/2016/04/25/serial-console-access-kvm-guest/</url>
    <content><![CDATA[<a id="more"></a>
<p>当ssh,vnc都不能访问客户机时,serial console可以提供另一种访问客户机的途径。</p>
<p><strong>客户机serial console配置</strong></p>
<p>/etc/inittab文件打开或添加如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">T0:<span class="number">23</span>:respawn:<span class="regexp">/sbin/g</span>etty -L ttyS0 <span class="number">38400</span> vt100</span><br></pre></td></tr></table></figure>

<p>/etc/securetty文件中确保列出了ttyS0:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ttyS0</span><br></pre></td></tr></table></figure>

<p>/etc/default/grub文件添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">GRUB_CMDLINE_LINUX=<span class="string">&#x27;console=tty0 console=ttyS0,38400n8&#x27;</span></span><br><span class="line">GRUB_TERMINAL=serial</span><br><span class="line">GRUB_SERIAL_COMMAND=<span class="string">&quot;serial --speed=38400 --unit=0 --word=8 --parity=no --stop=1&quot;</span></span><br></pre></td></tr></table></figure>

<p>波特率是38400，没有奇偶校验，停止位是1</p>
<p>使用virsh来连接客户机串行控制台比较简单，应该也可以重定向客户机的串行端口到主机。</p>
<p>References:<br>[1]<a href="http://www.cyberciti.biz/faq/howto-setup-serial-console-on-debian-linux/">Debian Linux: Set a Serial Console</a><br>[2]<a href="https://wiki.archlinux.org/index.php/working_with_the_serial_console">Working with the serial console</a><br>[3]<a href="https://blackdot.be/2013/07/qemu-kvm-monitor-and-serial-console-over-sockets-with-minicom/">qemu(-kvm) monitor and serial console over sockets with minicom</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>服务器名字指示SNI(Server Name Indication)</title>
    <url>/2009/09/21/server-name-indication/</url>
    <content><![CDATA[<p>Server Name Indication是用来改善SSL(Secure Socket Layer)和TLS(Transport Layer Security)的一项特性。它允许客户端在服务器端向其发送证书之前请求服务器的域名。这对于在虚拟主机模式使用TLS是必要的。</p>
<a id="more"></a>
<p><strong>TLS背景</strong></p>
<p>加密一个面向流的通讯会话最常用的方法之一就是使用TLS协议。比如，当用户在浏览器的地址栏里面输入https时就是在使用这个协议。</p>
<p>为了确认用户想要连接的站点就是浏览器实际连接到的站点，TLS使用包含站点域名的数字签名证书。客户端软件(比如浏览器)通常信任这个证书，如果这个证书是由其内置信任的认证机构签发的。<br>在TLS启动阶段，客户端软件比较用户输入的URI的域名部分与在服务器证书里面找到的域名部分，如果比较失败，浏览器会提示用户，这个站点的证书存在问题。<br><strong>缺点</strong></p>
<p>SSL v2的设计顺应经典的公钥基础设施PKI(public key infrastructure)设计，后者认为一个服务器只提供一个服务从而也就只使用一个证书。这意味着服务器可以在TLS启动的早期阶段发送或提交证书，因为它知道它在为哪个域服务。</p>
<p>HTTP服务器开启虚拟主机支持后，每个服务器通过相同的地址可以为很多域提供服务。服务器检查每一个请求来决定它在为哪个域服务。这个信息通常从HTTP请求头获得。不幸的是，当设置了TLS加密，服务器在读取HTTP请求里面的域名之前已经向客户端提交了证书，也就是已经为默认域提供了服务。</p>
<p>因此，这种为虚拟主机提供安全的简单途径经常导致使用了错误的数字证书，从而导致浏览器对用户发出警告。</p>
<p><strong>钓鱼连接</strong></p>
<p>实际上，这意味着每一个HTTP服务器只能为一个域提供安全浏览。而事实上每一个web服务器都为很多域提供服务，结果就是其他的域无法使用安全通信，从而处于危险境地。此外，安全浏览的缺乏使浏览器无法认证服务器，亦即它无法校验站点是否真的是属于宣称它的那个人或实体。钓鱼的一个重要因素是他们企图通过虚假站点来获取用户的信息。使用SSL或者TLS安全连接，浏览器可以基于它的证书来认证站点。钓鱼站点不会作为一个欺骗性的站点得到认证，浏览器会警告这个安全风险。然而，没有安全HTTP就没有标准的方法去认证服务器，使这种钓鱼的企图很容易就能实现。</p>
<p><strong>修正</strong></p>
<p>一个叫做SNI的TLS扩展通过发送虚拟域的名字做为TSL协商的一部分修正了这个问题。这会使服务器更早的切换到正确的虚拟域，并且发送给浏览器包含正确名字的数字证书。</p>
<p><strong>行动</strong></p>
<p>在2005年，人们意识到从SSL v2到TLS没有很容易的升级路径，并且站点不得不升级他们的软件来。为了尽快的推进，Mozilla宣告完全抛弃对SSL v2的支持。Firefox社区确信其余的站点会升级他们的服务器到SSL v3或TLS v1。</p>
<p>从2005年开始，CAcert在虚拟服务器上用不同的方法使用TLS来进行试验，大部分试验是不满意并且不实际的。比如，可以使用subjectAltName在一个数字证书中包含多个域，但是这是一个证书，意味着所有的域必须被一个人拥有并控制，并且每次域列表发生变化，证书必须重新发放。</p>
<p>2004年，EdelKey project为OpenSSL里面的TLS/SNI开发了一个补丁。2006年这个补丁进入OpenSSL的开发分支，2007年，它被向后移植到了OpenSSL 0.9.8，也就是当前的发行版本。</p>
<p><strong>支持状况</strong></p>
<p>支持SNI的浏览器</p>
<ul>
<li>Mozilla Firefox 2.0 or later</li>
<li>Opera 8.0 or later (the TLS 1.1 protocol must be enabled)</li>
<li>Internet Explorer 7 or later on Windows Vista or higher</li>
<li>Google Chrome (Vista, not XP)</li>
<li>Safari 3.2.1 Mac OS X 10.5.6</li>
</ul>
<p>支持SNI的服务器</p>
<ul>
<li>Apache 2.2.12 or later using mod_ssl (or alternatively with experimental mod_gnutls)</li>
<li>Cherokee if compiled with TLS support</li>
<li>Versions of lighttpd 1.4.x and 1.5.x with patch</li>
<li>Nginx with an accompanying OpenSSL built with SNI support</li>
<li>acWEB with OpenSSL 0.9.8j and later (on Windows)</li>
</ul>
<p>支持SNI的库</p>
<ul>
<li>Mozilla NSS 3.11.1 client side only</li>
<li>OpenSSL</li>
</ul>
<p> 0.9.8f (released 11 Oct 2007) - not compiled in by default, can be compiled in with config option ‘–enable-tlsext’.<br> 0.9.8j (released 07 Jan 2009) - now compiled in by default<br> Unreleased 0.9.9 is likely to include SNI compiled in by default.</p>
<ul>
<li>GNU TLS</li>
</ul>
<p>不支持SNI的操作系统,浏览器和库</p>
<p>客户端</p>
<ul>
<li>Internet Explorer 6 or earlier and any IE version on Windows XP , windows 2003 or earlier</li>
<li>Konqueror/KDE in any version</li>
</ul>
<p>服务器端</p>
<ul>
<li>Microsoft Internet Information Server IIS (As of 2009).</li>
<li>Apache Tomcat 8 or earlier</li>
</ul>
<p>库</p>
<ul>
<li>Qt</li>
<li>Mozilla NSS server side</li>
<li>Python</li>
</ul>
<p><strong>windows和IE</strong></p>
<p>可以看得出，windows XP和windows 2003 server系统上的任何IE版本浏览器都是不支持SNI的, vista及以后系统上的IE 7及更高版本的IE浏览器支持SNI。IE6及更早版本的IE浏览器在任何系统上都是不支持SNI的。</p>
<p><strong>tomcat</strong></p>
<p>tomcat当前的稳定版8尚不支持SNI,tomcat 9才会支持,以后可能会backport到tomcat 8和7。可以使用nginx反向https代理后端的tomcat,参见[2]</p>
<p><strong>SNI测试</strong></p>
<p>用浏览器或其他https客户端比如wget等访问SNI测试站点<a href="https://sni.velox.ch/%E5%8D%B3%E5%8F%AF%E4%BB%A5%E7%9F%A5%E9%81%93%E6%B5%8F%E8%A7%88%E5%99%A8%E6%88%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%98%AF%E5%90%A6%E6%94%AF%E6%8C%81SNI%E3%80%82">https://sni.velox.ch/即可以知道浏览器或客户端是否支持SNI。</a></p>
<p>References:<br>[1]<a href="https://en.wikipedia.org/wiki/Server_Name_Indication">Server Name Indication</a><br>[2]<a href="http://webapp.org.ua/sysadmin/setting-up-nginx-ssl-reverse-proxy-for-tomcat/">Setting up NGINX SSL reverse proxy for Tomcat</a><br>[3]<a href="http://stackoverflow.com/questions/20190464/howto-setup-tomcat-serving-two-ssl-certificates-using-sni">HowTo setup Tomcat serving two SSL Certificates using SNI?</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>servlet ajax samples</title>
    <url>/2013/10/06/servlet-ajax-request-samples/</url>
    <content><![CDATA[<p>用ajax异步请求servlet的简单示例程序</p>
<a id="more"></a>
<p>前后端完全分离的架构符合术业有专攻的思想，现在前端发展如此迅猛，前后端混在一起开发起来会愈发困难。</p>
<p>前端只负责UI，后端只负责数据。前端完全是单纯的html+javascript+css,无需后端生成，与后端通过ajax+json来交换数据，只要前后端遵守共同的数据交换协议，就可以将相互的影响降到最低，各自开发而互不影响。</p>
<p>而且，前后端完全分离框架可以使前端和后端使用的技术不受限制，可以随意组合，前端可以使用各种前端框架，比如angularjs，YUI,Bootstrap,Dojo,ExtJS,Backbone.js、Ember.js,DWZ等，后端可以使用各种服务器技术，比如java,php,python,node.js等。只要前后端都支持json数据交换标准即可。</p>
<p>这篇sample只演示了ajax前后端交互，没有使用json。</p>
<p><strong>前端代码</strong><br>index.html<br>[html]<br><!doctype html></p>
<html>
 <head>
 <meta charset="utf-8">
 <title>servlet 3 ajax sample</title>
 <script>
 var xhr = function(){
 try{
 return new XMLHttpRequest();
 }catch(e){
 console.log("XMLHttpRequest Initialize Exception!");
 }
 }
 var request = xhr();

<p> function ajaxcalc(){<br> if( request == null){<br> console.log(“the request is null!”);<br> }<br> var url = “/ajax/ajaxCalc?augend=” + document.getElementById(“augend”).value </p>
<ul>
<li><p>“&amp;addend=” + document.getElementById(“addend”).value;<br>request.open(“GET”,url,true);<br>request.onreadystatechange = updateCalcResult;<br>request.send(null);<br>}</p>
<p>function updateCalcResult(){<br>if(request.readyState == 4 &amp;&amp; request.status == 200){<br>console.log(“response text is “ + request.responseText);<br>document.getElementById(“result”).value = request.responseText;<br>}<br>}</p>
<p>document.addEventListener(<br>“DOMContentLoaded”,<br>function(){<br>document.getElementById(“calc”).addEventListener(“click”,ajaxcalc,false);<br>},<br>false);<br></script></p>
</head>
<body>
<input id="augend" type="text" value="1"> + <input id="addend" type="text" value="1"> = 
<input id="result" type="type">
<input id="calc" type="button" value="calculate">
</body>
</html>
\[/html\]

</li>
</ul>
<p><strong>后端代码</strong><br>AjaxCalc.java<br>[java]<br>import java.io.IOException;<br>import javax.servlet.ServletException;<br>import javax.servlet.annotation.WebServlet;<br>import javax.servlet.http.HttpServlet;<br>import javax.servlet.http.HttpServletRequest;<br>import javax.servlet.http.HttpServletResponse;</p>
<p>@WebServlet(name=”ajaxCalc”, urlPatterns={“/ajaxCalc”}, loadOnStartup=1)<br>public class AjaxCalc extends HttpServlet{<br> @Override<br> protected void doGet(HttpServletRequest request,HttpServletResponse response)<br> throws ServletException,IOException{</p>
<p> int intAugend = Integer.parseInt(request.getParameter(“augend”));<br> int intAddend = Integer.parseInt(request.getParameter(“addend”));<br> int intResult = intAugend + intAddend;</p>
<p> response.setContentType(“text/plain”);<br> response.getWriter().println(intResult);<br> }</p>
<p> @Override<br> protected void doPost(HttpServletRequest request,HttpServletResponse response)<br> throws ServletException,IOException{</p>
<p> doGet(request,response);<br> }<br>}<br>[/java]</p>
<p><strong>截图</strong><br><img src="/downloads/ajaxsample.png" alt="ajax sample"><br>点击calculate按钮，前端发起ajax请求，后端计算出二者之和后返回，最后前端更新结果值。</p>
]]></content>
      <categories>
        <category>java</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>servlet ajax sample json版</title>
    <url>/2013/10/06/servlet-ajax-sample-json-version/</url>
    <content><![CDATA[<p>简单的样例程序，前后端完全分离，前端纯html,后端servlet,前后端完全使用ajax + json沟通数据</p>
<a id="more"></a>
<p><strong>先贴代码</strong><br>前端html源代码<br>index.html<br>[html]<br><!DOCTYPE html></p>
<html>
 <head>
 <meta charset="utf-8">
 <title>servlet 3 ajax sample</title>
 <script>
 var xhr = function(){
 try{
 return new XMLHttpRequest();
 }catch(e){
 console.log("XMLHttpRequest Initialize Exception!");
 }
 }
 var xhreq = xhr();

<p> function ajaxcalc(){<br> if(xhreq == null){<br> console.log(“the xhreq is null!”);<br> }<br> var url = “/ajaxjson/ajaxCalc”;</p>
<p> var data = {augend:document.getElementById(“augend”).value,<br> addend:document.getElementById(“addend”).value};<br> xhreq.open(“POST”,url,true);<br> xhreq.setRequestHeader(‘Content-Type’,’application/json; charset=UTF-8’);</p>
<p> xhreq.onreadystatechange = updateCalcResult;</p>
<p> xhreq.send(JSON.stringify(data));<br> }</p>
<p> function updateCalcResult(){<br> if(xhreq.readyState == 4 &amp;&amp; xhreq.status == 200){<br> console.log(“response is “ + xhreq.response);<br> var jsonResponse = JSON.parse(xhreq.response);<br> document.getElementById(“result”).value = jsonResponse[“result”];<br> }<br> }</p>
<p> document.addEventListener(<br> “DOMContentLoaded”,<br> function(){<br> document.getElementById(“calc”).addEventListener(“click”,ajaxcalc,false);<br> },<br> false);<br> </script><br> </head><br> <body><br> <input id="augend" type="text" value="1"> + <input id="addend" type="text" value="1"> =<br> <input id="result" type="type"><br> <input id="calc" type="button" value="calculate"><br> </body></p>
</html>

<p>[/html]</p>
<p>后端servlet源代码<br>AjaxJsonCalc.java<br>[java]<br>import java.io.IOException;<br>import javax.servlet.ServletException;<br>import javax.servlet.annotation.WebServlet;<br>import javax.servlet.http.HttpServlet;<br>import javax.servlet.http.HttpServletRequest;<br>import javax.servlet.http.HttpServletResponse;</p>
<p>import javax.json.Json;<br>import javax.json.JsonReader;<br>import javax.json.JsonWriter;<br>import javax.json.JsonObject;<br>import java.io.StringReader;</p>
<p>@WebServlet(name=”ajaxJsonCalc”, urlPatterns={“/ajaxCalc”}, loadOnStartup=1)<br>public class AjaxJsonCalc extends HttpServlet{<br> @Override<br> protected void doGet(HttpServletRequest request,HttpServletResponse response)<br> throws ServletException,IOException{</p>
<p> }</p>
<p> @Override<br> protected void doPost(HttpServletRequest request,HttpServletResponse response)<br> throws ServletException,IOException{</p>
<p> JsonReader jsonReader = Json.createReader(request.getReader());<br> JsonObject jsonObject = jsonReader.readObject();</p>
<p> int intAugend = Integer.parseInt(jsonObject.getString(“augend”));</p>
<p> String strAddend = jsonObject.getString(“addend”);<br> int intAddend = Integer.parseInt(strAddend);</p>
<p> int intResult = intAugend + intAddend;<br> response.setContentType(“applicaton/json; charset=UTF-8”);</p>
<p> JsonObject jsonResponse = Json.createObjectBuilder().add(“result”,intResult).build();<br> JsonWriter jsonWriter = Json.createWriter(response.getWriter());<br> jsonWriter.writeObject(jsonResponse);<br> jsonWriter.close();<br> }<br>}<br>[/java]</p>
<p><strong>先说后端</strong></p>
<p>使用<a href="http://jcp.org/en/jsr/detail?id=353">JSR 353</a>:Java API for Processing JSON Processing(简称JSON-P，不要与<a href="http://json-p.org/">JSONP</a>混淆)，这是Java EE 7带来的处理json数据的JAVA官方API,<a href="http://docs.oracle.com/javaee/7/api/javax/json/package-summary.html">开发文档</a>,可移植性好。<br>其<a href="https://jsonp.java.net/">参考实现</a>可以从这里<a href="http://search.maven.org/remotecontent?filepath=javax/json/javax.json-api/1.0/javax.json-api-1.0.jar">下载</a>,当前版本为1.0.2,下载回来的文件为javax.json-1.0.2.jar，将其放置到app/WEB-INFO/lib/目录下。</p>
<p>JsonObject有一个方法int getInt(String name)可以返回name对应的整型值，但是估计参考实现有bug,这样用会有类型转换异常抛出<br>java.lang.ClassCastException: org.glassfish.json.JsonStringImpl cannot be cast to javax.json.JsonNumber</p>
<p>所以先使用JsonObject.getSting方法获取字符串，然后转型就可以了<br>int intAugend = Integer.parseInt(jsonObject.getString(“augend”));</p>
<p>后端返回的数据类型设置为applicaton/json，字符集为UTF-8<br>response.setContentType(“applicaton/json; charset=UTF-8”);</p>
<p>因为前端发来是纯粹的json数据，所以无法用request.getParameter来获取数据，可以使用JsonReader来读取request请求数据流<br>JsonReader jsonReader = Json.createReader(request.getReader());</p>
<p>最后将计算结果构造成一个JsonObject,然后使用JsonWriter写入response数据流中<br>JsonObject jsonResponse = Json.createObjectBuilder().add(“result”,intResult).build();<br>JsonWriter jsonWriter = Json.createWriter(response.getWriter());<br>jsonWriter.writeObject(jsonResponse);</p>
<p>这样返回给前端的也是纯粹的json数据。</p>
<p><strong>再说前端</strong></p>
<p>这里使用POST方法与后端通讯，先构造json对象<br>var data = {augend:document.getElementById(“augend”).value,<br> addend:document.getElementById(“addend”).value};</p>
<p>设置请求内容类型为application/json,字符集为UTF-8<br>xhreq.setRequestHeader(‘Content-Type’,’application/json; charset=utf-8’);</p>
<p>最后通过XMLHttpRequest对象的send方法发送数据，发送前需要用浏览器JSON内置对象将json对象字符串化。<br>xhreq.send(JSON.stringify(data));</p>
<p>因为后端设置了返回的内容类型为applicaton/json，所以返回的数据存储在XMLHttpRequest对象的response成员中，<br>其实此时responseText与response内容是相同的，取哪个字段的值都可以。<br>最后，解析返回的json数据并更新UI<br>var jsonResponse = JSON.parse(xhreq.response);<br>document.getElementById(“result”).value = jsonResponse[“result”];</p>
<p>有一点儿需要注意，XMLHttpRequest可以设置期望的响应类型为json,如下<br>xhreq.responseType=”json”;<br>但是设置了此属性后，firefox 24.0 和chrome 30.0.1599.66出现了不兼容的行为。</p>
<p>先说firefox,设置期望响应类型为json，请求返回后，XMLHttpRequest对象的response字段已经存储了解析后的json对象，而不是json字符串，responseText字段则是undefined。<br>所以，如果继续使用JSON.parse解析返回结果时，firefox会有错误提示：<br>SyntaxError: JSON.parse: unexpected character<br>如果直接使用response字段则一切正常。<br>如果试图使用responseText字段，则firefox会有错误提示：<br>InvalidStateError: An attempt was made to use an object that is not, or is no longer, usable</p>
<p>再说chrome,设置期望响应类型为json，请求返回后，XMLHttpRequest对象的response字段和responseText字段皆存储的为json字符串，需要使用JSON.parse解析后才可以转换为json对象来使用。</p>
<p>所以为了兼容性考虑，只要后端设置正确的ContentType就可以了，前端不要设置xhreq.responseType,并且要使用xhreq.response来获取返回的数据。</p>
<p><strong>其他</strong></p>
<p>1、如果请求参数很多，拼接会很麻烦，可以考虑使用form来组织请求字段，然后序列化各个请求字段，JQuery有相应的支持。</p>
<p>2、前端设置请求内容为application/json，则后端无法使用更简单的request.getParameter来获取请求参数数据，只能通过读取请求流来获取数据。可以稍微做些变化，将json请求流作为一个命名参数发送给后端，后端就可以用getParameter(“paraname”)来获取json数据了。</p>
<p>//将发送的内容类型设置为application/x-www-form-urlencoded，这就是通常的表单参数对形式，name=value，也就是GET请求所使用的。<br>xhreq.setRequestHeader(‘Content-Type’,’application/x-www-form-urlencoded; charset=UTF-8’);<br>//为json对象添加名字data<br>xhreq.send(“data=”+JSON.stringify(data));</p>
<p>然后后端就可以这样来获取json数据了<br>//直接获取data请求参数<br>String strData = request.getParameter(“data”);</p>
<p>//然后继续解析出json对象<br>JsonReader jsonReader = Json.createReader(new StringReader(strData));</p>
<p>3、其实不止POST方法可以发送JSON数据，GET方法也可以</p>
<p>//构造符合GET方法调用的URL,将json数据构造为一个命名参数data，最后形成的请求URL是这样的<br>// /ajaxjson/ajaxCalc?data={“augend”:”1”,”addend”:”1”}<br>// 但是直接在浏览器的地址栏输入上面的URL是不能看到结果页面的，因为请求只会返回一个json数据流。<br>var url2 = “/ajaxjson/ajaxCalc?data=” + JSON.stringify(data);<br>//GET方法<br>xhreq.open(“GET”,url2,true);<br>//发送请求<br>xhreq.send(null);</p>
<p>这样后端servlet的doGet会接受到请求，将其委托给doPost就可以了。</p>
<p>不过还是<strong>前后端纯json交互的方式比较清爽</strong>。</p>
]]></content>
      <categories>
        <category>java</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>使用servlet获取所有请求头</title>
    <url>/2013/09/30/servlet-request-headers/</url>
    <content><![CDATA[<p>使用servlet获取HTTP请求中的所有请求头</p>
<a id="more"></a>
<p><strong>源代码</strong><br>PrintRequestHeaders.java</p>
<p>[java]<br>import java.io.PrintWriter;<br>import java.io.IOException;<br>import java.util.Enumeration;<br>import javax.servlet.annotation.WebServlet;</p>
<p>import javax.servlet.ServletException;<br>import javax.servlet.http.HttpServlet;<br>import javax.servlet.http.HttpServletRequest;<br>import javax.servlet.http.HttpServletResponse;</p>
<p>@WebServlet(name = “printHeaders”, urlPatterns = {“/printHeaders”}, loadOnStartup = 1)<br>public class PrintRequestHeaders extends HttpServlet {</p>
<p> @Override<br> public void doGet(HttpServletRequest request, HttpServletResponse response)<br> throws IOException, ServletException {</p>
<p> printHeader(request, response);<br> }</p>
<p> @Override<br> public void doPost(HttpServletRequest request, HttpServletResponse response)<br> throws IOException, ServletException {</p>
<p> printHeader(request, response);<br> }</p>
<p> public void printHeader(HttpServletRequest request, HttpServletResponse response)<br> throws IOException, ServletException {</p>
<p> response.setContentType(“text/html”);</p>
<p> PrintWriter out = response.getWriter();<br> out.println(“<!doctype html>“);<br> out.println(“<html><head><title>Request Headers</title></head>“);<br> out.println(“<body>“);<br> out.println(“<table align=center border=1>“);<br> out.println(“<tr><th>Header</th><th>Value</th></tr>“);</p>
<p> String header = null;<br> Enumeration<String> e = request.getHeaderNames();<br> while(e.hasMoreElements()) {<br> header = e.nextElement();<br> if(header != null){<br> out.println(“<tr><td align=center>“ + header + “</td>“);<br> out.println(“<td align=center>“ + request.getHeader(header) + “</td></tr>“);<br> }<br> }</p>
<p> out.println(“</table>“);<br> out.println(“</body></html>“);<br> }<br>}<br>[/java]</p>
<p><strong>输出</strong><br>chrome浏览器输出</p>
<p>Header</p>
<p>Value</p>
<p>host</p>
<p>127.0.0.1</p>
<p>connection</p>
<p>keep-alive</p>
<p>cache-control</p>
<p>max-age=0</p>
<p>accept</p>
<p>text/html,application/xhtml+xml,application/xml;q=0.9,<em>/</em>;q=0.8</p>
<p>user-agent</p>
<p>Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36</p>
<p>accept-encoding</p>
<p>gzip,deflate,sdch</p>
<p>accept-language</p>
<p>en-US,en;q=0.8</p>
<p>firefox浏览器输出：</p>
<p>Header</p>
<p>Value</p>
<p>host</p>
<p>127.0.0.1</p>
<p>user-agent</p>
<p>Mozilla/5.0 (X11; Linux x86_64; rv:24.0) Gecko/20100101 Firefox/24.0</p>
<p>accept</p>
<p>text/html,application/xhtml+xml,application/xml;q=0.9,<em>/</em>;q=0.8</p>
<p>accept-language</p>
<p>en-US,en;q=0.5</p>
<p>accept-encoding</p>
<p>gzip, deflate</p>
<p>connection</p>
<p>keep-alive</p>
<p>cache-control</p>
<p>max-age=0</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>使用servlet获取所有请求参数</title>
    <url>/2013/09/30/servlet-request-parameters/</url>
    <content><![CDATA[<p>使用servlet获取HTTP请求中的所有请求参数。</p>
<a id="more"></a>
<p><strong>源代码</strong><br>PrtReqParas.java<br>[java]<br>import java.io.PrintWriter;<br>import java.io.IOException;<br>import java.util.Enumeration;<br>import javax.servlet.annotation.WebServlet;</p>
<p>import javax.servlet.ServletException;<br>import javax.servlet.http.HttpServlet;<br>import javax.servlet.http.HttpServletRequest;<br>import javax.servlet.http.HttpServletResponse;</p>
<p>@WebServlet(name = “printParas”, urlPatterns = {“/printParas/“}, loadOnStartup = 1)<br>public class PrtReqParas extends HttpServlet {</p>
<p> @Override<br> public void doGet(HttpServletRequest request, HttpServletResponse response)<br> throws IOException, ServletException {</p>
<p> printParas(request, response);<br> }</p>
<p> @Override<br> public void doPost(HttpServletRequest request, HttpServletResponse response)<br> throws IOException, ServletException {</p>
<p> printParas(request, response);<br> }</p>
<p> public void printParas(HttpServletRequest request, HttpServletResponse response)<br> throws IOException, ServletException {</p>
<p> response.setContentType(“text/html”);</p>
<p> PrintWriter out = response.getWriter();<br> out.println(“<!doctype html>“);<br> out.println(“<html><head><title>Request Parameters</title></head>“);<br> out.println(“<body>“);<br> out.println(“<table align=center border=1>“);<br> out.println(“<tr><th>Parameters</th><th>Value</th></tr>“);</p>
<p> String para = null;<br> Enumeration<String> e = request.getParameterNames();<br> while(e.hasMoreElements()) {<br> para = e.nextElement();<br> if(para != null){<br> out.println(“<tr><td align=center>“ + para + “</td>“);<br> out.println(“<td align=center>“ + request.getParameter(para) + “</td></tr>“);<br> }<br> }</p>
<p> out.println(“</table>“);<br> out.println(“</body></html>“);<br> }<br>}<br>[/java]</p>
<p><strong>输出</strong><br>使用URL <a href="http://127.0.0.1/hello/printParas/?a=1&amp;b=2&amp;c=3&amp;d=4">http://127.0.0.1/hello/printParas/?a=1&amp;b=2&amp;c=3&amp;d=4</a> 访问样例程序，输出如下：</p>
<p>Parameters</p>
<p>Value</p>
<p>d</p>
<p>4</p>
<p>b</p>
<p>2</p>
<p>c</p>
<p>3</p>
<p>a</p>
<p>1</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>java servlet 3 入门</title>
    <url>/2013/09/30/servlet3-hello/</url>
    <content><![CDATA[<p>web开发没怎么搞过，还是看好java ee在web开发领域的实力。servlet 3 来了，写个简单的hello world程序，熟悉熟悉。</p>
<a id="more"></a>
<p><strong>开发环境：</strong><br>linux debian jessie + openjdk 7 + tomcat 7,具体安装配置不详述，安装debian官方源里的包即可，简单快捷。</p>
<p><strong>目录结构</strong><br>web程序的根目录为hello,其目录结构如下：<br>[java]<br>hello<br>– common<br>– css<br>– html<br>– images<br>– js<br>– src<br> `– HelloServlet3.java<br>`– WEB-INF<br> – classes<br> `– HelloServlet3.class<br> – lib<br> `– web.xml<br>[/java]</p>
<p><strong>源代码</strong><br>HelloServlet3.java<br>[java]<br>import java.io.IOException;<br>import javax.servlet.ServletException;<br>import javax.servlet.annotation.WebServlet;<br>import javax.servlet.http.HttpServlet;<br>import javax.servlet.http.HttpServletRequest;<br>import javax.servlet.http.HttpServletResponse;</p>
<p>@WebServlet(name=”helloServlet3”,urlPatterns={“/“},loadOnStartup=1)<br>public class HelloServlet3 extends HttpServlet{<br> @Override<br> protected void doGet(HttpServletRequest request,HttpServletResponse response)<br> throws ServletException,IOException{</p>
<p> response.setContentType(“text/plain”);<br> response.getWriter().write(“hello servlet 3!”);<br> }</p>
<p> @Override<br> protected void doPost(HttpServletRequest request,HttpServletResponse response)<br> throws ServletException,IOException{</p>
<p> doGet(request,response);<br> }<br>}</p>
<p>[/java]</p>
<p><strong>部署描述符</strong><br>servlet 3支持使用注解来部署servlet，因此无需再用web.xml来部署servlet。此web应用的web.xml部署描述符只是一个空的骨架，内容如下：<br>[xml]<br><?xml version="1.0" encoding="UTF-8" ?></p>
<p><web-app 
 xmlns="http://java.sun.com/xml/ns/javaee"
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"
 version="3.0"></p>
</web-app>
\[/xml\]

<p>此例程使用@WebServlet注解来部署HelloServlet,与在web.xml中使用如下配置部署是一样的。<br>[java]<br> <servlet><br> <servlet-name>helloServlet3</servlet-name><br> <servlet-class>HelloServlet3</servlet-class><br> <load-on-startup>1</load-on-startup><br></servlet><br><servlet-mapping><br> <servlet-name>helloServlet3</servlet-name><br> <url-pattern>/</url-pattern><br></servlet-mapping><br>[/java]</p>
<p><strong>编译打包</strong></p>
<p>编译<br>$ javac -classpath /usr/share/java/servlet-api-3.0.jar HelloServlet3.java</p>
<p>编译完成后生成class文件HelloServlet3.class,将其拷贝到WEB-INF/classes/目录下</p>
<p>打包<br>切换到web应用程序根目录hello，然后执行<br>$ jar cvf hello.war *</p>
<p>added manifest<br>adding: common/(in = 0) (out= 0)(stored 0%)<br>adding: css/(in = 0) (out= 0)(stored 0%)<br>adding: html/(in = 0) (out= 0)(stored 0%)<br>adding: images/(in = 0) (out= 0)(stored 0%)<br>adding: js/(in = 0) (out= 0)(stored 0%)<br>adding: src/(in = 0) (out= 0)(stored 0%)<br>adding: src/HelloServlet3.class(in = 923) (out= 532)(deflated 42%)<br>adding: src/HelloServlet3.java(in = 796) (out= 292)(deflated 63%)<br>adding: WEB-INF/(in = 0) (out= 0)(stored 0%)<br>adding: WEB-INF/lib/(in = 0) (out= 0)(stored 0%)<br>adding: WEB-INF/web.xml(in = 295) (out= 168)(deflated 43%)<br>adding: WEB-INF/classes/(in = 0) (out= 0)(stored 0%)<br>adding: WEB-INF/classes/HelloServlet3.class(in = 923) (out= 532)(deflated 42%)</p>
<p><strong>部署访问</strong><br>将hello.war拷贝到tomcat7默认的虚拟主机目录下</p>
<p>#cp hello.war /var/lib/tomcat7/webapps/</p>
<p>默认配置下hello.war会被展开到一个文件夹hello，这是因为/etc/tomcat7/server.xml里面默认配置的host的unpackWARs属性为true。</p>
<p>用浏览器打开地址<a href="http://127.0.0.1/hello,%E6%B5%8F%E8%A7%88%E5%99%A8%E4%BC%9A%E8%BE%93%E5%87%BA%EF%BC%9A">http://127.0.0.1/hello,浏览器会输出：</a></p>
<p>hello servlet 3!</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建git服务器</title>
    <url>/2019/07/29/setu-git-server/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用git和ssh搭建一个私有的小型git服务器</p>
<p><strong>安装</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt install git openssh-server</span><br></pre></td></tr></table></figure>

<p><strong>创建用户</strong></p>
<p>使用git用户来运行git服务</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># adduser git</span><br></pre></td></tr></table></figure>

<p><strong>添加用户公钥</strong></p>
<p>把所有用户的公钥导入到/home/git/.ssh/authorized_keys文件里，一个公钥独占一行。</p>
<p><strong>初始化仓库</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># su - git</span><br><span class="line">$ git init --bare test.git</span><br></pre></td></tr></table></figure>

<p><strong>克隆仓库</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone git@server:test</span><br></pre></td></tr></table></figure>

<p><strong>禁止git用户登录</strong></p>
<p>将git用户的shell修改为/usr/bin/git-shell</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># usermod --shell=/usr/bin/git-shell git</span><br></pre></td></tr></table></figure>

<p>或者直接修改/etc/passwd文件</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>setuid与setgid</title>
    <url>/2015/04/07/setuid-setgid/</url>
    <content><![CDATA[<a id="more"></a>
<p>setuid与setgid使可执行二进制文件(不包括脚本)无论用哪个用户执行都具有文件属主或属组的权限。<br>比如一个文件的属主为root,如果设置了setuid位,则一个非特权用户执行此程序时就可以以root的身份运行此程序，可以访问到非特权用户访问不到的用户资源。setgid与此同。</p>
<p>setuid</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># chmod u+s binary </span><br></pre></td></tr></table></figure>

<p>setgid</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># chmod g+s binary</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建debian源镜像服务器</title>
    <url>/2013/01/29/setup-debian-archive-mirror/</url>
    <content><![CDATA[<p>内网的linux服务器越来越多,有必要搭建一个内网debian源镜像服务器</p>
<a id="more"></a>
<p>debian官方提供了建设源镜像的脚本<a href="http://ftp-master.debian.org/ftpsync.tar.gz">ftpsync</a>,而且有<a href="http://www.debian.org/mirror/ftpmirror">详细的源镜像设置说明</a></p>
<p><strong>准备工作</strong></p>
<p>ftpsync使用rsync程序进行源镜像</p>
<h1 id="apt-get-install-rsync"><a href="#apt-get-install-rsync" class="headerlink" title="apt-get install rsync"></a>apt-get install rsync</h1><p>从官方下载ftpsync脚本</p>
<h1 id="wget-http-ftp-master-debian-org-ftpsync-tar-gz"><a href="#wget-http-ftp-master-debian-org-ftpsync-tar-gz" class="headerlink" title="wget http://ftp-master.debian.org/ftpsync.tar.gz"></a>wget <a href="http://ftp-master.debian.org/ftpsync.tar.gz">http://ftp-master.debian.org/ftpsync.tar.gz</a></h1><p><strong>配置ftpsync</strong></p>
<p>ftpsync使用环境变量BASEDIR来定位程序文件、配置文件和日志文件等的存放路径，BASEDIR默认取值${HOME},可以将ftpsync放置到用户主目录下</p>
<p>在用户主目录下新建bin,etc,log目录，解压ftpsync,</p>
<p>$ tar zxvf ftpsync.tar.gz<br>$ cp distrib/bin/ftpsync ~/bin<br>$ cp distrib/etc/ftpsync.conf.sample ~/etc/ftpsync.conf<br>$ cp distrib/etc/common ~/etc/common</p>
<p>建立存放镜像文件的单独目录，各种架构需要的<a href="http://www.debian.org/mirror/size">磁盘空间</a>，当前镜像all,amd64和source总共约需要190G硬盘空间。<br>可以在任何位置存放镜像，只要运行ftpsync的用户对目录有读写权限即可。此处使用/srv/mirrors/debian存放镜像文件，将目录的所有者和所属组设置为当前用户。</p>
<p>最后打开~/etc/ftpsync.conf,修改以下内容：</p>
<p>TO=”/srv/mirrors/debian/“ ##镜像源存放位置<br>RSYNC_HOST=”ftp.cn.debian.org” ##镜像自哪个外部源,debian中国官方源镜像是最佳选择，当然ftp.tw.debian.org,ftp.kr.debian.org和ftp.jp.debian.org速度也很快，<a href="http://lug.ustc.edu.cn/blog/2011/05/ftp-cn-debian-org-comes/">中国官方源镜像</a>由中国科技大学维护<br>ARCH_EXCLUDE=”alpha arm armel armhf hppa hurd-i386 i386 ia64 kfreebsd-amd64 kfreebsd-i386 m68k mipsel mips powerpc s390 s390x sh sparc source” ##排除的架构，此处只保留amd64源，source源也排除，只镜像必要的，尽量节省硬盘空间。</p>
<p><strong>注</strong>：当前脚本排除source镜像会提示错误：<br>Unexpected remote arg: ftp.cd.debian.org::debian<br>rsync error: syntax or usage error (code 1) at main.c(1232) [sender=3.0.9]<br>不要排除source可解决此错误。</p>
<p><strong>推送模式镜像服务器</strong></p>
<p>当档案库有变化时，上游源镜像服务器会主动向下游镜像服务器推送同步通知,然后下游源镜像服务器就可以及时的更新自己的档案库，这就是<a href="http://www.debian.org/mirror/push_mirroring">推模式镜像</a>。debian的主服务器与下游镜像服务器之间即采用此种模式。</p>
<p>此种模式需要下游镜像服务器配置ssh服务，上游镜像服务器使用ssh来通知下游服务器。可以使用一个普通用户来接受通知，将上游镜像服务器的公钥保存在~/.ssh/authorized_keys文件中，并且在此文件中添加如下语句以限制上游镜像服务器的权限</p>
<p>no-port-forwarding,no-X11-forwarding,no-agent-forwarding,no-pty,command=”~/bin/ftpsync”,from=”ip_address”</p>
<p>此处ip_address即上游镜像服务器的IP地址。<br>而且上游upstream镜像服务器还可以通过用户名/密码来授权谁可以向某些下游镜像服务器进行推送，并且这些用户名/密码是与系统隔离的，并不是使用/etc/passwd,进一步增强安全性。</p>
<p>使用推送模式同步需要将下游downstream服务器地址，ssh端口和使用的用户告知上游源镜像服务器维护者</p>
<p>对于企业内部的源镜像服务器，没有必要使用推模式，只要在空闲时段定时与上游源镜像服务器同步即可。</p>
<p><strong>让ftpsync自动运行</strong> </p>
<p>使用cron让ftpsync定时自动运行，/etc/cron.d/目录下添加文件ftpsync,内容如下：</p>
<p>SHELL=/bin/bash<br>PATH=/home/username/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin</p>
<p>#minute hour day_of_month month day_of_week user command<br>01 * **username ftpsync</p>
<p>username为运行ftpsync脚本的用户,每天凌晨1点自动运行ftpsync脚本与上游源镜像服务器同步</p>
<p><strong>源镜像http配置</strong></p>
<p>内网其他用户需要通过http或者ftp协议从本地源镜像服务器更新系统，此处使用apache来提供http方式的源镜像服务</p>
<h1 id="apt-get-install-apache2"><a href="#apt-get-install-apache2" class="headerlink" title="apt-get install apache2"></a>apt-get install apache2</h1><p>/etc/apache2/sites-available/目录下添加文件debian_mirror,内容如下：</p>
<p> 1 &lt;VirtualHost *:80&gt;<br> 2<br> 3     DocumentRoot /srv/mirrors/debian<br> 4     #<Directory /><br> 5     #    Options FollowSymLinks<br> 6     #    AllowOverride None<br> 7     #</Directory><br> 8     &lt;Directory /srv/mirrors/debian&gt;<br> 9         Options Indexes SymlinksIfOwnerMatch FollowSymLinks MultiViews<br>10         IndexOptions NameWidth=* SuppressDescription<br>11         AllowOverride None<br>12         Order allow,deny<br>13         allow from all<br>14     </Directory><br>15<br>16     ErrorLog ${APACHE_LOG_DIR}/debian_mirror_error.log<br>17<br>18     # Possible values include: debug, info, notice, warn, error, crit,<br>19     # alert, emerg.<br>20     LogLevel warn<br>21<br>22     CustomLog ${APACHE_LOG_DIR}/debian_mirror_access.log combined<br>23 </VirtualHost> </p>
<p>然后/etc/apache2/sites-enabled目录下新建符号链接,此处将其设置为默认网站，也可以使用虚拟主机</p>
<h1 id="rm-000-default"><a href="#rm-000-default" class="headerlink" title="rm 000-default"></a>rm 000-default</h1><h1 id="ln-sf-etc-apache2-sites-available-debian-mirror-000-default"><a href="#ln-sf-etc-apache2-sites-available-debian-mirror-000-default" class="headerlink" title="ln -sf /etc/apache2/sites-available/debian_mirror 000-default"></a>ln -sf /etc/apache2/sites-available/debian_mirror 000-default</h1><p>最后</p>
<h1 id="etc-init-d-apache2-reload"><a href="#etc-init-d-apache2-reload" class="headerlink" title="/etc/init.d/apache2 reload"></a>/etc/init.d/apache2 reload</h1><p><strong>使用本地源镜像服务</strong></p>
<p>编辑/etc/apt/source.list,添加<br>deb <a href="http://mirror_ip/">http://mirror_ip</a> wheezy main contrib non-free<br>deb <a href="http://mirror_ip/">http://mirror_ip</a> wheezy-updates main contrib non-free<br>deb <a href="http://mirror_ip/">http://mirror_ip</a> wheezy-proposed-updates main contrib non-free</p>
<p>mirror_ip即是新建的源镜像服务器的IP地址。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Shadowsocks科学上网</title>
    <url>/2015/06/26/shadowsocks-fuck-gfw/</url>
    <content><![CDATA[<p>ssh tunnel全面失效,WTF!</p>
<a id="more"></a>
<p>ssh tunnel无论如何更改端口都无效了，听说Shadowsocks科学上网不错，记录一下安装过程．</p>
<p>为了使用Gmail也是拼了！当然前提是要有个VPS,我用linode．</p>
<p><strong>服务器端</strong></p>
<p>安装</p>
<p>/etc/apt/sources.list目录下添加shadowsocks.list,文件内容如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">deb http:<span class="comment">//shadowsocks.org/debian wheezy main</span></span><br></pre></td></tr></table></figure>

<p>添加GPG公钥</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget -O- http:<span class="comment">//shadowsocks.org/debian/1D27208A.gpg sudo apt-key add -</span></span><br></pre></td></tr></table></figure>

<p>最后安装：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get update</span><br><span class="line">$ sudo apt-get install shadowsocks-libev</span><br></pre></td></tr></table></figure>

<p>配置:<br>/etc/shadowsocks-libev/config.json</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;server&quot;</span>:<span class="string">&quot;your_server_ip&quot;</span>,</span><br><span class="line"> <span class="string">&quot;server_port&quot;</span>:<span class="number">8388</span>,</span><br><span class="line"> <span class="string">&quot;local_port&quot;</span>:<span class="number">1080</span>,</span><br><span class="line"> <span class="string">&quot;password&quot;</span>:<span class="string">&quot;barfoo!&quot;</span>,</span><br><span class="line"> <span class="string">&quot;timeout&quot;</span>:<span class="number">60</span>,</span><br><span class="line"> <span class="string">&quot;method&quot;</span>:<span class="string">&quot;aes-256-cfb&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>填上服务器密码,修改一下访问密码,加密方法选择高强度加密方法aes-256-cfb,最后重新启动shadowsocks-libev即可．</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service shadowsocks-libev restart</span><br></pre></td></tr></table></figure>

<p><strong>客户端</strong></p>
<p>linux(debian testing Stretch):<br>安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install shadowsocks</span><br></pre></td></tr></table></figure>

<p>配置:<br>/etc/shadowsocks/config.json</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="string">&quot;server&quot;</span>:<span class="string">&quot;my_server_ip&quot;</span>,</span><br><span class="line"> <span class="string">&quot;server_port&quot;</span>:<span class="number">8388</span>,</span><br><span class="line"> <span class="string">&quot;local_address&quot;</span>: <span class="string">&quot;127.0.0.1&quot;</span>,</span><br><span class="line"> <span class="string">&quot;local_port&quot;</span>:<span class="number">1080</span>,</span><br><span class="line"> <span class="string">&quot;password&quot;</span>:<span class="string">&quot;mypassword&quot;</span>,</span><br><span class="line"> <span class="string">&quot;timeout&quot;</span>:<span class="number">300</span>,</span><br><span class="line"> <span class="string">&quot;method&quot;</span>:<span class="string">&quot;aes-256-cfb&quot;</span>,</span><br><span class="line"> <span class="string">&quot;fast_open&quot;</span>: <span class="literal">false</span>,</span><br><span class="line"> <span class="string">&quot;workers&quot;</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>修改与服务器相关的item<br>默认安装的shadowsocks是用于启动服务器的,因此修改一下/etc/init.d/shadowsocks使其用于运行客户端daemon程序</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">#DAEMON=/usr/bin/ssserver # Introduce the server&#x27;s location here</span><br><span class="line">DAEMON=/usr/bin/sslocal # Introduce the cilent&#x27;s location here</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>保存后重新启动shadowsocks</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service shadowsocks restart</span><br></pre></td></tr></table></figure>

<p>客户端软件访问本地端口127.0.0.1:1080即可．</p>
<p>Mac OS X:<br>下载安装<a href="https://github.com/shadowsocks/shadowsocks-iOS/releases">ShadowsocksX</a></p>
<p>References:<br>[1]<a href="https://github.com/shadowsocks/shadowsocks">shadowsocks</a><br>[2]<a href="https://github.com/shadowsocks/shadowsocks-libev">shadowsocks-libev</a><br>[3]<a href="https://wiki.archlinux.org/index.php/Shadowsocks_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">Shadowsocks (简体中文)</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>缩小qcow2格式kvm虚拟镜像磁盘大小</title>
    <url>/2012/04/26/shrink-kvm-qcow2-disk/</url>
    <content><![CDATA[<p>qcow2格式的虚拟磁盘初始容量设置过大,虽然并不会实际占用主机这么大的磁盘空间,只占用客户机实际使用的空间大小,但有时候还是有些不太方便,所以需要将其收缩(shrink)以下。</p>
<a id="more"></a>
<p>qemu-img命令有一个选项resize可以改变磁盘镜像的大小,其格式如下</p>
<p>#qemu-img resize filename [+-]size</p>
<p>+就是增加磁盘镜像的大小,-就是缩小磁盘镜像的大小,此处的磁盘镜像的大小并不是磁盘镜像文件在KVM主机中实际占用的存储空间大小,而是KVM客户机看到的磁盘的大小。</p>
<p>但是扩大或收缩磁盘镜像大小远没有这么简单。</p>
<p>man qemu-img如是说:<br>当使用此命令收缩磁盘镜像之前,必须使用客户机的文件系统和分区工具来收缩文件系统和分区,然后再执行resize操作,不然会可能丢失数据。当使用此命令扩大了磁盘镜像之后,必须使用客户机的文件系统和分区工具来使用新增加的磁盘容量。这很好理解,KVM支持的客户机操作系统多种多样,而且都有成熟的文件系统和分区操作工具,resize操作只是简单的扩大或缩小磁盘镜像大小,而不能也无需来了解客户机怎么应对这个改变,这是客户机的事情。面对这么多种类型的客户机,resize也只能做这么多工作了。</p>
<p>不幸的是resize尚不支持qcow2格式的磁盘镜像收缩,会有提示</p>
<p>qemu-img: This image format does not support resize</p>
<p>但是扩大qcow2磁盘镜像没有问题。磁盘镜像扩大另文再叙,先说下缩小,针对不同的客户机会有不同的操作方式。</p>
<p><strong>linux客户机</strong></p>
<p>这里收缩的是一个debian客户机磁盘镜像,其他linux客户机应无不同。</p>
<p>主要的思路就是通过分配一个新的小容量的磁盘镜像,挂载为虚拟机的新的磁盘,然后使用gparted live cd启动虚拟机,将分区拷贝到新的磁盘,然后用新的磁盘启动客户机。</p>
<p>主要步骤如下：</p>
<ol>
<li><p>创建新的小容量的磁盘镜像</p>
<p> #qemu-img create -f qcow2 debian_new.qcow2 15G<br> Formatting ‘debian_new.qcow2’, fmt=qcow2 size=16106127360 encryption=off cluster_size=65536<br> 下载<a href="http://gparted.sourceforge.net/">GParted</a> live cd iso镜像,将二者挂载为客户机的新磁盘驱动器和光驱<br>  1 #!/bin/bash<br> 2<br> 3 kvm -bios /usr/share/seabios/bios.bin -smp 32 -m 2G -rtc base=utc,clock=host     <strong>\</strong><br> 4     -net nic,model=virtio,macaddr=52-54-00-12-34-02 -net tap,ifname=tap2                   <strong>\</strong><br> 5     -boot order=d -no-fd-bootchk                                                            <strong>\</strong><br> 6     -drive file=debian.qcow2,if=virtio,index=0,media=disk,format=qcow2,cache=writeback  <strong>\</strong><br> 7     -drive file=debian_new.qcow2,if=virtio,index=1,media=disk,format=qcow2,cache=writeback  <strong>\</strong><br> 8     -drive file=gparted.iso,index=2,media=cdrom  <strong>\</strong><br> 9     -vnc :0<br> 启动虚拟机</p>
</li>
</ol>
<p>为新硬盘分区,然后将老硬盘上的分区拷贝到新的硬盘分区,如果原硬盘上的分区大于新的硬盘上的分区,可以通过GParted将原分区resize到小于新分区即可。交换分区不用拷贝,只要划出交换分区,在客户机内重新设置即可。分区拷贝完成后关闭虚拟机。<br>2.  用原硬盘引导客户机,使用dd将原硬盘的MBR及grub2用到的扇区拷贝到新的硬盘,grub2用到了MBR后面的保留扇区。这个保留扇区叫做post-MBR gap,范围为MBR之后,第一个分区之前。</p>
<pre><code>#fdisk -l
Disk /dev/vda: 64.4 GB, 64424509440 bytes
255 heads, 63 sectors/track, 7832 cylinders, total 125829120 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x000c6773

 Device Boot Start End Blocks Id System
/dev/vda1 * 2048 27262975 13630464 83 Linux
/dev/vda2 120637438 125827071 2594817 5 Extended
/dev/vda5 120637440 125827071 2594816 82 Linux swap / Solaris

Disk /dev/vdb: 16.1 GB, 16106127360 bytes
255 heads, 63 sectors/track, 1958 cylinders, total 31457280 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x0005fc82

 Device Boot Start End Blocks Id System
/dev/vdb1 2048 27262975 13630464 83 Linux
/dev/vdb2 27262976 31457279 2097152 82 Linux swap / Solaris

可以看到客户机磁盘的第一个分区从2048扇区开始,保留扇区为2-2047扇区,第一扇区为MBR。因为两个硬盘分区并不完全相同,所以只拷贝MBR中的前446字节的引导代码即可。

拷贝MBR引导代码
#dd if=/dev/vda of=/dev/vdb bs=446 count=1
拷贝保留扇区
#dd if=/dev/vda of=/dev/vdb bs=512 seek=1 skip=1 count=2046</code></pre>
<ol start="3">
<li><p>关闭客户机,为客户机换上新的硬盘并从新硬盘启动<br> 一般来说拷贝过来的分区与原分区有相同的UUID,如若不然,新硬盘将无法引导客户机,但新建的swap分区其UUID发生了变化</p>
<p> 查看新硬盘分区的UUID<br> #blkid<br> /dev/vda1: UUID=”48ed13f7-8640-4aba-8b8a-5efb087fadbf” TYPE=”ext4”<br> /dev/vda2: UUID=”b484c752-69be-4bcd-86c1-a3f70185cde1” TYPE=”swap”</p>
<p> 打开/etc/fstab文件,将自动挂载文件系统的UUID修改成新硬盘上对应分区的UUID</p>
<p> 重新启动客户机,调整完毕。</p>
</li>
</ol>
<p><strong>windows客户机</strong></p>
<ol>
<li><p>创建新的小容量的磁盘镜像</p>
<p> #qemu-img create -f qcow2 windows_new.qcow2 20G<br> 将其挂载为客户机的第二块硬盘,将GParted挂载为客户机的光驱,设置客户机为光驱启动并启动客户机</p>
</li>
<li><p> 用gparted resize调整老硬盘分区使其略小于新硬盘容量并apply</p>
</li>
</ol>
<ol start="3">
<li><p>打开终端<br> $sudo su -<br> #dd if=/dev/vda of=/dev/vdb bs=512 count=1<br> 将老硬盘的MBR完整复制到新硬盘</p>
</li>
<li><p> 用GParted复制老硬盘分区至新硬盘,然后resize拷贝过来的分区至新硬盘全部容量</p>
</li>
<li><p> 将新硬盘挂载为客户机的第一块硬盘,并从新硬盘启动即可。启动时windows会检查磁盘,之后一切正常。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>KVM</tag>
      </tags>
  </entry>
  <entry>
    <title>shutdown immediate 无响应</title>
    <url>/2015/07/17/shutdown-immediate-hang/</url>
    <content><![CDATA[<a id="more"></a>
<p>shutdown immediate有时候会长时间挂起(hang),一般是因为在等待某些进程关闭。<br>不要轻易尝试shutdown abort,shutdown abort之后启动时，需要进行实例恢复，容易出现问题。</p>
<p>据说startup force会中止当前数据库的运行，并开始重新正常的启动数据库，没试过，最好也不好尝试。</p>
<p>最佳的办法还是找到等待的进程，将其kill之后，再行shutdown immediate。 </p>
<p>References:<br>[1]<a href="http://blog.chinaunix.net/uid-15866552-id-3419874.html">oracle shutdown 没有反应</a><br>[2]<a href="http://www.cnblogs.com/kerrycode/p/3435581.html">Oracle shutdown immediate无法关闭数据库解决方法</a><br>[3]<a href="http://www.cnblogs.com/dba_xiaoqi/archive/2010/11/02/1867059.html">oracle shutdown immediate 一直没反应解决方案</a></p>
<p>===<br><strong>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>基于KWinUI的换肤框架KSkinX的简单Demo</title>
    <url>/2009/08/14/skin-demo/</url>
    <content><![CDATA[<p>KWinUI虽然很简洁，但仍然可以做不少事情。曾经有段时间，基于KWinUI写了一个换肤框架叫做KSkinX，现在就放出KSkinX的一个简单Demo。因为KSkinX还比较粗糙，比如滚动条的换肤尚未实现、标题栏按钮的处理还有待改进、实现的窗口组件还太少等原因，所以暂时还不开放源代码。</p>
<p>下面是这个换肤Demo的snapshots:<br>[gallery link=”file” columns=”2” orderby=”title”]</p>
<p>Demo程序<a href="/downloads/kwinui/skin_demo.zip">从此</a>下载。</p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>权限导致soffice(libreoffice/openoffice)无法运行的问题</title>
    <url>/2016/09/17/soffice-permission-deny-issues/</url>
    <content><![CDATA[<a id="more"></a>
<p>以tomcat8用户运行soffice服务：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u tomcat8 soffice --accept=<span class="string">&quot;socket,host=0,port=8100;urp;StarOffice.ServiceManager&quot;</span> --headless --nofirststartwizard --nologo --nodefault --nocrashreport --nolockcheck &amp;</span><br></pre></td></tr></table></figure>

<p>提示错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[Java framework\] <span class="built_in">Error</span> <span class="keyword">in</span> <span class="function"><span class="keyword">function</span> <span class="title">createSettingsDocument</span> (<span class="params">elements.cxx</span>).</span></span><br><span class="line"><span class="function"><span class="title">javaldx</span> <span class="title">failed</span>!</span></span><br><span class="line"><span class="function"><span class="title">Warning</span>: <span class="title">failed</span> <span class="title">to</span> <span class="title">read</span> <span class="title">path</span> <span class="title">from</span> <span class="title">javaldx</span></span></span><br></pre></td></tr></table></figure>

<p>这是由于soffice没有权限无法写配置文件造成的错误。<br>tomcat8的用户主目录为/usr/share/tomcat8，此目录的所有者和组都是root，soffice需要在用户主目录下写.config和其他配置文件才能正常工作，所以造成了以上问题。</p>
<p>如果非要使用tomcat8用户来运行soffice,则可以这样来解决此问题：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo chown tomcat8:tomcat8 /usr/share/tomcat8</span><br></pre></td></tr></table></figure>

<p>如果一个用户对自己的主目录都没有所有权，这怎么也说不过去吧。</p>
<p><strong>update(17/10/2019):</strong><br>tomcat9 on debian buster系统,启动soffice时提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">javaldx failed!</span><br><span class="line">Warning: failed to read path <span class="keyword">from</span> javaldx</span><br><span class="line"></span><br><span class="line">(process:<span class="number">12586</span>): dconf-CRITICAL **: <span class="number">09</span>:<span class="number">57</span>:<span class="number">38.865</span>: unable to create directory <span class="string">&#x27;/.cache/dconf&#x27;</span>: Permission denied. dconf will not work properly.</span><br></pre></td></tr></table></figure>
<p>tomcat9在系统内的用户为tomcat，主目录为/</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop tomcat9.service</span><br><span class="line">$ sudo usermod --home /usr/share/tomcat9 tomcat</span><br><span class="line">$ sudo chown tomcat /usr/share/tomcat9</span><br></pre></td></tr></table></figure>
<p>再次运行soffice一切正常。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo -u tomcat8 /usr/bin/tomcat soffice --accept=<span class="string">&quot;socket,host=0,port=8100;urp;StarOffice.ServiceManager&quot;</span> --headless --nofirststartwizard --nologo --nodefault --nocrashreport --nolockcheck &amp;</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>一条命令统计源代码行数</title>
    <url>/2015/03/30/souece-code-line-stat/</url>
    <content><![CDATA[<a id="more"></a>
<p>一条命令统计源代码行数<br><code>js$ find . -name &quot;*.java&quot; -or -name &quot;*.js&quot; xargs wc -l sort -g</code></p>
<p>只输出总行数:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ find . -name <span class="string">&quot;*.java&quot;</span> xargs wc -l sort -g grep <span class="string">&#x27;total&#x27;</span> awk <span class="string">&#x27;&#123;print $1&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>去空行版:<br><code>js$ find . -name &quot;*.java&quot; xargs grep -v &quot;^$&quot; wc -l </code></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>拆分sstables</title>
    <url>/2019/07/31/split-sstables/</url>
    <content><![CDATA[<a id="more"></a>
<p>因为使用默认的compaction策略SizeTieredCompactionStrategy，导致产生了几个巨大的sstable，虽然已经更改为了LeveledCompactionStrategy策略，但是cassadra自动进行major compaction的时候因为需要巨大的空闲存储空间出错了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">WARN \[CompactionExecutor:<span class="number">6</span>\] <span class="number">2019</span>-<span class="number">07</span>-<span class="number">31</span> <span class="number">16</span>:<span class="number">32</span>:<span class="number">15</span>,<span class="number">726</span> CompactionTask.java:<span class="number">298</span> - Not enough space <span class="keyword">for</span> compaction, estimated sstables = <span class="number">8643</span>, expected write size = <span class="number">2320284556243</span></span><br><span class="line">ERROR \[CompactionExecutor:<span class="number">6</span>\] <span class="number">2019</span>-<span class="number">07</span>-<span class="number">31</span> <span class="number">16</span>:<span class="number">32</span>:<span class="number">15</span>,<span class="number">727</span> CassandraDaemon.java:<span class="number">195</span> - Exception <span class="keyword">in</span> thread Thread\[CompactionExecutor:<span class="number">6</span>,<span class="number">1</span>,main\]</span><br><span class="line">java.lang.RuntimeException: Not enough space <span class="keyword">for</span> compaction, estimated sstables = <span class="number">8643</span>, expected write size = <span class="number">2320284556243</span></span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionTask.checkAvailableDiskSpace(CompactionTask.java:<span class="number">299</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:<span class="number">119</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:<span class="number">28</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:<span class="number">74</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:<span class="number">59</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:<span class="number">257</span>) ~\[apache-cassandra-<span class="number">2.2</span><span class="number">.14</span>.jar:<span class="number">2.2</span><span class="number">.14</span>\]</span><br><span class="line">at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:<span class="number">511</span>) ~\[na:<span class="number">1.8</span><span class="number">.0_211</span>\]</span><br><span class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:<span class="number">266</span>) ~\[na:<span class="number">1.8</span><span class="number">.0_211</span>\]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>) ~\[na:<span class="number">1.8</span><span class="number">.0_211</span>\]</span><br><span class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>) \[na:<span class="number">1.8</span><span class="number">.0_211</span>\]</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">748</span>) \[na:<span class="number">1.8</span><span class="number">.0_211</span>\]</span><br></pre></td></tr></table></figure>

<p>所有可以借助离线工具sstablesplit拆分大的sstables，拆分后使用LCS策略进行compaction就不需要那么多的空闲磁盘空间了。</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install cassandra-tools</span><br></pre></td></tr></table></figure>
<p>cassandra-tools包中包含sstablesplit和sstablemeta等工具</p>
<p><strong>停止cassandra</strong></p>
<p>要注意，拆分sstable一定要在离线状态下进行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop cassandra</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo kill -sigterm &lt;pid_of_cassandra&gt;</span><br></pre></td></tr></table></figure>

<p><strong>拆分</strong></p>
<p>sstablesplit帮助信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sstablesplit -h</span><br><span class="line">usage: sstablesplit \[options\] &lt;filename&gt; \[&lt;filename&gt;\]*</span><br><span class="line">--</span><br><span class="line">Split the provided sstables files <span class="keyword">in</span> sstables <span class="keyword">of</span> maximum provided filesize (see option --size).</span><br><span class="line">--</span><br><span class="line">Options are:</span><br><span class="line"> --debug display stack traces</span><br><span class="line"> -h,--help display <span class="built_in">this</span> help message</span><br><span class="line"> --no-snapshot don<span class="string">&#x27;t snapshot the sstables before splitting</span></span><br><span class="line"><span class="string"> -s,--size &lt;size&gt; maximum size in MB for the output sstables (default:</span></span><br><span class="line"><span class="string"> 50)</span></span><br></pre></td></tr></table></figure>

<p>sstablesplit按给定的文件尺寸拆分指定的sstables，可以一次指定多个。注意文件权限的问题，使用cassandra用户来执行操作，下面是一个例子，：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo -u cassandra sstablesplit -s <span class="number">256</span> /<span class="keyword">var</span>/lib/cassandra/data/keyspace/table-xxxx/la-xxxx-big-Data.db</span><br></pre></td></tr></table></figure>

<p>拆分完成后cassandra可以重新上线。</p>
<p>sstablesplit设定的默认堆内存只有256M，拆分过程中出现了OOM错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Exception <span class="keyword">in</span> thread <span class="string">&quot;main&quot;</span> java.lang.OutOfMemoryError: Direct buffer memory</span><br><span class="line"> at java.nio.Bits.reserveMemory(Bits.java:<span class="number">694</span>)</span><br><span class="line"> at java.nio.DirectByteBuffer.&lt;init&gt;(DirectByteBuffer.java:<span class="number">123</span>)</span><br><span class="line"> at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:<span class="number">311</span>)</span><br><span class="line"> at org.apache.cassandra.io.compress.BufferType$2.allocate(BufferType.java:<span class="number">35</span>)</span><br><span class="line"> at org.apache.cassandra.io.compress.CompressedSequentialWriter.&lt;init&gt;(CompressedSequentialWriter.java:<span class="number">70</span>)</span><br><span class="line"> at org.apache.cassandra.io.util.SequentialWriter.open(SequentialWriter.java:<span class="number">168</span>)</span><br><span class="line"> at org.apache.cassandra.io.sstable.format.big.BigTableWriter.&lt;init&gt;(BigTableWriter.java:<span class="number">75</span>)</span><br><span class="line"> at org.apache.cassandra.io.sstable.format.big.BigFormat$WriterFactory.open(BigFormat.java:<span class="number">107</span>)</span><br><span class="line"> at org.apache.cassandra.io.sstable.format.SSTableWriter.create(SSTableWriter.java:<span class="number">84</span>)</span><br><span class="line"> at org.apache.cassandra.db.compaction.writers.MaxSSTableSizeWriter.append(MaxSSTableSizeWriter.java:<span class="number">83</span>)</span><br><span class="line"> at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:<span class="number">186</span>)</span><br><span class="line"> at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:<span class="number">28</span>)</span><br><span class="line"> at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:<span class="number">74</span>)</span><br><span class="line"> at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:<span class="number">59</span>)</span><br><span class="line"> at org.apache.cassandra.db.compaction.SSTableSplitter.split(SSTableSplitter.java:<span class="number">44</span>)</span><br><span class="line"> at org.apache.cassandra.tools.StandaloneSplitter.main(StandaloneSplitter.java:<span class="number">156</span>)</span><br></pre></td></tr></table></figure>

<p>修改/usr/bin/sstablesplit脚本中的<code>MAX_HEAP_SIZE=&quot;256M&quot;</code>为<code>MAX_HEAP_SIZE=&quot;8192M&quot;</code>，重启一下cassandra会自动清除掉临时的sstables，<code>nodetool clearsnapshot</code>清除掉sstablesplit自动生成的快照，最后停止cassandra再重新拆分。</p>
<p><strong>删除再repair</strong></p>
<p>拆分大sstable需要离线操作，重新上线后应该需要repair,其实还有一种最小离线时间的方法，那就是”停止节点-&gt;删除大sstable-&gt;启动节点-&gt;repair节点”，这也是一种可行的方法。</p>
<p>References:<br>[1]<a href="https://docs.datastax.com/en/archived/cassandra/2.2/cassandra/tools/toolsSSTableSplit.html">sstablesplit</a><br>[2]<a href="https://support.datastax.com/hc/en-us/articles/115005668426-FAQ-How-to-split-large-SSTables-on-another-server">FAQ - How to split large SSTables on another server</a><br>[3]<a href="https://stackoverflow.com/questions/42042665/do-sstablesplit-on-the-side">do sstablesplit on the side</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>spring 3 使用注解配置Bean和依赖注入</title>
    <url>/2013/10/13/spring-annotation-bean-injection/</url>
    <content><![CDATA[<p>除了使用XML配置文件配置Bean和依赖元数据外，spring 3 还支持使用注解来配置相关的元数据。</p>
<a id="more"></a>
<p>Spring Framework 3 除了自己提供的注解如@Component,@Autowired之外，还支持JSR 250提供的@Resource等注解，JSR 330提供的@Inject等注解。</p>
<p><strong>使用注解定义配置Bean</strong></p>
<p><strong>1、spring提供的注解@Component,@Repository,@Service,@Controller</strong></p>
<p><strong>@Component等注解基本使用</strong></p>
<p>@Component是个一般性的注解，使用此注解修饰的POJO类，即成为spring容器管理的组件。而@Repository,@Service,@Controller这三个则是更语义化的注解，分别指名修饰的相应类为持久层，服务层和展示层组件。这四个注解本质上是一样的，但后三个未来可能会增加更多语义。</p>
<p>可以这样使用@Component</p>
<p>@Component<br>public class MyComponent () {…}</p>
<p>@Component(value=”aComponent”)<br>public class MyComponent () {…}</p>
<p>@Component(“aComponent”)<br>public class MyComponent () {…}</p>
<p>@Component有一个value属性，可以用来指定bean的名字，与xml文件中元素中的id含义相同，也可以省略掉value，直接写组件的名字，就像最后一个示例一样。如果不指定bean的名字，则spring会使用默认的BeanNameGenerator策略类来生成bean的名字，为小写开头的非限定类名，比如第一个示例的bean名字为myComponent。</p>
<p>@Component注解还可以与注解@Qualifier,@Scope,@Lazy，@Primary,@DependsOn合作进行更细粒度的bean配置。</p>
<p>@Qualifier 指定限定描述符，对应于基于XML配置中的<qualifier>标签,虽然@Qualifier向后兼容可以与bean id匹配，但@Qualifier指定的不是bean id,最好不要依赖于这一隐式的规则。bean id在整个容器内是独一无二的，但@Qualifier限定符却可以重复，特别是用于集合类时十分方便。</p>
<p>也可以扩展@Qualifier注解，提供更细致的限定匹配策略，而且更加语义化。比如：</p>
<p>@Target({ElementType.FIELD, ElementType.PARAMETER})<br>@Retention(RetentionPolicy.RUNTIME)<br>@Qualifier<br>public @interface Offline {<br>}</p>
<p>@Scope 用于指定bean 作用域，默认为singleton</p>
<p>@Lazy 指名bean延迟初始化，等需要时再初始化而不是容器初始化时就初始化bean。</p>
<p>@Primary 自动装配时当出现多个Bean候选者时，被注解为@Primary的Bean将作为首选者。</p>
<p>@DependsOn：定义Bean初始化及销毁时的顺序。</p>
<p><strong>扩展@Component</strong></p>
<p>可以通过自定义注解扩展@Component，定制更语义化的组件注解，只要在扩展的注解上注解@Component即可.其实@Repository、@Service、@Controller也是通过该方式实现的。</p>
<p>@Target({ElementType.TYPE})<br>@Retention(RetentionPolicy.RUNTIME)<br>@Documented<br>@Component<br>public @interface business{<br> String value() default “”;<br>} </p>
<p><strong>2、JSR 330的@Named注解</strong></p>
<p>Java标准中与@Component等价的注解是JSR 330提供的@Named注解，其用法与@Component相同，也有一个value属性可以指定bean id。</p>
<p><strong>使用注解注入依赖的bean</strong></p>
<p><strong>1、spring的@Autowired注解</strong></p>
<p>spring提供了@Autowired来自动注入依赖装配beans。@Autowired默认按类型(byType)来装配beans，可以与注解@Qualifier,@Required配合进行细类度的装配配置。<br>默认情况下，如果存在多个匹配的beans或者不存在匹配的bean，容器会抛出BeanCreationException异常。</p>
<p>@Required 指示必须存在匹配的依赖组件，否则会抛出异常。</p>
<p>@Qualifier 指定限定描述符，容器会匹配与限定描述符相一致的组件，即与组件的限定描述符一致的进行匹配。</p>
<p>@Autowired自身也有一个required属性，可以设定的值为true或false。推荐优先使用这个属性而不是注解@Required。</p>
<p><strong>2、JSR 250的@Resource注解</strong></p>
<p>@Resource注解默认按名称(byName)自动注入。@Resource有两个属性name和type,如果使用name属性，则使用byName的自动注入策略，而使用type属性时则使用byType自动注入策略。如果既不指定name也不指定type属性，则使用byName自动注入策略。</p>
<p>@Resource装配顺序<br>　　1. 如果同时指定了name和type，则从Spring上下文中找到唯一匹配的bean进行装配，找不到则抛出异常<br>　　2. 如果指定了name，则从上下文中查找名称（id）匹配的bean进行装配，找不到则抛出异常<br>　　3. 如果指定了type，则从上下文中找到类型匹配的唯一bean进行装配，找不到或者找到多个，都会抛出异常<br>　　4. 如果既没有指定name，又没有指定type，则自动按照byName方式进行装配；如果没有匹配，则回退为一个原始类型进行匹配，如果匹配则自动装配；</p>
<p><strong>3、JSR 330的@Inject注解</strong></p>
<p>@Inject可以注入依赖的bean,如果需要一个限定名字的依赖bean，可以与@Named配合使用，如</p>
<p>[java]<br>import javax.inject.Inject;<br>import javax.inject.Named;</p>
<p>public class SimpleMovieLister {</p>
<p> private MovieFinder movieFinder;</p>
<p> @Inject<br> public void setMovieFinder(@Named(“main”) MovieFinder movieFinder) {<br> this.movieFinder = movieFinder;<br> }<br> // …<br>}<br>[/java]</p>
<p>参考：<a href="http://docs.spring.io/spring/docs/3.2.4.RELEASE/spring-framework-reference/html/beans.htm">The IoC container</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Bean Scopes</title>
    <url>/2013/11/24/spring-bean-scopes/</url>
    <content><![CDATA[<a id="more"></a>
<p>Spring 3 内置支持5种scope(bound),还可以自定义scope。</p>
<ul>
<li>  <strong>singleton</strong></li>
</ul>
<p>如果没有明确的指定scope,默认就是singleton。Spring IoC容器只会创建一个singleton bean的实例，所有对这个bean的请求，spring都会返回这个实例。spring的singleton不同于GOF模式书中的singleton,GOF的singleton是每一个类装载器实例化一个对象，而spring是每一个容器实例化一个对象。<br>因为singleton是被共享的，因此singleton bean应该是无状态的，线程安全的，不然并发访问会出现问题。</p>
<ul>
<li>  <strong>prototype</strong></li>
</ul>
<p>每次请求prototype bean，容器会生成(或从缓存队列中挑选)一个新的bean实例，因此prototype bean没有并发的问题，因为没有共享问题。所有有状态的bean应该使用prototype scope,而所有无状态的bean应该使用singleton scope。<br>singleton bean的性能和节约资源方面会优于prototype bean</p>
<p>但是spring不会管理prototype bean的全部生命周期，spring只负责实例并初始化prototype bean，然后交付给客户就撒手不管了，客户使用完prototype bean后必须负责清理bean使用的资源。也可以通过<a href="http://docs.spring.io/spring/docs/3.2.4.RELEASE/spring-framework-reference/html/beans.html#beans-factory-extension-bpp">bean post-processor</a>让容器负责prototype bean的清理工作。</p>
<ul>
<li>  <strong>Request</strong></li>
</ul>
<p>每一个HTTP请求有一个Request scope bean的实例。每一个http请求会在一个单独的线程里处理，因此Request scope bean无需考虑并发问题。其他的HTTP请求不会看到另一个HTTP请求使用的bean实例的状态。</p>
<ul>
<li>  <strong>Session</strong></li>
</ul>
<p>每一个HTTP Session生成一个Session scope bean实例。会话之间是隔离的，因此也不会有并发问题。</p>
<ul>
<li>  <strong>Global session</strong></li>
</ul>
<p>只有portlet web应用程序中才有的scope,绑定到整个portlet Session。</p>
<p><strong>注意事项：</strong></p>
<p>1、只要有可能，尽量将bean设计为线程安全的，从而可以使用默认的singleton scope,提高程序的运行效率，减少对系统资源的占用。<br>可以通过使用ThreadLocal改造非线程安全的类，使其可以使用singleton scope。Spring和Mybatis的很多组件使用了这个技术。</p>
<p>2、@Controller, @Service, @Repository, @Compenent等注解修饰的bean默认都是singleton scope,因此一定要注意线程安全问题。非线程安全的类要么使用ThreadLocal改造为线程安全的，要么使用其他scope。</p>
<p>3、Request，Session和Global session只在web应用程序环境中存在。</p>
<p>4、通常不应该让容器管理细粒度的domain对象(又叫entity对象或者model对象)，因为创建和管理domain对象是DAO和业务逻辑层的职责。实际上一定不要让容器管理domain对象，因为domain对象是state full的，非线程安全的，自己管理比交给容器管理更容易，更少出问题。<br>Typically one does not configure fine-grained domain objects in the container, because it is usually the responsibility of DAOs and business logic to create and load domain objects.</p>
<p><strong>参考：</strong><br><a href="http://docs.spring.io/spring/docs/3.2.4.RELEASE/spring-framework-reference/html/beans.html#beans-factory-scopes">The IoC container</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring Framework,MyBatis,PostgreSQL整合示例</title>
    <url>/2013/10/16/spring-mybatis-postgres-integration/</url>
    <content><![CDATA[<p>Spring Framework,MyBatis,PostgreSQL整合</p>
<a id="more"></a>
<p><strong>简介</strong></p>
<p><a href="http://projects.spring.io/spring-framework/">Spring Framework</a>是优秀的JAVA应用程序开发框架和IoC容器，支持依赖注入，事务管理，Web MVC模式开发，数据存取，JMS等，是全功能(full stack)的开发框架。</p>
<p><a href="https://code.google.com/p/mybatis/">MyBatis</a>是ORM半自动映射框架，是支持普通SQL查询,存储过程和高级映射的优秀持久层框架，其架构十分灵活，允许用户定制OR影射规则，其精华在mapper。</p>
<p><a href="http://www.postgresql.org/">PostgreSQL</a>是最好的开源关系数据库，虽然现在使用的并不是很广泛。</p>
<p>企业应用开发可以整合Spring MVC，Spring，Mybatis，PostgreSQL实现一个完整的体系架构。Spring MVC作为MVC开发框架，Spring作为IoC容器，<br>MyBatis则为ORM持久层框架，底层使用PostgreSQL数据库。Spring MVC本来就是Spring Framework中的一个组件，所以二者是天然集成在一起的。</p>
<p><strong>集成配置</strong></p>
<p><strong>依赖</strong></p>
<p>因为Spring 3发布时，MyBatis 3尚未完成，所以MyBatis提供了与Spring集成的包<a href="http://mybatis.github.io/spring/">MyBatis-Spring</a>。所以需要下载MyBatis和MyBatis两个依赖包。<br>因为要使用数据库，所以需要Spring Famework提供的数据库相关的包,又因为Spring的事务管理框架是基于AOP实现的，所以还需要Spring AOP相关的jar包。<br>使用PostgresQL需要官方提供的<a href="http://jdbc.postgresql.org/">PostgreSQL JDBC驱动</a>。<br>使用<a href="http://www.mchange.com/projects/c3p0/">C3P0连接池</a>，需要C3P0的相关包。</p>
<p>整合需要添加的jar包汇总如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Spring:</span><br><span class="line">===</span><br><span class="line">spring-aop-<span class="number">3.2</span><span class="number">.4</span>.RELEASE.jar</span><br><span class="line">spring-aspects-<span class="number">3.2</span><span class="number">.4</span>.RELEASE.jar</span><br><span class="line">spring-jdbc-<span class="number">3.2</span><span class="number">.4</span>.RELEASE.jar</span><br><span class="line">spring-tx-<span class="number">3.2</span><span class="number">.4</span>.RELEASE.jar</span><br><span class="line"></span><br><span class="line">MyBatis:</span><br><span class="line">===</span><br><span class="line">asm-<span class="number">3.3</span><span class="number">.1</span>.jar</span><br><span class="line">cglib-<span class="number">2.2</span><span class="number">.2</span>.jar</span><br><span class="line">javassist-<span class="number">3.17</span><span class="number">.1</span>-GA.jar</span><br><span class="line">mybatis-<span class="number">3.2</span><span class="number">.3</span>.jar</span><br><span class="line">mybatis-spring-<span class="number">1.2</span><span class="number">.1</span>.jar</span><br><span class="line"></span><br><span class="line">PostgreSQL:</span><br><span class="line">===</span><br><span class="line">postgresql-<span class="number">9.2</span>-<span class="number">1003.</span>jdbc4.jar</span><br><span class="line"></span><br><span class="line">C3P0:</span><br><span class="line">===</span><br><span class="line">mchange-commons-java-<span class="number">0.2</span><span class="number">.3</span><span class="number">.4</span>.jar</span><br><span class="line">c3p0-<span class="number">0.9</span><span class="number">.2</span><span class="number">.1</span>.jar</span><br></pre></td></tr></table></figure>

<p>以上jar包都放入WEB-INF/lib目录下</p>
<p><strong>配置</strong></p>
<p>Spring配置文件spring-servlet.xml<br>[xml]<br> <!-- C3P0 pooled datasource --><br> <bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"
 destroy-method="close"><br> <property name="driverClass" value="${jdbc.driverClassName}" /><br> <property name="jdbcUrl" value="${jdbc.url}" /><br> <property name="user" value="${jdbc.username}" /><br> <property name="password" value="${jdbc.password}" /><br> </bean><br> &lt;context:property-placeholder location=”WEB-INF/jdbc.properties” /&gt;</p>
 <!-- SqlSessionFactory for MyBatis -->
 <bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean" >
 <property name="dataSource" ref="dataSource" />
 <property name="configLocation" value="WEB-INF/mybatis.xml" />
 </bean>

 <!-- scanning for mappers -->
<p> &lt;mybatis:scan base-package=”net.openwares.test.mapper” /&gt;<br>[/xml]<br>其中配置了C3P0 jdbc数据源dataSource，使用刚配置好的spring数据源dataSource配置MyBatis的SqlSessionFactoryBean,用来产生mapper需要的sqlsession,最后是自动扫描包下面的mapper,并生成相应接口的代理实现类。<br>不要忘了在spring-servlet.xml中添加mybatis 名字空间，如下：<br>[xml]<br><beans xmlns="http://www.springframework.org/schema/beans"
 xmlns:mybatis="http://mybatis.org/schema/mybatis-spring"
 xsi:schemaLocation="
 http://mybatis.org/schema/mybatis-spring
 http://mybatis.org/schema/mybatis-spring.xsd"><br>[/xml]</p>
<p>WEB-INF/jdbc.properties文件<br>[java]<br>jdbc.driverClassName=org.postgresql.Driver<br>jdbc.url=jdbc:postgresql://localhost/testdb<br>jdbc.username=postgres<br>jdbc.password=postgres<br>[/java]</p>
<p>MyBatis的其他配置可以设置在WEB-INF/mybatis.xml文件中,但不用再设置environments元素，因为MyBatis-Spring会使用spring配置的数据库环境包括数据源和事务配置。</p>
<p>这样配置就算完成了，MyBatis-Spring会自动扫描类classpath下包net.openwares.test.mapper里面的mapper配置xml和接口,生成mapper接口的代理实现类，并自动注入sqlSessionFactory为mapper提供可用的sqlSession。<br>如果有多个包需要扫描，只需用逗号或分号分隔包名即可。这是设置mapper bean最简单的方式。</p>
<p>而且,MyBatis-Spring自动扫描产生的mapper接口实现类是线程安全的,也完全不用再与sqlsession打交道,MyBatis-Spring会在背后默默的处理好这一切。</p>
<blockquote>
<p>Rather than code data access objects (DAOs) manually using SqlSessionDaoSupport or SqlSessionTemplate, Mybatis-Spring can create a thread safe <a href="http://mybatis.github.io/spring/mappers.html">mapper</a> that you can inject directly into other beans</p>
</blockquote>
<p><strong>简单示例代码</strong></p>
<p>与前面的例子一样，这里只是把前端提交的加数augend和被加数addend存入postgresql数据库，PostgreSQL建库脚本testdb.sql如下：<br>[sql]<br>CREATE DATABASE testdb;</p>
<p>\c testdb;</p>
<p>CREATE TABLE Attender(<br> augend int,<br> addend int<br>);<br>[/sql]</p>
<p>然后执行命令行建库,psql的简单使用参见 <a href="https://openwares.net/database/postgres_first.html">PostgreSQL初步</a></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ psql -U postgres -h localhost -f testdb.sql</span><br></pre></td></tr></table></figure>

<p>MyBatis mapper</p>
<p>mapper分为两部分，一个是java接口，另一个是xml配置文件，这两个文件要放置在一个目录下，而且接口的全限定接口名一定要与xml配置文件中mapper元素的命名空间完全一致。MyBatis会扫描xml为mapper接口生成实现类，并注册到spring容器中，供应用程序使用。这个mapper接口实际上就是一个DAO接口。</p>
<p>先看mapper配置文件<br>[xml]<br><?xml version="1.0" encoding="UTF-8" ?><br><!DOCTYPE mapper
 PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN"
 "http://mybatis.org/dtd/mybatis-3-mapper.dtd"><br><mapper namespace="net.openwares.test.mapper.AttenderMapper"><br> <select id="selectAttender" parameterType="int" resultType="net.openwares.test.mapper.AttenderPO"><br> select * from attender where augend = #{augend}<br> </select><br> <insert id="insertAttender" parameterType="net.openwares.test.mapper.AttenderPO"><br> insert into attender (augend, addend) values (#{augend},#{addend})<br> </insert><br></mapper><br>[/xml]</p>
<p>mapper接口代码：<br>[java]<br>package net.openwares.test.mapper;</p>
<p>import java.util.List;</p>
<p>public interface AttenderMapper{<br> List<AttenderPO> getAttender(String augend);</p>
<p> void insertAttender(AttenderPO attender);<br>}<br>[/java]</p>
<p>接口全限定类名和xml配置文件中mapper的命名空间都为net.openwares.test.mapper.AttenderMapper，有了这些信息，无需实现mapper接口,<br>mybatis会自动提供接口的实现。</p>
<p>最后使用此接口将客户提交的数据持久化到数据库<br>[java]<br>@Controller<br>public class Persistent{</p>
<p> @Autowired<br> private Outcome outcome;</p>
<p> @Autowired(required=true)<br> private AttenderMapper attenderMapper;</p>
<p> @RequestMapping(“/ajaxcalc”)<br> public @ResponseBody Outcome getResult(@RequestBody Attender attender){</p>
<p> //persistent Attender object<br> AttenderPO attenderPO = new AttenderPO();</p>
<p> attenderPO.setAugend(attender.getAugend());<br> attenderPO.setAddend(attender.getAddend());</p>
<p> attenderMapper.insertAttender(attenderPO);</p>
<p> outcome.setResult(attender.getAugend() + attender.getAddend());<br> return outcome;<br> }<br>}<br>[/java]</p>
<p>使用@Autowired(required=true)自动注入依赖attenderMapper即可。</p>
<p>因为是简单的示例，这里没有使用事务管理，也没有仔细的分层，将代码直接写入了controller。</p>
<p><a href="/downloads/persistent.war">完整的示例代码下载</a>。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>spring,mybatis事务管理配置与@Transactional注解使用</title>
    <url>/2013/10/20/spring-mybatis-transaction/</url>
    <content><![CDATA[<p>spring,mybatis事务管理配置与@Transactional注解使用</p>
<a id="more"></a>
<p><strong>概述</strong><br>事务管理对于企业应用来说是至关重要的，即使出现异常情况，它也可以保证数据的一致性。<br>Spring Framework对事务管理提供了一致的抽象，其特点如下：</p>
<ul>
<li>  为不同的事务API提供一致的编程模型，比如JTA(Java Transaction API), JDBC, Hibernate, JPA(Java Persistence API和JDO(Java Data Objects)</li>
<li>  支持声明式事务管理，特别是基于注解的声明式事务管理，简单易用</li>
<li>  提供比其他事务API如JTA更简单的编程式事务管理API</li>
<li>  与spring数据访问抽象的完美集成</li>
</ul>
<p><strong>事务管理方式</strong></p>
<p>spring支持编程式事务管理和声明式事务管理两种方式。</p>
<p>编程式事务管理使用TransactionTemplate或者直接使用底层的PlatformTransactionManager。对于编程式事务管理，spring推荐使用TransactionTemplate。</p>
<p>声明式事务管理建立在AOP之上的。其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。声明式事务最大的优点就是不需要通过编程的方式管理事务，这样就不需要在业务逻辑代码中掺杂事务管理的代码，只需在配置文件中做相关的事务规则声明(或通过基于@Transactional注解的方式)，便可以将事务规则应用到业务逻辑中。</p>
<p>显然声明式事务管理要优于编程式事务管理，这正是spring倡导的非侵入式的开发方式。声明式事务管理使业务代码不受污染，一个普通的POJO对象，只要加上注解就可以获得完全的事务支持。和编程式事务相比，声明式事务唯一不足地方是，后者的最细粒度只能作用到方法级别，无法做到像编程式事务那样可以作用到代码块级别。但是即便有这样的需求，也存在很多变通的方法，比如，可以将需要进行事务管理的代码块独立为方法等等。</p>
<p>声明式事务管理也有两种常用的方式，一种是基于tx和aop名字空间的xml配置文件，另一种就是基于@Transactional注解。显然基于注解的方式更简单易用，更清爽。</p>
<p><strong>自动提交(AutoCommit)与连接关闭时的是否自动提交</strong></p>
<p><em>自动提交</em></p>
<p>默认情况下，数据库处于自动提交模式。每一条语句处于一个单独的事务中，在这条语句执行完毕时，如果执行成功则隐式的提交事务，如果<br>执行失败则隐式的回滚事务。</p>
<p>对于正常的事务管理，是一组相关的操作处于一个事务之中，因此必须关闭数据库的自动提交模式。不过，这个我们不用担心，spring会将底层连接的自动提交特性设置为false。<br>org/springframework/jdbc/datasource/DataSourceTransactionManager.java<br>[java]<br>// switch to manual commit if necessary. this is very expensive in some jdbc drivers,<br>// so we don’t want to do it unnecessarily (for example if we’ve explicitly<br>// configured the connection pool to set it already).<br>if (con.getautocommit()) {<br> txobject.setmustrestoreautocommit(true);<br> if (logger.isdebugenabled()) {<br> logger.debug(“switching jdbc connection [“ + con + “] to manual commit”);<br> }<br> con.setautocommit(false);<br>}<br>[/java]</p>
<p>有些数据连接池提供了关闭事务自动提交的设置，最好在设置连接池时就将其关闭。但C3P0没有提供这一特性，只能依靠spring来设置。<br>因为JDBC规范规定，当连接对象建立时应该处于自动提交模式，这是跨DBMS的缺省值，如果需要,必须显式的关闭自动提交。C3P0遵守这一规范，让客户代码来显式的设置需要的提交模式。</p>
<p><em>连接关闭时的是否自动提交</em></p>
<p>当一个连接关闭时，如果有未提交的事务应该如何处理？JDBC规范没有提及，C3P0默认的策略是回滚任何未提交的事务。这是一个正确的策略，但JDBC驱动提供商之间对此问题并没有达成一致。<br>C3P0的autoCommitOnClose属性默认是false,没有十分必要不要动它。或者可以显式的设置此属性为false，这样会更明确。</p>
<p><strong>基于注解的声明式事务管理配置</strong><br>spring-servlet.xml<br>[xml]<br> <!-- transaction support--><br> <!-- PlatformTransactionMnager --><br> <bean id="txManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"><br> <property name="dataSource" ref="dataSource" /><br> </bean><br> <!-- enable transaction annotation support --><br> &lt;tx:annotation-driven transaction-manager=”txManager” /&gt;<br>[/xml]<br>还要在spring-servlet.xml中添加tx名字空间<br>[xml]<br>…<br> xmlns:tx=”<a href="http://www.springframework.org/schema/tx&quot;">http://www.springframework.org/schema/tx&quot;</a><br> xmlns:aop=”<a href="http://www.springframework.org/schema/aop&quot;">http://www.springframework.org/schema/aop&quot;</a><br> xsi:schemaLocation=”<br> …<br> <a href="http://www.springframework.org/schema/tx">http://www.springframework.org/schema/tx</a><br> <a href="http://www.springframework.org/schema/tx/spring-tx.xsd">http://www.springframework.org/schema/tx/spring-tx.xsd</a><br> …<br>[/xml]</p>
<p>MyBatis自动参与到spring事务管理中，无需额外配置，只要org.mybatis.spring.SqlSessionFactoryBean引用的数据源与DataSourceTransactionManager引用的数据源一致即可，否则事务管理会不起作用。</p>
<p>另外需要下载依赖包<a href="http://aopalliance.sourceforge.net/">aopalliance</a>.jar放置到WEB-INF/lib目录下。否则spring初始化时会报异常<br>java.lang.NoClassDefFoundError: org/aopalliance/intercept/MethodInterceptor</p>
<p><strong>spring事务特性</strong></p>
<p>spring所有的事务管理策略类都继承自org.springframework.transaction.PlatformTransactionManager接口<br>[java]<br>public interface PlatformTransactionManager {</p>
<p> TransactionStatus getTransaction(TransactionDefinition definition)<br> throws TransactionException;</p>
<p> void commit(TransactionStatus status) throws TransactionException;</p>
<p> void rollback(TransactionStatus status) throws TransactionException;<br>}<br>[/java]</p>
<p>其中TransactionDefinition接口定义以下特性：</p>
<p><em>事务隔离级别</em></p>
<p>隔离级别是指若干个并发的事务之间的隔离程度。TransactionDefinition 接口中定义了五个表示隔离级别的常量：</p>
<ul>
<li><p>  TransactionDefinition.ISOLATION_DEFAULT：这是默认值，表示使用底层数据库的默认隔离级别。对大部分数据库而言，通常这值就是TransactionDefinition.ISOLATION_READ_COMMITTED。</p>
</li>
<li><p>  TransactionDefinition.ISOLATION_READ_UNCOMMITTED：该隔离级别表示一个事务可以读取另一个事务修改但还没有提交的数据。该级别不能防止脏读，不可重复读和幻读，因此很少使用该隔离级别。比如PostgreSQL实际上并没有此级别。</p>
</li>
<li><p>  TransactionDefinition.ISOLATION_READ_COMMITTED：该隔离级别表示一个事务只能读取另一个事务已经提交的数据。该级别可以防止脏读，这也是大多数情况下的推荐值。</p>
</li>
<li><p>  TransactionDefinition.ISOLATION_REPEATABLE_READ：该隔离级别表示一个事务在整个过程中可以多次重复执行某个查询，并且每次返回的记录都相同。该级别可以防止脏读和不可重复读。</p>
</li>
<li><p>  TransactionDefinition.ISOLATION_SERIALIZABLE：所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。但是这将严重影响程序的性能。通常情况下也不会用到该级别。</p>
</li>
</ul>
<p><em>事务传播行为</em></p>
<p>所谓事务的传播行为是指，如果在开始当前事务之前，一个事务上下文已经存在，此时有若干选项可以指定一个事务性方法的执行行为。在TransactionDefinition定义中包括了如下几个表示传播行为的常量：</p>
<ul>
<li>  TransactionDefinition.PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是默认值。</li>
<li>  TransactionDefinition.PROPAGATION_REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li>
<li>  TransactionDefinition.PROPAGATION_SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li>
<li>  TransactionDefinition.PROPAGATION_NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li>
<li>  TransactionDefinition.PROPAGATION_NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。</li>
<li>  TransactionDefinition.PROPAGATION_MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</li>
<li>  TransactionDefinition.PROPAGATION_NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于TransactionDefinition.PROPAGATION_REQUIRED。</li>
</ul>
<p><em>事务超时</em></p>
<p>所谓事务超时，就是指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务。在 TransactionDefinition 中以 int 的值来表示超时时间，其单位是秒。</p>
<p>默认设置为底层事务系统的超时值，如果底层数据库事务系统没有设置超时值，那么就是none，没有超时限制。</p>
<p><em>事务只读属性</em></p>
<p>只读事务用于客户代码只读但不修改数据的情形，只读事务用于特定情景下的优化，比如使用Hibernate的时候。<br>默认为读写事务。</p>
<p><strong>spring事务回滚规则</strong></p>
<p>指示spring事务管理器回滚一个事务的推荐方法是在当前事务的上下文内抛出异常。spring事务管理器会捕捉任何未处理的异常，然后依据规则决定是否回滚抛出异常的事务。</p>
<p>默认配置下，spring只有在抛出的异常为运行时unchecked异常时才回滚该事务，也就是抛出的异常为RuntimeException的子类(Errors也会导致事务回滚)，而抛出checked异常则不会导致事务回滚。<br>可以明确的配置在抛出那些异常时回滚事务，包括checked异常。也可以明确定义那些异常抛出时不回滚事务。</p>
<p>还可以编程性的通过setRollbackOnly()方法来指示一个事务必须回滚，在调用完setRollbackOnly()后你所能执行的唯一操作就是回滚。</p>
<p><strong>@Transactional注解</strong></p>
<p><em>@Transactional属性</em></p>
<p>属性</p>
<p>类型</p>
<p>描述</p>
<p>value</p>
<p>String</p>
<p>可选的限定描述符，指定使用的事务管理器</p>
<p>propagation</p>
<p>enum: Propagation</p>
<p>可选的事务传播行为设置</p>
<p>isolation</p>
<p>enum: Isolation</p>
<p>可选的事务隔离级别设置</p>
<p>readOnly</p>
<p>boolean</p>
<p>读写或只读事务，默认读写</p>
<p>timeout</p>
<p>int (in seconds granularity)</p>
<p>事务超时时间设置</p>
<p>rollbackFor</p>
<p>Class对象数组，必须继承自Throwable</p>
<p>导致事务回滚的异常类数组</p>
<p>rollbackForClassName</p>
<p>类名数组，必须继承自Throwable</p>
<p>导致事务回滚的异常类名字数组&lt;/td</p>
<p>noRollbackFor</p>
<p>Class对象数组，必须继承自Throwable</p>
<p>不会导致事务回滚的异常类数组</p>
<p>noRollbackForClassName</p>
<p>类名数组，必须继承自Throwable</p>
<p>不会导致事务回滚的异常类名字数组&lt;/td</p>
<p><em>用法</em></p>
<p>@Transactional 可以作用于接口、接口方法、类以及类方法上。当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时，我们也可以在方法级别使用该标注来覆盖类级别的定义。</p>
<p>虽然 @Transactional 注解可以作用于接口、接口方法、类以及类方法上，但是 Spring 建议不要在接口或者接口方法上使用该注解，因为这只有在使用基于接口的代理时它才会生效。另外， @Transactional 注解应该只被应用到 public 方法上，这是由 Spring AOP 的本质决定的。如果你在 protected、private 或者默认可见性的方法上使用 @Transactional 注解，这将被忽略，也不会抛出任何异常。</p>
<p>默认情况下，只有来自外部的方法调用才会被AOP代理捕获，也就是，类内部方法调用本类内部的其他方法并不会引起事务行为，即使被调用方法使用@Transactional注解进行修饰。</p>
<p>示例代码：<br>[java]<br>@Transactional(readOnly = true)<br>public class DefaultFooService implements FooService {</p>
<p> public Foo getFoo(String fooName) {<br> // do something<br> }</p>
<p> // these settings have precedence for this method<br> //方法上注解属性会覆盖类注解上的相同属性<br> @Transactional(readOnly = false, propagation = Propagation.REQUIRES_NEW)<br> public void updateFoo(Foo foo) {<br> // do something<br> }<br>}<br>[/java]</p>
<p><strong>参考</strong><br><a href="http://docs.spring.io/spring/docs/3.2.4.RELEASE/spring-framework-reference/html/transaction.html">Transaction Management</a></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring找不到bean定义异常</title>
    <url>/2013/11/21/spring-nosuchbeandefinitionexception/</url>
    <content><![CDATA[<a id="more"></a>
<p>测试部署应用程序时，spring容器出现异常:</p>
<p>org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [xxx.xxx.service.UploadService] found for dependency: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}</p>
<p>明明UploadService是个POJO类都编译通过了,最后发现错误原因是service层的组件需要用@Service注解来修饰。那为啥DAO层的组件就没报错来！！！</p>
<p><strong>注：知道为什么报错了，因为controller使用@Autowired(required=true)来引用UploadService,而UploadService没有使用注解修饰，从而不会被spring管理，故而出错。而DAO组件是Mybatis-Spring自动管理的，所以不会有问题。不加注解，spring是不会理会用户定义的POJO的。</strong></p>
<p>好吧，以后DAO层组件也老老实实的加上@Repository注解，就算普通的POJO，如果需要spring容器来自动管理注入，也要用@Component注解修饰。</p>
<p>@Controller,@Service，@Repository，@Component都在包org.springframework.stereotype里。</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring 3 MVC JSON Sample</title>
    <url>/2013/10/12/spring3-mvc-json-sample/</url>
    <content><![CDATA[<p>Spring Framework 3 对 JSON的支持很不错。</p>
<a id="more"></a>
<p>这个例子程序和以前一样，前端为html、javascript,这次后端改为使用spring framework 3.2.4,前后端通过ajax交换json数据，这个例子比只使用servlet 3更简洁，当然配置更复杂一些。</p>
<p>完整的代码和配置<a href="/downloads/springjson.war">下载</a>。</p>
<p><strong>配置</strong></p>
<p>要使用spring framework,首先要在WEB-INF/web.xml中配置spring的DispatcherServlet，由其来接管映射的URL请求，之后就进入spring framework的处理流程。<br>web.xml<br>[xml]<br> <servlet><br> <servlet-name>spring</servlet-name><br> <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class><br> <load-on-startup>1</load-on-startup><br> </servlet><br> <servlet-mapping><br> <servlet-name>spring</servlet-name><br> <url-pattern>/</url-pattern><br> </servlet-mapping><br>[/xml]</p>
<p>如果不配置的DispatcherServlet的初始化参数contextConfigLocation，则spring framework会读取WEB-INF/<servlet-name>-servlet.xml作为其context参数文件，在这个配置里，这个文件为spring-servlet.xml,其内容如下：</p>
<p>[xml]<br><?xml version="1.0" encoding="UTF-8"?><br><beans xmlns="http://www.springframework.org/schema/beans"
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xmlns:p="http://www.springframework.org/schema/p"
 xmlns:context="http://www.springframework.org/schema/context"
 xmlns:mvc="http://www.springframework.org/schema/mvc"
 xsi:schemaLocation="
 http://www.springframework.org/schema/beans
 http://www.springframework.org/schema/beans/spring-beans.xsd
 http://www.springframework.org/schema/context
 http://www.springframework.org/schema/context/spring-context.xsd
 http://www.springframework.org/schema/mvc
 http://www.springframework.org/schema/mvc/spring-mvc.xsd"></p>
<p> &lt;context:component-scan base-package=”net.openwares.test” /&gt;<br> &lt;mvc:default-servlet-handler /&gt;<br> &lt;mvc:annotation-driven /&gt;<br></beans><br>[/xml]</p>
<p>其中<br>[xml]&lt;context:component-scan base-package=”net.openwares.test” /&gt;[/xml]<br>表示从包net.openwares.test里面自动扫描使用注解标示的组件，比如@RqeustMapping,@RequestBody等注解的组件。<br>不过这个地方存在一点问题，spring对jar包的扫描有特殊的要求，用jar -cvf 命令创建的jar包,spring扫描不到其中的组件，而不打包使用层次文件路径则没有问题，这里的路径是WEB-INF/classes/net/openwares/test/。使用<a href="http://kyfxbl.iteye.com/blog/1675368">eclipse打包时有个选项add directory entries</a>，勾选这个选项打出来的包就可以被spring扫描到。现在还没发现如何用jar命令打包才可以让spring扫描到。</p>
<p>[xml]&lt;mvc:default-servlet-handler /&gt;[/xml]<br>可以将spring framework不处理的其他资源请求路由到容器的default servlet,这样容器就可以继续处理这些请求，而不是被spring framework拦截掉。</p>
<p>[xml]&lt;mvc:annotation-driven /&gt;[/xml]<br>支持注解，比如@RequestMapping,@PathVariable等。</p>
<p>对于这个例子，这个配置就够了。现在spring framework朝着零配置方向又进一步，在servlet 3.0+环境下，也可以不用xml而使用java代码来完成如上配置。</p>
<p><strong>代码</strong></p>
<p>前端index.html只是改一下请求的url就可以了</p>
<p>var url = “/springjson/ajaxcalc”;</p>
<p>后端SpringJson.java代码：<br>[java]<br>package net.openwares.test;</p>
<p>import java.io.Writer;<br>import java.io.IOException;<br>import org.springframework.stereotype.Controller;<br>import org.springframework.web.bind.annotation.RequestMapping;<br>import org.springframework.web.bind.annotation.RequestBody;<br>import org.springframework.web.bind.annotation.ResponseBody;</p>
<p>import org.springframework.stereotype.Component;<br>import org.springframework.beans.factory.annotation.Autowired;</p>
<p>@Component<br>class Attender {<br> private int augend, addend;</p>
<p> public Attender(){}</p>
<p> public int getAugend(){<br> return augend;<br> }<br> public void setAugend(int augend){<br> this.augend = augend;<br> }</p>
<p> public int getAddend(){<br> return addend;<br> }<br> public void setAddend(int addend){<br> this.addend = addend;<br> }<br>}</p>
<p>@Component<br>class Outcome {<br> private int result;</p>
<p> public Outcome(){}</p>
<p> public int getResult(){<br> return result;<br> }<br> public void setResult(int result){<br> this.result = result;<br> }<br>}</p>
<p>@Controller<br>public class SpringJson {</p>
<p> @Autowired<br> private Outcome outcome;</p>
<p> @RequestMapping(“/ajaxcalc”)<br> public @ResponseBody Outcome getResult(@RequestBody Attender attender){</p>
<p> outcome.setResult(attender.getAugend() + attender.getAddend());<br> return outcome;<br> }<br>}<br>[/java]</p>
<p><strong>说明</strong></p>
<p>只要前端ajax请求将Content-Type设置为application/json,则spring会自动的将请求内容映射到@RequestBody修饰的VO对象，<br>将@ResponseBody修饰的VO对象转换为返回的json数据。spring使用HttpMessageConverters来转换数据，<br>支持json,xml等多种数据类型，还以自定义转换接口。中间如有数据类型转换可能会出现转换问题。</p>
<p>打包为spingjson.war,部署后访问URL<br><a href="http://127.0.0.1/springjson/ajaxcalc">http://127.0.0.1/springjson/ajaxcalc</a></p>
<p><strong>依赖</strong></p>
<p>spring使用jackson来操作json数据，因此需要下载jackson jar包，spring 3.2.4支持jackson 2,直接下载<a href="http://wiki.fasterxml.com/JacksonDownload">最新的jackson包</a>丢到lib目录即可，当前为这个三个文件：<br>jackson-core-2.2.3.jar<br>jackson-annotations-2.2.3<br>jackson-databind-2.2.3.jar</p>
<p>spring使用<a href="http://commons.apache.org/proper/commons-logging/">apache commons logging</a>组件来输出日志，因此需要依赖包<br>commons-logging-1.1.3.jar</p>
<p>spring framework现在拆分了jar,不再提供单一的一个大jar包。此样例程序需要依赖以下spring包：<br>spring-core-3.2.4.RELEASE.jar //核心包，所有的spring程序都需要<br>spring-beans-3.2.4.RELEASE.jar //bean管理，依赖注入等核心功能<br>spring-context-3.2.4.RELEASE.jar //基础支持包<br>spring-expression-3.2.4.RELEASE.jar //此包必须，否则spring无法加载context配置文件，从而无法完成初始化<br>spring-web-3.2.4.RELEASE.jar //servlet支持<br>spring-webmvc-3.2.4.RELEASE.jar //MVC支持</p>
<p><strong>后记</strong><br>这个例子和以前的几个例子都是完全用vim编辑，用javac编译，用jar打包的。虽然只是极其简单的小例子，仍然感觉十分繁琐，看来研究下eclipse还是有必要的。</p>
<p>参考：<a href="http://docs.spring.io/spring/docs/3.2.4.RELEASE/spring-framework-reference/html/mvc.html">Spring 3.2.4 MVC文档</a><br> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>sqlplus 自动补全/完成</title>
    <url>/2016/04/23/sqlplus-auto-completion/</url>
    <content><![CDATA[<a id="more"></a>
<p>通过rlwrap可以<a href="https://openwares.net/linux/debian%E4%B8%8B%E4%BD%BFsqlplus%E5%85%B7%E6%9C%89%E5%91%BD%E4%BB%A4%E5%8E%86%E5%8F%B2%E5%9B%9E%E6%BA%AF%E5%92%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%BE%91%E5%8A%9F%E8%83%BD.html">使sqlplus具有具有命令历史回溯和命令行编辑功能</a>,通过提供自动完成字典，可以更进一步使sqlplus具有tab自动补全/完成功能。</p>
<p>德国一个哥们写了rlwrap_ext for oralce可以使sqlplus自动补全sql关键字，oracle视图、表、包等等，比较全面。</p>
<p><strong>下载</strong></p>
<p>可以直接下载最新的版本</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget http:<span class="comment">//www.linuxification.at/download/rlwrap-extensions-V12-0.03.tar.gz</span></span><br></pre></td></tr></table></figure>

<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo tar zxvf rlwrap-extensions-V12-<span class="number">0.03</span>.tar.gz -C /usr/local/share/rlwrap/completions</span><br><span class="line">$ sudo cp /usr/local/share/rlwrap/completions/sql+ <span class="regexp">/usr/</span>local/bin/</span><br></pre></td></tr></table></figure>

<p>然后使用sql+替代sqlplus就可以了。</p>
<p>References:<br>[1]<a href="http://www.linuxification.at/rlwrap_ext.html.en">rlwrap_ext for oracle</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库关闭状态下远程sqlplus客户端无法连接到实例</title>
    <url>/2011/02/22/sqlplus-cant-connect-to-remote-server/</url>
    <content><![CDATA[<p>用sys用户远程管理新安装的oracle 10.2.0.4 64bits服务器,shutdown immediate后,startup时出现错误提示：</p>
<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ORA-<span class="number">12514</span>: TNS:listener does not currently know <span class="keyword">of</span> service requested <span class="keyword">in</span> connect descriptor</span><br></pre></td></tr></table></figure>
<p>(监听程序当前无法识别连接描述符中请求的服务)</p>
<p>这是因为listener没有对外监听SID,而且PMON进程动态注册时只注册本地地址<br>解决办法之一是修改%ORACLE_HOME%\network\admin\listener.ora,在SID_LIST段落内增加监听实例名</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">(SID_DESC =</span><br><span class="line">(GLOBAL_DBNAME = &lt;SID&gt;)</span><br><span class="line">(ORACLE_HOME = E:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\db_1)</span><br><span class="line">(SID_NAME = &lt;SID&gt;)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lsnrctl reload</span><br></pre></td></tr></table></figure>
<p>然后执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lsnrctl status</span><br></pre></td></tr></table></figure>

<p>查看一下是否在监听新增加的实例名</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>tomcat 7,spring 3,mybatis 3 配置log4j日志组件</title>
    <url>/2013/10/16/spring3-mybatis3-log4j/</url>
    <content><![CDATA[<p>tomcat,spring,mybatis都内置通用的日志输出框架，可以配合各种具体的日志组件实现来输出日志，而log4j是最常用的日志组件。</p>
<a id="more"></a>
<p>tomcat和spring都使用JCL(Jakarta Commons Logging)日志框架，而mybatis貌似是自己实现的日志框架，三者都可以使用常见的日志组件来输出日志。</p>
<p><strong>tomcat 7</strong></p>
<p>tomcat使用JCL日志框架，默认配置使用JDK提供的JUL(java.util.logging)输出tomcat内部日志。也可以<a href="http://tomcat.apache.org/tomcat-7.0-doc/logging.html">配置使用log4j来输出tomcat内部日志</a>。<br>注意这里是配置tomcat自身日志的输出，在tomcat上运行的应用程序可以单独配置日志输出组件比如log4j，二者互不影响。</p>
<p>在tomcat上运行的应用程序可以使用以下方式来输出日志：</p>
<ul>
<li><p>  使用JAVA API java.util.logging</p>
</li>
<li><p>  使用servlet规范提供的API javax.servlet.ServletContext.log(…)</p>
</li>
<li><p>  使用自己选择的日志组件，比如使用log4j</p>
</li>
</ul>
<p>tomcat控制台输出</p>
<p>当在unix like系统上运行tomcat时，控制台输出被重定向到一个名字可配置的文件中，通常这个文件为catalina.out。因此所有写到System.err/out的输出都被写入这个文件中。包括：</p>
<ul>
<li><p>  使用java.lang.ThreadGroup.uncaughtException(..)输出的未捕获异常</p>
</li>
<li><p>  线程dump</p>
</li>
<li><p>  应用程序的System.out/System.err输出，这是不推荐的方式，尽量不要使用，推荐使用日志输出组件</p>
</li>
</ul>
<p><strong>spring 3</strong></p>
<p>spring 3 使用JCL日志框架，可以动态发现可以使用的日志组件，只要将日志组件的jar包扔到classpath路径里面就可以了，如果不使用其他日志组件，则spring 3使用java.util.logging来输出日志。</p>
<p>不过<a href="http://spring.io/blog/2009/12/04/logging-dependencies-in-spring">spring工程更倾向于使用SLF4J</a>，历史原因选择了JCL框架。</p>
<p>spring配置使用log4j也比较简单，只要将log4j-x.x.x.jar包放入classpath，然后提供一个配置文件log4j.properties放置在classpath根路径下，比如WEB-INF/classes目录下即可。</p>
<p>spring提供了一个listener来配置log4j,可以设置配置文件路径等相关设置，在web.xml中配置此listener：<br>[xml]<br> <!-- web应用程序根路径映射，如果不设置此参数，默认映射到变量webapp.root，log4j.propertiesw文件中
可以使用${webapp.root}来引用web应用程序根路径 --><br> <context-param><br> <param-name>webAppRootKey</param-name><br> <param-value>webapp.root</param-value><br> </context-param><br> <!-- log4j.properties配置文件路径 --><br> <context-param><br> <param-name>log4jConfigLocation</param-name><br> <param-value>WEB-INF/log4j.properties</param-value><br> </context-param><br> <context-param><br> <param-name>log4jRefreshInterval</param-name><br> <param-value>3000</param-value><br> </context-param><br> <listener><br> <listener-class>org.springframework.web.util.Log4jConfigListener</listener-class><br> </listener><br>[/xml]</p>
<p>这里将log4j.properties配置到WEB-INF目录下，方便统一管理应用程序的配置文件</p>
<p><strong>mybatis 3</strong></p>
<p>mybatis 3 也支持<a href="http://mybatis.github.io/mybatis-3/logging.html">使用log4j日志组件</a>，在spring mybatis集成应用程序中，mybatis直接使用spring的log4j设置即可，只要将mybaits相关的日志配置写入共用的配置文件log4j.properties即可。比如对映射器日志设置如下：</p>
<p>log4j.logger.net.openwares.test.mapper = TRACE<br>甚至可以对映射器里面映射的语句设置日志数据级别<br>log4j.logger.net.openwares.test.mapper.selectXXX = TRACE</p>
<p>对于独立使用的mybatis,需要在mybatis-config.xml文件中添加：<br>[xml]<br><configuration><br> <settings><br> …<br> <setting name="logImpl" value="LOG4J"/><br> …<br> </settings><br></configuration><br>[/xml]<br>然后将log4j jar包和log4j.properties文件放入classpath。</p>
<p><strong>log4j简单配置</strong></p>
<p>[xml]<br>#Global configuration<br>log4j.rootLogger = DEBUG, stdout, logfile</p>
<p>log4j.appender.stdout = org.apache.log4j.ConsoleAppender<br>log4j.appender.stdout.layout = org.apache.log4j.PatternLayout<br>log4j.appender.stdout.layout.ConversionPattern = %5p [%t] - %m%n</p>
<p>log4j.appender.logfile = org.apache.log4j.FileAppender<br>log4j.appender.logfile.File = ${webapp.root}/WEB-INF/logs/debug.log<br>log4j.appender.logfile.layout = org.apache.log4j.PatternLayout<br>log4j.appender.logfile.layout.ConversionPattern = %5p [%t] - %m%n</p>
<p>#Spring config<br>#log4j.logger.org.springframewaork = DEBUG</p>
<p>#Mybatis config<br>#log4j.logger.org.apache.ibatis = DEBUG<br>log4j.logger.net.openwares.test.mapper = TRACE</p>
<p>#JDBC config<br>#log4j.logger.java.sql.Connection = DEBUG<br>#log4j.logger.java.sql.Statement = DEBUG<br>#log4j.logger.java.sql.PreparedStatement = DEBUG<br>#log4j.logger.java.sql.ResultSet = DEBUG</p>
<p>[/xml]</p>
<p>log4j的主要概念就是logger,appender,layout还有logging level。<br>log4j的详细用法参见<a href="http://logging.apache.org/log4j/1.2/manual.html">官方文档</a>。</p>
<p><strong>log4j简单使用</strong><br>[java]<br>import org.apache.log4j.Logger;</p>
<p>public class helloLog {<br> private static Logger logger = Logger.getLogger(helloLog.class.getName());<br> public void MethodXXX(){<br> logger.debug(“xxx”);<br> logger.info(“xxx”);<br> …<br> }<br>}<br>[/java]</p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>sqlplus输出xls</title>
    <url>/2016/08/10/sqlplus-output-xls/</url>
    <content><![CDATA[<a id="more"></a>
<p>sql脚本文件内容如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">set linesize <span class="number">200</span> </span><br><span class="line">set term off verify off feedback off pagesize <span class="number">999</span> </span><br><span class="line">set markup html on entmap ON spool on preformat off</span><br><span class="line">spool result.xls</span><br><span class="line">@query.sql</span><br><span class="line">spool off</span><br><span class="line">exit</span><br></pre></td></tr></table></figure>

<p>entmap是指html实体映射,ent是entity的简写</p>
<p>将输出文件的名称改为.html后缀,即可输出html文档.其实输出的内容是完全一样的,只是文件扩展名不同.</p>
<p>sqlplus set指令详见[1]</p>
<p>References:<br>[1]<a href="https://docs.oracle.com/cd/E11882_01/server.112/e16604/ch_twelve040.htm#SQPUG060">SET System Variable Summary</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>squid 3 最简配置</title>
    <url>/2015/03/24/squid3-minimal-configuration/</url>
    <content><![CDATA[<a id="more"></a>
<p>squid是老牌的代理服务器，支持代理多种网络协议，acl安全配置强大，但十分复杂。</p>
<p>如果简单的作为http代理，只需更改几个选项就可以了，其他默认。</p>
<p>安装</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install squid3</span><br></pre></td></tr></table></figure>

<p>编辑/etc/squid3/squid.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># 配置一个需要访问squid的内网段</span><br><span class="line">acl localnet src 192.168.0.0/24 # RFC1918 possible internal network </span><br><span class="line"># 允许从上面配置的内网段访问代理服务器</span><br><span class="line">http_access allow localnet</span><br></pre></td></tr></table></figure>
<p>就可以了</p>
<p>更改默认代理端口：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">http_port 3128 # 改成想用的端口就可以了</span><br></pre></td></tr></table></figure>

<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>debian:ssh安全自动登录设置</title>
    <url>/2009/06/29/ssh-auto-login/</url>
    <content><![CDATA[<p>用ssh来管理远程服务器真是一件很舒适安逸的事情,当然前提是要做足安全工作,internet上可是杀机四伏啊。</p>
<p>记得我刚安装好Debian的时候 ,为root设置了一个很简单的密码，然后开放了ssh服务,没几天root帐号就让人给暴了, 看看/var/log/auth.log吧，真是惨不忍睹，里面全是尝试ssh登录的记录。好吧，我承认，当时是太没经验了。当然现在这种情况是一去不复返了。</p>
<p>下面就来说说如何提高ssh登录的安全性和自动登录ssh服务器。</p>
<a id="more"></a>
<p>1、服务器端设置</p>
<ul>
<li>  ssh的端口号是一定要更改的。最好更改到1024端口以上的一个随机端口，这样可以避免被大规模的扫描。</li>
<li>  禁止root用户ssh登录，普通用户登上来可以用su或sudo来获取root权限。</li>
<li>  采用密钥登录，禁止密码验证登录</li>
</ul>
<p>最后一点很重要，我现在采用2048位的RSA密钥来登录ssh，比密码登录强度高太多了。<br>以上几点是通过服务器上的/etc/ssh/sshd_config来设置的，具体如下：</p>
<p>#自定义端口号<br>Port xxxx<br>#禁止root登录<br>PermitRootLogin no<br>#RSA公钥认证<br>RSAAuthentication yes<br>PubkeyAuthentication yes<br>#公钥文件放置位置<br>AuthorizedKeysFile %h/.ssh/authorized_keys<br>#禁止密码验证登录<br>ChallengeResponeAuthentication no<br>PasswordAuthentication no</p>
<p>2、产生密钥对</p>
<p>可以通过ssh-keygen来产生RSA公私密钥对。将生成的公钥，默认文件名id_rsa.pub拷贝到服务器登录用户主目录下的.ssh/authorized_keys文件。</p>
<p>3、客户端设置</p>
<p>先说linux客户端自动登录设置。在用户home目录建立.ssh子目录，将私钥id_rsa拷贝过来，然后新建一个config文件，输入一下内容<br>#给服务器起个容易记住的名字<br>Host server_name<br>#服务器的ip地址<br>HostName xxx.xxx.xxx.xxx<br>#ssh登录用户名<br>User user_name<br>#ssh服务端口,修改后的端口号<br>Port xxxx</p>
<p>这样就OK了，要登录服务器的时候，shell中输入:ssh server_name就可以自动登录到服务器，是不是很方便啊。<br>如果你在windows上面使用PuTTY来登录远程服务器的话，有一点必须要注意，ssh-keygen产生的私钥格式PuTTY是不认识的，要用puttygen来转换一下才可以使用。至于PuTTY的详细设置就不详述了。</p>
<p>通过这样的设置后，清净、放心多了，再也没有看到那些无聊的登录尝试。只要你的私钥没有泄漏，就可以高枕无忧了，2048位的RSA加密基本是上无法破解的。</p>
<p>最后还要说明一点，这样的自动登录设置对scp一样有效，类似于这样scp server_name:/path/to/file就可以存取服务器端的文件了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh断点续传</title>
    <url>/2019/07/08/ssh-download-partial/</url>
    <content><![CDATA[<a id="more"></a>
<p>scp是不支持断点续传的，传输大文件意外中断会很痛苦。<br>rsync支持断点续传，也支持使用ssh协议传输数据，所以可以这样</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ rsync -P --rsh=ssh nasmdoc.pdf linode:</span><br></pre></td></tr></table></figure>

<p>这里linode是为一个ssh服务器配置的别名，而且支持tab补全，很好用。</p>
<p>可以在.bashrc中设置一个alias</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">alias scpr=<span class="string">&quot;rsync -P --rsh=ssh&quot;</span></span><br></pre></td></tr></table></figure>

<p>就可以这样用了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ scpr nasmdoc.pdf linode:</span><br></pre></td></tr></table></figure>

<p>注意，客户端和服务器都要安装rsync。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh execute background jobs remotely</title>
    <url>/2019/01/21/ssh-execute-background-jobs-remotely/</url>
    <content><![CDATA[<a id="more"></a>
<p>ssh远程执行后台作业时，在命令行最后添加<code>&amp;</code>标识并不是太好用，ssh还是会挂起，无法正常退出，可以使用nohup，并且重定向其所有的三个标准输入输出来解决：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ssh -T server &lt;&lt; EOF</span><br><span class="line"> nohup foobar &gt;<span class="regexp">/dev/</span><span class="literal">null</span> <span class="number">2</span>&gt;&amp;<span class="number">1</span> &lt;<span class="regexp">/dev/</span><span class="literal">null</span> &amp;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>


<p>References:<br>[1]<a href="https://en.wikipedia.org/wiki/Nohup">nohup</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh over socks5</title>
    <url>/2018/12/26/ssh-over-socks5/</url>
    <content><![CDATA[<p>nc要使用netcat-openbsd版本或者使用nmap实作的ncat</p>
<a id="more"></a>
<p>可以在ssh命令行或者config文件中:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ProxyCommand /bin/nc -x <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">1080</span> %h %p</span><br><span class="line">#ProxyCommand /usr/bin/ncat --proxy-type socks5 --proxy <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">1080</span> %h %p</span><br></pre></td></tr></table></figure>

<p>可以使用如下命令切换nc版本：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo update-alternatives --config nc</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>ssh packet_write_wait Broken pipe</title>
    <url>/2019/10/20/ssh-packet-write-wait-broken-pipe/</url>
    <content><![CDATA[<a id="more"></a>
<p>ssh连接空闲一段时间后出现：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">packet_write_wait: Connection to UNKNOWN port <span class="number">65535</span>: Broken pipe</span><br></pre></td></tr></table></figure>
<p>这是连接超时，需要设置一个保持心跳的参数，客户端是ServerAliveInterval，服务器端是ClientAliveInterval，参数值单位为second，还可以在.ssh/config中为每用户、每连接设置此参数</p>
<p>客户端：<br>/etc/ssh/ssh_config文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Host *</span><br><span class="line">ServerAliveInterval <span class="number">45</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://askubuntu.com/questions/127369/how-to-prevent-write-failed-broken-pipe-on-ssh-connection">How to prevent “Write Failed: broken pipe” on SSH connection?</a><br>[2]<a href="https://www.logcg.com/archives/897.html">当SSH遇到“Write failed: Broken pipe”</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh remote execute with backquote/backtick operator</title>
    <url>/2019/01/21/ssh-remote-execute-with-backquote-backtick-operator/</url>
    <content><![CDATA[<a id="more"></a>
<p>反引号backquote/backtick操作符默认是在本地命令行中展开的，因此如果要在远端执行此操作符有以下几种写法：</p>
<p><strong>HereDoc</strong></p>
<p>转义<code>``</code>或者<code>$()</code></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ssh -T server &lt;&lt; EOFSSH</span><br><span class="line"> kill -<span class="number">9</span> \\\<span class="string">`pgrep -f &#x27;foobar&#x27;\\\`</span></span><br><span class="line"><span class="string"> kill -9 \\$(pgrep -f &#x27;foobar&#x27;)</span></span><br><span class="line"><span class="string">EOFSSH</span></span><br></pre></td></tr></table></figure>

<p>或者将heredoc开始标志用单引号引用起来，指示shell不要解释heredoc中的特殊字符和指令</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ssh -T server &lt;&lt; <span class="string">&#x27;EOFSSH&#x27;</span></span><br><span class="line"> kill -<span class="number">9</span> \<span class="string">`pgrep -f &#x27;foobar&#x27;\`</span></span><br><span class="line"><span class="string"> kill -9 $(pgrep -f &#x27;foobar&#x27;)</span></span><br><span class="line"><span class="string">EOFSSH</span></span><br></pre></td></tr></table></figure>

<p><strong>单独的脚本文件</strong></p>
<p>将脚本写入单独的文件，然后：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cat foobar.sh ssh -T server</span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh -T server &lt; foobar.sh</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh x11 forward点滴</title>
    <url>/2020/02/02/ssh-x11-forward-tips/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>firefox</strong></p>
<p>加速X11 forward速度</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh -XC4 user@host firefox --no-remote</span><br></pre></td></tr></table></figure>

<p><strong>chrome</strong></p>
<p>直接下载chrome for linux amd64 latest</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb</span></span><br></pre></td></tr></table></figure>

<p>安装</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg -i google-chrome-stable_current_amd64.deb</span><br><span class="line">$ sudo apt install -f </span><br><span class="line">$ sudo apt install upower</span><br></pre></td></tr></table></figure>

<p>chrome会将自己设置为x和gnome默认的浏览器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) <span class="keyword">in</span> auto mode</span><br><span class="line">update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) <span class="keyword">in</span> auto mode</span><br><span class="line">update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) <span class="keyword">in</span> auto mode</span><br></pre></td></tr></table></figure>

<p>运行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ ssh -YC4 user@host google-chrome --disable-gpu --temp-profile</span><br></pre></td></tr></table></figure>
<p>但仍然无法运行成功，会不停的出现GCM通道请求失败错误</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[<span class="number">17069</span>:<span class="number">17069</span>:<span class="number">0202</span>/<span class="number">170630.407817</span>:ERROR:gcm_channel_status_request.cc(<span class="number">145</span>)\] GCM channel request failed.</span><br></pre></td></tr></table></figure>
<p>GCM是Google Cloud Messaging,google推出firebase云后，更名为FCM(Firebase Cloud Messaging)，看样子是Great Fucking Wall的锅</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>ssh x11forward from linux to macos</title>
    <url>/2019/10/10/ssh-x11forward-from-linux-to-macos/</url>
    <content><![CDATA[<a id="more"></a>
<p>MacOS Catalina上使用ssh -Xv 登录远程debian linux进行X11转发时提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">debug1: No xauth program.</span><br><span class="line">Warning: untrusted X11 forwarding setup failed: xauth key data not generated</span><br></pre></td></tr></table></figure>
<p>这是因为MacOS上的xauth路径与linux上不同，MacOS上使用XQuartZ其xauth路径为/opt/X11/bin/xauth，而debian上为/usr/bin/xauth，所以ssh客户端没有找到xauth，无法生成认证数据。<br>在~/.ssh/config文件中为单个主机，或者在/etc/ssh/ssh_config中为所有主机设置：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">XAuthLocation /opt/X11/bin/xauth</span><br></pre></td></tr></table></figure>

<p>在远程debian上执行glxinfo有错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ glxinfo</span><br><span class="line">name <span class="keyword">of</span> display: localhost:<span class="number">10.0</span></span><br><span class="line">libGL error: No matching fbConfigs or visuals found</span><br><span class="line">libGL error: failed to load driver: swrast</span><br><span class="line">X <span class="built_in">Error</span> <span class="keyword">of</span> failed request: GLXBadContext</span><br><span class="line"> Major opcode <span class="keyword">of</span> failed request: <span class="number">149</span> (GLX)</span><br><span class="line"> Minor opcode <span class="keyword">of</span> failed request: <span class="number">6</span> (X_GLXIsDirect)</span><br><span class="line"> Serial number <span class="keyword">of</span> failed request: <span class="number">26</span></span><br><span class="line"> Current serial number <span class="keyword">in</span> output stream: <span class="number">25</span></span><br></pre></td></tr></table></figure>
<p>在MacOS端执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ defaults write org.macosforge.xquartz.X11 enable_iglx -bool <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<p>重启XQuartz 2.7.11，然后就可以了，但是前两行错误继续存在。<br>iglx就是IndirectGLX的缩写，也就是关闭直接渲染。<br>远程debian上开启libgl debug</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ <span class="keyword">export</span> LIBGL_DEBUG=verbose</span><br><span class="line">$ glxgear</span><br><span class="line">libGL: OpenDriver: trying /usr/lib/x86_64-linux-gnu/dri/tls/swrast_dri.so</span><br><span class="line">libGL: OpenDriver: trying /usr/lib/x86_64-linux-gnu/dri/swrast_dri.so</span><br><span class="line">libGL: Can<span class="string">&#x27;t open configuration file /etc/drirc: No such file or directory.</span></span><br><span class="line"><span class="string">libGL: Can&#x27;</span>t open configuration file /home/john/.drirc: No such file or directory.</span><br><span class="line">libGL: Can<span class="string">&#x27;t open configuration file /etc/drirc: No such file or directory.</span></span><br><span class="line"><span class="string">libGL: Can&#x27;</span>t open configuration file /home/john/.drirc: No such file or directory.</span><br><span class="line">libGL error: No matching fbConfigs or visuals found</span><br><span class="line">libGL error: failed to load driver: swrast</span><br></pre></td></tr></table></figure>
<p>设置环境变量export LIBGL_ALWAYS_INDIRECT=1可以关闭这个错误提示，但是仍然是间接渲染。</p>
<p>这个问题需要XQuartz来解决，这货已经好久好久没有升级了…</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>用ssh登录android手机</title>
    <url>/2011/03/10/sshd-on-android/</url>
    <content><![CDATA[<p>Samsung Galaxy S(i9000)屏幕是挺大的,但是输入就别扭多了,没HTC G1的实体键盘来的爽快,有时候用terminal、改设置真是别扭，经常按错，如果能SSH登录到手机，大屏幕，全键盘多爽啊。</p>
<a id="more"></a>
<p>没问题，轻量SSH套件dropbear已经移植到了android平台。</p>
<p><strong>安装dropbear</strong></p>
<p>从cyanogenmod ROM中提取出dropbear和dropbearkey,拷贝到手机/system/xbin/目录下,在手机/data目录下建立子目录dropbear并在dropbear下继续建立子目录.ssh</p>
<p><strong>生成ssh登录密钥对</strong></p>
<p>电脑端利用ssh-keygen生成登录验证需要的RSA密钥对,将生成的公钥，默认文件名id_rsa.pub，拷贝并重命名为手机/data/dropbear/.ssh/authorized_keys文件,并在手机端打开终端执行<br>1 #dropbearkey -t rsa -f /data/dropbear/dropbear_rsa_host_key<br>2 #chmod 755 /data/dropbear /data/dropbear/.ssh<br>3 #chown root.root /data/dropbear/.ssh/authorized_keys<br>4 #chmod 600 /data/dropbear/.ssh/authorized_keys<br>5 #chmod 644 /data/dropbear/dropbear_rsa_host_key  </p>
<p><strong>启动sshd服务</strong><br>1 #dropbear -v -s -g  </p>
<p>从电脑端ssh登录手机<br>参考<a href="https://openwares.net/linux/ssh_auto_login.html">debian:ssh安全自动登录设置</a>,私钥要用上面用ssh-keygen生成的私钥，文件名为id_rsa,切记！</p>
]]></content>
      <categories>
        <category>Mobile</category>
      </categories>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>sshfs</title>
    <url>/2020/06/26/sshfs/</url>
    <content><![CDATA[<a id="more"></a>
<p>sshfs可以通过ssh和sftp协议来安全的在本地挂载远程文件系统，比NFS更方便的是无需更改防火墙设置，只要能使用ssh访问远程主机就可以了。</p>
<p>sshfs使用fuse在用户空间挂载远程文件系统，debian系统直接安装sshfs包，为了方便挂载，最好配置使用公私钥对来访问远程ssh主机，特别是fstab文件不支持ssh的密码访问方式。</p>
<p>挂载远程文件系统：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sshfs user@host:<span class="regexp">/mnt/</span>data/reis_dump/ <span class="regexp">/mnt/</span>hwy06_reisdb_bak/ -o reconnect</span><br></pre></td></tr></table></figure>
<p>也支持直接使用ssh别名</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sshfs hwy-reisdb-<span class="number">3</span>:<span class="regexp">/mnt/</span>data/reis_dump/ <span class="regexp">/mnt/</span>hwy06_reisdb_bak/ -o reconnect</span><br></pre></td></tr></table></figure>

<p>具体的sshfs选项参见man</p>
<p>注意：<br>ssh长时间连接会超时，导致出现类似错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">client_loop: send disconnect: Broken pipe</span><br></pre></td></tr></table></figure>
<p>可以在ssh服务器/etc/ssh/sshd_config中打开客户端心跳探测:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ClientAliveInterval <span class="number">30</span></span><br><span class="line">ClientAliveCountMax <span class="number">3</span></span><br></pre></td></tr></table></figure>
<p>30秒发送一个心跳探测，超过3次没有回应断开连接。</p>
<p>References:<br>[1]<a href="https://www.redhat.com/sysadmin/sshfs">SSHFS: Mounting a remote file system over SSH</a><br>[2]<a href="https://wiki.archlinux.org/index.php/SSHFS_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">SSHFS</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>standby数据库rman备份错误RMAN-10006</title>
    <url>/2019/09/29/standby%E6%95%B0%E6%8D%AE%E5%BA%93rman%E5%A4%87%E4%BB%BD%E9%94%99%E8%AF%AFrman-10006/</url>
    <content><![CDATA[<a id="more"></a>
<p>在物理备库上执行rman备份时出现错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">MAN-<span class="number">00601</span>: fatal error <span class="keyword">in</span> recovery manager</span><br><span class="line">RMAN-<span class="number">03004</span>: fatal error during execution <span class="keyword">of</span> command</span><br><span class="line">RMAN-10006: error running SQL statement: select sofar, context, start_time from v$session_longops where (start_time &gt; nvl(:1, sysdate-100) or start_time = nvl(:2, sysdate+100)) and sid = :3 and serial# = :4 and opname like &#x27;RMAN:%&#x27; order by start_time desc, context desc</span><br><span class="line">RMAN-<span class="number">10002</span>: ORACLE error: ORA-<span class="number">00000</span>: normal, successful completion</span><br></pre></td></tr></table></figure>

<p>这是oracle的一个bug</p>
<p>Metalink NoteID：1080134.1.<br>Cause<br>Unpublished Bug 4230058: FAIL TO CONNECT TO RMAN AFTER PHYSICAL STANDBY IS OPENED READ ONLY</p>
<p>If the standby database is opened readonly and then managed recovery is restarted without bouncing the database, queries against v$session_longops will fail with:</p>
<p>ORA-01219: database not open: queries allowed on fixed tables/views only</p>
<p>RMAN likewise will fail trying to access this view with RMAN-10006 error.</p>
<p>Solution<br>Restart the standby database after opening it in READ ONLY mode before restarting the Managed Recovery process.</p>
<p>最简单的解决方案就是重启standby实例，还有一个方法是修改数据库参数，但是如果备库转换为主库，这个参数可能会有影响，所以还是重启实例最简单。</p>
<p>References:<br>[1]<a href="https://support.oracle.com/knowledge/Oracle%20Database%20Products/1080134_1.html">RMAN backup of physical standby fails RMAN-10006 querying v$session_longops (Doc ID 1080134.1)</a><br>[2]<a href="https://www.linuxidc.com/Linux/2013-09/90095.htm">Standby上执行RMAN报错RMAN-10006错误处理</a><br>[3]<a href="http://blog.itpub.net/79499/viewspace-616835/">9208物理standby备份报错</a></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>监听模式启动libreoffice/openoffice服务</title>
    <url>/2016/09/14/start-openoffice-as-service/</url>
    <content><![CDATA[<a id="more"></a>
<p>使用JODConverter转换文档时，需要连接到正在运行的OpenOffice并执行API调用，这需要openoffice创建一个UNO监听器并运行于监听模式下。<br>下面记叙openoffice以TCP监听模式启动作为后台服务的配置方法。</p>
<p><strong>安装</strong></p>
<p>当前的debian testing官方源已经不再提供openoffice，因为这货被libreoffice替代了。去ooo<a href="https://www.openoffice.org/download/index.html">官方下载</a>Linux 64-bit(x86-64)(DEB)版本，下载的为tar.gz包，解压后进入en_US/DEBS目录，安装此目录下的所有deb包。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># dpkg -i *.deb</span><br></pre></td></tr></table></figure>

<p>ooo被安装在了/opt/openoffice4目录，可执行程序soffice位于/opt/openoffice4/program目录下。</p>
<p><strong>监听模式启动ooo</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ unset DISPLAY</span><br><span class="line">$ ./soffice -nologo -headless -nofirststartwizard -accept=<span class="string">&quot;socket,host=0,port=8100;urp;tcpNoDelay;StarOffice.ServiceManager&quot;</span></span><br></pre></td></tr></table></figure>

<p>这样ooo在本地所有网络接口地址的TCP 8100端口上启动监听服务。如果只在本地回环地址监听，可以设置host为127.0.0.1或localhost。<br>服务模式启动时不要设置DISPLAY变量。</p>
<p><strong>libreoffice</strong></p>
<p>ooo自从被收入o记囊中，是一天不如一天了，最近又传闻因为没有活跃的开发者要项目要关闭了。ooo当前最新的4.1.2还是2015年10月发布了，这货是没救了。</p>
<p>libreoffice则开发活跃，如日中天，开源社区真不是哪家公司可以一手遮天的，再大的公司也不行。</p>
<p>其实本篇所述的监听模式启动ooo是完全适用于libreoffice的，因此不必大费周章的安装openoffice,直接官方源安装libreoffice-common和libreoffice-writer即可。soffice bin存在于libreoffice-common包中，同时还需要安装jdk和libreoffice-java-common包。</p>
<p>使用libreoffice时，命令行参数使用双中线开头，不然会有deprecated提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Warning: -nologo is deprecated. Use --nologo instead.</span><br><span class="line">Warning: -headless is deprecated. Use --headless instead.</span><br><span class="line">Warning: -nofirststartwizard is deprecated. Use --nofirststartwizard instead.</span><br><span class="line">Warning: -accept=socket,host=<span class="number">0</span>,port=<span class="number">8100</span>;urp;tcpNoDelay;StarOffice.ServiceManager is deprecated. Use --accept=socket,host=<span class="number">0</span>,port=<span class="number">8100</span>;urp;tcpNoDelay;StarOffice.ServiceManager instead.</span><br></pre></td></tr></table></figure>

<p>注：ooo是openoffice.org曾经的简称,不知道现在为何官方不再使用了。</p>
<p><strong>为libreoffice设置systemd服务</strong><br>编辑libreoffice.service单元文件：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[Unit\]</span><br><span class="line">Description=LibreOffice service</span><br><span class="line">After=syslog.target</span><br><span class="line"></span><br><span class="line">\[Service\]</span><br><span class="line">ExecStart=<span class="regexp">/usr/</span>bin/soffice --accept=<span class="string">&quot;socket,host=0,port=8100;urp;StarOffice.ServiceManager&quot;</span> --headless --nofirststartwizard --nologo --nodefault --nocrashreport --nolockcheck</span><br><span class="line">Restart=always</span><br><span class="line">KillSignal=SIGQUIT</span><br><span class="line">Type=simple</span><br><span class="line">StandardError=syslog</span><br><span class="line">NotifyAccess=all</span><br><span class="line">User=tomcat8</span><br><span class="line"></span><br><span class="line">\[Install\]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<p>将编辑好的文件拷贝到/lib/systemd/system文件夹，然后启用该unit文件，最后启动libreoffice服务。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo cp libreoffice.service /lib/systemd/system/</span><br><span class="line">$ sudo systemctl enable libreoffice.service</span><br><span class="line">Created symlink <span class="keyword">from</span> /etc/systemd/system/multi-user.target.wants/libreoffice.service to /lib/systemd/system/libreoffice.service.</span><br><span class="line">$ sudo systemctl start libreoffice</span><br><span class="line">$ sudo netstat -anp grep <span class="number">8100</span></span><br><span class="line">tcp <span class="number">0</span> <span class="number">0</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">8100</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:* LISTEN <span class="number">9895</span>/soffice.bin</span><br></pre></td></tr></table></figure>

<p>可以看到libreoffice已经启用了后台服务，并在8100端口进行监听。</p>
<p><strong>update(17/10/2019):</strong><br>debian buster系统:<br>只安装libreoffice-common和libreoffice-writer包即可，tomcat9的系统用户为tomcat，权限问题<a href="https://openwares.net/2016/09/17/soffice_permission_deny_issues/">参考权限导致soffice(libreoffice/openoffice)无法运行的问题</a></p>
<p>References:<br>[1]<a href="http://serverfault.com/questions/753819/systemd-service-script-for-libreoffice-openoffice">systemd service script for libreoffice/openoffice</a><br>[2]<a href="https://gist.github.com/vjt/4194760">Libreoffice LSB init script</a><br>[3]<a href="https://blog.art-of-coding.eu/starting-multiple-openoffice-instances/">Starting Multiple OpenOffice Instances</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>函数调用栈帧示意图stack frame diagram</title>
    <url>/2009/06/27/statck-frame-diagram/</url>
    <content><![CDATA[<p><a href="/images/2009/06/stack_frame.png"><img src="/images/2009/06/stack_frame-212x300.png" alt="stack_frame" title="stack_frame"></a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>C/C++ static语义(semantics)</title>
    <url>/2009/11/18/static-semantics/</url>
    <content><![CDATA[<p>　　static可以用来修饰变量(variant)和函数(function)。但static作用于普通变量/函数与类(calss)变量/函数的语义是不一样的。<br>　　static有两种基本的语义，第一种是存储方式(storage)，这种语义只作用于变量，不适用于函数，第二种是访问控制(Access Control)。<br>　　用static修饰一个普通变量有两层含义。其一是表示该变量的值在超出作用域范围后仍然有效，一般编译器将static变量放置到全局静态存储区，比如.data或.bss(Block Started by Symbol)节，这就是存储方式语义。其二是表示该变量只在声明的作用域范围内可以被访问，比如， 声明在一个文件作用域内的变量不能被其他文件访问，这就是访问控制语义。<br>　　用static来修饰普通函数的时候则只有一种语义，即访问控制，因为无论如何，函数总是要被编译器放置到.text节的。也就是说用static修饰的普通函数不能被其他文件内的代码访问。<br>　　C++中用static来修饰成员变量和函数的语义稍有不同，其含义表示这些变量或函数是属于整个类(class)而不特定于任何一个该类的对象(object),即使该类没有一个对象产生，仍然可用使用类来访问这些变量和函数。这是C++对C static语义的扩展。</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>关于目录访问权限中的限制删除标志位(sticky位)</title>
    <url>/2009/05/07/sticky/</url>
    <content><![CDATA[<a id="more"></a>
<p>当我们说到sticky位(t)时，一般都是在说“在设置了sticky位(t)的目录下，用户只能删除属于自己的文件”，其实这样说并不确切。在网上找了几篇文章后 还是没有找到比较权威的解释，man一下chmod可以发现一段对该位的详细解释，说的很明白。翻译如下以备忘。原文见man chmod(1)。</p>
<p>“限制删除标志和粘滞位共用一个位，系统依赖于文件类型来解释此位。对于目录，该位阻止非授权用户删除或重命名本目录下的文件除非该用户是文件或目录的属 主，这就是所谓的目录的限制删除标志，通常在所有人都可写的目录/tmp上可以发现该标志。在一些老旧系统的普通程序文件上，该位使系统在交换设备上保存程序的映像从而使程序可以更快的再次运行，这就是所谓的粘滞位。”</p>
<p>所以当该位用于目录权限设置时，叫做“限制删除标志位”更合适。</p>
<p>PS:<a href="http://www.cppblog.com/proguru/archive/2009/01/13/71890.html">此文</a>最早发表于cppblog.</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Storwize v3700: CMMVC8020E</title>
    <url>/2019/08/29/storwize-v3700-cmmvc8020e/</url>
    <content><![CDATA[<a id="more"></a>
<p>v3700从服务界面新建系统时，提示：</p>
<p>CMMVC8020E: 存在存储集群标识时尝试创建集群</p>
<p>无法创建新系统，是因为以前的集群信息尚未完全清除干净,在机柜配置界面重置集群标识，再次尝试新建系统成功。</p>
<p>如果还是不行，可以尝试[1]里面讲的方法，ssh登录进存储，执行以下命令:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">satask chenclosurevpd -resetclusterid</span><br></pre></td></tr></table></figure>
<p>没有尝试，或许可以。</p>
<p>References:<br>[1]<a href="https://www.ibm.com/developerworks/community/forums/html/topic?id=183e3b72-b2c8-46cd-b677-9e784fee5855">[SOLVED] Storwize v3700: CMMVC8020E</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>奇怪的web.xml配置错误</title>
    <url>/2013/10/29/strange-web-xml-error/</url>
    <content><![CDATA[<p>奇怪的web.xml配置错误</p>
<a id="more"></a>
<p>为org.springframework.web.servlet.DispatcherServlet设置参数contextConfigLocation自定义spring配置文件的位置，设置完后如下：<br>[xml]<br><servlet><br> <servlet-name>spring</servlet-name><br> <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class><br> <load-on-startup>1</load-on-startup><br> <init-param><br> <param-name>contextConfigLocation</param-name><br> <param-value>/WEB-INF/spring-servlet.xml</param-value><br> </init-param><br></servlet><br>[/xml]</p>
<p>直接部署运行没有问题，但是用eclipse打开就在第5行处报错：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Description Resource Path Location Type</span><br><span class="line">cvc-complex-type<span class="number">.2</span><span class="number">.4</span>.a: Invalid content was found starting <span class="keyword">with</span> element <span class="string">&#x27;init-param&#x27;</span>. </span><br><span class="line">One <span class="keyword">of</span> <span class="string">&#x27;&#123;&quot;http://java.sun.com/xml/ns/javaee&quot;:enabled, &quot;http://java.sun.com/xml/ns/javaee&quot;:async-supported, </span></span><br><span class="line"><span class="string">&quot;http://java.sun.com/xml/ns/javaee&quot;:run-as, &quot;http://java.sun.com/xml/ns/javaee&quot;:security-role-ref, </span></span><br><span class="line"><span class="string">&quot;http://java.sun.com/xml/ns/javaee&quot;:multipart-config&#125;&#x27;</span> is expected.</span><br></pre></td></tr></table></figure>
<p>将配置文件改为：<br>[xml]<br><servlet><br> <servlet-name>spring</servlet-name><br> <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class><br> <init-param><br> <param-name>contextConfigLocation</param-name><br> <param-value>/WEB-INF/spring-servlet.xml</param-value><br> </init-param><br> <load-on-startup>1</load-on-startup><br></servlet><br>[/xml]<br>eclipse就不报怨了，init-param要紧跟servlet-class元素吗？没这规定吧！<br>是tomcat太宽松了还是eclipse太严格了呢？！</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>忘记sudo打开vim时写当前用户没有权限更新的文件</title>
    <url>/2014/10/23/sudo-vim-tea/</url>
    <content><![CDATA[<a id="more"></a>
<p>有时候打开文件编辑完了才发现没有权限写当前文件,退出重新编辑？不用！vim里面调用外部命令写时使用sudo就可以了。</p>
<p>:w 命令如果不提供参数,则将当前缓冲区写到当前编辑的文件内，但是如果提供参数，比如<br>:w new_file 则将当前缓冲区内容写到新文件new_file中，其实:w命令有很多种形式<br>更进一步</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:\[range\]w\[rite\] \[++opt\] !&#123;cmd&#125;</span><br><span class="line">Execute &#123;cmd&#125; <span class="keyword">with</span> \[range\] lines <span class="keyword">as</span> standard input</span><br></pre></td></tr></table></figure>
<p>上面的命令形式，将range范围内的缓冲区作为标准输入调用cmd命令。</p>
<p>而tee命令读取标准输入，然后将其写到文件和标准输出中,在vim中%代表当前编辑缓冲区的文件名，从而有了下面的命令：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:w !sudo tee %</span><br></pre></td></tr></table></figure>
<p>但tee命令还会向standard output输出内容,可以将其重定向到/dev/null</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:w !sudo tee % &gt; <span class="regexp">/dev/</span><span class="literal">null</span></span><br></pre></td></tr></table></figure>

<p>还可以利用cat命令来达到同样的目的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:w !sudo sh -c <span class="string">&quot;cat &gt; %&quot;</span></span><br></pre></td></tr></table></figure>

<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>禁止INIT:Id &quot;co&quot; respawning too fast提示</title>
    <url>/2011/07/02/suppress-init-warning/</url>
    <content><![CDATA[<p>debian testing控制台出现提示”INIT: Id “co” respawning too fast: disabled for 5 minutes.”</p>
<a id="more"></a>
<p>这应该是内核的一个bug,有很多人提出来了,这个提示是由/etc/inittab中的这行</p>
<p>co:2345:respawn:/sbin/getty hvc0 9600 linux</p>
<p>引起的。这行的意思是在运行级2345上运行一个终端类型为linux,波特率baud rate为9600的虚拟控制台hvc0</p>
<p>hvc0是一个hvc控制台实例,hvc是Hypeyvisor Virtual Console的缩写,其实际就是一个虚拟机监视虚拟控制台,因为现在linux内核集成了KVM，所以才有这么个控制台,一般我们都不会用到，所以将其关闭是安全的。</p>
<p>而XVC则指Xen Virtual Console,是Xen的管理虚拟控制台。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>为无盘系统增加交换空间(Add Swap over NFS)</title>
    <url>/2010/09/12/swap-over-nfs/</url>
    <content><![CDATA[<p>内核现在尚不支持直接在NFS磁盘空间上启用swap，如果你在NFS上创建一个swapfile，然后强行swapon，系统会毫不犹豫的提示：<br>swapon:swap file has holes<br>swapon: /path/to/swapfile: Invalid argument</p>
<a id="more"></a>
<p>只能智取，不能强攻.步骤如下：</p>
<p>在NFS共享文件系统上创建一个ext3 loop文件系统</p>
<p>dd if=/dev/zero of=/var/cache/swap.ext3 bs=1024 count=262144<br>mkfs -t ext3 /var/cache/swap.ext3</p>
<p>然后挂装之</p>
<p>echo ‘/var/cache/swap.ext3 /var/cache/swap ext3 defaults,noauto 0 0’ &gt;&gt; /etc/fstab<br>mkdir /var/cache/swap<br>mount -o loop /var/cache/swap</p>
<p>挂装后，在其中建立真正的swap文件</p>
<p>dd if=/dev/zero of=/var/cache/swap/swap0 bs=1024 count=260000<br>mkswap swap0<br>swapon swap0</p>
<p>最后一点也很重要</p>
<p>那就是这个loop文件系统不能自动挂装(noauto),因为系统启动的时候可能NFS共享还未准备好，所以在/etc/rc.local文件里增加下面两句<br>mount -o loop /var/cache/swap<br>swapon /var/cache/swap/swap0</p>
<hr>
<p>It’s OK!</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>swift on linux debian</title>
    <url>/2016/04/19/swift-on-linux-debian/</url>
    <content><![CDATA[<a id="more"></a>
<p>swift已经支持ubuntu,也可以在debian上安装</p>
<p><strong>下载</strong></p>
<p>下载ubuntu 15.10版本的安装包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//swift.org/builds/swift-2.2-release/ubuntu1510/swift-2.2-RELEASE/swift-2.2-RELEASE-ubuntu15.10.tar.gz</span></span><br></pre></td></tr></table></figure>

<p><strong>解压重新打包</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tar zxvf swift-<span class="number">2.2</span>-RELEASE-ubuntu15<span class="number">.10</span>.tar.gz</span><br><span class="line">$ cd swift-<span class="number">2.2</span>-RELEASE-ubuntu15<span class="number">.10</span></span><br><span class="line">$ tar czvf swift-<span class="number">2.2</span>.tar.gz usr</span><br><span class="line">$ sudo alien -v swift-<span class="number">2.2</span>.tar.gz </span><br></pre></td></tr></table></figure>

<p>会生成deb安装包swift_2.2-2_all.deb</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg -i swift_2<span class="number">.2</span>-2_all.deb</span><br></pre></td></tr></table></figure>

<p><strong>测试</strong></p>
<p>新建main.swift文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">print(<span class="string">&quot;hello swift&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>编译</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ swiftc main.swift -o main.s</span><br></pre></td></tr></table></figure>

<p>查看</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ file main.s</span><br><span class="line">main.s: ELF <span class="number">64</span>-bit LSB executable, x86-<span class="number">64</span>, version <span class="number">1</span> (SYSV), dynamically linked,</span><br><span class="line">interpreter /lib64/ld-linux-x86-<span class="number">64.</span>so<span class="number">.2</span>, <span class="keyword">for</span> GNU/Linux <span class="number">2.6</span><span class="number">.32</span>, </span><br><span class="line">BuildID\[sha1\]=9ed9fa8e5accc18cd0a4482b465aecf814a2a114, not stripped</span><br><span class="line"></span><br><span class="line">$ ldd main.s</span><br><span class="line"> linux-vdso.so<span class="number">.1</span> (<span class="number">0x00007ffe06af4000</span>)</span><br><span class="line"> libswiftCore.so =&gt; <span class="regexp">/usr/</span>lib/swift/linux/libswiftCore.so (<span class="number">0x00007fc4d764f000</span>)</span><br><span class="line"> libstdc++.so<span class="number">.6</span> =&gt; <span class="regexp">/usr/</span>lib/x86_64-linux-gnu/libstdc++.so<span class="number">.6</span> (<span class="number">0x00007fc4d72bc000</span>)</span><br><span class="line"> libm.so<span class="number">.6</span> =&gt; <span class="regexp">/lib/</span>x86_64-linux-gnu/libm.so<span class="number">.6</span> (<span class="number">0x00007fc4d6fbd000</span>)</span><br><span class="line"> libgcc_s.so<span class="number">.1</span> =&gt; <span class="regexp">/lib/</span>x86_64-linux-gnu/libgcc_s.so<span class="number">.1</span> (<span class="number">0x00007fc4d6da7000</span>)</span><br><span class="line"> libc.so<span class="number">.6</span> =&gt; <span class="regexp">/lib/</span>x86_64-linux-gnu/libc.so<span class="number">.6</span> (<span class="number">0x00007fc4d6a03000</span>)</span><br><span class="line"> libpthread.so<span class="number">.0</span> =&gt; <span class="regexp">/lib/</span>x86_64-linux-gnu/libpthread.so<span class="number">.0</span> (<span class="number">0x00007fc4d67e5000</span>)</span><br><span class="line"> libdl.so<span class="number">.2</span> =&gt; <span class="regexp">/lib/</span>x86_64-linux-gnu/libdl.so<span class="number">.2</span> (<span class="number">0x00007fc4d65e1000</span>)</span><br><span class="line"> libicuuc.so<span class="number">.55</span> =&gt; <span class="regexp">/usr/</span>lib/x86_64-linux-gnu/libicuuc.so<span class="number">.55</span> (<span class="number">0x00007fc4d624d000</span>)</span><br><span class="line"> libicui18n.so<span class="number">.55</span> =&gt; <span class="regexp">/usr/</span>lib/x86_64-linux-gnu/libicui18n.so<span class="number">.55</span> (<span class="number">0x00007fc4d5dea000</span>)</span><br><span class="line"> libbsd.so<span class="number">.0</span> =&gt; <span class="regexp">/lib/</span>x86_64-linux-gnu/libbsd.so<span class="number">.0</span> (<span class="number">0x00007fc4d5bd4000</span>)</span><br><span class="line"> /lib64/ld-linux-x86-<span class="number">64.</span>so<span class="number">.2</span> (<span class="number">0x0000557356b81000</span>)</span><br><span class="line"> libicudata.so<span class="number">.55</span> =&gt; <span class="regexp">/usr/</span>lib/x86_64-linux-gnu/libicudata.so<span class="number">.55</span> (<span class="number">0x00007fc4d411c000</span>)</span><br></pre></td></tr></table></figure>

<p>也可以动态解释执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ swift</span><br><span class="line">Welcome to Swift version <span class="number">2.2</span> (swift-<span class="number">2.2</span>-RELEASE). Type :help <span class="keyword">for</span> assistance.</span><br><span class="line"> <span class="number">1</span>&gt; print(<span class="string">&quot;hello, swift&quot;</span>)</span><br><span class="line">hello, swift</span><br><span class="line"> <span class="number">2</span>&gt; :q</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Github fork 分支与上游同步</title>
    <url>/2016/11/23/sync-github-fork-brach/</url>
    <content><![CDATA[<a id="more"></a>
<p>fork之后上游可能又有了一些更新，在提交pull request之前最好重新同步一下上游主干，解决可能存在的冲突之后再发起pull request</p>
<p>步骤如下：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ git remote add upstream https:<span class="comment">//github.com/jiangwen365/pypyodbc # 添加上游仓库</span></span><br><span class="line">$ git fetch upstream # 获取上游最新更新</span><br><span class="line">$ git checkout master # 切换到本地需要更新的分支头，master或者其他名字的分子都行，看需要</span><br><span class="line">$ git merge upstream/master # 合并上游master分支到本地master分支，分支名字根据需要指定，rebase亦可</span><br><span class="line">$ git push # 将更新后的本地分支推送到github</span><br></pre></td></tr></table></figure>

<p>简单明了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>系统范围内配置pac文件自动代理上网</title>
    <url>/2016/07/20/system-config-pac-auto-proxy/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果使用NetworkManager则十分简单，无需赘言。</p>
<p><strong>使用gsettings</strong><br>当然前提是使用gnome</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ gsettings set org.gnome.system.proxy autoconfig-url http:<span class="comment">//myserver/myconfig.pac</span></span><br><span class="line">$ gsettings set org.gnome.system.proxy mode auto</span><br></pre></td></tr></table></figure>

<p>浏览器配置使用系统代理设置就可以自动代理上网了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>systemd之确定的网络接口名</title>
    <url>/2015/10/08/system-predictable-network-interface-name/</url>
    <content><![CDATA[<a id="more"></a>
<p>传统的eth0,eth1,wlan0,wlan1等网络接口名字,在多网络接口卡的环境下，有多种因素会导致网络接口的名字与实际对应的网络设备发生变化，比如这次的eth0,可能下次系统重新启动后会变成eth1,这自然会导致很多很多问题。</p>
<p>当然出现了很多解决方案来避免这个问题，比如udev可以使一个网络接口的名字与网络接口的MAC地址绑定,从而只要还是那块网卡，对应的网络接口的名字就还是那个名字。</p>
<p>还有一种解决方案为”biosdevname”,当然systemd认为这些方案都有各种各样的问题，于是又有了它自己的解决方案。</p>
<p>systemd果然像有些人所言，想要控制一切！</p>
<p>systemd自v197开始使用自己的命名方案，但是只有全新安装的系统才默认使用这个命名规则，系统升级而来继续使用原先的方案。</p>
<p>所以这次系统重装后，发现wlan接口名字变成了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ iw dev</span><br><span class="line">phy#0</span><br><span class="line"> Interface wlx2016d803b954</span><br><span class="line"> ifindex <span class="number">2</span></span><br><span class="line"> wdev <span class="number">0x1</span></span><br><span class="line"> addr <span class="number">20</span>:<span class="number">16</span>:d8:<span class="number">03</span>:b9:<span class="number">54</span></span><br><span class="line"> ssid xxxxxxxx</span><br><span class="line"> type managed</span><br></pre></td></tr></table></figure>

<p>竟然用的是MAC地址,如果MAC地址改变了呢？</p>
<p>查看内核信息:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ dmesg grep wlan0</span><br><span class="line">\[ \] rtl8723au <span class="number">1</span>-<span class="number">1.4</span>:<span class="number">1.2</span> wlx2016d803b954: rename <span class="keyword">from</span> wlan0</span><br></pre></td></tr></table></figure>

<p>原来是systemd给改了名字,各种不适应,名字各种长。</p>
<p>可以禁用这种命名方式：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules</span><br></pre></td></tr></table></figure>

<p>或者给内核传递启动参数:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">net.ifnames=<span class="number">0</span></span><br></pre></td></tr></table></figure>

<p>随便吧。</p>
<p>References:<br>[1]<a href="http://www.freedesktop.org/wiki/Software/systemd/PredictableNetworkInterfaceNames/">Predictable Network Interface Names</a><br>[2]<a href="https://lists.archlinux.org/pipermail/arch-dev-public/2013-January/024231.html">network interface naming with systemd 197</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>windows内核函数命名规则(system routine naming convention)</title>
    <url>/2009/08/24/system-routine-naming-convention/</url>
    <content><![CDATA[<p>windows内核函数命名的一般格式为：</p>
<p><Prefix><Operation><Object></p>
<p>Prefix指示导出该例程的组件，Operation指出对对象或资源做什么样的动作，Object标示操作的对象或资源。比如ExAllocatePoolWithTag是一个执行体(Executive)例程,用来从分页池(paged pool)或非分页池(nonpaged pool)中分配内存。KeInitializeThread是一个分配并且设置内核线程对象(kernel thread object)的内核例程。</p>
<a id="more"></a>
<p>下面的表列出了常用的前缀和组件的对应关系。</p>
<p>Prefix</p>
<p>Component</p>
<p>Alpc</p>
<p>Advanced Local Inter-Process Communication</p>
<p>Cc</p>
<p>Common Cache</p>
<p>Cm</p>
<p>Configuration Manager</p>
<p>Dbgk</p>
<p>Debugging Framework for User-Mode</p>
<p>Em</p>
<p>Errata Manager</p>
<p>Etw</p>
<p>Event Tracing for Windows</p>
<p>Ex</p>
<p>Executive support routines</p>
<p>FsRtl</p>
<p>File System Driver Run-Time Library</p>
<p>Hal</p>
<p>Hardware abstraction layer</p>
<p>Hvl</p>
<p>Hypervisor Library</p>
<p>Io</p>
<p>I/O manager</p>
<p>Ke</p>
<p>Kernel</p>
<p>Kd</p>
<p>Kernel Debugger</p>
<p>Ks</p>
<p>Kernel Streaming</p>
<p>Lsa</p>
<p>Local Security Authority</p>
<p>Mm</p>
<p>Memory manager</p>
<p>Nt</p>
<p>NT system services(most of which are exported as Win32 functions) ,NT Native API  </p>
<p>Ob</p>
<p>Object manager</p>
<p>Pf</p>
<p>Prefetcher</p>
<p>Po</p>
<p>Power manager</p>
<p>Pp</p>
<p>PnP manager</p>
<p>Ps</p>
<p>Process support</p>
<p>Rtl</p>
<p>Run-time library</p>
<p>Se</p>
<p>Security</p>
<p>Tm</p>
<p>Transaction manager</p>
<p>Vf</p>
<p>Verifier</p>
<p>Whea</p>
<p>Windows Hardware Error Architecture</p>
<p>Wmi</p>
<p>windows management instrumentation</p>
<p>Wdi</p>
<p>windows diagnostic infrastructure</p>
<p>Zw</p>
<p>The origin of the prefix “Zw” is unknown;it is rumored that this prefix was chosen due to its having no significance at all.Mirror entry point for system services (beginning with Nt) that sets previous access mode to kernel,which eliminates parameter validation, since Nt system services validate parameters only if previous access mode is user mode</p>
<p>Lpc</p>
<p>Local Procedure Call</p>
<p>Ldr</p>
<p>Loader</p>
<p>Nls</p>
<p>National language support</p>
<p>Dbg</p>
<p>Debug</p>
<p>Tdi</p>
<p>Transport driver interface</p>
<p>Csr</p>
<p>Client Server Runtime,represents the interface to the win32 subsystem located in csrss.exe</p>
<p>Inbv</p>
<p>Initialize boot video</p>
<p>每一个系统组件还有一个变体前缀来指示内部使用(unexported)的函数，或者是组件前缀的第一个字母后面跟上i(指internal)，或者是全部的前缀跟上字母p(指private)。比如Ki指示一个Kernel内部函数，Psp指示一个Process support内部函数。</p>
<p>有些内核函数还在前缀或简化的前缀后面加上小写字母f，来指示这个函数使用fastcall调用约定,比如ObfDereferenceObject。KfRaiseIrql、KfLowerIrql、KfAcquireSpinLock、KfReleaseSpinLock等亦属此类。</p>
<p>经常会有人问Zw到底是什么单词的缩写(abbreviation),而且有种种的猜测在流传。实际上到现在也没有一个权威的说法，姑且认为选择这样一个古怪的前缀很难与其他组件发生冲突吧。</p>
<p>如果你知道这里没有列出的前缀或者有错误的地方，欢迎留言指出。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>systemd的模板单元文件和实例单元文件</title>
    <url>/2018/07/18/systemd-template-unit-file-and-instance-unit-file/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>模板单元文件和实例单元文件</strong></p>
<p>使用模板，一个模板单元(unit)文件可以创建多个实例化的单元文件，从而简化系统配置。</p>
<p>模板单元文件的文件名中包含一个@符号，@位于单元基本文件名和扩展名之间，比如:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">example@.service</span><br></pre></td></tr></table></figure>

<p>当从模板单元文件创建实例单元文件时，在@符号和单元扩展名(包括符号.)之前加入实例名,比如：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">example@instance1.service</span><br></pre></td></tr></table></figure>

<p>表明实例单元文件<a href="mailto:&#101;&#120;&#x61;&#109;&#112;&#108;&#x65;&#x40;&#105;&#x6e;&#115;&#x74;&#97;&#x6e;&#99;&#101;&#49;&#46;&#115;&#x65;&#114;&#x76;&#x69;&#x63;&#x65;">&#101;&#120;&#x61;&#109;&#112;&#108;&#x65;&#x40;&#105;&#x6e;&#115;&#x74;&#97;&#x6e;&#99;&#101;&#49;&#46;&#115;&#x65;&#114;&#x76;&#x69;&#x63;&#x65;</a>实例化自模板单元文件example@.service，其实例名为instance1</p>
<p>实例单元文件一般是模板单元文件的一个符号链接，符号链接命中包含实例名，systemd就会传递实例名给模板单元文件。</p>
<p>在相应的target中创建实例单元文件符号链接之后，需要运行一下命令将其装载：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure>

<p><strong>模板标识符/参数</strong></p>
<p>模板单元文件中可以使用一些标识符，当被实例化为实例单元文件并运行时，systemd会将标识符的实际值传递给对应的标识符，比如在模板单元文件中是用%i，实际运行实例单元文件时，会将实例名传递给%i标识符。</p>
<p>有以下可用的标识符：</p>
<blockquote>
<p>%n: Anywhere where this appears in a template file, the full resulting unit name will be inserted.<br>%N: This is the same as the above, but any escaping, such as those present in file path patterns, will be reversed.<br>%p: This references the unit name prefix. This is the portion of the unit name that comes before the @ symbol.<br>%P: This is the same as above, but with any escaping reversed.<br>%i: This references the instance name, which is the identifier following the @ in the instance unit. This is one of the most commonly used specifiers because it will be guaranteed to be dynamic. The use of this identifier encourages the use of configuration significant identifiers. For example, the port that the service will be run at can be used as the instance identifier and the template can use this specifier to set up the port specification.<br>%I: This specifier is the same as the above, but with any escaping reversed.<br>%f: This will be replaced with the unescaped instance name or the prefix name, prepended with a /.<br>%c: This will indicate the control group of the unit, with the standard parent hierarchy of /sys/fs/cgroup/ssytemd/ removed.<br>%u: The name of the user configured to run the unit.<br>%U: The same as above, but as a numeric UID instead of name.<br>%H: The host name of the system that is running the unit.<br>%%: This is used to insert a literal percentage sign.</p>
</blockquote>
<p>References:<br>[1] <a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files">Understanding Systemd Units and Unit Files</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>terminal modes</title>
    <url>/2020/02/25/terminal-modes/</url>
    <content><![CDATA[<a id="more"></a>
<p>The Linux terminals that are provided by the console device drivers include line-mode terminals, block-mode terminals, and full-screen mode terminals.</p>
<p>On a full-screen mode terminal, pressing any key immediately results in data being sent to the terminal. Also, terminal output can be positioned anywhere on the screen. This feature facilitates advanced interactive capability for terminal-based applications like the vi editor. It works in raw mode default,can set to cbreak mode also.</p>
<p>On a line-mode terminal, the user first types a full line, and then presses Enter to indicate that the line is complete. The device driver then issues a read to get the completed line, adds a new line, and hands over the input to the generic TTY routines. It works in cooked mode default.</p>
<p>The terminal that is provided by the 3270 terminal device driver is a traditional IBM® mainframe block-mode terminal. Block-mode terminals provide full-screen output support and users can type input in predefined fields on the screen. Other than on typical full-screen mode terminals, no input is passed on until the user presses Enter. The terminal that is provided by the 3270 terminal device driver provides limited support for full-screen applications. For example, the ned editor is supported, but not vi.</p>
<p>References:<br>[1]<a href="https://en.wikipedia.org/wiki/Terminal_mode">Terminal mode</a><br>[2]<a href="https://stackoverflow.com/questions/13104460/confusion-about-raw-vs-cooked-terminal-modes">Confusion about raw vs. cooked terminal modes?</a><br>[3]<a href="http://foldoc.org/cooked%20mode">cooked mode</a><br>[4]<a href="https://utcc.utoronto.ca/~cks/space/blog/unix/CBreakAndRaw">What goes into the terminal’s ‘cbreak’ and ‘raw’ modes</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>SyntaxHighlighter Evolved test</title>
    <url>/2013/05/11/test/</url>
    <content><![CDATA[<p>syntax highlight test case</p>
<a id="more"></a>
<p>cpp:<br>[cpp highlight=”3”]<br>#include <iostream><br>int main(int argc, char** argv){<br> std::cout&lt;&lt;”hello,world!”&lt;&lt;std::endl;<br> return 0;<br>}<br>[/cpp]</p>
<p>html:<br>[xml]<br><!DOCTYPE html></p>
<html>
 <head>
 <title>test</title>
 </head>
 <body>
 hello,world!
 </body>
</html>
\[/xml\]]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>TeX,LaTeX,TexLive与LyX</title>
    <url>/2013/12/02/tex-latex-texlive-lyx/</url>
    <content><![CDATA[<p>简单记叙这几者的关系</p>
<a id="more"></a>
<p>TeX是高爷爷(Donald.E.Knuth)为了他的巨著The Art of Computer Programming写的排版软件，在学术界十分流行，主要用于写学术论文和书籍。TeX发音类似”泰赫”。</p>
<p>LaTex基于Tex,LaTeX使用TᴇX作为它的格式化引擎，当前的版本是LaTeX2e。LaTex发音类似于”雷泰赫”。</p>
<blockquote>
<p>其实世界上只有一个TeX程序，它就叫做 “tex”, 它是由 D. E. Knuth 设计并且实现的。TeX 不仅是一个排版程序，而且是一种程序语言。LaTeX 就是用这种语言写成的一个“TeX 宏包”，它扩展了 TeX 的功能，使我们很方便的逻辑的进行创作而不是专心于字体，缩进这些烦人的东西。TeX 还有其它的大型宏包，它们和 LaTeX 一起 都被叫做 “format”，现在还有一种常用的format叫做 ConTeXt, 用 它能方便的作出漂亮的幻灯片，动态屏幕文档…… 我们通常用 TeX 都是在用 LaTeX, ConTeXt, 因为 TeX 的底层需要更多的知识才 能了解，一般人不需要自己设计自己的格式。</p>
</blockquote>
<p>TeXLive是一个跨平台LaTeX分发版，是一个LaTeX安装编译包。就像Debian之于Linux。</p>
<p>LyX是一个所见即所得的LaTex可视化编辑器。在Debian系统上,LyX正依赖于LaTex的分发版TeXLive。</p>
<p>参考：<br><a href="http://docs.huihoo.com/homepage/shredderyin/tex_frame.html">TeX — Beauty and Fun</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>TextEdit默认打开空白文档</title>
    <url>/2018/11/25/textedit-open-blank-document-default/</url>
    <content><![CDATA[<a id="more"></a>
<p>打开TextEdit时提示选择或者新建文件对话框，挺烦人的，用下面的命令可以关闭这一特性，让TextEdit直接打开新文档</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ defaults write -g NSShowAppCentricOpenPanelInsteadOfUntitledFile -bool <span class="literal">false</span></span><br></pre></td></tr></table></figure>

<p>还原命令：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ defaults <span class="keyword">delete</span> -g NSShowAppCentricOpenPanelInsteadOfUntitledFile</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>线程安全</title>
    <url>/2013/11/27/thread-safe/</url>
    <content><![CDATA[<p>在这个多核的时代，代码的线程安全是应该优先被考虑的事情。</p>
<a id="more"></a>
<p><strong>原子指令</strong></p>
<p>其实不只是函数有线程安全的考量，在CPU的指令级别也有中断安全(有时候也表现为线程安全)的问题，所有就有了原子操作之说。</p>
<p>在一条涉及内存操作的指令执行期间，如果其使用的内存被其他线程修改，则会造成corrupt，因此CPU提供了LOCK指令，可以用于暂时锁定总线上的内存单元。</p>
<p><strong>线程安全</strong></p>
<p>线程安全是指函数在多个并发(Concurrence)或并行(Parallel)线程中异步执行时，可以被安全的调用，并且函数的行为是可以预期的，则说函数是线程安全的。</p>
<p>如果一个函数不依赖于共享资源，只使用传递给函数的参数和函数的本地变量，并且本地变量没有引用其他共享资源，函数内部没有调用其他非线程安全的函数，则这样的函数是线程安全的。如果线程在使用共享资源时正确的通过锁机制访问共享资源，那么也可以是线程安全的。</p>
<p>系统中每个线程有一个单独使用的栈，所有的调用参数和本地变量都在栈上分配，线程可以安全的使用栈上的变量，但是当栈上的变量引用其他共享资源时，则应做单独的考量。</p>
<p><strong>可重入</strong></p>
<p>如果函数可以被安全的异步并发或并行执行，函数的行为是可以预期的，并且函数自身不改变函数外部的任何状态，只通过输入参数和输出参数与外部通讯，则说函数是可重入的。也可以说是幂等的。</p>
<p>可重入的函数一定是线程安全的，但线程安全的函数不一定是可重入的，比如修改共享资源状态的线程安全函数是不可重入的。</p>
<p><strong>有状态与无状态</strong></p>
<p>这里只讨论(类)对象的有状态与无状态。</p>
<p>有数据成员的(类)对象是有状态的，不同的数据值代表了(类)对象不同的状态，而没有数据成员的(类)对象是无状态的，因为除了(类)对象的内存地址不同之外，无法通过其他方式区分出不同的对象。</p>
<p>如果有状态的对象，其数据成员不全部都是static静态的，那么这个对象不是线程安全的。因为不同的线程可能会同时修改这个对象的非static数据成员，造成不一致的情况出现。</p>
<p>如果是无状态的对象，或者是有状态的对象，但是其数据成员全部是static的，并且对象的成员函数都是线程安全的，那么这个对象也是线程安全的。</p>
<p>对于非线程安全的对象，可以通过将其私有状态存储到线程局部变量(java里面叫ThreadLocal)里面来使其成为线程安全的，当然其成员函数也应该是线程安全的。</p>
<p>在成员函数是线程安全的前提下，可以这样说，无状态的对象一定是线程安全的，有状态的对象不一定是线程不安全的，如果其状态都是静态的，那么有状态对象也是线程安全的。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>Tk虚拟事件</title>
    <url>/2015/06/03/tk-vitual-events/</url>
    <content><![CDATA[<a id="more"></a>
<p>Tk预定了不少虚拟事件,比如<br>[html]<br>&lt;<Copy>&gt;,&lt;<Cut>&gt;,&lt;<Paste>&gt;,&lt;<Clear>&gt;,&lt;<SelectAll>&gt;,&lt;<Undo>&gt;,&lt;<Redo>&gt;<br>[/html]<br>等,方便应用程序处理一些公共事务。</p>
<p>References:<br>[1] <a href="https://www.tcl.tk/man/tcl/TkCmd/event.htm">Tk event</a></p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Tkinter系统剪贴板操作API</title>
    <url>/2015/06/03/tkinter-clipboard-api/</url>
    <content><![CDATA[<a id="more"></a>
<p>Tkinter.Tk.clipboard_get(selection=’CLIPBOARD’, type=’STRING’) # 获取系统剪贴板内容<br>Tkinter.Tk.clipboard_append(string,type=’STRING’) # 设置系统剪贴板内容<br>Tkinter.Tk.clipboard_clear() # 清空系统剪贴板</p>
]]></content>
      <categories>
        <category>Lang</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>tkinter可视化界面设计器page</title>
    <url>/2014/08/12/tkinter-visual-ui-editor-page/</url>
    <content><![CDATA[<a id="more"></a>
<p>发现一个靠谱的python tkinter可视化界面设计器,<a href="http://page.sourceforge.net/">page</a>,仍在活跃开发,支持python 2.7和3.2, 经测最新的python 3.4也没问题。</p>
<p>下载后，解压执行page.tcl即可，不要执行page。</p>
<p>不过page.tcl需要做小小的修改,最前面三行修改为如下行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line"># the next line restarts using wish\\</span><br><span class="line">exec wish <span class="string">&quot;$0&quot;</span> <span class="string">&quot;$@&quot;</span></span><br></pre></td></tr></table></figure>

<p>使用方法很简单，添加一个toplevel,然后拖拉组件，设置组件的属性，最后生成py模块,然后再添加事件处理函数就差不多了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>使用tls-alpn-01部署Let’s Encrypt证书</title>
    <url>/2019/07/08/tls-alpn-01-deploy-lets-encrypt-ssl-cert/</url>
    <content><![CDATA[<a id="more"></a>
<p>TLS-SNI-01已经deprecated，但certbot尚不支持tls-alpn-01验证方法，因此可以使用dehydrated或者acme.sh通过https来获取Let’s Encrypt证书。</p>
<p>使用TLS_ALPN获取证书，需要使用443端口进行验证，借助nginx的ngx_stream_ssl_preread_module模块，可以路由来自443的请求到不同的处理后端。</p>
<p><strong>确保nginx支持ssl_preread特性</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ nginx -V <span class="number">2</span>&gt;&amp;<span class="number">1</span> grep -o ssl_preread</span><br><span class="line">ssl_preread</span><br></pre></td></tr></table></figure>

<p><strong>配置nginx</strong><br>/etc/nginx/nginx.conf文件最后添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">stream &#123;</span><br><span class="line"> map $ssl_preread_alpn_protocols $tls_port &#123;</span><br><span class="line"> ~\\bacme-tls/<span class="number">1</span>\\b <span class="number">10443</span>;</span><br><span class="line"> <span class="keyword">default</span> <span class="number">8443</span>;</span><br><span class="line"> &#125;</span><br><span class="line"> server &#123;</span><br><span class="line"> listen <span class="number">443</span>;</span><br><span class="line"> listen \[::\]:<span class="number">443</span>;</span><br><span class="line"> proxy_pass <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:$tls_port;</span><br><span class="line"> ssl_preread on;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样来自签发证书时的验证请求会被路由到10443端口，而其他对443端口的访问会被路由到8443端口，所以虚拟主机应该在8443端口上监听ssl连接。</p>
<p>reload nginx使新配置生效</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl reload nginx</span><br></pre></td></tr></table></figure>

<p><strong>申请证书</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"># acme.sh --issue --alpn --tlsport 10443 -d openwares.net</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">**安装证书**</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span>js</span><br><span class="line"># acme.sh --installcert -d openwares.net \\</span><br><span class="line"> --key-file /etc/nginx/ssl/openwares.net.key \\</span><br><span class="line"> --fullchain-file /etc/nginx/ssl/fullchain.cer \\</span><br><span class="line"> --reloadcmd <span class="string">&quot;systemctl force-reload nginx&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>更新证书</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># acme.sh --renew -d openwares.net --force</span><br></pre></td></tr></table></figure>

<p><strong>注意(updated 02/29/2020)：</strong><br>如果<a href="https://openwares.net/2020/02/07/nginx-ssl-preread-real-client-ip/">启用了proxy_protocol</a>以获取客户端的真实地址，申请或者更新证书时会出现错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Verify error:<span class="built_in">Error</span> getting validation data</span><br></pre></td></tr></table></figure>
<p>因此申请或更新证书时需要临时禁止proxy_protocol协议。</p>
<p>References:<br>[1]<a href="https://medium.com/@decrocksam/deploying-lets-encrypt-certificates-using-tls-alpn-01-https-18b9b1e05edf">Deploying Let’s Encrypt certificates using tls-alpn-01 (https)</a><br>[2]<a href="https://www.wuzhiyuan.com/2018/11/18/tls-alpn/">使用TLS-ALPN-01验证签发证书</a><br>[3]<a href="https://github.com/Neilpang/acme.sh/wiki/TLS-ALPN-without-downtime">TLS ALPN without downtime</a><br>[4]<a href="https://raymii.org/s/tutorials/nginx_1.15.2_ssl_preread_protocol_multiplex_https_and_ssh_on_the_same_port.html">ssl_preread_protocol, multiplex HTTPS and SSH on the same port</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>配置tomcat7使用http端口80</title>
    <url>/2013/09/27/tomcat-80-port/</url>
    <content><![CDATA[<p>tomcat默认配置使用8080端口提供服务。tomcat主要是作为一个java容器或者说servlet容器存在，而apache,nginx,iis此类的web服务器通常占用http默认端口80。tomcat也可以作为web服务器使用，只是其性能和灵活性比apache,nginx等略差。若配置tomcat使用APR(Apache Portable Runtime)能极大的提升其web服务性能。</p>
<a id="more"></a>
<p>如果只使用tomcat,没有其他web服务器占用80端口，则可以更改配置使其使用80端口对外提供服务。因为非特权用户无法绑定1024以下的端口，因此还需要借助于authbind。</p>
<p>此处配置针对的是debian jessie上tomcat7而言。</p>
<p>首先，修改/etc/tomcat7/server.xml<br>[xml]<br>&lt;Connector port=”8080” protocol=”HTTP/1.1”<br>[/xml]<br>更改为<br>[xml]<br>&lt;Connector port=”80” protocol=”HTTP/1.1”<br>[/xml]</p>
<p>如果此时重新启动tomcat7,则/var/log/tomcat7/catalina.out会有如下输出：</p>
<p>SEVERE: Failed to initialize end point associated with ProtocolHandler [“http-bio-80”]<br>java.net.BindException: Permission denied :80<br>…</p>
<p>这就是权限问题导致的。</p>
<p>其次，修改/etc/default/tomcat7,在文件最后添加<br>AUTHBIND=yes</p>
<p>然后</p>
<h1 id="etc-init-d-tomcat7-restart"><a href="#etc-init-d-tomcat7-restart" class="headerlink" title="/etc/init.d/tomcat7 restart"></a>/etc/init.d/tomcat7 restart</h1><p>就可以用80端口访问tomcat了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat将应用程序部署到主机根目录</title>
    <url>/2013/11/19/tomcat-deploy-root-context/</url>
    <content><![CDATA[<a id="more"></a>
<p>Tomcat支持多虚拟主机，每个虚拟主机又可以有多个虚拟目录,应用程序可以部署到虚拟目录，也可以直接部署到虚拟主机的根目录</p>
<p><strong>添加虚拟主机</strong></p>
<p>[xml]<br><Engine name="Catalina" defaultHost="localhost"><br> <Host name="openwares.net" appBase="/path/to/webapps"
 unpackWARs="true" autoDeploy="true"></p>
<p> <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs"
 prefix="openwares_access_log." suffix=".txt"
 pattern="%h %l %u %t &quot;%r&quot; %s %b" /></p>
 </Host>
</Engine>
\[/xml\]

<p>主机的基本目录为/path/to/webapps，默认情况下,该目录下的ROOT目录为主机根虚拟目录，其他命名目录为相应名字的虚拟目录。<br>也就是说，访问<a href="http://openwares.net/%E4%BC%9A%E8%AE%BF%E9%97%AE%E5%88%B0/path/to/webapps/ROOT%E7%9B%AE%E5%BD%95%EF%BC%8C%E8%80%8C%E8%AE%BF%E9%97%AEhttp://openwares.net/foo">http://openwares.net/会访问到/path/to/webapps/ROOT目录，而访问http://openwares.net/foo</a><br>则会访问到/path/to/webapps/foo目录。</p>
<p>如果是部署war文件，则ROOT.war对应根虚拟目录/，而foo.war则对应/foo虚拟目录</p>
<p><strong>部署应用程序到根虚拟目录</strong></p>
<p>最简单的办法就是，直接将应用程序部署到虚拟主机appBase目录下的ROOT目录，如果是部署war包则将其命名为ROOT.war放到appBase目录下</p>
<p>还有一个方法是为应用程序在虚拟主机内添加一个Context,有两个选择：</p>
<ul>
<li>直接修改server.xml配置文件<br>在虚拟主机配置下面添加Context<br>[xml]<br><Host name="openwares.net" appBase="/path/to/webapps"
unpackWARs="true" autoDeploy="true"><br><Context path="" docBase="/path/to/webapps"></Context></Host>
\[/xml\]
path留空，则表示根虚拟路径/映射到/path/to/webapps目录。如果path="/foo",则/foo虚拟路径映射到/path/to/webapps</li>
<li>  在Catalina/主机名/目录下添加Context配置文件<br>Catalina/openwares.net/ROOT.xml<br>[xml]<?xml version="1.0" encoding="utf-8"?>
<Context path="" docBase="/path/to/webapps"></Context><br>[/xml]</li>
</ul>
<p>注意xml配置文件的命名，ROOT.xml表示配置的虚拟路径为根虚拟路径，配置文件里面的path和上面一样要置空。<br>如果配置访问应用程序的虚拟路径为/foo,则配置文件名为foo.xml<br>Catalina/openwares.net/foo.xml<br>[xml]<br><?xml version="1.0" encoding="utf-8"?><br><Context path="/foo" docBase="/path/to/webapps"></Context><br>[/xml]</p>
<p>第二种方法更好一些</p>
<p><strong>注意</strong>：使用context配置根虚拟路径时，host的docBase一定不要与Context的docBase指向同一个目录，host默认的ROOT Context优先级比较高，会使用户设置的ROOT Context失效。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>随机数生成导致的tomcat启动缓慢</title>
    <url>/2015/08/22/tomcat-startup-slow/</url>
    <content><![CDATA[<a id="more"></a>
<p>tomcat 7+依赖于SecureRandom为其session id及其他事项生成随机数，但由于JRE等各方面的因素，可能会导致tomcat启动特别缓慢。<br>catalina.out里会有类似如下提示</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">INFO: Creation <span class="keyword">of</span> SecureRandom instance <span class="keyword">for</span> session ID generation using \[SHA1PRNG\] took \[<span class="number">586</span>,<span class="number">623</span>\] milliseconds.</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>通过配置JRE使用非阻塞的熵源，可以解决此问题，但因随机性下降会降低系统安全性。</p>
<p>为JRE添加如下属性</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-Djava.security.egd=file:<span class="regexp">/dev/</span>./urandom</span><br></pre></td></tr></table></figure>

<p>比如可以在/etc/default/tomcat8中的添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=<span class="string">&quot;-Djava.awt.headless=true -Xmx1280m -XX:+UseConcMarkSweepGC -Djava.security.egd=file:/dev/./urandom&quot;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://wiki.apache.org/tomcat/HowTo/FasterStartUp">How do I make Tomcat startup faster?</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Debian系统Tomcat 7多实例配置</title>
    <url>/2013/10/25/tomcat7-multiinstances-setup/</url>
    <content><![CDATA[<p>一个服务器上一个tomcat安装，可以运行多个实例，多个实例有自己单独的配置。</p>
<a id="more"></a>
<p>tomcat支持一个安装运行多个实例。$CATALINA_HOME表示tomcat安装目录，$CATALINA_BASE表示实例所在的目录。<br>debian遵循<a href="http://www.pathname.com/fhs/">FHS</a>标准，所以将tomcat拆分安装到符合FHS标准的目录。debian官方包tomcat7的$CATALINA_HOME指向/usr/share/tomcat7，默认安装实例的$CATALINA_BASE指向/var/lib/tomcat7。配置文件理所当然的在/etc/tomcat7，配置默认值在/etc/default/tomcat7。</p>
<p>默认情况下，如果没有配置多实例，$CATALINA_BASE和$CATALINA_HOME指向同一个路径，当然Debian做了拆分，就算单实例，二者也指向不同的路径。</p>
<p>当运行单独的多个实例时，tomcat文件应做如下拆分：</p>
<p>每个单独实例$CATALINA_BASE中包含以下目录和文件：</p>
<ul>
<li>  bin目录: setenv.sh (*nix) 或者 setenv.bat (Windows),tomcat-juli.jar</li>
<li>  conf目录：服务器配置文件包括server.xml等</li>
<li>  lib目录：实例共享的库和类文件</li>
<li>  logs目录：日志和输出文件</li>
<li>  webapps目录：放置自动加载的应用程序</li>
<li>  temp目录：临时文件目录</li>
</ul>
<p>唯一的Tomcat安装$CATALINA_HOME包含以下目录和文件：</p>
<ul>
<li>  bin目录：启动和关闭脚本。如果单独实例的bin没有包含setenv.sh (*nix)或setenv.bat (Windows)、tomcat-juli.jar，这些文件也可以放在此处。</li>
<li>  lib目录：所有实例共享的库和类文件</li>
<li>  endorsed目录：用于覆盖JRE标准库的库文件。默认这个目录是空的。</li>
</ul>
<p>因为debian使用init启动脚本来管理tomcat7，所以并没有使用setenv.sh这个文件。所以一个最小的单独运行实例只要有一个conf目录和完整的配置文件即可,<br>将tomcat-juli.jar放到$CATALINA_HOME/bin目录下。可以拷贝$CATALINA_HOME/conf目录，然后做相应修改即可。</p>
<p>每一个实例必须使用单独的控制端口和连接端口，各个实例不能冲突。<br>在由tomcat处理的XML配置文件中，可以用${catalina.home}引用$CATALINA_HOME，用${catalina.base}引用$CATALINA_BASE。</p>
<p>比如，tomcat标准的web管理应用可以安装在$CATALINA_HOME/webapps/manager,然后在实例中按如下方式加载：</p>
<ol>
<li> $ cp ${CATALINA_HOME}/webapps/manager/META-INF/context.xml ${CATALINA_BASE}/conf/Catalina/localhost/manager.xml</li>
<li>在配置文件中添加:<br> [xml]<br> <Context docBase="${catalina.home}/webapps/manager"
  antiResourceLocking="false" privileged="true" ><br>  <Valve className="org.apache.catalina.valves.RemoteAddrValve"
  allow="127\\.0\\.0\\.1" />  </Context>
 \[/xml\]


</li>
</ol>
<p>参考：<br><a href="http://tomcat.apache.org/tomcat-7.0-doc/RUNNING.txt">Advanced Configuration - Multiple Tomcat Instances</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>tomcat9 默认文件/目录创建权限</title>
    <url>/2019/11/14/tomcat9-umask/</url>
    <content><![CDATA[<a id="more"></a>
<p>tomcat9默认的文件创建权限UMASK更改为0027,创建的文件/目录其他用户是没有权限访问的,而nginx worker process默认使用nobody用户来运行,因此也无法访问tomcat9创建的文件</p>
<p><strong>更改tomcat9的UMASK</strong></p>
<p>/usr/share/tomcat9/bin目录下如果没有setenv.sh,添加此文件,内容如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">UMASK=<span class="number">0022</span></span><br></pre></td></tr></table></figure>

<p>使此文件可执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo chmod +x setenv.sh</span><br></pre></td></tr></table></figure>

<p>重新启动tomcat9</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl restart tomcat9</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>tomcat9 访问目录权限问题</title>
    <url>/2019/11/13/tomcat9-%E8%AE%BF%E9%97%AE%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<a id="more"></a>
<p>tomcat9在systemd的沙箱中运行，默认只能访问一下路径：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">- <span class="regexp">/var/</span>lib/tomcat9/conf/Catalina (actually /etc/tomcat9/Catalina)</span><br><span class="line">- <span class="regexp">/var/</span>lib/tomcat9/logs (actually /<span class="keyword">var</span>/log/tomcat9)</span><br><span class="line">- <span class="regexp">/var/</span>lib/tomcat9/webapps</span><br><span class="line">- <span class="regexp">/var/</span>lib/tomcat9/work (actually /<span class="keyword">var</span>/cache/tomcat9)</span><br></pre></td></tr></table></figure>
<p>如果需要访问其他路径，需要覆盖默认的service设置，添加文件/etc/systemd/system/tomcat9.service.d/override.conf，其内容如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[Service\]</span><br><span class="line"> ReadWritePaths=<span class="regexp">/path/</span>to/the/directory/</span><br></pre></td></tr></table></figure>
<p>然后</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl daemon-reload</span><br><span class="line">$ sudo systemctl restart tomcat9</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://salsa.debian.org/java-team/tomcat9/blob/master/debian/README.Debian">README.Debian</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
        <category>java</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ff带套(tor)翻墙上youtube无法播放视频问题的解决办法</title>
    <url>/2010/02/20/tor-youtube/</url>
    <content><![CDATA[<p>firefox 3.6带套上youtube(一定要代理*.youtube.com,只代理<a href="http://www.youtube.com是不可以的),首页页面显示混乱,打不开视频,随便点击一个视频连接,出现提示“hello/">www.youtube.com是不可以的)，首页页面显示混乱，打不开视频，随便点击一个视频连接，出现提示“Hello</a>, you either have JavaScript turned off or an old version of Adobe’s Flash Player. Get the latest Flash player.” flash版本不够新云云。如果更新了adobe flash player并且打开了JavaScript还是无法观看，请将这个网址ytimg.com一并加入tor代理网络，应该就可以正常观看了。不是火狐的问题，也不是洋葱的问题，都是该死的Great Fucking Wall的问题。郁闷了很久…</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>负数补码(two’s complement)的原理及证明</title>
    <url>/2009/07/01/tows-complement-proof/</url>
    <content><![CDATA[<p>在本文里面，com指代complement, neg指代negative,并且本文涉及的是”2的补码”(two’s complement)而不是”1的补码”(one’s complement)</p>
<p>学过计算机的大部分人都知道负数在计算机内部是用补码表示的，但是大部分的教材和文章里面都只是简单的告诉你负数的补码等于其反码加一云云，至于为什么是这样，则基本上都语焉不详。</p>
<p>负数用补码表示的好处就是减法可以转化为加法，简化硬件设计，CPU只用一个加法器就可以进行加减法运算了。</p>
<p>下面我就尝试着来证明一下，为什么负数的补码等于反码加一。<br>理解下面的推导要求读者必须了解模数的概念和求模运算。</p>
<a id="more"></a>
<p>假设我们的运算使用n位二进制数，那么这n位二进制数的模数为2n,数α为一个用n位二进制表示的常数，数x为一个用n位二进制表示的变数，那么α &lt; 2n ，x &lt; 2n是成立的，在这里α与x都是用原码表示的。现在我们从α减掉x，推导如下：</p>
<p>α – x = 2n%2n + (α - x) % 2n<br>        = (2n + (α - x)) % 2n<br>        = (α + 2n - x) % 2n<br>        = (α) % 2n + (2n – x) % 2n<br>        = α + (2n – x)</p>
<p>我们现在将α – x这个减法运算成功演化成了 α + (2n – x)这个加法运算。从模数的概念我们知道,如果两个数相加等于其模数，那么这两个数是互补的。在这里x与2n – x是互补的，减掉数x与加上其补数2n - x是相等的。在这里还隐藏了一层含义，一个正数加上一个负数，如果有进位产生，把进位简单的舍弃掉是不影响计算结果的。<br>我们得出第一个结论：<br>xcom = 2n – x</p>
<p>反码则简单的多，一个数的全部二进制位取反则得到其反码，由此可知，如果一个数加上它的反码，则此全部二进制位是满的，也就是全部是1，其值为2n-1 + 2n-2 + … + 22 + 21 + 20 = 2n – 1<br>我们得出第二个结论<br>xneg = 2n – 1 – x</p>
<p>综合结论一和二，我们可以做如下推导：<br>xcom = 2n– x<br>        = 2n – 1 – x + 1<br>        = xneg + 1</p>
<p>至此我们得出最终结论一个n位二进制数的补数等于其反码加一。</p>
<p>我们再回头看看，我们曾经说“x与2n - x是互补的，减掉数x与加上其补数2n – x是相等的”，减掉数x，我们可以看做是加-x,也就是”加-x”与”加2n – x”是对等的，那么在计算机中-x用2n – x做其补码就顺理成章了,注意这里说的是补码而不是补数。</p>
<p>现在我们把x替换为1，n替换为8，得出-1的补码为28-1=255=0xFF，这就是-1在计算机里面的真实面目。当然对于正数就另当别论了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>trac + git + nginx + postgresql 配置</title>
    <url>/2015/04/05/trac-git-nginx-configuration/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>简介(intro)</strong><br>Trac is an enhanced wiki and issue tracking system for software development projects.<br>Trac是成熟的软件开发项目管理自由软件，支持wiki，问题跟踪，里程碑，版本控制工具集成等特性。</p>
<p><strong>先决条件(prerequisites)</strong></p>
<p>不使用源里的包安装，使用pip安装最新的stable,所以需要先安装python-dev</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># apt-get install python-dev</span><br></pre></td></tr></table></figure>

<p>安装uWGSI</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ apt-get install uwsgi uwsgi-plugin-python</span><br></pre></td></tr></table></figure>

<p><strong>安装(install)</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># pip \[--proxy http://ip:port\] install babel pygments trac psycopg2</span><br></pre></td></tr></table></figure>
<p>如果需要使用代理，指定–proxy参数<br>babel用于国际化，pygments用于语法高亮,由于使用PostgresQL数据库，所以要安装psycopg2</p>
<p><strong>创建数据库角色和数据库</strong></p>
<p>创建角色</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ createuser -U postgres -h localhost --createdb trac_db_admin </span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo su - postgres</span><br><span class="line">postgres@xxx:~$ createuser --pwprompt --createdb trac_db_admin</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">postgres=# CREATE ROLE trac_db_admin CREATEDB LOGIN PASSWORD &#x27;passwd&#x27;;</span><br></pre></td></tr></table></figure>

<p>创建数据库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ createdb --host=localhost --username=trac_db_admin --owner=trac_db_admin --encoding=UTF8 trac_db</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ psql -U trac_db_admin -h localhost</span><br><span class="line">sql&gt;create database trac_db;</span><br></pre></td></tr></table></figure>

<p><strong>升级setuptools</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget https:<span class="comment">//bootstrap.pypa.io/ez_setup.py -O - sudo python</span></span><br></pre></td></tr></table></figure>

<p><strong>创建trac项目/环境</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># trac-admin /var/trac/projects/proj_name initenv</span><br></pre></td></tr></table></figure>

<p>提示输入数据库连接串时这样输入：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">postgres:<span class="comment">//trac_db_admin:admin@localhost/trac_db</span></span><br></pre></td></tr></table></figure>
<p>也可以用unix socket方式，具体看官方文档。</p>
<p><strong>WSGI方式部署trac到nginx</strong></p>
<p>生成uWSGI入口程序/var/trac/cgi-bin/trac.wsgi文件</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># trac-admin /var/trac/projects/proj_name deploy /var/trac</span><br></pre></td></tr></table></figure>
<p>修改trac.wsgi支持多项目,去掉trac.env_path环境变量，添加trac.env_parent_dir变量为多个项目所在路径的父路径。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">environ.setdefault(<span class="string">&#x27;trac.env_parent_dir&#x27;</span>, <span class="string">&#x27;/var/trac/projects&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>配置uWSGI应用trac,配置文件/etc/uwsgi/apps-enabled/trac.ini</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[uwsgi\]</span><br><span class="line">plugins = python</span><br><span class="line">;socket = <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">3000</span></span><br><span class="line">wsgi-file = <span class="regexp">/var/</span>trac/cgi-bin/trac.wsgi</span><br><span class="line">processes = <span class="number">2</span></span><br><span class="line">stats = <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">3001</span></span><br></pre></td></tr></table></figure>

<p>配置nginx,配置文件/etc/nginx/sites-enabled/trac.xxx.com.conf</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line"> listen <span class="number">80</span>; </span><br><span class="line"> server_name trac.xxx.com ;</span><br><span class="line"> access_log /<span class="keyword">var</span>/log/nginx/trac_xxx_com_access.log;</span><br><span class="line"> error_log /<span class="keyword">var</span>/log/nginx/trac_xxx_com_error.log;</span><br><span class="line"></span><br><span class="line"> location / &#123; </span><br><span class="line"> include uwsgi_params;</span><br><span class="line"> #uwsgi_pass <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">3000</span>;</span><br><span class="line"> uwsgi_pass unix:<span class="comment">///run/uwsgi/app/trac/socket;</span></span><br><span class="line"> &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>uWSGI应用生成的unix socket文件为/run/uwsgi/app/{$app_name}/socket，$app_name即是配置文件/etc/uwsgi/apps-enabled/trac.ini配置文件的basename,不包含扩展名。</p>
<p><strong>用户管理插件</strong></p>
<p>不是用trac内置的用户管理模块，安装AccountManagerPlugin插件</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># easy_install ​https://trac-hacks.org/svn/accountmanagerplugin/tags/acct_mgr-0.4.4</span><br></pre></td></tr></table></figure>

<p>配置文件/var/trac/projects/proj_name/conf/trac.ini添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[account-manager\]</span><br><span class="line">htpasswd_file = <span class="regexp">/var/</span>trac/trac.htpasswd</span><br><span class="line">htpasswd_hash_type = md5</span><br><span class="line">;hash_method = md5</span><br><span class="line">password_store = HtPasswdStore</span><br><span class="line">reset_password = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">\[components\]</span><br><span class="line">acct_mgr.admin.* = enabled</span><br><span class="line">acct_mgr.api.* = enabled</span><br><span class="line">acct_mgr.db.sessionstore = disabled</span><br><span class="line">acct_mgr.htfile.htdigeststore = disabled</span><br><span class="line">acct_mgr.htfile.htpasswdstore = enabled</span><br><span class="line">acct_mgr.pwhash.* = enabled</span><br><span class="line">acct_mgr.pwhash.htpasswdhashmethod = enabled</span><br><span class="line">acct_mgr.http.* = disabled</span><br><span class="line">acct_mgr.notification.* = enabled</span><br><span class="line">acct_mgr.register.* = enabled</span><br><span class="line">acct_mgr.svnserve.svnservepasswordstore = disabled</span><br><span class="line">acct_mgr.web_ui.* = enabled</span><br><span class="line">acct_mgr.web_ui.resetpwstore = disabled</span><br><span class="line">trac.web.auth.loginmodule = disabled</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>插件官方文档中配置了acct_mgr.pwhash.* = disabled，会导致以下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Cannot find an implementation <span class="keyword">of</span> the IPasswordHashMethod interface named HtDigestHashMethod. Please check that the Component is enabled or update the option \[account-manager\] hash_method <span class="keyword">in</span> trac.ini.</span><br></pre></td></tr></table></figure>

<p>注册第一个用户，然后将第一个用户设置为管理员:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># trac-admin /var/trac/projects/proj_name permission add firstusername TRAC_ADMIN</span><br></pre></td></tr></table></figure>

<p><strong>git集成</strong></p>
<p>配置文件/var/trac/projects/proj_name/conf/trac.ini添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[components\]</span><br><span class="line">; git</span><br><span class="line">tracopt.versioncontrol.git.* = enabled</span><br><span class="line"></span><br><span class="line">\[trac\]</span><br><span class="line">repository_dir = <span class="regexp">/home/gi</span>t/repositories/xxx.git/</span><br><span class="line">repository_sync_per_request = (<span class="keyword">default</span>)</span><br><span class="line">repository_type = git</span><br></pre></td></tr></table></figure>

<p>uWSGI是以用户www-data运行的，www-data用户必须拥有读git仓库的权限，否则可能会提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Warning: Can<span class="string">&#x27;t synchronize with repository &quot;(default)&quot; (/home/git/repositories/reis.git does not appear to be a Git repository.). Look in the Trac log for more information.</span></span><br></pre></td></tr></table></figure>

<p>如果无法浏览代码，且log文件中有如下错误字样：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Trac\[PyGIT\] DEBUG: git exits <span class="keyword">with</span> <span class="number">128</span>, <span class="attr">dir</span>: u<span class="string">&#x27;/path/to/xxx.git/&#x27;</span>, <span class="attr">args</span>: branch -&gt; (<span class="string">&#x27;-v&#x27;</span>, <span class="string">&#x27;--no-abbrev&#x27;</span>), <span class="attr">stderr</span>: <span class="string">&#x27;fatal: Failed to resolve HEAD as a valid ref.\\n&#x27;</span></span><br></pre></td></tr></table></figure>
<p>则仍然应该是权限的问题，运行trac的用户无法读取一些文件，可以将git仓库对other用户开发rx权限，或者更改仓库文件的组为www-data并适当授权。</p>
<p><strong>gitolite集成</strong><br>可以使用插件<a href="https://github.com/boldprogressives/trac-GitolitePlugin">trac-GitolitePlugin</a>集成trac和gitolite</p>
<p><strong>日志</strong></p>
<p>日志设置见<a href="http://trac.edgewall.org/wiki/TracLogging">Trac Logging</a></p>
<p><strong>安装结束</strong></p>
<p>References:<br>[1]<a href="http://trac.edgewall.org/wiki/TracGuide">The Trac User and Administration Guide</a><br>[2]<a href="https://sandalov.org/blog/1981/">Trac 1.0.1 in Ubuntu 14.04 with Basic Authentication (Nginx + uWSGI)</a><br>[3]<a href="http://www.iroowe.com/installs_trac_in_funtoo/">installs Trac with uWSGI and Nginx in gentoo/funtoo</a><br>[4]<a href="http://wiki.woodpecker.org.cn/moin/NginxuWSGIPublishTrac">Nginx8.x+uWSGI驱动 Trac</a><br>[5]<a href="http://trac-hacks.org/wiki/AccountManagerPlugin">Account Manager Plugin to manage user accounts</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>traceroute: 使用纯真IP数据库显示中间路由器以及主机的地理位置</title>
    <url>/2009/06/15/traceroute-route-qqwry/</url>
    <content><![CDATA[<p>traceroute是常用的网络诊断和查询工具，但是通常traceroute只能显示中间路由器和主机的ip地址和主机名，如果能输出机器的地理位置是最好不过了。怎么办？重新写一个traceroute？这是windows的思路。traceroute已经足够好了，为什么要重写呢，我们只要把结果加工一下就可以了。不得不佩服UNIX的设计哲学，无疑这种正交的功能，如果硬要搀和在一起，实在是没什么必要和额外的好处。</p>
<a id="more"></a>
<p>有了<a href="https://openwares.net/linux/awstats_ip_geo_qqwrypl.html">查询纯真IP数据库的Perl程序</a><a href="/downloads/ip_geo_qqwry.zip">ip_geo_qqwry.pl</a>，让traceroute显示机器的地理位置是十分简单的事情。把traceroute的输出重定向到一个脚本，脚本中将ip替换成对应的地理位置就可以了。下面是这个perl脚本ip2geo.pl的代码：</p>
<p> 1 #!/usr/bin/perl<br> 2<br> 3 <strong>binmode</strong>(STDOUT, ‘:encoding(utf8)’);<br> 4 <strong>require</strong> “ip_geo/ip_geo_qqwry.pl”;<br> 5<br> 6 <strong>my</strong> $pattern_ip = ‘\(((?:(?:1?[0-9]?[0-9]2(?:[0-4][0-9]5[0-5]))\.){3}(?:1?[0-9]?[0-9]2(?:[0-4][0-9]5[0-5])))\)’;<br> 7 <strong>my</strong> $line,$matches, $match, $ip_geo_addr;<br> 8 <strong>while</strong>($line = <STDIN>){<br> 9     @matches = $line =~ <strong>/</strong>$pattern_ip**/g**;<br>10     <strong>foreach</strong> $match (@matches){<br>11         $ip_geo_addr = &amp;ipwhere($match);<br>12         $line =~ <strong>s/**\($match\)</strong>/<strong>[$ip_geo_addr]</strong>/<strong>;<br>13     }<br>14     **print</strong> $line;<br>15 }<br>16<br>17 1;  </p>
<p>然后这样traceroute <a href="http://www.google.cn/">www.google.cn</a> ip2geo.pl就可以看到中间路由器和主机的地理位置了。<br>下面是我用PuTTY从远程主机执行该命令行的截图：<a href="/images/2009/06/traceroute.jpg"><img src="/images/2009/06/traceroute-300x141.jpg" alt="traceroute" title="traceroute"></a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Perl</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库事务隔离级别</title>
    <url>/2013/10/18/transaction-isolation-level/</url>
    <content><![CDATA[<p>事务隔离级别主要用于事务之间的并发控制，保证事务并发执行时数据正确性。</p>
<a id="more"></a>
<p>事务并发交互中容易出现以下几种问题：</p>
<p><strong>脏读(Dirty Read)</strong><br>一个事务读取到另一个并发事务修改但尚未提交的数据，此数据未来可能提交也可能回滚。</p>
<p><strong>不可重复读(Nonrepeatable Read)</strong><br>一个事务重复读取以前曾经读取过的数据，发现数据发生了变化，两次读取结果不一致(被其他并发事务修改并提交)。</p>
<p><strong>幻读(Phantom Read)</strong><br>一个事务按给定条件两次请求的结果集合发生变化，比原来的结果集多了几条数据或少了几条数据(被其他并发事务修改并提交)。</p>
<p><strong>隔离级别</strong></p>
<p>ANSI/ISO的SQL标准中，定义了四个事务隔离级别：</p>
<p>隔离级别</p>
<p>肮脏读取</p>
<p>不可重复读取</p>
<p>幻象读取</p>
<p>读未提交</p>
<p>可能发生</p>
<p>可能发生</p>
<p>可能发生</p>
<p>读已提交</p>
<p>-</p>
<p>可能发生</p>
<p>可能发生</p>
<p>可重复读取</p>
<p>-</p>
<p>-</p>
<p>可能发生</p>
<p>可序列化</p>
<p>-</p>
<p>-</p>
<p>-</p>
<p>最高的隔离级别是可序列化级别，这个级别保证任何并发执行的事务就像按序执行一样产生确定的结果，这是最严格的隔离级别，但其并发性能是最差的。</p>
<p><strong>更新丢失问题</strong><br>第一类更新丢失(回滚丢失)：<br>在事务A期间，事务B对数据进行了更新；在事务A回滚之后，覆盖了事务B已经提交的数据。<br>SQL标准没有定义这种现象，标准定义的所有隔离级别都不允许第一类丢失更新发生。</p>
<p>第二类更新丢失(覆盖丢失):<br>在事务A期间，事务B对数据进行了更新；在事务A提交之后，覆盖了事务B已经提交的数据。主要的问题在于”读取,计算,写回”这种操作方式，事务A读取并缓存了事务B修改之前的数据，在事务A提交的时候并没有校验缓存的数据是否仍然有效就直接提交了，导致事务B的更新丢失了。<br>这种更新丢失只有最高的可序列化隔离级别可以防止发生，其他级别都无法保证(PostgreSQL可以在Repeatable Read级别防止此类更新丢失,但有些数据库是不可以的)，应该由客户程序自己加锁来杜绝此类问题的发生。</p>
<p>第二类更新丢失其实就是不可重复读问题，就是缓存了不可重复读的结果从而导致的问题</p>
<p><strong>悲观锁(pessimistic locking)与乐观锁(optimistic locking)</strong><br>为了防止不可重复读和幻读问题，客户程序可以通过加锁来解决。但是加锁是有代价的，会影响并发性能，所以又有了悲观锁和乐观锁之分。</p>
<p>悲观锁<br>在整个数据处理过程中，将数据处于锁定状态，其他需要这些数据的事务只能等待解锁后才能继续处理。悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会。在长事务中使用悲观锁会对系统的影响比较大，特别是在等待用户输入的时候不要持有悲观锁，因为用户的行为是不可预测的。</p>
<p>select * from sometable for update用于显示显式锁定结果集进行后续更新，锁定期间其他事务无法修改这些数据。也可以使用locak table锁表，但这样锁定的粒度太大，会严重影响系统性能，一般不要使用。</p>
<p>乐观锁<br>事务在提交数据更新之前，再次检查所缓存的数据有没有被其他事务修改，如果数据没有被修改则可以直接提交，如果数据已经被其他事务修改了，则当前事务需要回滚，然后重新开始当前事务。<br>一种可靠的乐观锁的实现是使用“多版本控制(multi-version control)”，即在每一行加一个version属性。修改这一行时将version增加1，写回数据库要检查当前的version值是否还是获取时的那个值了。如果还是，说明期间没有其他事务对其修改，直接提交即可，如果已经不是了，说明期间已经有别的事务修改了这一行，当前事务获取的数据已经过期了，事务失败回滚。<br>也可以通过为记录添加高精度时间戳来实现乐观锁。</p>
<p><strong>死锁</strong></p>
<p>事务A锁定了表的第m行<br>事务B锁定了表的第n行<br>然后事务A请求锁定表的第n行，而事务B请求锁定表的第的m行，这样死锁就产生了。数据库会检测此类死锁并使其中一个事务失败，但不要依赖这种行为。<br>应用程序中应该尽量保持一致的顺序来请求资源，从而减少死锁的发生。</p>
<p><strong>PostgreSQL</strong></p>
<p>PostgreSQL支持四个标准的事务隔离级，但实际上其内部只有三个隔离级：读已提交，可重复读，可序列化。如果设置PostgreSQL事务隔离级为读未提交，其实际上的隔离级设置为读已提交。而且在PostgreSQL的可重复读隔离级，幻读是不会发生的。PostgreSQL提供了比ANSI/ISO要求更高的隔离级。PostgreSQL内部使用MVCC(MultiVersion concurrency control)并发架构。<br>postgreSQL默认的隔离级别为读已提交。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>transfer.sh快速分享文件</title>
    <url>/2019/07/08/transfer-sh-share-files/</url>
    <content><![CDATA[<a id="more"></a>
<p><a href="https://transfer.sh/">transfer.sh</a>可以使用命令行快速的分享文件，最大可以上传10G，有效期最长14天，也可以设定下载次数和有效期。</p>
<p>上传文件</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ curl --upload-file ./go.sh https:<span class="comment">//transfer.sh/go.sh</span></span><br><span class="line">https:<span class="comment">//transfer.sh/Pyg2a/go.sh #生成的下载链接</span></span><br></pre></td></tr></table></figure>

<p>设定下载次数和最大天数</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ curl -H <span class="string">&quot;Max-Downloads: 1&quot;</span> -H <span class="string">&quot;Max-Days: 5&quot;</span> --upload-file ./hello.txt https:<span class="comment">//transfer.sh/hello.txt </span></span><br><span class="line">https:<span class="comment">//transfer.sh/66nb8/hello.txt </span></span><br></pre></td></tr></table></figure>

<p>添加.bashrc命令行别名</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">transfer</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line"> curl --progress-bar --upload-file <span class="string">&quot;$1&quot;</span> https:<span class="comment">//transfer.sh/$(basename &quot;$1&quot;) tee /dev/null;</span></span><br><span class="line"> echo</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">alias transfer=transfer</span><br></pre></td></tr></table></figure>
<p>然后可以这样</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ transfer hello.txt</span><br></pre></td></tr></table></figure>
<p>是不是很简单，很好用，但是，不要用来传输敏感文件，传输敏感文件请使用onionshare或加密后再传输。<br>还有一点儿要注意，github上的tansfer.sh项目与<a href="http://transfer.sh网站并无关系./">http://transfer.sh网站并无关系。</a></p>
<p>References:<br>[1]<a href="https://github.com/dutchcoders/transfer.sh">Easy and fast file sharing from the command-line</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>KWinUI:半透明窗口</title>
    <url>/2009/07/05/transparent-window/</url>
    <content><![CDATA[<p>KWinUI很轻松的就可以让我们拥有一个半透明窗口。<br>先贴代码</p>
<a id="more"></a>
<p> 1 #include “kwin.h”<br> 2 #include “kapp.h”<br> 3<br> 4 <strong>using</strong> <strong>namespace</strong> kwinui;<br> 5<br> 6 <strong>class</strong> KMainWindow : <strong>public</strong> KWindowBase<KMainWindow>{<br> 7 <strong>public</strong>:<br> 8     KMainWindow():KWindowBase<KMainWindow>(_T(“transparent”)){}<br> 9<br>10     BEGIN_MSG_MAP<br>11         MSG_HANDLER(WM_CREATE,OnCreate)<br>12     END_MSG_MAP(KWindowBase<KMainWindow>)<br>13     <br>14     <strong>bool</strong> PreCreateWindow(CREATESTRUCT&amp; cs){<br>15         cs.dwExStyle=WS_EX_LAYERED;<br>16         <strong>return</strong> true;<br>17     }<br>18<br>19     LRESULT OnCreate(UINT uMsg,WPARAM wParam,LPARAM lParam,<strong>bool</strong>&amp; bHandled){<br>20         SetLayeredWindowAttributes();<br>21         <strong>return</strong> 0;<br>22     }<br>23 };<br>24<br>25 <strong>class</strong> KHelloApp : <strong>public</strong> KWinApp<KHelloApp>{<br>26 <strong>public</strong>:<br>27     <strong>bool</strong> InitInstance(){<br>28         m_pMainWindow=<strong>new</strong> KMainWindow();<br>29         m_pMainWindow-&gt;CreateOverlappedWindow(_T(“transparent window”));<br>30         m_pMainWindow-&gt;ShowWindow(m_nCmdShow);<br>31         m_pMainWindow-&gt;UpdateWindow();<br>32         <br>33         <strong>return</strong> true;<br>34     }<br>35     <strong>void</strong> ExitInstance(){<br>36         SAFE_DEL_PTR(m_pMainWindow);<br>37     }<br>38     <br>39 <strong>private</strong>:<br>40     KMainWindow* m_pMainWindow;<br>41 };<br>42<br>43 KHelloApp hello;</p>
<p>这个半透明窗口的实现主要是利用了随windows 2000 ship而来的分层窗口特性,代码14-17行在窗口建立之前为窗口增加扩展风格WS_EX_LAYERED,这样窗口就成为一个分层窗口。然后在WM_CREATE消息处理函数中调用SetLayeredWindowAttributes(0,128); 其中SetLayeredWindowAttributes是对windows同名函数的简单包装,SetLayeredWindowAttributes的函数原型为bool SetLayeredWindowAttributes(COLORREF crKey=(COLORREF)0,BYTE bAlpha=128,DWORD dwFlags=LWA_ALPHA);<br>接受的参数如下：</p>
<ol>
<li> 参数crKey是透明颜色,默认为0</li>
<li> 参数bAlpha是透明度，取值0~255,0为完全透明，255为完全不透明,默认为128</li>
<li> 参数dwFlags为透明模式，如果取值LWA_COLORKEY则使用第一个参数设置的透明颜色来使窗口透明，如果取值LWA_ALPHA则使用第二个参数设置的alpha值来透明化窗口,默认为LWA_ALPHA</li>
</ol>
<p>这里使用了默认参数。<br>用Visual C++ 2008 Express win32 project默认设置静态链接Release版本生成的程序大小为54KB。<br>截图:<a href="/images/2009/07/transparent_window.png"><img src="/images/2009/07/transparent_window-300x226.png" alt="transparent_window" title="transparent_window"></a><br><a href="/downloads/kwinui/samples/transparent_window.cpp">代码下载</a></p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
  <entry>
    <title>TSC_DEADLINE disabled due to Errata</title>
    <url>/2019/09/21/tsc-deadline-disabled-due-to-errata/</url>
    <content><![CDATA[<a id="more"></a>
<p>dmesg中有错误消息：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[Firmware Bug\]: TSC_DEADLINE disabled due to Errata; please update microcode to version: <span class="number">0x3a</span> (or later)</span><br></pre></td></tr></table></figure>

<p>安装intel微码可以解决此问题：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install intel-microcode</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>修改WP默认主题Twenty Thirteen的宽度</title>
    <url>/2013/10/30/twenty-thirteen-width/</url>
    <content><![CDATA[<p>Wordpress默认主题wenty Thirteen的宽度实在太窄了</p>
<a id="more"></a>
<p>对于主题要求不高，默认主题就可以了，但是post的宽度实在是太窄了，现在的显示器分辨率都辣么高，完全可以设置的再宽一些。自适应宽度就不想了，不折腾。</p>
<p>修改wenty Thirteen主题的style.css的一行就可以了<br>大约977行处<br>[css]<br>.entry-header,<br>.entry-content,<br>.entry-summary,<br>.entry-meta {<br>margin: 0 auto;<br>max-width: 604px;<br>width: 100%;<br>}<br>[/css]</p>
<p>将max-width: 604px;改为max-width: 1024px;</p>
<p>OK!<br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>twentyseventeen</title>
    <url>/2018/11/28/twentyseventeen/</url>
    <content><![CDATA[<p>.wrap {<br>/* margin-left: auto; <em>/<br>/</em> margin-right: auto; <em>/<br>max-width: 100%;<br>/</em> padding-left: 2em; <em>/<br>/</em> padding-right: 2em; */<br>}</p>
<p>@media screen and (min-width: 48em) {<br>.wrap {<br>max-width: 100%;<br>/* padding-left: 3em; <em>/<br>/</em> padding-right: 3em; */<br>}<br>}</p>
<p>.page.page-one-column:not(.twentyseventeen-front-page) #primary {<br>/<em>margin-left: auto;</em>/<br>/<em>margin-right: auto;</em>/<br>max-width: 100%;<br>}</p>
<p>@media screen and (min-width: 30em) {<br>.page-one-column .panel-content .wrap<br>{<br>max-width: 100%;<br>}<br>}</p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>Ubuntu 10.04 AMD64 mplayer 开启ATI卡硬解加速</title>
    <url>/2010/05/08/ubuntu-10-04-amd64-mplayer-ati-video-acceleration/</url>
    <content><![CDATA[<p>昨晚在Ubuntu 10.04(Lucid Lynx) AMD64上面设置ATI Mobile Readon 3470硬解加速成功,mplayer播放高清视频时CPU占有率大大降低，大约只有原来的1/10。使用Ubuntu 9.10时也曾经试图硬解，但没成功。具体设置/安装方法记叙如下。</p>
<p>首先A卡要支持UVD(Unified Video Decoder)，比较新的显卡应该都是支持到UVD2的，另外Lucid自带的ATI驱动在我的机器上不支持UVD功能。<br>cat /var/log/Xorg.0.log grep UVD<br>如果输出如下字样<br>(II) fglrx(0): UVD2 feature is available<br>则表明支持驱动UVD特性<br>我的卡子在未安装ATI官方最新驱动ATI Catalyst Display Driver 10.4以前是不支持UVD2的。ATI驱动如何安装请参考ATI官方文档。</p>
<a id="more"></a>
<p>A卡现在在linux平台上能够进行硬解得益于intel与开源社区开发的vaapi(Video Acceleration API)，只要安装相应的后端驱动，vaapi可以支持A卡和N卡，A卡的后端就是xvba-video,N卡的后端是vdpau-video.</p>
<p>安装完ATI最新的官方驱动后，下载相应平台的<a href="http://www.splitted-desktop.com/~gbeauchesne/libva/">libva</a>包安装，当然也可以下载源码进行安装，<a href="http://www.splitted-desktop.com/~gbeauchesne/%E4%B8%8A%E6%9C%89%E8%AF%A6%E7%BB%86%E7%9A%84%E8%AF%B4%E6%98%8E%E3%80%82%E8%BF%98%E8%A6%81%E6%8A%8Alibva%E7%9A%84%E5%BC%80%E5%8F%91%E5%8C%85%E4%B8%80%E5%B9%B6%E5%AE%89%E8%A3%85%EF%BC%8C%E5%9B%A0%E4%B8%BA%E5%90%8E%E9%9D%A2%E7%BC%96%E8%AF%91%E5%B8%A6vaavpi%E6%89%A9%E5%B1%95%E7%9A%84mplayer%E8%A6%81%E7%94%A8%E5%88%B0%E3%80%82%E6%88%91%E5%AE%89%E8%A3%85%E7%9A%84%E6%98%AF%E6%9C%80%E6%96%B0%E7%9A%84libva1_0.31.0-1+sds13_amd64.deb%E5%92%8Clibva-dev_0.31.0-1+sds13_amd64.deb">http://www.splitted-desktop.com/~gbeauchesne/上有详细的说明。还要把libva的开发包一并安装，因为后面编译带vaavpi扩展的mplayer要用到。我安装的是最新的libva1_0.31.0-1+sds13_amd64.deb和libva-dev_0.31.0-1+sds13_amd64.deb</a></p>
<p>然后下载并安装<a href="http://www.splitted-desktop.com/~gbeauchesne/xvba-video/">xvba-video</a>。安装完成后测试一下vaapi是否就绪<br>$ vainfo<br>我的输出如下<br>libva: libva version 0.31.0-sds6<br>Xlib: extension “XFree86-DRI” missing on display “:0.0”.<br>libva: va_getDriverName() returns 0<br>libva: Trying to open /usr/lib/va/drivers/fglrx_drv_video.so<br>libva: va_openDriver() returns 0<br>vainfo: VA API version: 0.31<br>vainfo: Driver version: Splitted-Desktop Systems XvBA backend for VA API - 0.6.11<br>vainfo: Supported profile and entrypoints<br> <strong>VAProfileMPEG2Simple : VAEntrypointIDCT<br> VAProfileMPEG2Main : VAEntrypointIDCT<br> VAProfileH264High : VAEntrypointVLD<br> VAProfileVC1Advanced : VAEntrypointVLD</strong><br>最重要的是后面输出的profile，如果有内容输出应该问题就不大了。</p>
<p>最后就是让mplayer来支持vaapi了，发行版自带的版本目前是不支持此特性的，所以要重新编译。先执行<br>$sudo apt-get build-dep mplayer<br>然后下载<a href="http://www.splitted-desktop.com/~gbeauchesne/mplayer-vaapi/">mplayer-vaapi-latest-FULL.tar.bz2</a> ,解开后执行$ ./checkout-patch-build.sh即可。<br>编译完成后生成的mplayer在mplayer-vaapi目录下面。</p>
<p>$./mplayer -vo vaapi -va vaapi path_to_movie<br>如果有以下字样输出<br>VO: [vaapi] 1280x720 =&gt; 1280x720 H.264 <strong>VA API Acceleration</strong><br>则说明硬件加速成功。<br>enjoy it!</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>MPlayer</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 10.10 maverick AMD64安装firefox 4.0 正式版</title>
    <url>/2011/03/30/ubuntu-10-10-install-firefox4/</url>
    <content><![CDATA[<p>Firefox 4正式发布一周了,貌似有些童鞋还是不会在Ubuntu上面安装,简单说一下</p>
<a id="more"></a>
<p>现在mozilla已经开始官方制作AMD64平台的二进制包了,也就是说不用再为ubuntu AMD64下载源代码编译再安装了，直接下载build好的二进制包就好了,我用的<a href="ftp://ftp.mozilla.org/pub/firefox/releases/4.0/linux-x86_64/en-US/firefox-4.0.tar.bz2">en_US版本</a>,其他平台、语言版本请自行去mozilla ftp查找下载。</p>
<p>下载后,执行命令</p>
<p>1 $sudo tar jxvf firefox-4.0.tar.bz2 -C /opt/firefox<br>2 $/opt/firefox/firefox  </p>
<p>就可以运行firefox 4了,很简单吧！还是使用~/.mozilla/firefox下的profile文件夹。</p>
<p>enjoy it!</p>
]]></content>
      <categories>
        <category>Firefox</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 9.10 karmic 英文环境en_US.UTF-8 locale下安装ibus</title>
    <url>/2009/10/31/ubuntu-9-10-karmic-en-us-ibus/</url>
    <content><![CDATA[<p>ubuntu 9.10已经默认安装了ibus，我们只要再安装ibus拼音输入法就可以了<br>sudo apt-get install ibus-pinyin<br>然后运行ibus-setup把拼音输入法增加进来<br>在~/.profile里面增加以下语句<br>export XMODIFIERS=”@im=ibus”<br>export GTK_IM_MODULE=ibus<br>export QT_IM_MODULE=ibus<br>ibus-daemon -d -x &amp;<br>这样就可以了。</p>
<p>如果输入法状态条无法显示，可以删除掉~/.config/ibus目录然后logout,login试一下。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 9.10 karmic koala 官方源</title>
    <url>/2009/11/03/ubuntu-9-10-karmic-koala-office-source/</url>
    <content><![CDATA[<p>deb <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic main restricted universe multiverse<br>deb <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-security main restricted universe multiverse<br>deb <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-updates main restricted universe multiverse<br>deb <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-proposed main restricted universe multiverse<br>deb <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-backports main restricted universe multiverse<br>deb-src <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic main restricted universe multiverse<br>deb-src <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-security main restricted universe multiverse<br>deb-src <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-updates main restricted universe multiverse<br>deb-src <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-proposed main restricted universe multiverse<br>deb-src <a href="http://archive.ubuntu.com/ubuntu/">http://archive.ubuntu.com/ubuntu/</a> karmic-backports main restricted universe multiverse</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 9.10(Karmic Koala)官方正式发布啦</title>
    <url>/2009/10/29/ubuntu-9-10-offical-released/</url>
    <content><![CDATA[<p>终于等到这一刻，呵呵<br>明天本本T400的系统就全新安装到Ubuntu 9.10 AMD64版本,64位应该很爽吧，除了该死的ATI卡,不行就切换到Intel的卡子了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu配置ad hoc网络</title>
    <url>/2009/12/29/ubuntu-ad-hoc-network/</url>
    <content><![CDATA[<p>　　Network manager老难用了，忍无可忍之后将其remove,据说wicd不错，装上试了试也卸载掉了。其实linux的世界，还是cli用起来最顺手。<br>　　<br>　　配置一个ad hoc网络很简单的，在/etc/network/interfaces里面添加就可以了，我的设置如下：</p>
<p>auto wlan0<br>iface wlan0 inet static<br>wireless-mode ad-hoc<br>wireless-channel 11<br>wireless-essid Adhoc<br>address 10.42.43.1<br>netmask 255.255.255.0<br>gateway 10.42.43.1</p>
<p>　　还是比较直白的，一般我们就一个无线网卡，没意外名字就是wlan0了，选个没有重叠的wifi信道11，设置一下IP、掩码、网关就好了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 9.10(kamic koala) amd64编译安装firefox 3.6(namoroka)</title>
    <url>/2010/01/24/ubuntu-amd64-compile-install-firefox-3-6/</url>
    <content><![CDATA[<p>代号为”namoroka”的firefox 3.6正式发布了，性能提升不少。ubuntu估计要到下一个版本10.04(Lucid Lynx)才会更新到firefox 3.6，但愿不要这么晚。mozilla官方不提供amd64版本的安装包，那么下载源代码本地编译吧，这样性能还能更优。编译安装步骤如下，参考了官方<a href="https://developer.mozilla.org/En/Developer_Guide/Build_Instructions">build文档</a>。<br>　　<br>　　0. 准备编译环境和依赖<br>　　sudo apt-get build-dep firefox<br>　　sudo apt-get install libasound2-dev libcurl4-openssl-dev libnotify-dev libxt-dev libiw-dev mesa-common-dev autoconf2.13</p>
<a id="more"></a>
<p>1. 下载源代码<br>　　从官方下载3.6的<a href="http://releases.mozilla.org/pub/mozilla.org/firefox/releases/3.6/source/">源代码</a>firefox-3.6.source.tar.bz2,然后tar jxf firefox-3.6.source.tar.bz2解压源代码到某个位置，得到的源代码根目录名字为mozilla-1.9.2，因为gecko的版本是1.9.2。</p>
<p>　　2. 准备编译配置文件<br>　　在源代码根目录mozilla-1.9.2下新建一个文件.mozconfig，输入以下内容：<br>　　# my mozilla firefox config<br>　　mk_add_options MOZ_OBJDIR=@TOPSRCDIR@/obj-@CONFIG_GUESS@</p>
<p>　　ac_add_options - -enable-application=browser<br>　　mk_add_options MOZ_CO_PROJECT=browser</p>
<p>　　ac_add_options - -enable-optimize<br>　　ac_add_options - -disable-tests</p>
<p>　　3. 编译并制作安装包<br>　　在源代码根目录mozilla-1.9.2下运行命令make -f client.mk build开始编译，编译完成后切换到obj目录，我的机器上生成的目录名字为obj-x86_64-unknown-linux-gnu，进入该目录并执行make package，会在当前目录的子目录dist里面生成最终的安装包，名字为firefox-3.6.en-US.linux-x86_64.tar.bz2。</p>
<p>　　4. 安装<br>　　执行命令sudo tar jxf firefox-3.6.en-US.linux-x86_64.tar.bz2 -C /opt，把firefox安装到/opt目录下，然后sudo ln -sf /opt/firefox/firefox /usr/bin/firefox更新符号连接。</p>
<p>　　编译安装完毕。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu播放视频定期黑屏问题</title>
    <url>/2010/02/05/ubuntu-blanktime/</url>
    <content><![CDATA[<p>使用mplayer播放视频的时候,如果没有鼠标或键盘活动,大约10分钟后显示器会自动关闭,要动下鼠标才能继续观看,比较烦.我是没有设置屏保的,因为包gnome-screensaver已经卸载掉了.而且power manager里面已经把所有的电源选项都关闭了.竟然还会定期自动关闭LCD,真败了，无法容忍.</p>
<p>其实”罪魁祸首”就是X server,在/etc/X11/xorg.conf的ServerFlags节增加一下选项就可以了.<br>Section “ServerFlags”<br> Option “BlankTime” “0”<br> Option “StandbyTime” “0”<br> Option “SuspendTime” “0”<br> Option “OffTime” “0”<br>EndSection</p>
<p>该问题是由Blanktime控制的,这个值控制多长时间没有动作来启动屏保,默认时间是10分钟,设置为0就可以关闭该特性了.</p>
<p>其他三个选项依次是DPMS的待机、挂起、关闭超时值，也可以通过Monitor节的DPMS选项来关闭这三个特性</p>
<p>Section “Monitor”<br>Option “DPMS” “false”<br>EndSection</p>
<p>注意，BlankTime特性是不受DPMS特性控制的。</p>
<p>这四个参数的详细信息参见<a href="http://www.x.org/archive/X11R6.8.0/doc/xorg.conf.5.html">xorg配置文件手册</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu更改用户名及相应的用户主目录</title>
    <url>/2010/09/07/ubuntu-change-username-home/</url>
    <content><![CDATA[<p>　　某天突然感觉用了一阵子的用户名不爽,想换个名字新鲜新鲜,不过最好不要简单的编辑/etc/passwd和/etc/group了事,linux有相应的命令来做这些dirty things。最好不要在当前用户下操作,去recovery模式下做这件事比较妥当。<br>　　1、修改用户名。<br>　　usermod -l new_username -d /home/new_username -m old_username<br>用usermod命令来修改用户帐户相关信息，-l指定新的登录名称,-d指定新的主目录,如果同时指定-m选项则移动原来用户主目录的内容到新的用户住目录,最后指定原来的登录用户名。<br>　　2、修改组名<br>　　groupmod -n new_username old_username<br>groupmod命令用来修改组相关信息，-n用来指定新的组名，用原来的组名作为参数。这里修改的是与用户默认同名的组。<br>　　3、更改用户的全称<br>　　chfn -f new_fullname username<br>chfn命令来修改真实的用户名称和其他相关信息,-f指定新的用户全称,需要修改全称的用户名作为参数<br>　　4、其他修改<br>更改用户主目录后,有些依赖于绝对路径的程序需要进行相应的修改。firefox profile路径下的extensions.ini里面的有依赖于用户名的绝对路径，修改之，用vim打开，然后:%s/old_username/new_username/g，然后:wq即可，prefs.js里面做同样的处理，firefox就可以正常使用了。其他的东西基本不用动就可以了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu 9.10禁止记录最近使用文档(disable recent documents)</title>
    <url>/2010/01/28/ubuntu-disable-recent-documents/</url>
    <content><![CDATA[<p>在ubuntu 9.10下修改<del>/.recently-used和</del>/..recently-used.xbel文件的属性已经无法阻止gnome记录最近使用文档.正确的做法是在主目录建立.gtk-2.0文件<br> touch ~/.gtk-2.0<br>然后输入<br> gtk-recent-files-max-age=0<br>如果想限制记录最经文档的书录输入<br> gtk-recent-files-limit=3 #比如只记录3个</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu系统HTC G1通过笔记本wifi ad hoc网络共享宽带上网</title>
    <url>/2009/10/18/ubuntu-g1-adhoc-wifi/</url>
    <content><![CDATA[<p>因为没有使用无线路由器，两台笔记本一直使用wifi的ad hoc模式网络互联，xp共享ubuntu的wifi上网。新入手黑色HTC G1，自然也想利用笔记本的ad hoc wifi网络共享上网，没必要再购置无线路由器。幸好G1支持wifi的ad hoc网络模式，拥有宽带的笔记本使用32bits ubuntu 9.04，记叙设置方法如下。</p>
<p>1、参考<a href="http://modmygphone.com/forums/showthread.php?t=22681">Connect G1 to Ad-hoc network SOLVED</a>弄好G1端的wifi设置</p>
<p>2、因为我的ad hoc网络没有启用DHCP,笔记本ubuntu无线网卡wlan0的静态IP设置为10.42.43.1,mask为255.255.255.0,网关未设，所以设置G1的wifi也使用静态IP。G1的“wifi设置-&gt;高级”里面，这样设置，IP在一个网段即可，我设置为10.42.43.8,掩码为255.255.255.0,网关设置为ubuntu wlan0的IP，也就是10.42.43.1。可以根据个人情况自由选择私有网络地址。</p>
<p>3、默认设置下， ubuntu是不在多个接口间转发数据的，也就是没有开启路由功能，通过修改/etc/sysctrl.conf来打开IP转发功能。使net.ipv4.ip_forward=1就可以了，这是启用ipv4的转发功能，如果要启用ipv6的转发功能，使net.ipv6.conf.all.forwarding=1就可以了。这样ubuntu主机上来自ad hoc网络的请求就可以被路由到其他网络接口了。但是现在G1还不能访问internet,因为我们使用的是私有ip地址，是不能在公网上路由的，必须要进行NAT才可以。可以使用iptables来设置NAT规则，打开rc.local，在exit 0之前添加下面这几句:<br>iptables -F<br>iptables -P INPUT ACCEPT<br>iptables -P FORWARD ACCEPT<br>iptables -t nat -A POSTROUTING -s 10.42.43.0/24 -o ppp0 -j MASQUERADE</p>
<p>其中-s 10.42.43.0/24可以根据你使用的私有IP段和掩码位数来设置，-o ppp0根据你使用的上网宽带接口设置，我使用pppoe拨号，所以此处设置为ppp0。</p>
<p>ubuntu重启一下应该就可以了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu:解决非官方源导致的GPG error</title>
    <url>/2009/07/05/ubuntu-gpg-error/</url>
    <content><![CDATA[<p>当我们在/etc/apt/sources.list中加入非官方源来安装、更新部分软件时,sudo apt-get update会有错误提示</p>
<a id="more"></a>
<p>下面以我使用的ibus非官方源作为示例，错误提示如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">W: GPG error: http:<span class="comment">//ppa.launchpad.net jaunty Release: The following signatures couldn&#x27;t be verified because the public key is not available: NO_PUBKEY 21C022AA985E0E11</span></span><br><span class="line">W: You may want to run apt-get update to correct these problems</span><br></pre></td></tr></table></figure>
<p>也就是这个非官方源是不可信任的，解决办法是导入该源的公钥。</p>
<p>因为平时我们是使用sudo来管理系统的，所以有些地方要注意，不然很容易出现错误。</p>
<p>先把这个源的公钥从公钥服务器导入到当前用户的公钥库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$gpg --keyserver pgp.mit.edu --recv-key 21C022AA985E0E11</span><br></pre></td></tr></table></figure>
<p>此处没有必要用sudo来运行，把公钥导入当前用户即可，使用了反而有可能提示错误</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">gpg: WARNING: unsafe ownership on configuration file \<span class="string">`/home/username/.gnupg/gpg.conf&#x27;</span></span><br><span class="line"><span class="string">gpg: external program calls are disabled due to unsafe options file permissions</span></span><br><span class="line"><span class="string">gpg: keyserver communications error: general error</span></span><br><span class="line"><span class="string">gpg: keyserver receive failed: general error</span></span><br></pre></td></tr></table></figure>
<p>因为这样会导致gpg.conf的所有者与运行程序的用户不一致,当然如果你在root用户下运行则不存在这个问题，因为公钥导入到了root用户的密钥库。</p>
<p>公钥导入成功后会有如些提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">gpg: requesting key 985E0E11 <span class="keyword">from</span> hkp server pgp.mit.edu</span><br><span class="line">gpg: key 985E0E11: public key <span class="string">&quot;Launchpad PPA for ibus-dev&quot;</span> imported</span><br><span class="line">gpg: Total number processed: <span class="number">1</span></span><br><span class="line">gpg: imported: <span class="number">1</span> (RSA: <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>下一步是让apt-get 来使用这个公钥</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$gpg --armor --<span class="keyword">export</span> 985E0E11 sudo apt-key add -</span><br></pre></td></tr></table></figure>
<p>注意apt-key add要用特权用户来运行才可以，也就是要用sudo来运行，不然有如下错误提示：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">gpg: no writable keyring found: eof</span><br><span class="line">gpg: error reading \<span class="string">`-&#x27;: general error</span></span><br><span class="line"><span class="string">gpg: import from \`-&#x27; failed: general error</span></span><br></pre></td></tr></table></figure>
<p>导入成功后sudo apt-get update就不会有错误提示了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu 9.04下安装Firefox 3.5正式版(Release)</title>
    <url>/2009/07/15/ubuntu-install-firefox-3-5-release/</url>
    <content><![CDATA[<p>让我们翘首企盼的firefox 3.5正式版(Release)于6月30日正式推出，但是Ubuntu社区却迟迟没有更新，至今已经有半月，官方源仍然毫无动静，难道是因为bug太多，要等到firefox 3.5.1再进行更新？不得而知了。</p>
<p>看来暂时只有自己动手，丰衣足食了。对于firefox的安装我不推荐使用非官方源，而是从<a href="http://www.mozilla.com/en-US/firefox/all.html">Mozilla</a>下载更新，3.5与以前的版本并存，这样当Ubuntu官方源更新的时候，可以顺利的更新到最新的官方firefox版本。</p>
<p>firefox 3.5的安装比较简单，从<a href="http://www.mozilla.com/en-US/firefox/all.html">mozilla</a>下载回来的文件名字为firefox-3.5.tar.bz2，遵循FHS(Filesystem Hierarchy Standard)的指导意见，firefox最好安装到/opt目录下面，用下面的命令直接把bz2包解压到/opt目录下就可以了。<br>tar jxvf firefox-3.5.tar.bz2 -C /opt<br>这样就算安装完成了，命令行运行/opt/firefox/firefox或者建一个桌面快捷方式都可以，记得一定要运行/opt/firefox目录下的firefox,而不是firefox-bin或run-mozilla.sh。<br>这样两个版本的firefox使用同一套profile，可以和平共处，至于暂时不兼容的插件(Extensions)hack一下吧。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu:Partition table entries are not in disk order</title>
    <url>/2009/05/01/ubuntu-partition-table-unorder/</url>
    <content><![CDATA[<p>前几天刚安装了ubuntu 9.04，在分区的时候，先从磁盘的最后面划出大约2G的空间做了swap,然后再分的/，/var，/tmp,/home。安装好了才发现，虽然swap在磁盘的最后面，其设备号却为/dev/sda6,排在其他分区的前面，sda1和sda5为XP使用的分区。虽然看着有些不爽，但是不影响使用，也就没管它。</p>
<p>今天用sudo fdisk -l查看分区表的时，在打印的分区列表最后面有一句话：Partition table entries are not in disk order，又勾起了我的洁癖，决定把分区表顺序调整过来。</p>
<p>sudo fdisk /dev/sda进入fdisk的shell,然后输入f回车就可以把分区顺序调整过来了，然后输入w保存退出。因为root分区的设备号从(hd0,6)变成了(hd0,5)，所以grub就会无法找到root分区,从而无法进行引导。</p>
<p>用ubuntu 9.04的livecd引导进入系统，进入grub,然后root (hd0,5),setup (hd0) 就可以了。<br>ubuntu9.04是用uuid来标示分区的，所以/etc/fstab和/boot/grub/menu.lst不用更改就可以顺利的启动系统了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>ubuntu xterm终端字体发虚模糊的解决方法</title>
    <url>/2009/11/01/ubuntu-terminal-font-blur/</url>
    <content><![CDATA[<p>　　比较喜欢Courier New字体，但是在xterm里设置使用Courier New字体后，总是感觉文字显示有些模糊、发虚，文字边角一点儿也不锐利。但在.Xresources文件里设置各种Xft属性都不能解决问题，最后发现是反锯齿(anti-alias)造成到问题，修改/etc/fonts/conf.d/10-antialias.conf里面的antialias属性为false即可解决此问题。现在xterm里面显示的文字相当的清晰锐利，当然这样修改是全局性的，但是我还是很喜欢锐利的文字。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Xterm</tag>
      </tags>
  </entry>
  <entry>
    <title>UEFI+GPT windows 8 超级本安装debian wheezy双启动</title>
    <url>/2013/01/17/uefi-gpt-window8-debian-dual-boot/</url>
    <content><![CDATA[<p>近期换了lenovo yoga 13超级变形本,windows本来用的就不多,windows 8更是无从下手,debian才顺手</p>
<a id="more"></a>
<p>yoga 13外形靓丽,还能360度旋转,价格还算适中,最终没有选macbook air选了yoga 13,还是有些大了,但是yoga 11性能差了太多，未做考虑。升级了8G内存,硬盘只有128G,空间略显紧张,但速度飞快。</p>
<p>yoga 13使用UEFI BIOS,硬盘为GPT分区格式,还是第一次用UEFI和GPT。</p>
<p>debian wheezy已经开始支持UEFI启动和传统的BIOS启动两种启动方式。</p>
<p>此处使用usb盘UEFI启动方式安装,大体过程如下：</p>
<p><strong>1、下载最新的</strong><a href="http://cdimage.debian.org/cdimage/daily-builds/daily/arch-latest/amd64/iso-cd/debian-testing-amd64-netinst.iso">debian testing netinst iso amd64 daily build</a></p>
<p><strong>2、制作启动usb stick</strong></p>
<h1 id="cat-debian-testing-amd64-netinst-iso-gt-dev-sdb"><a href="#cat-debian-testing-amd64-netinst-iso-gt-dev-sdb" class="headerlink" title="cat debian-testing-amd64-netinst.iso &gt; /dev/sdb"></a>cat debian-testing-amd64-netinst.iso &gt; /dev/sdb</h1><h1 id="sync"><a href="#sync" class="headerlink" title="sync"></a>sync</h1><p>此处sdb为usb stick的设备名,请一定要弄明白你的usb stick是哪个设备名再下手,切记！或者用dd命令亦可。<br>这样制作的usb stick启动盘支持UEFI和LEGACY两种启动模式。</p>
<p><strong>3、usb启动安装debian</strong></p>
<p>插入usb stick,进入BIOS,启动方式不要动,保持UEFI方式,启动设备会多了一个,将其调整到第一个启动顺序。保存启动后开始安装debian,安装过程与以往基本相同,只是grub2这次不会安装到MBR而已,其实MBR根本就不存在。</p>
<p><strong>4、修正grub2启动配置文件</strong></p>
<p>grub2也会扫描到windows 8的存在,但其配置文件却是错误的，如下：<br> 88 ### BEGIN /etc/grub.d/30_os-prober ###<br> 89 menuentry “Windows Recovery Environment (loader) (on /dev/sda3)” –class windows –class os {<br> 90     insmod part_gpt<br> 91     insmod fat<br> 92  <strong>set root</strong>=‘(hd0,gpt3)’<br> 93  <strong>search –no-floppy –fs-uuid –set</strong>=root 80AB-6F68<br> 94     drivemap -s (hd0) $<strong>{root}</strong><br> 95     chainloader +1<br> 96 }<br> 97 menuentry “Windows 8 (loader) (on /dev/sda5)” –class windows –class os {<br> 98     insmod part_gpt<br> 99     insmod ntfs<br>100  <strong>set root</strong>=‘(hd0,gpt5)’<br>101  <strong>search –no-floppy –fs-uuid –set</strong>=root F8FA707EFA703B48<br>102     drivemap -s (hd0) $<strong>{root}</strong><br>103     chainloader +1<br>104 }<br>105 ### END /etc/grub.d/30_os-prober ### </p>
<p>虽然是GPT分区模式,却仍然使用了传统BIOS的链式启动方式,也就是legacy模式,所以启动windows 8时会报错:</p>
<p>error: unknown command ‘drivemap’<br>error: invalid EFI filepath</p>
<p>所以需要手动修正grub2的启动配置</p>
<p>首先禁止grub2探测其他windows 8系统<br>/etc/default/grub文件中添加<br>GRUB_DISABLE_OS_PROBER=true</p>
<p>然后在文件/etc/grub.d/40_custom文件中添加如下配置<br> menuentry <strong>“**windows 8 uefi</strong>“** {<br>    search –file –no-floppy –<strong>set</strong>=root /efi/Microsoft/Boot/bootmgfw.efi<br>    chainloader <strong>(</strong>${root}<strong>)</strong>/efi/Microsoft/Boot/bootmgfw.efi<br>} </p>
<p>最后<br>#update-grub<br>就可以顺利启动windows 8系统了。</p>
<p><strong>P.S.</strong><br>触摸屏在wheezy下还不能用,据说安装touchscreen驱动可以,但好像都支持的不好,还是等kernel 3.8更靠谱,彼时会支持windows多点触摸协议。bluetooth和wireless都没驱动起来,型号为RTL8723AU,但Realtek官方没有此芯片的信息,发送邮件询问尚未得到答复。现在使用了一个迷你usb wifi dongle上网,真悲催！从askubuntu找到了RTL8723AE的驱动,二者的区别在接口形式不同,RTL8723AU为usb 2.0接口,RTL8723AE为pci-e接口,RTL8723AE的驱动没有usb相关的支持,如果官方没有驱动,改造RTL8723AE使其支持usb 2.0接口?这是个挑战！</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>废除rman备份对象记录</title>
    <url>/2012/09/14/uncatalog-rman-records/</url>
    <content><![CDATA[<p>可以直接从rman中删除备份、备份集、拷贝等备份对象的记录信息。</p>
<a id="more"></a>
<p>使用CHANGE … UNCATALOG来删除记录,rman会从控制文件中删除相应的记录,如果使用了恢复目录,rman也会从恢复目录中删除这些记录。但RMAN不会对相应的物理文件做任何动作,它只是从控制文件或恢复目录中删除这些物理文件对应的记录。</p>
<p>命令格式:<br>CHANGE [ARCHIVELOG BACKUP BACKUPPIECE BACKUPSET COPY CONTROLFILECOPY DATAFILECOPY] [file specification key] UNCATALOG;</p>
<p>比如:<br>RMAN&gt;CHANGE DATAFILECOPY ‘/path/to/datafilecopy’ UNCATALOG;</p>
<p>uncataloged datafile copy<br>datafile copy filename=/path/to/datafilecopy recid=xxx stamp=xxx<br>Uncataloged 1 objects</p>
<p>或者直接指定备份对象的key<br>RMAN&gt;CHANGE DATAFILECOPY 63722 UNCATALOG;</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>umount已经下线的远程NFS文件系统</title>
    <url>/2019/10/09/umount-offline-nfs-filesystem/</url>
    <content><![CDATA[<a id="more"></a>
<p>如果远程的NFS服务器/文件系统已经奔溃，这时候umount会stuck住，可以用下面的命令行将其卸除掉：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo umount -f -l /mnt/mount_point</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>javascript的undefined和null</title>
    <url>/2013/11/16/undefined-null/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>undefiend</strong></p>
<p>javascript定义了一个全局变量undefined，它的值是undefined，它的值的类型也是undefined。 但是这个undefined全局变量不是一个常量，也不是一个关键字，而且可以被用户定义的名字覆盖。<br>[javascript]<br> console.log(undefined); //undefined<br> console.log(typeof undefined); //undefined<br> var undefined=”test”;<br> console.log(undefined); //test<br> console.log(typeof undefined); //string<br>[/javascript]<br>为了防止undefined全局变量被无意覆盖，一个常用的技巧是使用一个传递到函数的额外形式参数。 在调用时故意不为其提供实际参数,从而这个参数不会获取任何值,成为undefined。比如jquery就是这样玩的：</p>
<p>[javascript]<br>(function( window, undefined ) {<br> …<br>})( window );<br>[/javascript]<br>这样，在匿名函数内部，可以保证undefined就是undefined不是任何其他值。<br>其实质是定义了一个匿名函数局部作用域变量undefined,其值为undefined。</p>
<p><strong>null</strong></p>
<p>null不是变量，是一个预定义的对象，其值为null</p>
<p>[javascript]<br> console.log(null); //null<br> console.log(typeof null); //object<br> console.log(null == undefined) //true<br> console.log(null === undefined) //false</p>
<p> console.log(null.toString()); //Uncaught TypeError: Cannot call method ‘toString’ of null<br> var null=”test” //Uncaught SyntaxError: Unexpected token null<br>[/javascript]</p>
<p>不能重定义null的名字，null虽然被认为是对象，但其没有任何方法。null对象可以作为原型继承链的终点。</p>
<p>null与undefiend的值相等，但二者的类型不同。<br><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>UNICODE字符集</title>
    <url>/2012/10/16/unicode-intro/</url>
    <content><![CDATA[<p>unicode字符集是几乎涵盖地球上所有使用的文字符号的统一编码方案。</p>
<a id="more"></a>
<h2 id="渊源"><a href="#渊源" class="headerlink" title="渊源"></a><strong>渊源</strong></h2><p>最初有两个组织独立的开发通用字符编码标准,一个是统一码联盟(The Unicode Consortium),他们开发的字符集叫Unicode,另一个是ISO组织,他们开发的字符集叫UCS(Universal Character Set),由ISO/IEC 10646标准来定义。后来两个组织都意识到世界不需要两个不兼容的通用字符集,二者开始协同工作,为开发一个真正统一的通用字符集共同努力。当前的Unicode与UCS是完全兼容的,字符在两者中的代码点(code point)是一致的,最新的Unicode版本为6.1。</p>
<p>代码点(code point)是指字符在字符集中的编码值,比如字符’A’,在Unicode中的编码值为0041,在Unicode标准中标记为U+0041。</p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a><strong>编码</strong></h2><p>unicode最初使用16位的编码空间来编码字符,后来扩展到4个字节(32个位)。Unicode的编码空间划分为17个平面(plane),这最初的16位编码空间在UCS中称作”基本多文种平面”BMP(Basic Multilingual Plane),BMP为第一个平面,或称第零平面（Plane 0）,其他平面称为辅助平面(Supplementary Planes)。基本多语言平面BMP内，从U+D800到U+DFFF之间的码位区段是永久保留不映射到字符，因此可以利用保留下来的0xD800-0xDFFF区段的码位来对辅助平面的字符的码位进行编码。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a><strong>实现</strong></h2><p>每个字符的unicode编码是固定不变的。但出于不同的考量,存在多种编码转换格式(Unicode/UCS Transformation Format),比如最常见的UTF-8。</p>
<p><strong>UCS-2</strong></p>
<p>UCS-2使用两个字节来编码Unicode(UCS),只能表达BMP平面内的字符,无法对于BMP之外的字符进行编码。</p>
<p><strong>UTF-16</strong></p>
<p>UTF-16是对UCS-2的扩展,是UCS-2的超集,可以编码BMP之外的所有其他平面。对于基本平面BMP之外的字符,UTF-16需要使用4个字节来表示。UTF-16正是使用了BMP中保留的0xD800-0xDFFF来编码辅助平面内的字符,所以并不会与UCS-2产生冲突。Unicode也采用了UTF-16转换格式,在Unicode的术语中0xD800-0xDFFF中的高位部分称为高位代理(high surrogates),低位部分称为低位代理(low surrogates)。</p>
<p>由于UTF-16(UCS-2)使用两个字节编码,不得不面临字节序的问题。所以UTF-16又分为UTF-16LE(Little Endian)和UTF-16BE(Big Endian)。为了在文件中区分UTF-16LE和UTF16-BE,在文件的开头放置一个字符U+FEFF字符作为字节序标志BOM(Byte Order Mark),以显示这个文本文件是以UTF-16编码,其中UTF-16LE以FF FE开头，UTF-16BE以FE FF开头</p>
<p><strong>UCS-4与UTF-32</strong></p>
<p>ISO 10646标准定义了UCS-4编码格式,使用4个字节中的31位来表达一个UCS字符,最高位恒为0。编码范围从0到0x7FFFFFFF。但是因为当前的Unicode只使用了17个平面,所有的代码点(code point)都位于0到0x10FFFF之间,这已经是相当大的数字了,在这个范围内仍然有充裕的空闲代码点。 因此又有了一个新的编码格式UTF-32,UTF-32只编码0到0x10FFFF之间的码位。UCS-4/UTF-32虽然可以直观的映射Unicode字符集,但是也存在浪费存储空间,与原有系统兼容性差的缺点。</p>
<p>UCS-4是UCS-2的超集,最高2个字节为0的UCS-4编码即是一个UCS-2编码。</p>
<p><strong>UTF-8</strong></p>
<p>UTF-8是可变长度字符编码格式,而且UTF-8是与ASCII兼容的,是ASCII的超集。原来使用ASCII字符集的应用程序不做任何修改即可在UTF-8编码环境下使用。而且UTF-8比UTF-16/UTF-32更节省存储空间。<br>字节0xFE和0xFF在UTF-8编码中从未用到，同时，UTF-8以字节为编码单元，它的字节顺序在所有系统中都是一様的，没有字节序的问题，也因此它实际上并不需要BOM,虽然有些软件会在UTF-8编码的文件中写入BOM,但这其实打破了兼容性,特别是与ASCII的兼容性。因此,写入BOM是不被推荐的。BOM字符U+FEFF的UTF-8编码为字节串EF BB BF。</p>
<p>UTF-8的另一个优点是容易查找字符的边界,很容易从字符串中辨识出字符,容易重新同步,而不像某些编码格式需要从字符串的头部开始查找辨识字符。</p>
<p>UTF-8现在是应用最广泛的Unicode编码格式。</p>
<p><strong>UTF-1</strong></p>
<p>可能很少人会知道还有UTF-1这个编码格式。UTF-1是ISO 10646/Unicode的一个字符流编码格式,也是一个可变长度的编码。UTF-1由于设计不良,比如如果从字符编码的中间开始查找字符的话,UTF-1是无法找到字符的起始编码位置并重新查找字符的。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>unicode终端访问中文BBS</title>
    <url>/2010/01/15/unicode-terminal-bbs/</url>
    <content><![CDATA[<a id="more"></a>
<p>系统一直是使用的en_US.UTF-8编码，用xterm登录<a href="http://bbs.tsinghua.edu.cn/">水木清华BBS</a>时中文字符全是乱码，肯定是两端字符集不一致引起的。先生成zh_CN.GB18030 locale,然后export LANG=zh_CN.GB18030再访问一样是乱码,不知道是为什么。</p>
<p>用luit进行字符集转换则一切正常,使用的命令为:</p>
<figure class="highlight plain"><figcaption><span>luit -encoding GB18030 -- telnet bbs.tsinghua.edu.cn</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>luit是为unicode终端比如xterm提供locale和ISO 2022支持的工具。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>linux系统卸载oracle 10g</title>
    <url>/2012/04/10/uninstall-oracle-10g-linux/</url>
    <content><![CDATA[<p>debian squeezy amd64系统,卸载oracle 10.2.0.4 64bits版本</p>
<a id="more"></a>
<p>1、停止服务</p>
<p>以oracle用户登陆系统,停止监听和数据库</p>
<p>$lsnrctl stop</p>
<p>SQL&gt;shutdown immediate</p>
<p>2、删除文件</p>
<p>#rm -rf $ORACLE_BASE<br>#rm /etc/oraInst.loc<br>#rm /etc/oratab<br>#rm /usr/local/bin/coraenv<br>#rm /usr/local/bin/dbhome<br>#rm /usr/local/bin/oraenv</p>
<p>3、删除用户和组</p>
<p>#userdel oracle<br>#groupdel oinstall<br>#groupdel dba</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>unzip解压缩中文名乱码问题</title>
    <url>/2018/12/07/unzip-gbk-filename/</url>
    <content><![CDATA[<p>windows平台生成的zip文件名是使用CP936也就是GBK编码的，导致这样的文件在linux平台utf-8环境下解压缩的时候文件名会成为乱码，这个问题由来已久，但并没有从zip那边有个根本性的解决方案。</p>
<p>可以使用python的zipfile模块来解决这个问题。</p>
<p>python3版本：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;env python3</span><br><span class="line"></span><br><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import zipfile</span><br><span class="line"></span><br><span class="line">print(&quot;Processing File &quot; + sys.argv[1])</span><br><span class="line"></span><br><span class="line">file&#x3D;zipfile.ZipFile(sys.argv[1],&quot;r&quot;);</span><br><span class="line">for name in file.namelist():</span><br><span class="line">    utf8name&#x3D;name.encode(&#39;cp437&#39;).decode(&#39;cp936&#39;)</span><br><span class="line">    print(&quot;Extracting &quot; + utf8name)</span><br><span class="line">    pathname &#x3D; os.path.dirname(utf8name)</span><br><span class="line">    if not os.path.exists(pathname) and pathname!&#x3D; &quot;&quot;:</span><br><span class="line">        os.makedirs(pathname)</span><br><span class="line">    data &#x3D; file.read(name)</span><br><span class="line">    if not os.path.exists(utf8name):</span><br><span class="line">        fo &#x3D; open(utf8name, &quot;wb&quot;)</span><br><span class="line">        fo.write(data)</span><br><span class="line">        fo.close</span><br><span class="line">file.close()</span><br></pre></td></tr></table></figure>

<p>因为zipfile把所有非utf-8编码格式的文件名都作为cp437进行处理，因此需要先还原回cp437，然后重新编码为cp936。</p>
<p>python版本见Reference[1]。</p>
<p>References:</p>
<p>[1]<a href="https://www.jianshu.com/p/72bb8d2ed4df">Linux 下 zip 文件解压乱码解决方案</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>USB stick安装debian</title>
    <url>/2011/07/04/usb-stick-install-debian/</url>
    <content><![CDATA[<p>一直以来基本上都是刻录光盘来安装debian,但是这样还是比较浪费的,刻过好多光盘了</p>
<a id="more"></a>
<p>最初也用硬盘安装过，但是起码要有一个系统存在才可以从硬盘安装。新换的PC上带有8合1读卡器,通过lsusb可以看到读卡器是USB接口，那应该是可以通过读卡器来安装系统。正好手上有一个sony的256M记忆棒memory stick pro,正好可以废物利用了。</p>
<p>现在debian的ISO镜像都是hybrid格式,可以方便的直接写入USB stick,制作起来特别简单。因为记忆棒只有256M，刚好能容下netinst网络安装镜像。下载安装镜像，插入记忆棒</p>
<p>#fdisk -l</p>
<p>可以看到记忆棒的设备名为/dev/sdc,不同的机器设备名会不同,一般为/dev/sdX,X是从a到z的字母,一般/dev/sda为第一块硬盘。有一点要明白，写入光盘镜像后，记忆棒里面原有的内容会全部被覆盖，丢失，所以一定要先把记忆棒里面重要的东西备份出来。通过以下命令来制作usb启动设备</p>
<p>#cat debian.iso &gt; /dev/sdc<br>#sync</p>
<p>这样就制作完成了。进入BIOS选择启动设备，可以发现一个可引导的设备，名字叫USB KEY1:GENERIC STORAGE DEVICE 9744，就是它了，让它做第一个引导设备，重新启动机器，顺利进入debian安装界面。</p>
<p>dd命令应该也没问题,不过我没试<br>#dd if=debian.iso of=/dev/sdc</p>
<p>看来如果再安装系统就可以不用刻录光盘了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>即将到来的Cassandra  3.0</title>
    <url>/2015/03/12/upcoming-cassandra-3-0/</url>
    <content><![CDATA[<a id="more"></a>
<p>The 3.0 release will have numerous features and improvements, including:</p>
<p>• Disk-aware vnodes</p>
<p>• Non-frozen UDTs (user defined types)</p>
<p>• Nested collections</p>
<p>• File-based hints</p>
<p>• Json support</p>
<p>• UDFs (user defined functions)</p>
<p>• Global indexes</p>
<p>…</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>用户身份认证</title>
    <url>/2013/11/30/user-auth/</url>
    <content><![CDATA[<p>传统的静态密码安全性之低，使其不能用在一些对安全要求很高的领域。</p>
<a id="more"></a>
<p>目前主流的身份认证方式有几种，OTP(One Time Password)方式的身份认证，基于PKI的身份认证以及基于生物特征的认证等。</p>
<p><strong>OTP</strong></p>
<p>OTP一般采用OATH标准的TOTP或HOTP算法。算法基于使用HMAC(hash message authentication code)的摘要算法，两端共享密钥，添加动态因子，防止重放攻击。</p>
<p>HTOP的算法为<br>HOTP(K,C) = Truncate(HMAC-SHA-1(K,C))</p>
<p>K为共享密钥，C为计数器。HTOP用于计数同步型的口令牌。</p>
<p>TOTP算法则基于时间动态因子，服务器和口令牌在相同的时间窗口内基于共享密钥分别进行计算，在允许的时间窗口内计算结果一致即为认证成功。对服务器和令牌的时钟要求比较高。TOTP用于时间型口令牌。</p>
<p>OTP有这么几种常见的方式：</p>
<ul>
<li>  口令矩阵卡<br>这是成本很低，也比较简陋的OTP认证方式。每次认证使用不同坐标组合的口令，简单有效。但是很容易被复制而无法觉察，现在已经很少使用。</li>
<li>  动态口令牌<br>非接触式，采用独立硬件的动态口令牌。共享密钥当面分发，口令牌的密钥内置其硬件中，密钥设计为无法从外部读取，口令牌本身无法拆解，暴力拆解会无法使用，通过这些方式来加强其口令牌的安全性。动态口令牌的安全性依赖于其密钥的安全性，一般采用位数较长的密钥。</li>
</ul>
<p>由于采用非接触式使用方式，可以完全杜绝PC恶意程序的攻击。还可以采用PIN(Personal Identification Number)码对令牌进一步加强保护。</p>
<p>但是动态口令卡无法防止中间人攻击(man in the middle)，这可以通过使用SSL/HTTPS来防止中间人攻击。这种情况下，如果有人伪造证书，浏览器是会有警告的。还有一种迷惑性很强的欺骗方式，注册一个与真实站点域名十分相近的域名，然后申请真正的数字证书，网站做的与真实站点一模一样。如果被诱导到此种网站，后果就严重了，再强大的加密算法都于事无补。</p>
<ul>
<li>  手机动态口令<br>由于独立硬件的令牌成本比较高，而手机的普及率又很高，因此又出现了手机动态口令这种认证方式。其实手机正好符合非接触式，独立硬件的条件，只不过不是专用的硬件而已。手机动态口令不受网络信号的影响，手机端与服务器认证端也是独立同步运算的。</li>
</ul>
<p>手机动态口令的密钥分发要保证安全，因为是软件实现方式，与手机其他软件一起运行，因此有可能会受手机恶意软件的影响，如果在手机端直接使用动态口令进行认证登录，还是存在一些风险。PC登录与手机动态口令分开的话会比较安全。</p>
<ul>
<li>  短信随机密码<br>这种方式依赖于移动网络，每次需要身份认证时，会发一个随机密码到绑定的手机上。这种方式也有弱点，比如有人伪造机主身份证件恶意补卡，GSM短信被截获等。手机动态口令使用短信绑定时，也有短信被劫持的风险存在。</li>
</ul>
<p><strong>PKI认证方式</strong></p>
<p>PKI的基本原理为基于大数因数分解的难度，生成一对密钥，公钥(public key)和私钥(private key)。使用公钥加密的信息，只能使用私钥来解密，反之亦然。</p>
<p>公钥可以公开发布，而私钥必须要小心的保管，以防泄漏。但是公钥发布时也存在一个问题，如何保证公钥就是发布者宣称的那个人的公钥，所以就有了<strong>数字证书</strong>。</p>
<p>CA(Certificate Authority)是大家都认可的机构，CA的公钥是周知的，一般浏览器里都带有很多CA的根证书，里面就有CA的公钥。</p>
<p>用户申请数字证书时，CA会验证用户的身份，并将用户的身份信息与其公钥绑定在一起进行数字签名，这就是用户的数字证书。有了数字证书后，用户可以用其进行数字签名，保证数据的完整性和不可抵赖。这是一个信任链，如果CA私钥泄漏，则整个信任链就垮塌了。</p>
<p>公钥的认证也可以采用公认的公钥服务器的形式，比如GPG使用的方式。</p>
<p><strong>数字签名的流程为,将要发送的信息计算摘要并使用私钥加密，然后与正文信息一起发送。接收者受到信息后，用相同的算法计算正文的摘要，然后使用签名者的公钥解密作者发送过来的加密后的摘要，如果二者一致则证明信息是完整的，没有被篡改的，也是不能抵赖的。</strong></p>
<p><strong>数字证书就是CA将用户的公钥和验证过的身份信息使用CA的私钥进行数字签名而来的，可以使用CA根证书中的公钥来验证数字证书的真伪。</strong></p>
<p><strong>然后用户又可以拿自己的数字证书来进行数字签名，这是一个完整的链条。而CA的数字证书是拿自己的私钥自签的，所以CA并不神秘，但是浏览器内置了其自签的数字证书，并称之为CA根证书。</strong></p>
<p>HTTPS服务器也是使用数字证书来表名自己的身份，其数字证书会绑定域名和所有者及其组织的相关信息。也可以在HTTPS协议上使用双向认证。</p>
<p>常见的PKI身份认证方式:<br>其实无论是数字证书还是USB KEY，都是使用非对称加密PKI(公钥和私钥对)来进行用户认证，只是密钥的保存方式有些区别而已。</p>
<ul>
<li>  CA数字证书<br>早期需要高级别安全的领域，使用数字证书来认证，比如网上银行。银行为用户颁发个人数字证书，个人持有私钥和公钥，银行持有个人的公钥。登录认证时，银行会发送一个challenge随机码，又叫挑战或冲击，客户使用自己的私钥加密收到的challenge,然后发送到银行服务端，银行服务器使用客户的公钥解密客户发回的加密信息，又叫应答或响应，如果解密后的结果与银行发给客户的挑战码一致，则可以说明是正确的用户。<br>如果客户持有银行的公钥，这个认证过程也可以是双向的，让客户端也确认是连接到正确的银行网站。</li>
</ul>
<p>但是因为木马病毒等恶意程序横行，客户的私钥很容易被窃取，因此这种方式逐渐被淘汰了，现在应该没有人用了。</p>
<ul>
<li>  USB KEY<br>这种方式直接将用户私钥存储在key的受保护数据区，私钥是不可读取的，所有的加密都在key内部进行，电脑端无法看到加密的过程，只能输入需要加密的数据和接收加密后的数据，因此安全性大大提高。服务器端发来的挑战随机码被送入key内部，key加密完成后将结果送到PC端，然后传输给服务器。一般USB KEY会有pin码保护，只有用户输入正确的pin码才可以使用,而且多次输入错误的密码，key会被锁定。<br>虽然木马等恶意程序已经无法再获取到用户的私钥，但是如果用户将key插到电脑上，而且已经输入了正确的pin码，离开时忘记将key拔出，则木马等恶意程序仍然可以通过用户的电脑获得非法的身份认证。所以有些USB KEY设计了物理实体按键，每次认证需要按KEY上的物理键确认操作才可以，木马等恶意程序也就无能为力了。</li>
</ul>
<p>总体来讲，基于PKI非对称密钥的认证方式是更安全的。动态口令牌采用共享密钥同步计算的方式来认证。不过挑战/应答型的动态口令牌也可以采用PKI认证方式，这种口令牌会有一个输入键盘，客户端电脑上显示服务器端发来的挑战随机码，用户将挑战码输入口令牌，口令牌使用内部的私钥计算出加密后的应答码，然后用户将应答码通过PC返回给服务端。这种口令牌也可以用于数字签名。如果口令牌内存放服务端的公钥，也可以进行双向认证。</p>
<p>采用PKI认证方式加pin码保护的挑战/应答型动态口令牌是十分安全的，只是使用起来可能有些繁琐。</p>
<p>References:<br>[1]<a href="http://tech.tjs.im/2013-11-23/two-factor-authentication.html">身份验证的 2 步验证</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>普通用户的crontab</title>
    <url>/2015/05/16/user-crontab/</url>
    <content><![CDATA[<a id="more"></a>
<p>除了root用户外,普通用户可以添加自己的定时服务。/usr/bin/crontab程序设置了组ID,因此普通用户运行crontab时是以crontab组权限运行的。</p>
<p><strong>编辑用户cron配置</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ crontab -e </span><br></pre></td></tr></table></figure>
<p><strong>列出用户cron配置</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ crontab -l</span><br></pre></td></tr></table></figure>
<p>更详细的用法见man crontab。</p>
<p><strong>用户crontab文件位置</strong></p>
<p>不同的操作系统，用户的crontab文件位置可能会不同:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Debian / Ubuntu Linux - <span class="regexp">/var/</span>spool/cron/crontabs/</span><br><span class="line">Mac OS X - <span class="regexp">/usr/</span>lib/cron/tabs/ </span><br><span class="line">FreeBSD/OpenBSD/NetBSD - <span class="regexp">/var/</span>cron/tabs/ </span><br><span class="line">CentOS/Red Hat/RHEL/Fedora/Scientific Linux - <span class="regexp">/var/</span>spool/cron/ </span><br><span class="line">HP-UX Unix - <span class="regexp">/var/</span>spool/cron/crontabs/</span><br><span class="line">IBM AIX Unix - <span class="regexp">/var/</span>spool/cron/</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用ceph块设备</title>
    <url>/2019/11/04/using-ceph-rdb/</url>
    <content><![CDATA[<a id="more"></a>
<p>ceph提供了一个具有很多高级特性的虚拟块设备，可以当做普通块设备来使用，也可以用于qemu等虚拟化环境。ceph提供的块设备具有多副本高可用、快照、精简配置、条带化、远程镜像等很多特性。</p>
<p><strong>基本操作</strong></p>
<p>创建并初始化一个块设备池，取名叫rbd</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ceph osd pool create rbd <span class="number">36</span> <span class="number">36</span></span><br><span class="line">$ sudo rbd pool init</span><br></pre></td></tr></table></figure>
<p>如不提供pool名字,rdb命令默认使用名字为rdb的pool</p>
<p>创建块设备镜像data，大小为1024MB，可以忽略掉pool名字</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rbd create --size <span class="number">1024</span> rbd/data</span><br></pre></td></tr></table></figure>
<p>因为ceph使用精简配置，所以把size设置的大一些也无妨，不使用并不会真正的占用存储空间。</p>
<p>获取镜像信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rbd info data</span><br><span class="line">rbd image <span class="string">&#x27;data&#x27;</span>:</span><br><span class="line">size <span class="number">1</span> GiB <span class="keyword">in</span> <span class="number">256</span> objects</span><br><span class="line">order <span class="number">22</span> (<span class="number">4</span> MiB objects)</span><br><span class="line">snapshot_count: <span class="number">0</span></span><br><span class="line">id: 2ab0d130bf615</span><br><span class="line">block_name_prefix: rbd_data.2ab0d130bf615</span><br><span class="line">format: <span class="number">2</span></span><br><span class="line">features: layering, exclusive-lock, object-map, fast-diff, deep-flatten</span><br><span class="line">op_features: </span><br><span class="line">flags: </span><br><span class="line">create_timestamp: Wed Nov <span class="number">6</span> <span class="number">21</span>:<span class="number">59</span>:<span class="number">10</span> <span class="number">2019</span></span><br><span class="line">access_timestamp: Wed Nov <span class="number">6</span> <span class="number">21</span>:<span class="number">59</span>:<span class="number">10</span> <span class="number">2019</span></span><br><span class="line">modify_timestamp: Wed Nov <span class="number">6</span> <span class="number">21</span>:<span class="number">59</span>:<span class="number">10</span> <span class="number">2019</span></span><br></pre></td></tr></table></figure>

<p>resize镜像,扩大和缩小</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rbd resize --size <span class="number">2048</span> foo</span><br><span class="line">$ sudo rbd resize --size <span class="number">2048</span> foo --allow-shrink</span><br></pre></td></tr></table></figure>

<p>删除块设备镜像</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ suro rbd rm &#123;pool-name&#125;/&#123;image-name&#125;</span><br><span class="line">$ sudo rbd rm foo</span><br></pre></td></tr></table></figure>

<p><strong>内核模块块设备映射</strong></p>
<p>可以通过内核模块将ceph块设备镜像映射成为OS可以操作的块设备，就像一个真的块设备一样，比如一块硬盘。</p>
<p>镜像列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rbd list</span><br></pre></td></tr></table></figure>

<p>映射为块设备，使用默认的client.admin用户</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">###format: rbd device map &#123;pool-name&#125;/&#123;image-name&#125; --id &#123;user-name&#125;</span><br><span class="line">$ sudo rbd device map data</span><br><span class="line">bd: sysfs write failed</span><br><span class="line">RBD image feature set mismatch. You can disable features unsupported by the kernel <span class="keyword">with</span> <span class="string">&quot;rbd feature disable data object-map fast-diff deep-flatten&quot;</span>.</span><br><span class="line">In some cases useful info is found <span class="keyword">in</span> syslog - <span class="keyword">try</span> <span class="string">&quot;dmesg tail&quot;</span>.</span><br><span class="line">rbd: map failed: (<span class="number">6</span>) No such device or address</span><br><span class="line">$ sudo rbd feature disable data object-map fast-diff deep-flatten</span><br><span class="line">$ sudo rbd device map data</span><br><span class="line">/dev/rbd0</span><br></pre></td></tr></table></figure>
<p>这里映射出来的块设备名字为/dev/rbd0，当做普通的块设备来使用就行了。</p>
<p>查看映射设备列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo rbd device list</span><br><span class="line">id pool namespace image snap device </span><br><span class="line"><span class="number">0</span> rbd data - <span class="regexp">/dev/</span>rbd0 </span><br></pre></td></tr></table></figure>

<p>取消设备映射</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">###format: rbd device unmap /dev/rbd/&#123;poolname&#125;/&#123;imagename&#125;</span><br><span class="line">###format: rbd device unmap &#123;devicename&#125;</span><br><span class="line">$ sudo rbd device unmap /dev/rbd0</span><br></pre></td></tr></table></figure>

<p>注意：块设备是不能共享访问的，所以不要多次映射并行访问同一个镜像。</p>
<p><strong>QEMU集成</strong></p>
<p>创建镜像,要使用raw格式,不要使用其他格式</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">###format: qemu-img create -f raw rbd:&#123;pool-name&#125;/&#123;image-name&#125; &#123;size&#125;</span><br><span class="line">$ sudo qemu-img create -f raw rbd:rbd/foo 10G</span><br><span class="line">Formatting <span class="string">&#x27;rbd:rbd/foo&#x27;</span>, fmt=raw size=<span class="number">10737418240</span></span><br></pre></td></tr></table></figure>

<p>查看镜像信息</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo qemu-img info rbd:rbd/foo</span><br><span class="line">image: json:&#123;<span class="string">&quot;driver&quot;</span>: <span class="string">&quot;raw&quot;</span>, <span class="string">&quot;file&quot;</span>: &#123;<span class="string">&quot;pool&quot;</span>: <span class="string">&quot;rbd&quot;</span>, <span class="string">&quot;image&quot;</span>: <span class="string">&quot;foo&quot;</span>, <span class="string">&quot;driver&quot;</span>: <span class="string">&quot;rbd&quot;</span>&#125;&#125;</span><br><span class="line">file format: raw</span><br><span class="line">virtual size: 10G (<span class="number">10737418240</span> bytes)</span><br><span class="line">disk size: unavailable</span><br><span class="line">cluster_size: <span class="number">4194304</span></span><br></pre></td></tr></table></figure>

<p>resize镜像</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">###format: qemu-img resize rbd:&#123;pool-name&#125;/&#123;image-name&#125; &#123;size&#125;</span><br><span class="line">$ sudo qemu-img resize rbd:rbd/foo 20G</span><br></pre></td></tr></table></figure>

<p>转换已有kvm镜像为ceph镜像</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ sudo qemu-img convert -f qcow2 -O raw bar.qcow2 rbd:rbd/bar</span><br><span class="line">###or: sudo qemu-img convert -f qcow2 bar.qcow2 -O raw rbd:rbd/bar</span><br></pre></td></tr></table></figure>

<p>运行客户机</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ qemu -m <span class="number">1024</span> -drive format=rbd,file=rbd:rbd/bar,cache=writeback</span><br></pre></td></tr></table></figure>

<p><strong>lxd集成</strong></p>
<p>lxd已经内置支持ceph集群存储,执行lxd init时，指定存储后端为ceph即可。<br>也可以使用lxc storage命令创建新的存储池。<br>lxd集群使用ceph后端存储可以创建高可用lxd容器，但是同一时刻只能有一个节点在运行一个容器实例，需要其他机制来自动故障转移。</p>
<p>References:<br>[1]<a href="https://docs.ceph.com/docs/master/rbd/">CEPH BLOCK DEVICE</a><br>[2]<a href="https://amito.me/2018/Using-RBD-in-Ceph/">Ceph 中块设备 RBD 的基本用法</a><br>[3]<a href="https://ubuntu.com/blog/ceph-storage-driver-in-lxd">Ceph storage driver in LXD</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>firefox使用dnscrypt-proxy内建doh服务器</title>
    <url>/2020/02/10/using-dnscrypt-proxy-inbuild-doh-server/</url>
    <content><![CDATA[<a id="more"></a>
<p>dnscrypt-proxy内建doh服务器，可以为本机或外部提供doh服务</p>
<p><strong>本地使用</strong></p>
<p>先生成自签证书</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ openssl req -x509 -nodes -newkey rsa:<span class="number">2048</span> -days <span class="number">5000</span> -sha256 -keyout localhost.pem -out localhost.pem</span><br></pre></td></tr></table></figure>

<p>编辑/usr/local/etc/dnscrypt-proxy.toml，添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[local_doh\]</span><br><span class="line"> listen_addresses = \[<span class="string">&#x27;127.0.0.1:3000&#x27;</span>\]</span><br><span class="line"> path = <span class="string">&quot;/dns-query&quot;</span></span><br><span class="line"> cert_file = <span class="string">&quot;localhost.pem&quot;</span></span><br><span class="line"> cert_key_file = <span class="string">&quot;localhost.pem&quot;</span></span><br></pre></td></tr></table></figure>

<p>重启dnscrypt-proxy服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo brew services restart dnscrypt-proxy</span><br></pre></td></tr></table></figure>

<p>打开firefox浏览器，访问<a href="https://127.0.0.1:3000/dns-query%E5%B9%B6%E6%8E%A5%E5%8F%97%E8%87%AA%E7%AD%BE%E8%AF%81%E4%B9%A6">https://127.0.0.1:3000/dns-query并接受自签证书</a><br>然后输入about:config配置如下选项：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">network.trr.custom_uri = https:<span class="comment">//127.0.0.1:3000/dns-query</span></span><br><span class="line">network.trr.uri = https:<span class="comment">//127.0.0.1:3000/dns-query</span></span><br><span class="line">network.trr.resolvers = \[&#123; <span class="string">&quot;name&quot;</span>: <span class="string">&quot;local&quot;</span>, <span class="string">&quot;url&quot;</span>: <span class="string">&quot;https://127.0.0.1:3000/dns-query&quot;</span> &#125;\]</span><br><span class="line">network.trr.mode = <span class="number">3</span></span><br><span class="line">network.security.esni.enabled = <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>重新启动firefox，访问<a href="https://www.cloudflare.com/ssl/encrypted-sni/">Browsing Experience Security Check</a>检查浏览器设置结果。</p>
<p>References:<br>[1]<a href="https://github.com/DNSCrypt/dnscrypt-proxy/wiki/Local-DoH">Local DoH</a></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>uWSGI简介</title>
    <url>/2015/04/06/uwsgi/</url>
    <content><![CDATA[<a id="more"></a>
<p>为了实现动态web,我们发展出了各式各样的技术，那真是五花八门，乱花渐欲迷人眼。</p>
<p>各种网关接口协议，从最古老的<a href="http://en.wikipedia.org/wiki/Common_Gateway_Interface">CGI</a>(Common Gateway Interface)到<a href="http://python.ca/scgi/protocol.txt">SCGI</a>(Simple Common Gateway Interface),<a href="http://www.fastcgi.com/drupal/">FastCGI</a>,<a href="https://www.python.org/dev/peps/pep-0333/">WSGI</a>(Python Web Server Gateway Interface),<a href="http://plackperl.org/">PSGI</a>(Perl Web Server Gateway Interface),<a href="http://rack.github.io/">rack</a>,<a href="http://keplerproject.github.io/wsapi/">WSAPI</a>(Lua Web Server API),甚至还出现了JWSGI(Java Web Server Gateway Interface)等,当然还有HTTP协议。这些协议大部分已经标准化，还有许许多多的私有协议。只有协议是不够的，所以又有了对协议的各种各样的实现，比如<a href="http://php-fpm.org/">php-fpm</a>,<a href="http://redmine.lighttpd.net/projects/spawn-fcgi/wiki">spawn-fcgi</a>,<a href="http://wiki.nginx.org/Fcgiwrap">fcgiwrap</a>,<a href="http://uwsgi-docs.readthedocs.org/en/latest/index.html#">uWSGI</a>等</p>
<p>web server也通过很多内置的模块来直接实现对动态web支持，比如<a href="https://perl.apache.org/">mod_perl</a>,<a href="http://modpython.org/">mod_python</a>,mod_php,<a href="http://httpd.apache.org/docs/trunk/mod/mod_lua.html">mod_lua</a>等。</p>
<p>传统的web server，比如apache,nginx等，自身处理静态资源请求，然后将动态资源请求通过内置模块或者支持相关网关协议的application server转发到相应的应用程序来处理。当然也有tomcat此类的应用服务器，可以通过http来与传统的web服务器进行集成，甚至自身完全担当起application server和web server两种角色。有很多web框架自己也提供了http服务器。但一般来讲传统的web server除了处理静态资源性能上的优势，还有其他很多丰富的功能，比如访问控制，反向代理，负载均衡等等。</p>
<p>为什么会有这么多的协议，这么多的模块？应该讲主要还是性能方面的考量，动态web从无到有，从小规模到大规模，还要面对各种各样的后端开发技术，有这么多的协议和模块也是无可避免的。</p>
<p>一般来讲，部署一个动态应用可以有多种不同的选择。比如部署php应用可以使用php-fpm,也可以使用mod_php,甚至也可以使用其他的FCGI服务器，只要FCGI服务器实现了对PHP的支持即可。</p>
<p><strong>uWSGI是个什么东东?</strong></p>
<p>uWSGI是一个应用服务器，支持几乎所有现有的网关接口协议，同时自己也实现了另一个网关接口协议，叫做<a href="http://uwsgi-docs.readthedocs.org/en/latest/Protocol.html">uwsgi</a>。这么多接口了，为什么再造一个？据说还是性能，据说uwsgi比fastcgi和wsgi都快的多。</p>
<p>且不论uWSGI的性能有多高，只是能支持几乎所有的网关接口协议就已经很不错了。nginx已经内置支持uWSGI,这样nginx + uWSGI这种组合可以应对各种各样的后端应用，部署和管理起来都方便的多。</p>
<p>nginx不支持CGI,只能通过<a href="https://openwares.net/internet/fastcgi_intro.html">FastCGI</a>来调用CGI程序。</p>
<p>References:<br>[1]<a href="http://uwsgi-docs.readthedocs.org/en/latest/index.html">uWSGI</a><br>[2]<a href="http://metz.gehn.net/2013/02/running-anything-on-nginx-with-uwsgi/">Running (almost) anything on Nginx with uWSGI</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>vim自动重新加载文件内容变化</title>
    <url>/2016/10/16/vim-autoread/</url>
    <content><![CDATA[<a id="more"></a>
<p>vim有一个选项autoread，可以自动重新读取当前正在缓冲区但其内容变化了的文件，一般来讲是因为外部程序修改了vim当前正在编辑的文件。<br>但是这个选项并不会自动加载变化之后的内容，只有特定的事件被触发时才会重新加载，比如执行外部命令，或者简单的执行vim内部命令:e</p>
<p>这一切都不是自动和实时的，所以有了这样一个插件auto_autoread.vim<br>下载auto_autoread.vim文件丢到~/.vim/plugin/目录下，打开一个文件，然后输入：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:Autoread <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>这样插件会后台周期性监视文件变化，这里设定的周期是1秒，当文件内容发生变化后会自动重新读取进来。</p>
<p>输入：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:AutoreadStop</span><br></pre></td></tr></table></figure>
<p>停止监视文件变化。</p>
<p>这个功能应该由vim内部实现，vim主配置文件配置一下监视周期就好了。</p>
<p>References:<br>[1]<a href="http://www.vim.org/scripts/script.php?script_id=5206">auto_autoread.vim : Automatically read files when they’ve changed. Does what ‘autoread’ promises.</a><br>[2]<a href="https://github.com/vim-scripts/auto_autoread.vim">auto_autoread.vim</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim调用python格式化json数据</title>
    <url>/2013/11/30/vim-call-python-format-json/</url>
    <content><![CDATA[<p>python有个标准模块叫json,用于编码/解码,序列化/按序列化json格式数据。</p>
<a id="more"></a>
<p>服务器返回的json数据是非格式化的,程序使用没问题，如果需要阅读则亚历山大。</p>
<p>可以使用vim调用python json模块提供的命令行工具json/tool.py格式化json文本。</p>
<p>vim打开json数据,命令行模式下</p>
<p>:%!python3 -m json.tool</p>
<p>%表示针对全部的行范围,用!调用外部命令</p>
<p>python3的 -m选项用于指定模块的名字,并将对应的.py文件作为脚本运行。这里运行的脚本就是json/tool.py</p>
<p>json/tool.py是一个命令行工具,使用json模块来校验和格式化json数据。</p>
<p>json是python3内置模块,在包libpython3.3-stdlib中提供。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Vim</tag>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM列编辑模式</title>
    <url>/2014/01/11/vim-column-edit/</url>
    <content><![CDATA[<p>在vim面前感觉自己永远是个新手！这句话对emacs说不定也适用,不过我没用过emacs这么高大上的编辑器!</p>
<a id="more"></a>
<p>列编辑模式的很多功能用:s命令同样可以做到,但某些情况下使用列编辑模式效率更高。</p>
<p><strong>进入列编辑模式</strong></p>
<p>在normal模式下按CTRL+v进入Visual Block模式,也就是列编辑模式。windows下可能需要按CTRL+q。</p>
<p><strong>选择</strong></p>
<p>可以使用h/j/k/l来选择文本,当前也可以使用数字前缀。使用$或0选择到行尾或行首。</p>
<p><strong>插入</strong></p>
<p>I用于在选择的文本块前面添加文本,添加之后按ESC就会在选择块的每行前面添加插入的文本。A用于在后面添加,同样添加之后按ESC。<br>I是Insert,A是Append</p>
<p><strong>替换</strong></p>
<p><em>c命令</em><br>先选中需要替换的文本块,然后键入”c”进入输入状态，键入文本后按下”Esc”键。如果想替换掉选中文本块到行尾的所有内容，使用C代替c。</p>
<p><em>r命令</em><br>选中需要替换的文本块,按r再输入替换后的字符,所有选中的文本会全部替换为键入的字符。</p>
<p><strong>移动文本块</strong></p>
<p>选择文本块后,使用&gt;可以向右移动文本块,每次移动一个shiftwidth定义的宽度,也可以输入数字前缀加&gt;,比如3&gt;,向右移动3倍的距离。向左移动使用&lt;。</p>
<p><strong>VisIncr</strong></p>
<p><a href="http://vim.sourceforge.net/scripts/script.php?script_id=670">VisIncr</a>插件可以为列添加递增或递减的数字,日期或者某一天的名字(Sun,Mon,Tue,…),这可是可以按顺序增减变化的。</p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim插件之html标签匹配与高亮</title>
    <url>/2013/06/12/vim-html-match-highlight/</url>
    <content><![CDATA[<p>vim默认通过%命令可以匹配(),{},等符号</p>
<a id="more"></a>
<p>但无法对html标签进行匹配，也无法高亮匹配的标签对。当然可以通过插件来实现这些功能，<a href="http://www.vim.org/scripts/script.php?script_id=39">MatchIt</a>扩展%命令来支持匹配html标签对，<a href="https://github.com/gregsexton/MatchTag">MatchTag</a>可以高亮匹配的标签对。</p>
<p><strong>安装MatchIt</strong></p>
<p>下载后在<del>/.vim目录下解压，生成两个文件,一个是插件</del>/.vim/plugin/matchit.vim，另一个是文档~/.vim/doc/matchit.txt</p>
<p>~/.vimrc中添加<br>:filetype plugin on </p>
<p>然后在vim中执行命令<br>:source ～/.vim/plugin/matchit.vim<br>或者重启vim<br>就可以使用%命令在标签对之间跳转了。</p>
<p>使用命令<br>:helptags ~/.vim/doc<br>重建本地帮助文件，然后</p>
<p>:help matchit<br>可以查看matchit的帮助文件</p>
<p><strong>安装MatchTag</strong><br>直接将下载到的html.vim放到~/.vim/ftplugin/目录下即可<br>这个插件是file type plugin，所以需要放到ftplugin目录下<br>之后可以自动高亮匹配的标签对，但只限可视范围之内的标签对。</p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>vim编辑Markdown使用chrome实时预览</title>
    <url>/2013/12/10/vim-markdown-chrome/</url>
    <content><![CDATA[<p>有了Markdown,写文档神马的轻松多了。</p>
<a id="more"></a>
<p>当然还是要用vim</p>
<p><strong>语法高亮</strong></p>
<p>使用<a href="https://github.com/plasticboy/vim-markdown">vim-markdown</a>就好了，下载下来直接unzip到~/.vim/目录即可。</p>
<p><strong>实时预览</strong></p>
<p>使用chrome插件Markdown Preview Plus。在插件管理界面选中”Allow access to file URLs”，在插件自身的选项里选中<br>“Enable auto-reload”,还以选择内置的CSS或者自定义CSS，这插件还挺靠谱。</p>
<p>然后用vim写Markdown,Chrome就可以实时预览了。</p>
<hr>
<p>以后用vim写Markdown来更新wordpress好了。</p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim多文件查找</title>
    <url>/2014/12/08/vim-multifile-find/</url>
    <content><![CDATA[<a id="more"></a>
<p>在linux平台上,有很多优秀的shell命令组合来做多文件查找/替换,比如这些命令:find,sed,grep,awk,perl。但其他平台比如windows上就没那么方便了,这时候vim内置的多文件查找命令就有用武之地了，虽然比起外部命令来稍微慢了一点点儿。</p>
<p>这个vim内置命令就是vimgrep,有两种基本的使用方式：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:vim\[grep\]\[!\] /&#123;pattern&#125;/\[g\]\[j\] &#123;file&#125; ...</span><br><span class="line">:vim\[grep\]\[!\] &#123;pattern&#125; &#123;file&#125; ...</span><br></pre></td></tr></table></figure>

<p>file部分支持通配符,<em>代表当前目录,**代表当前目录及其子目录(递归)，比如</em>/<em>.c代表当前目录下的c源程序文件,**/</em>.c代表当前目录及其递归子目录下的所有源程序文件。file部分可以指定多次。</p>
<p>g(global)是全局标志，没有g,每行只会匹配一次，如果有g,则匹配行内所有符合的pattern，也就是行可以会多次被添加到quickfix列表。<br>j(jump)是跳转标志，没有j，vim会跳转到第一个匹配，如果有j，则只更新</p>
<p>以下命令查看匹配结果：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:cn\[ext\] 下一个结果</span><br><span class="line">:cp\[revious\] 上一个结果</span><br><span class="line">:cw\[indow\] quickfix窗口,结果文件列表</span><br></pre></td></tr></table></figure>

<p>更详细的用法参见:help vimgrep 和下面的refs。</p>
<p>References:<br>[1]<a href="http://mywcd.sinaapp.com/blog/425">使用vimgrep查找文件</a><br>[2]<a href="http://easwy.com/blog/archives/advanced-vim-skills-quickfix-mode/">vi/vim使用进阶: 剑不离手 – quickfix</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim 多文件替换</title>
    <url>/2014/12/08/vim-multifile-replace/</url>
    <content><![CDATA[<a id="more"></a>
<p>References:<br>[1]<a href="http://www.vimer.cn/2009/10/vimgvim%E5%AE%9E%E7%8E%B0%E5%A4%9A%E6%96%87%E4%BB%B6%E7%9A%84%E6%9F%A5%E6%89%BE%E5%92%8C%E6%9B%BF%E6%8D%A2.html">Vim(gvim)实现多文件的查找和替换</a><br>[2]<a href="http://iyuan.iteye.com/blog/1683286">vim批量修改多文件数据</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>VIM 删除奇数行,删除偶数行以及奇数行和偶数行合并</title>
    <url>/2013/11/08/vim-odd-even-line-delete-and-merge/</url>
    <content><![CDATA[<p>vim奇偶数行操作</p>
<a id="more"></a>
<p>思路很简单，就是一次匹配两行，然后删除奇数行，删除偶数行或者两行合并。</p>
<p><strong>删除奇数行</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:%s/^.*$\\n\\(^.*$\\)/\\<span class="number">1</span>/g</span><br></pre></td></tr></table></figure>
<p><strong>删除偶数行</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:%s/\\(^.*$\\)\\n^.*$/\\<span class="number">1</span>/g</span><br></pre></td></tr></table></figure>
<p><strong>奇数行和偶数行合并，以空格分格</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:%s/\\(^.*$\\)\\n\\(^.*$\\)/\\<span class="number">1</span> \\<span class="number">2</span>/g</span><br></pre></td></tr></table></figure>
<p><strong>要点：</strong></p>
<p>主要就是使用正则表达式的分组捕获特性，小括号round brackets（ 和 ）用于捕获匹配的结果，存储到一个内部数组内，<br>然后可以使用索引1,2,3,…来引用按顺序捕获的匹配。<br>在vim中,( 和 )必须用backslash转义，所以分别为\( 和 \)，引用捕获的分组使用\1,\2,\3,…<br>而\n匹配换行符，上面的命令就不难理解了。</p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim:匹配中文的正则表达式</title>
    <url>/2013/11/10/vim-regexp-chinese/</url>
    <content><![CDATA[<p>中文在不同的字符集编码中的匹配规则也不同，这里说的是UNICODE字符集中汉字的匹配规则。</p>
<a id="more"></a>
<p>UNICODE标准中，中日韩三国的文字通称为CJK象形文字，在UNICODE 6.3标准中占据的<a href="http://www.unicode.org/Public/6.3.0/ucd/Blocks.txt">编码块</a>有以下几个:<br>[html]<br>2E80..2EFF; CJK Radicals Supplement 中日韩部首增补<br>2F00..2FDF; Kangxi Radicals 康熙部首<br>3000..303F; CJK Symbols and Punctuation 中日韩符号和标点<br>31C0..31EF; CJK Strokes 中日韩笔画<br>3200..32FF; Enclosed CJK Letters and Months 带圈中日韩字母和月份<br>3300..33FF; CJK Compatibility 中日韩兼容<br>3400..4DBF; CJK Unified Ideographs Extension A 中日韩统一表意文字扩展A<br>4DC0..4DFF; Yijing Hexagram Symbols 易经六十四卦符号<br>4E00..9FFF; CJK Unified Ideographs 中日韩统一表意文字<br>F900..FAFF; CJK Compatibility Ideographs 中日韩兼容表意文字<br>FE30..FE4F; CJK Compatibility Forms 中日韩兼容形式<br>20000..2A6DF; CJK Unified Ideographs Extension B 中日韩统一表意文字扩展B<br>2A700..2B73F; CJK Unified Ideographs Extension C 中日韩统一表意文字扩展C<br>2B740..2B81F; CJK Unified Ideographs Extension D 中日韩统一表意文字扩展D<br>2F800..2FA1F; CJK Compatibility Ideographs Supplement 中日韩兼容表意文字增补<br>[/html]</p>
<p>不得不说UNICODE字符集才是王道，什么GBK,GB2312,GB18030之类的玩蛋儿去吧。<br>不得不说，英文只有26个字符很有优势，中文神马的象形文字真的挺麻烦的。</p>
<p>所以如果使用UNICODE字符集，无论使用何种编码转换格式,当然优先utf-8，就可以使用[\uxxxxx-\uxxxxx]这种格式来匹配相应的象形文字。<br>对于我们日常使用的中文字符，[\u4E00-\u9FFF]基本上都可以涵盖了，但是这个范围内没有标点符号，只能匹配文字。<br>[\u3000-\u303F]也只涵盖一部分全角标点符号,比如没匹配到全角的逗号。<br>还真有点儿麻烦。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim寄存器</title>
    <url>/2016/11/25/vim-registers/</url>
    <content><![CDATA[<a id="more"></a>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vim --version grep clipboard</span><br><span class="line">-clipboard </span><br><span class="line">-xterm_clipboard</span><br></pre></td></tr></table></figure>

<p>debian系统终端下面的vim默认编译选项并不支持系统剪贴板，所以如果需要与系统剪贴板交互需要使用gvim,当然鼠标中键一直是可以用的，不过，用vim不就是为了丢掉效率地下的鼠标吗？</p>
<p>References:<br>[1]:help registers<br>[2]<a href="http://yejinxin.github.io/vim-register-usage/">Vim中寄存器的使用</a><br> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>vim技巧两则:使用数字序列替换匹配的pattern和插入数字序列</title>
    <url>/2018/11/22/vim-repalce-with-sequence/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>使用数字序列替换</strong></p>
<p>vim查找替换时，可以使用一个数字序列来替换匹配的内容</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:<span class="keyword">let</span> i=<span class="number">1</span> \[range\]g/PATTERN/s<span class="comment">//\\=i/g let i=i+1</span></span><br></pre></td></tr></table></figure>

<p><strong>插入数字序列</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:put =range(<span class="number">11</span>,<span class="number">15</span>)</span><br></pre></td></tr></table></figure>
<p>可以在文件当前行后插入５行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="number">11</span></span><br><span class="line"><span class="number">12</span></span><br><span class="line"><span class="number">13</span></span><br><span class="line"><span class="number">14</span></span><br><span class="line"><span class="number">15</span></span><br></pre></td></tr></table></figure>

<p><strong>函数式替换</strong></p>
<p>在替换命令 s/// 中可以使用函数表达式来书写替换内容，格式为</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:s/替换字符串/\\=函数式</span><br></pre></td></tr></table></figure>

<p>在函数式中可以使用 submatch(1)、submatch(2) 等来引用 \1、\2 等的内容，而submatch(0)可以引用匹配的整个内容。</p>
<p>举个栗子，将文件从第一行开始的行首替换为如下样式：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">mem\[<span class="number">0</span>\]=</span><br><span class="line">mem\[<span class="number">1</span>\]=</span><br><span class="line">mem\[<span class="number">2</span>\]=</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>可以执行如下替换：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:%s/^/\\=<span class="string">&#x27;mem\[&#x27;</span>.(line(<span class="string">&quot;.&quot;</span>)-<span class="number">1</span>).<span class="string">&#x27;\]=&#x27;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="http://vim.wikia.com/wiki/Making_a_list_of_numbers">Making a list of numbers</a><br>[2]<a href="https://blog.csdn.net/hylaking/article/details/80270763">vi/vim的巧妙使用-数值加减,递增,序列等</a></p>
]]></content>
      <categories>
        <category>uncategorized</category>
      </categories>
  </entry>
  <entry>
    <title>Vim分页窗口(tabpage)</title>
    <url>/2014/07/31/vim-tabpage/</url>
    <content><![CDATA[<p>Vim已经内置支持页签,每个页签内可以有一个或多个窗口,<a href="http://www.vim.org/scripts/script.php?script_id=159">MiniBufExplorer</a>已经是老黄历了。</p>
<a id="more"></a>
<p>References:<br>[1]<a href="http://vimdoc.sourceforge.net/htmldoc/tabpage.html#tabpage">Vim documentation: tabpage</a><br>[2]<a href="http://vim.wikia.com/wiki/Using_tab_pages">Using tab pages</a></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim切分窗口(Split Window)</title>
    <url>/2013/12/19/vim-split/</url>
    <content><![CDATA[<p>vim即可以切分窗口,也可以将窗口分页，分页以后仍然可以在页签内继续切分窗口，很强大有木有。</p>
<a id="more"></a>
<p><strong>启动时切分窗口</strong></p>
<p>启动时分割窗口的参数,man里是这样写的：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">-o\[N\] Open N windows stacked. When N is omitted, open one <span class="built_in">window</span> <span class="keyword">for</span> each file.</span><br><span class="line">-O\[N\] Open N windows side by side. When N is omitted, open one <span class="built_in">window</span> <span class="keyword">for</span> each file.</span><br></pre></td></tr></table></figure>

<p>参数小写o用于水平分割窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vim -o\[N\] file1 file2 ... </span><br></pre></td></tr></table></figure>
<p>参数大写O用于垂直分割窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vim -O\[N\] file1 file2 ... </span><br></pre></td></tr></table></figure>
<p>N指定分割几个窗口,如果不指定参数N,则每一个文件打开一个分割窗口。如果指定参数N，不指定file参数，则显示空白的分割窗口<br>,参数N不必与要打开的文件个数相同。</p>
<p>vimdiff命令也是以切分窗口的方式来打开文件并高亮展示文件之间的差异，vimdiff同样识别上面说过的小写o和大写O参数,同样也可以指定N,vimdiff默认以垂直切分窗口显示。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vimdiff \[-o\[N\] -O\[N\]\] file1 file2 ... </span><br></pre></td></tr></table></figure>

<p><strong>动态切分窗口</strong></p>
<p>打开vim编辑窗口之后,仍然可以方便的按需切分窗口。</p>
<p>水平切分<br>有多个命令可以水平切分窗口,如果提供file参数,可以在新分割的窗口中显示文件内容</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:\[N\]sp\[lit\] \[file\]</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:\[N\]<span class="keyword">new</span> \[file\]</span><br></pre></td></tr></table></figure>
<p>还有一个快捷键组合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w s</span><br></pre></td></tr></table></figure>

<p>垂直切分<br>有多个命令可以垂直切分窗口，如果提供file参数,可以在新分割的窗口中显示文件内容</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:\[N\]vs\[plit\]</span><br><span class="line">:vert\[ical\] sp\[lit\]</span><br></pre></td></tr></table></figure>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:\[N\]vne\[w\]</span><br><span class="line">:vert\[ical\] <span class="keyword">new</span></span><br></pre></td></tr></table></figure>
<p>还有一个快捷键组合</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w v</span><br></pre></td></tr></table></figure>

<p>可选参数N是一个数字,用于指定新分割窗口的大小，以行数计。</p>
<p><strong>移动光标</strong></p>
<p>要在切分窗口间移动光标,只要先按CTRL+w,然后组合vim的光标移动键h,j,k,l等就可以在窗口间移动光标</p>
<p>移动到左侧紧邻窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w h</span><br></pre></td></tr></table></figure>
<p>移动到下面紧邻窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w j</span><br></pre></td></tr></table></figure>
<p>移动到上面紧邻窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w k</span><br></pre></td></tr></table></figure>
<p>移动到右侧紧邻窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w l</span><br></pre></td></tr></table></figure>

<p>在窗口间依次循环切换</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w w</span><br></pre></td></tr></table></figure>

<p>移动到最顶部(top)的窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w t</span><br></pre></td></tr></table></figure>

<p>移动到最底部(bottom)的窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w b</span><br></pre></td></tr></table></figure>

<p>移动到前一个(previous)的窗口</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w p</span><br></pre></td></tr></table></figure>

<p><strong>移动窗口</strong></p>
<p>仍然需要先按CTRL+w,不过移动窗口使用大写的vim光标键H,J,K,L等。不过这里稍微有些不同，马上会看到</p>
<p>移动当前窗口到最左侧</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w H</span><br></pre></td></tr></table></figure>
<p>移动当前窗口到最底部</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w J</span><br></pre></td></tr></table></figure>
<p>移动当前窗口到最顶部</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w K</span><br></pre></td></tr></table></figure>
<p>移动当前窗口到最右侧</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">CTRL+w L</span><br></pre></td></tr></table></figure>
<p>当前窗口与下面窗口或右侧窗口进行位置交换(eXchange)。<br>如果当前窗口在底部，下面已经没有其他窗口，这时命令将当前窗口与上面窗口进行位置交换。<br>如果当前窗口在最右侧，右侧已经没有其他窗口，这是命令将当前窗口与其左侧的窗口进行位置交换。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">ctrl+w x</span><br></pre></td></tr></table></figure>
<p>窗口向下进行循环(recycle)移动,这个命令可以前缀一个数字N作为参数，指明向下循环移动所执行的次数。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]ctrl+w r</span><br></pre></td></tr></table></figure>
<p>窗口向上进行循环(Recycle)移动,这个命令可以前缀一个数字N作为参数，指明向上循环移动所执行的次数。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]ctrl+w R</span><br></pre></td></tr></table></figure>

<p><strong>窗口大小</strong></p>
<p>调整窗口高度</p>
<p>增加高度,默认每次增加一行,如果指定参数N则增加N行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w \[N\]+</span><br></pre></td></tr></table></figure>
<p>减少高度,默认每次减少一行,如果指定参数N则减少N行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w \[N\]-</span><br></pre></td></tr></table></figure>
<p>所有窗口高度一致</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Ctrl+w =</span><br></pre></td></tr></table></figure>
<p>使当前窗口调整到指定高度,如果指定参数N则调整到指定的N行高度,否则当前窗口的高度尽可能的最大。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w _</span><br></pre></td></tr></table></figure>

<p>resize命令调整窗口高度。resize不带任何参数,则当前窗口的高度尽可能的最大。如果指定参数N则调整到指定的N行高度,如果指定参数N的同时使用+或者-前缀修饰,则在当前窗口高度的基础上增加或者减少N行高度。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:res\[ize\] \[\[+-\]N\]</span><br></pre></td></tr></table></figure>

<p>窗口宽度调整</p>
<p>增加窗口宽度,如果指定N则增加N行宽度</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w \[N\]&gt;</span><br></pre></td></tr></table></figure>

<p>减少窗口宽度,如果指定N则减少N行宽度</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\[N\]Ctrl+w \[N\]&lt;</span><br></pre></td></tr></table></figure>

<p><strong>关闭窗口</strong></p>
<p>可以使用<code>ZZ</code>或是<code>:q</code>命令或<code>ctrl+w c</code>关闭当前窗口。</p>
<p>命令<code>ctrl+w o</code>可以使得当前窗口成为屏幕上的唯一(only)窗口，而其他窗口全部关闭。</p>
<p>References:<br>[1]<a href="http://yyq123.blogspot.com/2009/08/vim-window.html">VIM学习笔记 窗口(Window)</a><br>[2]<a href="http://coolshell.cn/articles/1679.html">Vim的分屏功能</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>ubunut pppoe拨号部分网站无法访问的原因及解决办法</title>
    <url>/2009/11/03/ubunut-pppoe-mtu-issue/</url>
    <content><![CDATA[<p>ubuntu 9.10(karmic koala)AMD64系统下，设置好ADSL PPPoE拨号后，出现一种情况，部分网站可以正常访问，而有些网站则没有响应，无法正常访问。比如google.cn是正常的，而sina.com.cn则无法访问。</p>
<p>　　出现这个问题的原因是PPPoE默认设置的MTU1492字节有问题。MTU是链路层的一个特性，叫做最大传输单元(Maximum Transfer Unit)。如果网络层(IP层)要发送的数据比链路层的MTU还要大，那么IP层必须对数据进行分片(fragmentation)。PPPoE的MTU是一种逻辑MTU,因为PPPoE并没有一个实体的链路层存在。通常情况下以太网(ethernet)的MTU为1500字节，所以PPPoE设置其MTU为1492字节，加上PPPoE 8个字节的头部，刚好达到以太网的MTU，从而可以提高网络的利用率。但实际上很多ADSL接入方式的MTU并不是1500字节，比如我的ADSL链路使用traceroute实测的路径MTU(PMTU)是1492字节。那么这种情况下，PPPoE设置其MTU为1492就存在问题了，加上8个字节的PPPoE头部后，就超过了以太网的MTU大小。</p>
<a id="more"></a>
<p>那为什么部分网站可以访问，而部分网站不能访问呢？回答这个问题前先介绍一个概念最大报文段长度MSS(Maximum Segment Size)，MSS表示传输控制层(TCP)传往另一端的最大数据块长度。大多数系统为了提高链路层的利用率，减少TCP分段，通常将MSS设置为MTU减去40字节，因为这40字节刚好是20字节到TCP头和20字节的IP头之和。浏览网站到时候，首先要和网站建立TCP连接，在握手阶段，两端的TCP层会向对方通告自己能够接受的MSS。</p>
<p>　　可以用tcpdump来监测整个TCP交互的过程。当请求sina.com.cn的时候，本地系统的MSS期望值是1452字节，加上20个字节的TCP头，20个字节的IP头，8个字节的PPPoE头，正好是1500字节。而sina.com.cn的MSS是1460，这也是以太网(RFC 894)可以接受的最大的MSS。这样网站接受了客户系统通告的MSS大小1452，然后发送MSS大小的数据块(包括可能的选项)给客户端，加上总共40字节的TCP和IP头部后，到达PPPoE服务器到数据大小是1492字节,再加上8个字节的PPPoE头后达到了1500字节，超过了以太网的MTU1492，如果PPPoE服务器无法处理这种情况，数据包就会被丢弃，也就无法看到网站的回应。而浏览google.cn的时候，服务器选择了较小的MSS(我监测到的是1430)来发送数据包，从而服务器的响应会顺利返回到浏览器。一般来说我们浏览网站的时候，系统发送给网站的请求数据量是很小的，基本都可以顺利通过链路到达服务器。</p>
<p>　　既然物理链路的路径MTU(PMTU)为1492，那么设置PPPoE的MTU为1484(1492-8)或更小就可以解决问题了。当然最好实测一下你自己的路径MTU。<br>　　设置方法有两个。<br>　　一个是使用ifconfig命令,sudo ifconfig ppp0 mtu 1484,但是这样设置系统重新启动后会回复到原来的设置，所以一劳永逸的办法是修改/etc/ppp/peers/dsl-provider文件，在里面增加一行mtu 1484就可以了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>Vim TaskList插件</title>
    <url>/2014/07/31/vim-tasklist-plugin/</url>
    <content><![CDATA[<a id="more"></a>
<p>Eclipse神马的都支持任务列表,vim也可以。有一个插件叫<a href="http://www.vim.org/scripts/script.php?script_id=2607">TaskList</a>就是做这个事的,它使用与eclipse一样的语法，写FIXME,TODO或者XXX就可以了。</p>
<p>安装很简单，下载插件扔到plugin目录就可以了，比如 ~/.vim/plugin目录。</p>
<p>输入命令<code>:TaskList</code>调用任务列表窗口,按q退出窗口</p>
<p>.vimrc文件为TaskList映射快捷键:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">map t :TaskList&lt;CR&gt;</span><br></pre></td></tr></table></figure>

<p>然后按t进入任务列表，按q退出就可以了。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>安装vim插件管理器vundle</title>
    <url>/2013/05/27/vim-vundle-install/</url>
    <content><![CDATA[<p><a href="https://github.com/gmarik/vundle">vundle</a>可以自动管理vim插件，从自动下载安装到更新</p>
<a id="more"></a>
<p><strong>安装</strong><br>$ git clone <a href="https://github.com/gmarik/vundle.git">https://github.com/gmarik/vundle.git</a> ~/.vim/bundle/vundle</p>
<p>Cloning into ‘/home/${username}/.vim/bundle/vundle’…<br>remote: Counting objects: 2456, done.<br>remote: Compressing objects: 100% (1587/1587), done.<br>remote: Total 2456 (delta 831), reused 2385 (delta 776)<br>Receiving objects: 100% (2456/2456), 296.68 KiB 49 KiB/s, done.<br>Resolving deltas: 100% (831/831), done.</p>
<p><strong>配置</strong><br>编辑~/.vimrc</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">set nocompatible <span class="string">&quot; be iMproved</span></span><br><span class="line"><span class="string">filetype off &quot;</span> required!</span><br><span class="line"></span><br><span class="line">set rtp+=~<span class="regexp">/.vim/</span>bundle/vundle/</span><br><span class="line">call vundle#rc()</span><br><span class="line"></span><br><span class="line"><span class="string">&quot; let Vundle manage Vundle</span></span><br><span class="line"><span class="string">&quot;</span> required!</span><br><span class="line"><span class="string">&quot;使用vundle插件管理器管理自身</span></span><br><span class="line"><span class="string">Bundle &#x27;gmarik/vundle&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;</span>vundel管理的插件，有三种类型</span><br><span class="line"><span class="string">&quot; My Bundles here:</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="string">&quot;第一种为github上的插件</span></span><br><span class="line"><span class="string">&quot;</span> original repos on github</span><br><span class="line"><span class="string">&quot;Bundle &#x27;tpope/vim-fugitive&#x27;</span></span><br><span class="line"><span class="string">&quot;</span>Bundle <span class="string">&#x27;Lokaltog/vim-easymotion&#x27;</span></span><br><span class="line"><span class="string">&quot;Bundle &#x27;rstacruz/sparkup&#x27;, &#123;&#x27;rtp&#x27;: &#x27;vim/&#x27;&#125;</span></span><br><span class="line"><span class="string">&quot;</span>Bundle <span class="string">&#x27;tpope/vim-rails.git&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;这是我要安装的html5语法高亮,自动缩进和自动完成插件</span></span><br><span class="line"><span class="string">Bundle &#x27;othree/html5.vim&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;</span>第二种为普通的脚本插件</span><br><span class="line"><span class="string">&quot; vim-scripts repos</span></span><br><span class="line"><span class="string">&quot;</span>Bundle <span class="string">&#x27;L9&#x27;</span></span><br><span class="line"><span class="string">&quot;Bundle &#x27;FuzzyFinder&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;</span>第三种为非github上的git 仓库</span><br><span class="line"><span class="string">&quot; non github repos</span></span><br><span class="line"><span class="string">&quot;</span>Bundle <span class="string">&#x27;git://git.wincent.com/command-t.git&#x27;</span></span><br><span class="line"><span class="string">&quot; ...</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">filetype plugin indent on &quot;</span> required!</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;使用说明</span></span><br><span class="line"><span class="string">&quot;</span> Brief help</span><br><span class="line"><span class="string">&quot; :BundleList - list configured bundles</span></span><br><span class="line"><span class="string">&quot;</span> :BundleInstall(!) - install(update) bundles</span><br><span class="line"><span class="string">&quot; :BundleSearch(!) foo - search(or refresh cache first) for foo</span></span><br><span class="line"><span class="string">&quot;</span> :BundleClean(!) - confirm(or auto-approve) removal <span class="keyword">of</span> unused bundles</span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="string">&quot;</span> see :h vundle <span class="keyword">for</span> more details or wiki <span class="keyword">for</span> FAQ</span><br><span class="line"><span class="string">&quot; NOTE: comments after Bundle command are not allowed..</span></span><br></pre></td></tr></table></figure>
<p><strong>安装插件</strong><br>打开vim,输入:BundleInstall即自动安装配置的插件，插件全部安装到~/.vim/bundle目录下</p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>用vim来解决wordpress的代码高亮和缩进</title>
    <url>/2009/06/05/vim-wordpress-syntax/</url>
    <content><![CDATA[<p>因为要经常在post中贴一些代码出来，为了美观，安装了WP-Syntax插件来高亮代码，但是wordpress的visual编辑器实在是太逊了，经常把整齐的代码搞的一团糟，虽然有语法高亮，但是仍然惨不忍睹。</p>
<p>终于再无法忍受，寻觅其他解决的办法。平时编辑代码都是用vim的，突然想到vim有一个功能可以把编辑的文本转换为HTML格式，这不正是我想要的吗！vim的语法高亮能力可不是一般的强悍，用vim编辑代码那可是相当的舒适。</p>
<p>终于可以抛弃wordpress的visual编辑器了。在vim里面执行:TOhtml就可以把当前编辑的文本转换为HTML页面，转换结果相当的好，也可以用：m,nTOhtml把一个范围内的文本转换为html。</p>
<p>因为我的vim用的自己修改的desert256配色方案，背景是黑色的，所以转换出来的html在白色背景下略显刺眼。</p>
<p><strong>UPDATE:</strong><br>最新版的vim默认使用CSS来生成html代码,这样嵌入wordpress会有问题,可以在~/.vimrc文件里面设置变量关闭CSS来解决问题</p>
<p>:let g:html_use_css=0</p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim折叠</title>
    <url>/2013/11/19/vim-zip-fold/</url>
    <content><![CDATA[<p>vim支持文本折叠,将多行文本折叠到一行显示，并提供折叠起来的多行文本的预览。通过折叠，可以更容易明白整个文档的结构。<br>一个折叠就相当于文档中的一个小节。</p>
<a id="more"></a>
<p><strong>vim支持6种折叠方式：</strong></p>
<ul>
<li>  manual<br>手工定义折叠</li>
<li>  indent<br>根据缩进定义折叠，更多的缩进代表更高的折叠级别</li>
<li>  expr<br>通过一个表达式定义折叠</li>
<li>  syntax<br>通过语法高亮定义折叠</li>
<li>  diff<br>折叠未改变的文本，在使用vimdiff或diffsplit等时，就自动采用这种折叠方式</li>
<li>  marker<br>通过文本中的标记定义折叠</li>
</ul>
<p><strong>设置折叠方式</strong></p>
<p>通过命令<br>:set foldmethod=manual<br>或配置文件中<br>set foldmethod=manual<br>来设置折叠方式，默认为手工折叠方式。当比较文本时默认采用diff折叠模式。</p>
<p><strong>手工折叠命令</strong></p>
<p>所有的折叠命令都以z开头，官方文档说，”从一边看，z就像一张折叠起来的纸”,这样方便记忆，还有可以将z理解为zip,也有压缩之意。</p>
<ul>
<li>  zf<br>创建折叠<br>记忆法: zf stands for “F-old creation”</li>
</ul>
<p>命令格式为：<br>zf{motion} 或者 {Visual}zf</p>
<p>{motion}是指移动光标位置的命令，{Visual}指可视模式,比如:<br>zf10j 折叠当前光标开始向后的10行，因为10j是光标向后移动10行<br>zf9G或zf9gg 折叠当前光标和第9行之间的行，因为9G或9gg移动光标到第9行<br>8zf 将当前行及之后的8行折叠起来，因为8是光标向后移动8行</p>
<p>zfa命令(可以这样记忆，zf at *)</p>
<p>将光标放置到(,{,[,&lt;等字符上，然后执行<br>zfa(,zfa{,zfa[,zfa&lt;<br>等命令，就可以将(),{},[],包围的文本折叠起来</p>
<p>zfap将光标所在的段落(paragraph)折叠起来,一般前后有空行的一段文本称为段落。 zfap可以这样记忆，zf at paragraph</p>
<ul>
<li>  :{range}fo[ld]<br>在行范围内创建折叠。比如<br>:10,20fo 在第10行到20行之间创建折叠</li>
<li>  zo<br>打开折叠<br>zp stands for “O-pen a fold”</li>
<li>  zc<br>关闭折叠<br>zc standsfor “C-lose a fold”</li>
<li>  za<br>在当前折叠上循环打开、关闭折叠(toggle)<br>当在一个关闭的折叠上，打开这个折叠；<br>当在一个打开的折叠上，关闭这个折叠，并设置’foldenable’属性</li>
<li>  zA<br>在当前嵌套的折叠上循环打开、关闭折叠(toggle)<br>当在一个关闭的折叠上，打开所有嵌套的折叠<br>挡在一个打开的折叠上，关闭所有嵌套的折叠，并设置’foldenable’属性</li>
<li>  zr<br>打开所有折叠<br>zr stands for “R-educe the folding”</li>
<li>  zm<br>关闭所有折叠<br>zm stands for “folds M-ore”</li>
<li>  zR<br>一次全部打开嵌套的折叠<br>zR stands for “R-educes folds until there are none left”</li>
<li>  zM<br>关闭所有折叠和嵌套的折叠<br>zM stands for “folds M-ore and M-ore”</li>
<li>  :{range}foldo[pen][!]<br>打开指定行范围内的折叠，如果没有指定[!]只打开一层折叠</li>
<li>  :{range}foldc[lose][!]<br>关闭指定行范围内的折叠，如果没有指定[!]只关闭一层折叠</li>
<li>  zn<br>禁止折叠<br>zn stands for “no foldenable”</li>
<li>  zN<br>启用折叠<br>zN stands for “NO NO foldenable”</li>
<li>  zi<br>在zn和zN之间循环<br>zi stands for “Invert foldenable”</li>
<li>  zd<br>删除当前光标下的一个折叠<br>zd stands for “delete fold”</li>
<li>  zD<br>删除光标下的所有嵌套的折叠<br>zD stands for “Delete more folds”</li>
<li>  zE<br>删除当前窗口的所有折叠<br>zE stands for “Eliminate all folds in the window”</li>
<li>  [z<br>移动到当前打开折叠的最开始处</li>
<li>  ]z<br>移动到当前打开折叠的最后</li>
<li>  zj<br>移动到一下个折叠的开始处</li>
<li>  zk<br>移动到上一个折叠的结束处</li>
<li>  :[range]foldd[oopen] {cmd}<br>在所有非关闭折叠的行或行范围[range]内执行命令{cmd}</li>
<li>  :[range]folddoc[losed] {cmd}<br>在关闭折叠的所有行或行范围[range]内执行命令{cmd}</li>
</ul>
<p><strong>保存折叠</strong><br>Vim不自动记忆手工折叠。使用以下命令，来保存当前的折叠状态：</p>
<p>:mkview</p>
<p>下次打开文档时，使用下面的命令，来载入记忆的折叠信息：</p>
<p>:loadview</p>
<p><strong>其他折叠方式及相关命令见vim doc</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>vim贪婪匹配与非贪婪匹配</title>
    <url>/2015/05/07/vim%E8%B4%AA%E5%A9%AA%E5%8C%B9%E9%85%8D%E4%B8%8E%E9%9D%9E%E8%B4%AA%E5%A9%AA%E5%8C%B9%E9%85%8D/</url>
    <content><![CDATA[<a id="more"></a>
<p>贪婪匹配模式会尽可能多的匹配结果，非贪婪模式则相反，尽可能少的去匹配。</p>
<p>以下这些为贪婪匹配,参见:help /\{</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\\&#123;n,m&#125; Matches n to m <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> many <span class="keyword">as</span> possible</span><br><span class="line">\\&#123;n&#125; Matches n <span class="keyword">of</span> the preceding atom</span><br><span class="line">\\&#123;n,&#125; Matches at least n <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> many <span class="keyword">as</span> possible </span><br><span class="line">\\&#123;,m&#125; Matches <span class="number">0</span> to m <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> many <span class="keyword">as</span> possible</span><br><span class="line">\\&#123;&#125; Matches <span class="number">0</span> or more <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> many <span class="keyword">as</span> possible (like *)</span><br></pre></td></tr></table></figure>

<p>以下这些为非贪婪匹配,参见:hep /\{-</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">\\&#123;-n,m&#125; matches n to m <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> few <span class="keyword">as</span> possible</span><br><span class="line">\\&#123;-n&#125; matches n <span class="keyword">of</span> the preceding atom </span><br><span class="line">\\&#123;-n,&#125; matches at least n <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> few <span class="keyword">as</span> possible</span><br><span class="line">\\&#123;-,m&#125; matches <span class="number">0</span> to m <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> few <span class="keyword">as</span> possible</span><br><span class="line">\\&#123;-&#125; matches <span class="number">0</span> or more <span class="keyword">of</span> the preceding atom, <span class="keyword">as</span> few <span class="keyword">as</span> possible</span><br></pre></td></tr></table></figure>

<p>因此*<em>.\{-}可以实现.<em>的非贪婪匹配，.\{-1,}可以实现.+的非贪婪匹配</em></em></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualBox:客户机FreeBSD 7.2时间严重漂移、跑慢问题</title>
    <url>/2009/06/23/virtualbox-freebsd-timekeeping/</url>
    <content><![CDATA[<a id="more"></a>
<p>一直琢磨着抽空再玩玩FreeBSD,第一次接触FreeBSD是6.0-Release,距现在时间不短了。</p>
<p>前几天有点儿时间，在windows 2003 R2 x86服务器上的VirualBox 2.2.4里面开始安装最新的FreeBSD 7.2 AMD64 Release。安装也还算顺利，毕竟原来接触过，熟悉了他的分区规则概念slice和partition就没啥大的障碍了。这次装FreeBSD要好好的研究一下，以后在FreeBSD里面host个网站，FreeBSD毕竟是TCP/IP的发源地，其稳定性也是有目共睹的。</p>
<p>因为有在VirtualBox里面安装Debian的经验，特别关注了一下客户机的时间，果然客户机的时间走的特别慢，没多久就与Host差了几分钟，而且可以看到时间差在明显的拉大。系统时间的准确性对于服务器来讲还是比较重要的，cron守护程序，网络日志等都严重依赖于系统时间。因为在客户机Debian使用的ntpd来校对系统时间，运行很正常，也在这里如法炮制吧，在运行ntpd之前也用ntpdate同步了几次时间。但是，为什么又是”但是”。<br>ntpd看样子很正常，但是Guest系统时间依旧比Host慢一拍,差距眼看着在拉大。当时实在是搞不清怎么回事了，google了一下也没找到满意答案，就暂时放下了。</p>
<p>今天连上FreeBSD一看，晕，时间都慢了一天多了，看来不解决时间是不行了。去google英文站搜，经过几轮筛选总算发现了一个有价值的信息：在FreeBSD的/boot/loader.conf文件里面增加一句kern.hz=100。赶快试验了一下，还真是这样,记得要重启一下guest。不用开ntpd时间也跑的很准确了。当然如果你要求很高可以继续开着ntpd。kern=100这几话怎么讲呢，<a href="http://cnsnap.cn.freebsd.org/doc/zh_CN.GB2312/books/handbook/virtualization-guest.html">官方</a>说是降低客户化FreeBSD的CPU使用率，难道是因为CPU使用率高导致部分时钟中断丢失造成时间跑慢吗？我还没想明白，谁明白这个原理给我留言解释一下吧，谢谢。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>FreeBSD</category>
      </categories>
      <tags>
        <tag>FreeBSD</tag>
        <tag>Virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title>virtualbox headless模式</title>
    <url>/2019/05/31/virtualbox-headless-mode/</url>
    <content><![CDATA[<a id="more"></a>
<p>以下示例中只有一台客户机，名称为”buster”，术语虚拟机等同于客户机</p>
<p>虚拟机列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ VBoxManage list vms</span><br><span class="line"><span class="string">&quot;buster&quot;</span> &#123;6c18ec7b-<span class="number">5730</span>-4e8e-a7d1-768dd0601be1&#125;</span><br></pre></td></tr></table></figure>

<p>无头模式启动虚拟机，自动进入后台模式</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ VBoxManage startvm buster --type headless</span><br><span class="line">Waiting <span class="keyword">for</span> VM <span class="string">&quot;buster&quot;</span> to power on...</span><br><span class="line">VM <span class="string">&quot;buster&quot;</span> has been successfully started.</span><br></pre></td></tr></table></figure>

<p>无头模式启动虚拟机，前台模式</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ VBoxHeadless -s buster</span><br><span class="line">Oracle VM VirtualBox Headless Interface <span class="number">6.0</span><span class="number">.8</span></span><br><span class="line">(C) <span class="number">2008</span>-<span class="number">2019</span> Oracle Corporation</span><br><span class="line">All rights reserved.</span><br></pre></td></tr></table></figure>

<p>正在运行的客户机列表</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ VBoxManage list runningvms</span><br><span class="line"><span class="string">&quot;buster&quot;</span> &#123;6c18ec7b-<span class="number">5730</span>-4e8e-a7d1-768dd0601be1&#125;</span><br></pre></td></tr></table></figure>

<p>关闭客户机电源</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ VBoxManage controlvm buster poweroff</span><br><span class="line"><span class="number">0</span>%..<span class="number">.10</span>%..<span class="number">.20</span>%..<span class="number">.30</span>%..<span class="number">.40</span>%..<span class="number">.50</span>%..<span class="number">.60</span>%..<span class="number">.70</span>%..<span class="number">.80</span>%..<span class="number">.90</span>%..<span class="number">.100</span>%</span><br></pre></td></tr></table></figure>

<p>使用VirtualBox图形界面也可以headless模式启动客户机，选择Start-&gt;Headless Start即可。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>VirtualBox虚拟硬盘VDI扩展容量(resize/expand capacity)</title>
    <url>/2009/07/11/virtualbox-vdi-resize/</url>
    <content><![CDATA[<p>虽然VirtualBox支持虚拟硬盘的动态扩展,也就是VDI文件的大小随着guest使用的容量而增大，但是动态扩展的上限就是你最初指定的虚拟硬盘的大小值。也许是因为心理的原因，这个值你指定的过小了，你使用了一段时间才会发现这个问题。我就是这样:(。但是很不幸，现在VirtualBox还没有提供改变虚拟硬盘大小上限的功能。其实安装guest时完全可以指定一个很大的值，毕竟它不会占用多余的硬盘空间，仅仅占用guest真正利用到的空间而已。但是问题已经出现了，重新来过显然太过麻烦了，办法还是有的。</p>
<a id="more"></a>
<p>最简单的办法也许就是给guest增加一块虚拟硬盘吧，这样最省时省力了。但是我真的不想再搞出一块硬盘来，虚拟机还是越简单越好。<br>那怎么办呢？答案就是用一块更大容量的虚拟硬盘来替换原来的虚拟硬盘，把原来的内容完整的clone到新的虚拟硬盘上来。这次不要吝啬了，把虚拟硬盘设置的大一点吧。resize之前记得备份一下guest,如果搞坏了别怪我没告诉你:) 下面就说一说具体的步骤。</p>
<ol>
<li><p> 为你的guest新增一块大容量的虚拟硬盘，并在guest的HDD设置里面把它挂在IDE的primary slave接口上，原来的硬盘一般应该在primary master上面，当然你也可以随便挂，但会影响到后面的硬盘编号。</p>
</li>
<li><p> 从<a href="http://gparted.sourceforge.net/">http://gparted.sourceforge.net/</a>下载GParted LiveCD,将下载的ISO文件挂载到guest的光驱上面，并且从光驱启动。简单的回车默认启动就可以了。</p>
</li>
<li><p>因为新硬盘是空的，必须将旧硬盘的MBR拷贝过来，这样才能正常启动。从虚拟机桌面上点击terminal启动X终端模拟器,可以输入fdisk -l来查看一下你的硬盘设备号，按上面的设置，旧硬盘应该是hda,而新硬盘是hdb。<br> dd if=/dev/hda of=/dev/hdb bs=512 count=1<br> 切记不要搞反了，否则旧硬盘的MBR就成空白了。dd是dataset definition的缩写,此命令来源于古老的IBM JCL(作业控制语言)，是一个底层I/O facility。MBR里面包含有分区表信息，这样拷贝以后新硬盘里面也有了一个和旧硬盘一般大小的分区，这是我们不需要的，删除掉先。<br> fdisk /dev/hdb,然后输入fdisk命令d也就是在Command (m for help):后面输入d就可以删除掉这个分区，然后输入fdisk命令w把改变写回硬盘，然后q退出。</p>
</li>
<li><p> 启动GParted程序。GParted会扫描到这两个硬盘。在旧硬盘hda的分区(我的是主分区hda1)上面右击选择copy,然后选择新硬盘hdb,在其上右击选择paste,并把目的分区拖到最大，起码我的guest只要一个主分区就可以了,如下图所示。最后点击apply进行真正的拷贝动作。耐心的等待一段时间。<a href="/images/2009/07/gparted.png"><img src="/images/2009/07/gparted-300x206.png" alt="gparted" title="gparted"></a></p>
</li>
<li><p> 在新硬盘的主分区hdb1上右击选择”manage flags”,为此分区添加boot标志，以便从该分区启动。</p>
</li>
<li><p> 从虚拟机设置里面为guest去掉cd rom，去掉旧的虚拟硬盘，把新虚拟硬盘挂载到IDE的Primary master上面，启动guest。第一次用新硬盘启动可能会遇到磁盘检查。<br>到此应该就OK了,以后新建guest的时候一定要把虚拟硬盘搞大一点，省的这么麻烦。</p>
</li>
</ol>
<hr>
<p>最后是广告时间：<br>GNU牌GParted Live CD实在是您居家旅行,打家劫舍,杀人越货之必备佳品:)</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title>virtualbox vmdk虚拟硬盘扩容</title>
    <url>/2016/10/28/virtualbox-vmdk-resize/</url>
    <content><![CDATA[<a id="more"></a>
<p>virtualbox的原生虚拟磁盘格式是vdi,也支持vmware的vmdk格式。virtualbox提供的工具vboxmanage支持vdi动态扩展磁盘的扩容。<br>对于vmdk格式可以先转换成vdi格式再行扩容，如果有必要扩容后可以转换回vmdk格式</p>
<p><strong>虚拟硬盘扩容</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vboxmanage clonehd <span class="string">&quot;source.vmdk&quot;</span> <span class="string">&quot;cloned.vdi&quot;</span> --format vdi</span><br><span class="line">$ vboxmanage modifyhd <span class="string">&quot;cloned.vdi&quot;</span> --resize <span class="number">20480</span></span><br><span class="line">$ vboxmanage clonehd <span class="string">&quot;cloned.vdi&quot;</span> <span class="string">&quot;resized.vmdk&quot;</span> --format vmdk <span class="comment">//如果需要转换回原格式</span></span><br></pre></td></tr></table></figure>

<p><strong>客户系统扩容</strong></p>
<p>上一个步骤只是扩展了虚拟磁盘的容量，客户操作系统还需要扩展分区才能利用新的容量。<br>linux客户系统可以使用GParted动态扩展分区<br>windows客户系统可以使用diskpart命令来扩展分区，但此命令不能扩展当前启动分区，如需扩展启动分区，可以用其他虚拟机启动，扩容后的磁盘作为附加磁盘。</p>
<p>然后运行cmd，执行diskpart</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&gt; list disk <span class="comment">// 查看磁盘</span></span><br><span class="line">cmd&gt; select disk <span class="number">1</span> <span class="comment">// disk后面的数值为扩容后磁盘的编号，从list disk中可以查到</span></span><br><span class="line">cmd&gt; list partition <span class="comment">// 查看磁盘分区</span></span><br><span class="line">cmd&gt; select partition <span class="number">0</span> <span class="comment">// 根据list partition的显示，将0替换成C盘对应的分区号</span></span><br><span class="line">cmd&gt; extend <span class="comment">// 扩容分区0</span></span><br></pre></td></tr></table></figure>


<p>Refereces:<br>[1]<a href="http://blog.csdn.net/bourne_again/article/details/8063907">VirtualBox扩容vmdk格式的Windows分区</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title>透过ssh使用VNC(VNC over SSH)</title>
    <url>/2012/03/27/vnc-over-ssh/</url>
    <content><![CDATA[<p>除了SSH,linux平台还可以使用图形化的方式访问远端机器,最流行的当属VNC</p>
<a id="more"></a>
<p>然而VNC连接并不安全,容易被拦截,监听,所以更安全的方式是透过SSH隧道来使用VNC,SSH的安全性是有保证的。</p>
<p>很简单,使用SSH做端口转发</p>
<p><strong>终端方式</strong></p>
<p>$ ssh -L 5900:localhost:5900 -N -f sshserver_ip_or_name</p>
<p>参数</p>
<p>-L [bind_address:]port:host:hostport 将本地主机(ssh客户端)的指定端口转发到远端主机的指定端口,-L 5900:localhost:5900具体是指将本地任意接口的5900端口转发到远端localhost接口的5900端口。VNC服务器的默认起始端口为5900,然后再加上display号,如果VNC服务器在0号display上监听,其监听端口为5900+0也就是5900,如果在1号display上监听,则其监听端口为5900+1也就是5901,以此类推。</p>
<p>-N 不执行远端命令。此SSH连接只做端口转发之用。</p>
<p>-f 将SSH放到后台执行</p>
<p>然后使用vnc viewer连接本地的5900端口即可</p>
<p>$vncviewer 127.0.0.1[:5900]</p>
<p><strong>图形方式</strong></p>
<p>ssvnc - Enhanced TightVNC viewer with SSL/SSH tunnel helper<br>ssvnc内置SSL/SSH支持,提供安全的VNC连接,详情见<a href="http://www.karlrunge.com/x11vnc/ssvnc.html">ssvnc官方</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>VPN技术简介</title>
    <url>/2012/10/15/vpn-intro/</url>
    <content><![CDATA[<p>VPN(Virtual Private Network)虚拟专用网络在公用网络上建立一个安全的加密通道,常用于企业分支机构之间的通讯,或个人远程接入企业内网。</p>
<a id="more"></a>
<p>VPN通过认证、加密的隧道携带用户数据通过公共网络来保证其安全性。<br>最常见的VPN技术有PPTP,L2TP/IPSec,IPSec,SSL VPN,OponVPN等。</p>
<p><strong>PPTP</strong><br>Point to Point Tunneling Protocol 点对点隧道协议</p>
<p>PPTP主要用于windows平台,PPTP本身并未包括认证和加密特性,PPTP属专有厂商协议,并不是IETF批准的国际标准,单独使用PPTP并无法保证其安全性。<br>PPTP只能用于IP网络。</p>
<p><strong>L2TP/IPSec</strong><br>Layer Two Tunneling Protocol 二层隧道协议</p>
<p>L2TP是IETF标准。L2TP自身并不对携带的数据加密,通常与IPSec搭配使用从而实现对数据的加密和完整性校验,这就是L2TP/IPSec的由来。L2TP可用于IP、ATM、帧中继、X.25等网络。<br>L2TP与PPTP一样使用PPP协议来封装携带的数据。L2TP支持隧道验证,PPTP则不支持。</p>
<p><strong>IPSec</strong><br>Internet Protocol Security IP安全</p>
<p>原始的IP协议并没有提供分组的安全性和完整性,两个端点之间的任何一跳都可以监听IP流量,而且可以伪造IP分组。IPSec工作于IP层,可以透明的为上层提供加密服务,其上层不用做任何修改即可享受到安全保障。IPv6强制使用IPSec。SSL/TLS则工作于传输层。</p>
<p>只使用IPSec即可以实现完整的VPN功能,支持net-to-net和road warrior模式,但主要用于类unix系统。L2TP/IPSec使用ppp协议,在复杂的NAT环境下实现road warrior更方便,而且其他平台的兼容性更好。</p>
<p><strong>SSL VPN</strong></p>
<p>SSL VPN则是在客户和web应用之间附加一个https通道,由SSL协议来认证用户和加密数据。SSL VPN一般是在企业网络内部放置一个SSL代理服务器,客户首先链接到SSL代理服务器,通过身份认证之后,SSL代理服务器会在客户和web应用之间传输数据。一般使用证书来认证客户端。</p>
<p>SSL VPN的优势在于部署简单,无需特别的客户端配置,只要使用浏览器即可,而且可以通过其他形式VPN传播的局域网病毒无法通过SSL VPN传播。</p>
<p>SSL VPN的缺点则是一般只适用于B/S模式的应用程序,并不是一个通用的VPN解决方案。</p>
<p><strong>OpenVPN</strong></p>
<p>OpenVPN则是一种混合型的VPN,并不与其他VPN兼容,也不是基于web的。它对自己的定义是“SSL/TLS based user-space VPN”。OpenVPN可以通过TAP/TUN驱动来创建二层/三层隧道。</p>
<p>OpenVPN使用通用网络协议（TCP与UDP）,而且所有的通信都基于一个单一的IP端口,使它成为IPsec等协议的理想替代，尤其是在ISP过滤某些特定VPN协议的情况下,比如可以使用80端口。</p>
<p>OpenVPN可以在NAT环境下很好的工作。</p>
<p>OpenVPN需要专用的客户端来接入OpenVPN虚拟网络,支持常见的各种系统平台,能在Solaris、Linux、OpenBSD、FreeBSD、NetBSD、Mac OS X与Windows 2000/XP/Vista/Windows 7以及Android上运行。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>vundle安装配置</title>
    <url>/2015/09/17/vundle-install-config/</url>
    <content><![CDATA[<a id="more"></a>
<p>Vundle接口发生了变化，配置不太一样了</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ git clone https:<span class="comment">//github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim</span></span><br></pre></td></tr></table></figure>

<p><strong>配置</strong></p>
<p>~/.vimrc文件添加:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span></span><br><span class="line"><span class="string">&quot; vundle</span></span><br><span class="line"><span class="string">&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">set nocompatible &quot;</span> be iMproved, required</span><br><span class="line">filetype off <span class="string">&quot; required</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;</span> set the runtime path to include Vundle and initialize</span><br><span class="line">set rtp+=~<span class="regexp">/.vim/</span>bundle/Vundle.vim</span><br><span class="line">call vundle#begin()</span><br><span class="line"><span class="string">&quot; alternatively, pass a path where Vundle should install plugins</span></span><br><span class="line"><span class="string">&quot;</span>call vundle#begin(<span class="string">&#x27;~/some/path/here&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot; let Vundle manage Vundle, required</span></span><br><span class="line"><span class="string">Plugin &#x27;VundleVim/Vundle.vim&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;</span> The following are examples <span class="keyword">of</span> different formats supported.</span><br><span class="line"><span class="string">&quot; Keep Plugin commands between vundle#begin/end.</span></span><br><span class="line"><span class="string">&quot;</span> plugin on GitHub repo</span><br><span class="line">Plugin <span class="string">&#x27;tpope/vim-fugitive&#x27;</span></span><br><span class="line"><span class="string">&quot; plugin from http://vim-scripts.org/vim/scripts.html</span></span><br><span class="line"><span class="string">Plugin &#x27;L9&#x27;</span></span><br><span class="line"><span class="string">&quot;</span> Git plugin not hosted on GitHub</span><br><span class="line">Plugin <span class="string">&#x27;git://git.wincent.com/command-t.git&#x27;</span></span><br><span class="line"><span class="string">&quot; git repos on your local machine (i.e. when working on your own plugin)</span></span><br><span class="line"><span class="string">Plugin &#x27;file:///home/gmarik/path/to/plugin&#x27;</span></span><br><span class="line"><span class="string">&quot;</span> The sparkup vim script is <span class="keyword">in</span> a subdirectory <span class="keyword">of</span> <span class="built_in">this</span> repo called vim.</span><br><span class="line"><span class="string">&quot; Pass the path to set the runtimepath properly.</span></span><br><span class="line"><span class="string">Plugin &#x27;rstacruz/sparkup&#x27;, &#123;&#x27;rtp&#x27;: &#x27;vim/&#x27;&#125;</span></span><br><span class="line"><span class="string">&quot;</span> Avoid a name conflict <span class="keyword">with</span> L9</span><br><span class="line">Plugin <span class="string">&#x27;user/L9&#x27;</span>, &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;newL9&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="string">&quot; All of your Plugins must be added before the following line</span></span><br><span class="line"><span class="string">call vundle#end() &quot;</span> required</span><br><span class="line">filetype plugin indent on <span class="string">&quot; required</span></span><br><span class="line"><span class="string">&quot;</span> To ignore plugin indent changes, instead use:</span><br><span class="line"><span class="string">&quot;filetype plugin on</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="string">&quot; Brief help</span></span><br><span class="line"><span class="string">&quot;</span> :PluginList - lists configured plugins</span><br><span class="line"><span class="string">&quot; :PluginInstall - installs plugins; append \`!\` to update or just :PluginUpdate</span></span><br><span class="line"><span class="string">&quot;</span> :PluginSearch foo - searches <span class="keyword">for</span> foo; append \<span class="string">`!\` to refresh local cache</span></span><br><span class="line"><span class="string">&quot; :PluginClean - confirms removal of unused plugins; append \`!\` to auto-approve removal</span></span><br><span class="line"><span class="string">&quot;</span></span><br><span class="line"><span class="string">&quot; see :h vundle for more details or wiki for FAQ</span></span><br><span class="line"><span class="string">&quot; Put your non-Plugin stuff after this line</span></span><br></pre></td></tr></table></figure>

<p><strong>用法</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:PluginList <span class="comment">// 列出.vimrc文件中配置的插件</span></span><br><span class="line">:PluginInstall <span class="comment">// 安装插件</span></span><br><span class="line">:PluginInstall! <span class="comment">// 跟新插件</span></span><br><span class="line">:PluginUpdate <span class="comment">//　更新插件</span></span><br><span class="line">:PluginSearch foo <span class="comment">// 搜索插件,后面附加!号刷新本地缓存</span></span><br><span class="line">:PluginClean <span class="comment">// 清理不使用的插件</span></span><br></pre></td></tr></table></figure>

<p><strong>命令行安装插件</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ vim +PluginInstall +qall</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://github.com/VundleVim/Vundle.vim">Vundle</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>CSS盒模型和定位模型</title>
    <url>/2013/11/25/w3c-box-layout/</url>
    <content><![CDATA[<a id="more"></a>
<h5 id="盒模型"><a href="#盒模型" class="headerlink" title="盒模型"></a>盒模型</h5><p>一图胜千言：<br><img src="/downloads/box-model.png" alt="box model"></p>
<p>HTML元素实际占据content部分，外围是padding填充，再往外是border边框，最外面为margin空白。<br>padding又叫内边距,margin又叫外边距。</p>
<p>可以这样想象CSS盒模型：</p>
<p>有一个存储货物的仓库，货物用纸箱包装起来，因为货物很贵重，所以在货物和纸箱之间我们要加一些泡沫填充材料。货物就是HTML元素，填充的塑料泡沫就是padding,而纸箱本身就是border。因为货物很贵重，不能将箱子直接叠放在一起，所以我们有了margin,也就是箱子与箱子之间的空白。</p>
<p>而这些padding,border,margin都是可以调整的，如果货物比较廉价，那就不用太在意，直接将货物堆放在一起就可以了，这时候padding,border和margin就都为零了。</p>
<h5 id="定位模型"><a href="#定位模型" class="headerlink" title="定位模型"></a>定位模型</h5><p>HTML文档默认采用流式布局。</p>
<p><strong>块元素(block)和行内元素(inline)</strong></p>
<p>所有的HTML标签都遵守CSS Box Model,都是盒子，但是在HTML的流式布局中分为两种显示类型。</p>
<p>一种是<strong>块元素</strong>(block)，比如div,p,h1等。这种元素在默认的流式布局中会独占一行，前后都会有断行符。</p>
<p>另一种是<strong>行内元素</strong>(inline),比如span,strong,input等。这种元素在在默认的流式布局只会占据必要的宽度，而且不会自动断行，会与其他行内元素和平共处，共享同一行(line box)。</p>
<p>可以使用水平方向的内边距(padding)、边框(border)和外边距(margin)调整行内元素的间距。但是，垂直方向内边距、边框和外边距不影响行内元素的高度。行的高度总是足以容纳它包含的所有内联元素，也可以通过设置行高增加这个行的高度。</p>
<p>HTML元素有默认的显示类型，block或inline。但可以通过使用display属性显式的更改它们的显示类型，比如将典型的块级元素div,设置为行内元素<br>[html]<br>div {display:inline;}<br>[/html]</p>
<p>如果将元素的display属性设置为none,则元素根本就不会显示。</p>
<h6 id="定位-position"><a href="#定位-position" class="headerlink" title="定位(position)"></a>定位(position)</h6><p>HTML元素可以有4种不同的定位类型,使用positon元素来进行定位。</p>
<ul>
<li>  <strong>static</strong><br>这是默认的定位类型。元素在正常文档流中布局，块级元素生成一个矩形框，作为文档流的一部分，行内元素则会存在于行内。<br>元素的top,bottom,left,right还有z-index属性都会被忽略。</li>
<li>  <strong>relative</strong><br>元素相对于其在正常文档流中的位置(这个元素为static定位方式所应该占据的位置)定位。元素在正常文档流中的位置会保留，元素生成框的位置由’top’, ‘right’, ‘bottom’和’left’属性和包含块决定。如果不指定这些影响定位的属性,那么relative看起来与static没有差别,其实还是有差别的,比如可以作为absolute定位元素的相对定位父元素,而static元素则不可。</li>
<li>  <strong>absolute</strong><br>元素从正常文档流中删除，不保留其位置。然后相对于第一个非static定位的父级元素(祖先)进行定位。从元素自身逐级上溯查找父级元素，直到找到第一个非static定位的元素，如果没有找到非static定位的父元素，则其定位相对于顶级容器元素(html in standards compliant mode; body in quirks rendering mode)body进行定位。但是absolute定位的元素会跟随定位的父元素移动。元素生成框的位置由’top’, ‘right’, ‘bottom’和’left’属性和包含块决定。</li>
</ul>
<p>如果不指定其位置属性(top,bottom等),则元素会跟随在上一个正常文档流(没有被删除的,包括保留位置的relative定位元素)的位置之后定位,但其宽度只能容纳其实际内容,不会自动伸展。</p>
<p>虽然绝对定位框有外边距，这些外边距不与其他外边距折叠(Collapse)。</p>
<ul>
<li>  <strong>fixed</strong><br>元素相对于浏览器窗口(screen’s viewport)定位，就是绝对定位,fixed定位的元素不会随浏览器窗口滚动而移动。元素生成框的位置由’top’, ‘right’, ‘bottom’和’left’属性和包含块决定。</li>
</ul>
<h6 id="浮动-float"><a href="#浮动-float" class="headerlink" title="浮动(float)"></a>浮动(float)</h6><p>浮动可以让某个元素脱离正常的文档流，漂浮在正常的文档流之外。浮动元素在正常文档流中的位置不会保留。浮动的设置有两个属性,float和clear。</p>
<p>float可以设置为left,right和none值，用于指定元素的浮动类型。</p>
<ul>
<li>  left<br>元素向左侧浮动</li>
<li>  right<br>元素向右侧浮动</li>
<li>  none<br>默认值。元素不浮动，并会显示在其在正常文档流中应该出现的位置。</li>
</ul>
<p>根据HTML代码中元素定义的顺序，如果浮动元素的上一个元素不是浮动的，则当前浮动元素紧随上一个非浮动元素的下一个元素位置(下一个元素的位置依据非浮动元素的显示类型而有所不同)处布局，根据float属性，靠左侧或右侧浮动。<br>如果浮动元素的上一个元素也是浮动元素，则当前浮动元素会紧随上一个元素在同一个行内进行浮动。</p>
<p>而clear则用于清除浮动,取值为left,right,both和none。</p>
<ul>
<li>  left<br>不允许左侧有浮动元素</li>
<li>  right<br>不允许右侧有浮动元素</li>
<li>  both<br>左右两侧均不允许有浮动元素</li>
<li>  none<br>默认值。允许两边都可以有浮动元素</li>
</ul>
<p>对于CSS的清除浮动(clear)，有一点要注意，清除浮动只能影响使用清除的元素本身，不能影响其他元素。也就是说，比如想让A浮动元素右侧的B浮动元素移动到下一行，应该设置B浮动元素的clear属性为left，而不是在A元素中设置clear属性为right。也就是不能通过一个元素的clear属性强迫另一个元素移动，只能通过clear属性让自己移动。</p>
<h6 id="z-index"><a href="#z-index" class="headerlink" title="z-index"></a>z-index</h6><p>CSS不但可以平面布局，还可以通过指定元素的堆叠次序来进行垂直布局(深度方向),这个属性就是z-index。(x,y)是平面，而z是垂直于平面的第三维。</p>
<p>只有非静态定位(static)的定位元素可以使用z-index属性，也就是只有position:absolute, position:relative, 或者position:fixed的元素可以使用z-index指定堆叠次序。</p>
<p><strong>box-sizing</strong></p>
<p>如果所有的浏览器都遵守W3C规范就不会有这个属性。不用看我,我说的就是你,低版本的IE!</p>
<p>CSS属性box-sizing用于更改默认的CSS盒模型来计算元素的宽度和高度。可以用这个属性来模拟没有正确支持CSS盒模型的浏览器。</p>
<p>这个属性的取值如下:</p>
<ul>
<li>  content-box<br>CSS标准默认值。元素的宽度和高度属性只包含content,不包含padding,border和margin,</li>
<li>  padding-box<br>元素的宽度和高度属性包含content和padding,但不包含border和margin。目前这个属性只有firefox支持。</li>
<li>  border-box<br>元素的宽度和高度属性包含content,padding和border,但不包含margin。这种盒模型只在IE的怪异模式(Quirks mode)下使用。<br>IE在版本6之前使用不规范的CSS盒模型,也就是现在所说的border-box,I6之后使用符合规范的CSS盒模型,但使用Quirks mode来支持之前的不规范盒模型,直到IE9。</li>
</ul>
<p>不推荐使用这个属性,保持其默认值即可。</p>
<p><strong>IE 10+才算是现代浏览器,之前的版本都应该被抛弃！</strong></p>
<p>参考:<br>1、<a href="http://www.w3schools.com/css/css_boxmodel.asp">CSS Box Model</a><br>2、<a href="http://www.w3schools.com/css/css_positioning.asp">CSS Positioning</a><br>3、<a href="http://www.w3schools.com/css/css_display_visibility.asp">CSS Display and Visibility</a><br>4、<a href="http://www.w3schools.com/cssref/pr_pos_z-index.asp">CSS z-index Property</a><br>5、<a href="http://www.kuqin.com/webpagedesign/20090106/32686.html">理解绝对定位和相对定位布局</a><br>5、<a href="http://developer.51cto.com/art/201303/386884.htm#585532-tsina-1-5185-7e393678b940a4d55500bf3feae3d2e9">CSS浮动(float,clear)经验分享</a><br>6、<a href="http://zh.html.net/tutorials/css/lesson15.php">用z-index进行层次堆叠</a><br>7、<a href="http://www.w3school.com.cn/css/pr_class_float.asp">CSS float 属性</a><br>8、<a href="http://www.w3school.com.cn/css/pr_class_clear.asp">CSS clear 属性</a><br>[9]<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/box-sizing">box-sizing</a><br>[10]<a href="http://www.w3school.com.cn/jsref/prop_style_display.asp">HTML DOM display 属性</a><br>[11]<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/position">position</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title>/var/www vs. /srv/www vs. /home/username/public_html</title>
    <url>/2011/05/08/web-document-root-dir/</url>
    <content><![CDATA[<p>website的document root目录到底应该放在什么位置?</p>
<a id="more"></a>
<p>先摘录FHS(Filesystem Hierarchy Standard) 2.3里面相关的部分:</p>
<p><strong>/srv</strong> contains site-specific data which is served by this system.</p>
<p>This main purpose of specifying this is so that users may find the location of the data files for particular service, and so that services which require a single tree for readonly data, writable data and scripts (such as cgi scripts) can be reasonably placed. Data that is only of interest to a specific user should go in that users’ home directory.</p>
<p>The methodology used to name subdirectories of /srv is unspecified as there is currently no consensus on how this should be done. One method for structuring data under /srv is by protocol, eg. ftp, rsync, www,and cvs. On large systems it can be useful to structure /srv by administrative context, such as /srv/physics/www, /srv/compsci/cvs, etc. This setup will differ from host to host. Therefore, no program should rely on a specific subdirectory structure of /srv existing or data necessarily being stored in /srv. However /srv should always exist on FHS compliant systems and should be used as the default location for such data.</p>
<p>Distributions must take care not to remove locally placed files in these directories without administrator permission.</p>
<p>FHS规定由本系统提供服务的站点相关的数据放置于/srv目录下,对/srv子目录则没有明确的规定，推荐按提供服务的协议来划分子目录, 比如web文档放置在/srv/www子目录下,其他比如/srv/ftp,/srv/rsync,/srv/cvs,/srv/git等等。所以如果遵循FHS规范的话，就应该将web document放置于/srv/www目录下。</p>
<p>再来看一下对于Apache默认使用的document root /var/www在FHS中是怎么说的。</p>
<p><strong>/var</strong> contains variable data files. This includes spool directories and files, administrative and logging data, and transient and temporary files.</p>
<p>Some portions of /var are not shareable between different systems. For instance, /var/log, /var/lock, and /var/run. Other portions may be shared, notably /var/mail, /var/cache/man, /var/cache/fonts, and /var/spool/news.</p>
<p>/var is specified here in order to make it possible to mount /usr read-only. Everything that once went into /usr that is written to during system operation (as opposed to installation and software maintenance) must be in /var.</p>
<p>If /var cannot be made a separate partition, it is often preferable to move /var out of the root partition and into the /usr partition. (This is sometimes done to reduce the size of the root partition or when space runs low in the root partition.) However, /var must not be linked to /usr because this makes separation of /usr and /var more difficult and is likely to create a naming conflict. Instead, link /var to /usr/var.</p>
<p>Applications must generally not add directories to the top level of /var. Such directories should only be added if they have some system-wide implication, and in consultation with the FHS mailing list.</p>
<p>/var目录用来存储经常变化的数据,这样使/usr文件系统可以以read-only的方式挂装，这很重要。显然document root并不是很适合放在/var/www目录下,web应用程序动态产生的cache数据倒是可以放置在/var/cache/www目录下。</p>
<p>再看web document root的另一个选择/home/username/public_html，可以在/home/username/下建一个符号链接www链接到public_html。如果系统中有很多用户，而每个用户有自己独立的站点，也就是虚拟主机，那么每个用户将web document root放置在/home/username/public_html目录下是很不错的选择，这样可以最大程度的减少不同用户之间的干扰。</p>
<p>无论web document root放置于哪个位置，只要设置合适的访问权限，其实效果都是完全一样的，无论安全性还是访问速度。</p>
]]></content>
      <categories>
        <category>Internet</category>
      </categories>
  </entry>
  <entry>
    <title>WebAssembly cwrap无法传递大字符串问题</title>
    <url>/2018/11/29/webassembly-cwrap-bigstring/</url>
    <content><![CDATA[<a id="more"></a>
<p>当用很大的字符串调用cwrap包装的wasm函数时，出现如下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Stack overflow! Attempted to allocate <span class="number">8588685</span> bytes on the stack, but stack has only <span class="number">5242877</span> bytes available!</span><br></pre></td></tr></table></figure>

<p>这是数据太大，把栈撑爆了。cwrap使用stack来传递临时数据，只能拷贝数据，不支持引用传递，不支持自动扩展，并且，stack上的数据是临时的，被调用的代码如果保存通过stack传递进来的指针以备后用，有可能会引用到无效的数据，这是不安全的。<br>所以这样来传递大量数据是不妥当的，应该使用WebAssembly模块的heap来传递这样的大字符串。</p>
<p>官方文档是这样说的：<br>cwrap uses the C stack for temporary values. If you pass a string then it is only “alive” until the call is complete. If the code being called saves the pointer to be used later, it may point to invalid data. If you need a string to live forever, you can create it, for example, using _malloc and stringToUTF8(). However, you must later delete it manually!</p>
<p>可以使用Module._malloc()和Module.stringToUTF8()函数通过heap来传递大量数据：<br>[cpp]<br>const bufferSize = Module.lengthBytesUTF8(veryLargeString) + 1;<br>const bufferPtr = Module._malloc(bufferSize);<br>Module.stringToUTF8(veryLargeString, bufferPtr, bufferSize);<br>const sample = Module.cwrap(‘sample’, null, [‘number’]); // not ‘string’, pointer is a number<br>sample(bufferPtr);<br>Module._free(bufferPtr);<br>[/cpp]</p>
<p>要注意Module.lengthBytesUTF8给出的长度并不包括空终结符，所以缓冲区大小要再加1。被调用的函数不再使用string类型的参数，而改用number类型，因为指针就是一个number。分配的缓冲区使用完之后记得要free掉，不然会造成内存泄露。</p>
<p>为了确保heap能自动增长，build模块时应该添加-s ALLOW_MEMORY_GROWTH=1参数，就不用害怕传递大型参数了。</p>
<p>还有一个更简洁的包装方法allocateUTF8可用，直接传递给它数据，它就可以将数据拷贝到堆上，并返回在heap上分配的空间地址，这样用：<br>[cpp]<br>const bufferPtr = allocateUTF8(veryLargeString);<br>const sample = Module.cwrap(‘sample’, null, [‘number’]); // not ‘string’, pointer is a number<br>sample(bufferPtr);<br>Module._free(bufferPtr);<br>[/cpp]</p>
<p>allocateUTF8的源代码：<br>[javascript]<br>// Allocate heap space for a JS string, and write it there.<br>// It is the responsibility of the caller to free() that memory.<br>function allocateUTF8(str) {<br> var size = lengthBytesUTF8(str) + 1;<br> var ret = _malloc(size);<br> if (ret) stringToUTF8Array(str, HEAP8, ret, size);<br> return ret;<br>}<br>[/javascript]</p>
<p>wasm模块可以从emscripten HEAP上返回字符串，只要给javascript传回一个空终结UTF8编码的字符串指针就可以了：</p>
<p>[javascript]<br>// Given a pointer ‘ptr’ to a null-terminated UTF8-encoded string in the emscripten HEAP, returns<br>// a copy of that string as a Javascript String object.</p>
<p>function UTF8ToString(ptr) {<br> return UTF8ArrayToString(HEAPU8,ptr);<br>}<br>[/javascript]</p>
<p><strong>最后</strong>：</p>
<p>其实stack和heap都分配自WebAssembly.memory对象，这是一个ArrayBuffer对象，可以使用不同的视图来存取。stack和heap的区别是使用和管理内存的方式不同。<br>调用instance.exports._malloc时是调用的是C/C++标准库的malloc函数，而emscripten实现的malloc函数正是在WebAssembly.memory上动态分配内存。</p>
<p>References:<br>[1]<a href="https://github.com/kripken/emscripten/issues/6860">Stack overflow error when large string passed</a><br>[2]<a href="https://github.com/kripken/emscripten/issues/4344">Automatically growing the stack</a></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
  </entry>
  <entry>
    <title>WebAssembly standalone模块示例</title>
    <url>/2018/11/27/webassembly-standalone%E6%A8%A1%E5%9D%97%E7%A4%BA%E4%BE%8B/</url>
    <content><![CDATA[<a id="more"></a>
<p>WebAssembly还是个很新鲜的玩意儿，ABI都还没稳定。<br>通常emscripten/emcc会产生厚厚的胶水代码来连接Javascript和wasm模块，通过import/export，Javascript和原生代码可以相互访问、调用，<br>除了简单数据类型，还可以通过memory和table来模拟指针、函数指针运算。<br>当前，emscripten/emcc已经支持生成standalone单独的wasm模块，无需胶水代码就可以简单使用标准的JS来访问wasm数据和代码，下面是一个简单的栗子：</p>
<p><strong>C代码</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">double buf\[<span class="number">1024</span>\];</span><br><span class="line"></span><br><span class="line">double* <span class="function"><span class="title">getOffset</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line"> <span class="keyword">return</span> buf;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">double <span class="function"><span class="title">add</span>(<span class="params">int count</span>)</span>&#123;</span><br><span class="line"> double sum = <span class="number">0.0</span>;</span><br><span class="line"> <span class="keyword">for</span>(int i=<span class="number">0</span>; i&lt;count; i++)&#123;</span><br><span class="line"> sum += buf\[i\];</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>add函数计算buf缓冲区中前count个浮点数之和，注意这里整个C代码没有任何其他库的依赖。</p>
<p><strong>编译成wasm</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ emcc add.c -Os -s WASM=<span class="number">1</span> -s <span class="string">&quot;EXPORTED_FUNCTIONS=\[&#x27;_add&#x27;, &#x27;_getOffset&#x27;\]&quot;</span> -s SIDE_MODULE=<span class="number">1</span> -o add.wasm</span><br></pre></td></tr></table></figure>

<p>-Os 编译优化选项会将所有用不到的代码去除掉，也不会包括任何标准库<br>-s WASM=1 指示生成wasm文件<br>-s “EXPORTED_FUNCTIONS=[‘_add’, ‘_getOffset’]“ 指示导出add和getOffset这个两个函数，导出标识符要用C的方式，C++语言的时候要注意名字碾压，导出的函数需要使用extern “C”修饰<br>-s SIDE_MODULE=1 指示生成wasm动态库</p>
<p>生成的add.wasm可以使用<a href="https://github.com/WebAssembly/wabt">wabt</a>(The WebAssembly Binary Toolkit)工具集中的命令wasm2wat转换为WebAssembly的wat/wast文本S-Express格式</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wasm2wat add.wasm</span><br><span class="line">(<span class="built_in">module</span></span><br><span class="line"> (type (;<span class="number">0</span>;) (func (result i32)))</span><br><span class="line"> (type (;<span class="number">1</span>;) (func (param i32) (result f64)))</span><br><span class="line"> (type (;<span class="number">2</span>;) (func))</span><br><span class="line"> (<span class="keyword">import</span> <span class="string">&quot;env&quot;</span> <span class="string">&quot;__memory_base&quot;</span> (<span class="built_in">global</span> (;<span class="number">0</span>;) i32))</span><br><span class="line"> (<span class="keyword">import</span> <span class="string">&quot;env&quot;</span> <span class="string">&quot;memory&quot;</span> (memory (;<span class="number">0</span>;) <span class="number">256</span>))</span><br><span class="line"> (func (;<span class="number">0</span>;) (type <span class="number">0</span>) (result i32)</span><br><span class="line"> get_global <span class="number">0</span>)</span><br><span class="line"> (func (;<span class="number">1</span>;) (type <span class="number">1</span>) (param i32) (result f64)</span><br><span class="line"> (local i32 f64)</span><br><span class="line"> get_local <span class="number">0</span></span><br><span class="line"> i32.const <span class="number">0</span></span><br><span class="line"> i32.gt_s</span><br><span class="line"> <span class="keyword">if</span> ;; label = @<span class="number">1</span></span><br><span class="line"> loop ;; label = @<span class="number">2</span></span><br><span class="line"> get_local <span class="number">2</span></span><br><span class="line"> get_global <span class="number">0</span></span><br><span class="line"> get_local <span class="number">1</span></span><br><span class="line"> i32.const <span class="number">3</span></span><br><span class="line"> i32.shl</span><br><span class="line"> i32.add</span><br><span class="line"> f64.load</span><br><span class="line"> f64.add</span><br><span class="line"> set_local <span class="number">2</span></span><br><span class="line"> get_local <span class="number">1</span></span><br><span class="line"> i32.const <span class="number">1</span></span><br><span class="line"> i32.add</span><br><span class="line"> tee_local <span class="number">1</span></span><br><span class="line"> get_local <span class="number">0</span></span><br><span class="line"> i32.ne</span><br><span class="line"> br_if <span class="number">0</span> (;@<span class="number">2</span>;)</span><br><span class="line"> end</span><br><span class="line"> end</span><br><span class="line"> get_local <span class="number">2</span>)</span><br><span class="line"> (func (;<span class="number">2</span>;) (type <span class="number">2</span>)</span><br><span class="line"> nop)</span><br><span class="line"> (func (;<span class="number">3</span>;) (type <span class="number">2</span>)</span><br><span class="line"> get_global <span class="number">0</span></span><br><span class="line"> i32.const -<span class="number">8192</span></span><br><span class="line"> i32.sub</span><br><span class="line"> set_global <span class="number">1</span></span><br><span class="line"> get_global <span class="number">1</span></span><br><span class="line"> i32.const <span class="number">5242880</span></span><br><span class="line"> i32.add</span><br><span class="line"> set_global <span class="number">2</span>)</span><br><span class="line"> (<span class="built_in">global</span> (;<span class="number">1</span>;) (mut i32) (i32.const <span class="number">0</span>))</span><br><span class="line"> (<span class="built_in">global</span> (;<span class="number">2</span>;) (mut i32) (i32.const <span class="number">0</span>))</span><br><span class="line"> (<span class="built_in">global</span> (;<span class="number">3</span>;) i32 (i32.const <span class="number">0</span>))</span><br><span class="line"> (<span class="keyword">export</span> <span class="string">&quot;__post_instantiate&quot;</span> (func <span class="number">3</span>))</span><br><span class="line"> (<span class="keyword">export</span> <span class="string">&quot;_add&quot;</span> (func <span class="number">1</span>))</span><br><span class="line"> (<span class="keyword">export</span> <span class="string">&quot;_getOffset&quot;</span> (func <span class="number">0</span>))</span><br><span class="line"> (<span class="keyword">export</span> <span class="string">&quot;runPostSets&quot;</span> (func <span class="number">2</span>))</span><br><span class="line"> (<span class="keyword">export</span> <span class="string">&quot;_buf&quot;</span> (<span class="built_in">global</span> <span class="number">3</span>)))</span><br></pre></td></tr></table></figure>

<p>可以看到add.wasm的import和export的各种东西global、func、memory，如果使用了函数指针还会有table<br>如果没用到memory，可以用wasm2wat将其转为wat/wast文本格式，将import memory相关去掉，<br>然后使用wat2wasm再编译回wasm格式就无需导入任何东西了。</p>
<p><strong>调用wasm</strong></p>
<p>写一个简单的页面来调用wasm代码：<br>[html]<br><!doctype html></p>
<html lang="en-us">
 <head>
 <meta charset="utf-8">
 <script>
 // Check for wasm support.
 if (!('WebAssembly' in window)) {
 alert('you need a browser with wasm support enabled :(');
 }
 // Loads a WebAssembly dynamic library, returns a promise.
 // imports is an optional imports object
 var importObj = {
 'env': {'__memory_base': 0, 
 'memory': new WebAssembly.Memory({initial: 256})
 // if used function pointer
 '__table_base': 0,
 'table': new WebAssembly.Table({ initial: 0, element: 'anyfunc' })
 }
 }
 WebAssembly.instantiateStreaming(fetch('add.wasm'), importObj)
 .then(obj => {
 var button = document.getElementById('run');
 button.value = 'Call a method in the WebAssembly module';
 var exports= obj.instance.exports;
 button.addEventListener('click', function() {
 var offset = exports._getOffset();
 var mem = new Float64Array(importObj.env.memory.buffer, offset , 2);
 //var mem = new Float64Array(importObj.env.memory.buffer, exports._buf , 2);
 mem\[0\] = 1.2;
 mem\[1\] = 2.4;
 alert('1.2 + 2.4 is ' + exports._add(2));
 }, false);
 });
 </script>
 </head>
 <body>
 <input type="button" id="run" value="(waiting for WebAssembly)"/>
 </body>
</html>
\[/html\]

<p>其实获取C代码缓冲区起始地址的getOffset并没有必要，因为wasm模块直接导出了缓冲器的标识符_buf，其实就是缓冲区的首地址<br>除了基本类型，JS和原生代码通过memory的buffer来交换大块的数据。</p>
<p><strong>访问</strong></p>
<p>需要起一个web server</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ python3 -m http.server <span class="number">8081</span></span><br></pre></td></tr></table></figure>

<p>然后访问<a href="http://127.0.0.1:8081/add.html%EF%BC%8C%E7%82%B9%E5%87%BB%E6%8C%89%E9%92%AE%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0JS%E8%B0%83%E7%94%A8WASM%E4%B8%AD%E7%9A%84routine%E7%84%B6%E5%90%8E%E8%BF%94%E5%9B%9E%E4%BA%86%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C%E3%80%82">http://127.0.0.1:8081/add.html，点击按钮可以看到JS调用WASM中的routine然后返回了计算结果。</a></p>
<p><strong>最后</strong></p>
<p>如果WASM模块依赖于其他库代码，目前还无法生成standalone模块，需要生成胶水js代码来访问。</p>
<p>另外，tableBase和memoryBase已经更名为__table_base和__memory_base</p>
<p>References:<br>[1]<a href="https://github.com/kripken/emscripten/wiki/WebAssembly-Standalone">WebAssembly Standalone</a><br>[2]<a href="https://stackoverflow.com/questions/41653792/disable-linking-libc-in-emscripten/41871785">Disable linking libc in emscripten</a><br>[3]<a href="https://github.com/kripken/emscripten/pull/7467/commits/74ec83aec8227c55c1431411ceed15e3585ddff5">Rename tableBase/memoryBase to __table_base/__memory_base</a><br>[4]<a href="https://github.com/WebAssembly/tool-conventions/blob/master/DynamicLinking.md">WebAssembly Dynamic Linking</a><br>[5]<a href="https://stackoverflow.com/questions/46748572/how-to-access-webassembly-linear-memory-from-c-c">How to access WebAssembly linear memory from C/C++</a></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
  </entry>
  <entry>
    <title>wheel和staff用户组</title>
    <url>/2014/04/19/wheel-and-staff-group/</url>
    <content><![CDATA[<a id="more"></a>
<p>传统unix系统中,wheel用户组是管理员组，只有该组的成员才可以通过su获取root权限。当然要对该组做特殊设置才可以做到这些限制。<br>wheel实际上已经成了管理员组的代名词。</p>
<p><strong>配置wheel用户组</strong></p>
<p>编辑文件<br>/etc/pam.d/su</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#root使用su命令不需要密码</span><br><span class="line">auth sufficient pam_rootok.so</span><br><span class="line">#用户只有是wheel组的成员才可以su切换到root权限，如果不指定group=wheel,则默认的管理员组为root。</span><br><span class="line">#这样设置有一个副作用，root用户也必须成为管理员成员或者显式的允许root不需要密码使用su</span><br><span class="line">#这一行设置替代了/etc/login.defs文件中的SU_WHEEL_ONLY选项</span><br><span class="line">auth required pam_wheel.so group=wheel</span><br><span class="line">#管理员组的成员可以不用密码使用su</span><br><span class="line">auth required pam_wheel.so trust</span><br><span class="line">#nosu组的成员不允许使用su</span><br><span class="line">auth required pam_wheel.so deny group=nosu</span><br></pre></td></tr></table></figure>

<p><strong>staff用户组</strong></p>
<p>staff就是系统全体用户，所有的系统用户都是staff组的成员,因此改变的文件的组权限为staff则所有的用户都具有了相应的权限。</p>
<p>References:<br>[1]<a href="http://www.cnblogs.com/jan5/p/3359421.html">Linux 中的 wheel 组和 staff 组</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>while read line无法读取最后一行的问题</title>
    <url>/2014/08/02/while-read-line-last-line/</url>
    <content><![CDATA[<a id="more"></a>
<p>while read line读取文件时，如果文件最后一行之后没有换行符\n,则read读取最后一行时遇到文件结束符EOF,循环终止,虽然此时$line内存有最后一行,但程序已经没有机会再处理此行,因此可以通过以下代码来解决此问题:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> read line \[\[ -n $&#123;line&#125; \]\]; <span class="keyword">do</span></span><br><span class="line">...</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>这样当文件没有结束时不会测试-n $line,当遇到文件结束时,仍然可以通过测试$line是否有内容来进行继续处理。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title>window.open与弹出窗口阻止</title>
    <url>/2015/05/08/window-open-and-block/</url>
    <content><![CDATA[<a id="more"></a>
<p>由于恶意的自动弹出各种小广告窗口实在过于泛滥，因此各浏览器平台默认都是阻止自动弹出新窗口的。but,如果用户主动点击打开新窗口，那么再进行阻止就有些不合情理了。so,用户主动触发的弹出新窗口不会被阻止,如果是代码自动触发则不会如此幸运了。</p>
<p>各大浏览器的默认阻止策略见参考[1]，因此如果不想弹出的新窗口被浏览器阻止，可以这样来:</p>
<p>当然最简单就是直接写在元素的onclick事件里，当用户点击时就可以弹出了。</p>
<p>再进一步，可以搞一个隐藏按钮,其click事件为弹出新窗口,然后在另一个用户动作事件中，处理完其他事务后，用javascript调用隐藏窗口的click事件，这样也是可以的。但是就算这样，用setTimeout自动触发也是不行的，也就是必须要在一个用户触发的上下文里弹出窗口才不会被阻止。</p>
<p>用户触发上下文中，调用ajax请求，在ajax的回调函数中打开新窗口时，各个浏览器的反应各有不同，chrome是允许的，而firefox则进行了拦截。这是可以在ajax请求前先弹出空白窗口，ajax请求之后再设置window.location为想要的URL。</p>
<p>References:<br>[1]<a href="http://lingyi.red/window-open-and-the-browser-to-block-pop-up-window">window.open() 与浏览器阻止弹出窗口</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>windows 2003 远程桌面安全策略</title>
    <url>/2013/01/17/windows-2003-rdp-security/</url>
    <content><![CDATA[<p>windows的远程桌面虽然用起来比较方便,但其安全性和资源占用比起SSH还是有不少的差距。</p>
<a id="more"></a>
<p>想到的安全策略有一下几个:</p>
<p><strong>1、更改默认端口号</strong></p>
<p>终端服务默认使用知名端口号3389,很显然大家都知道这个端口是做什么的,所以改端口号可以躲过很多的机器扫描。可以从终端服务本机上修改默认端口号,如果有防火墙做NAT,那更简单了,NAT后的端口号别用3389就是了。</p>
<p><strong>2、设置复杂密码</strong></p>
<p>现在的GPU处理能力十分恐怖,所以密码位数少了就不安全了,大小写字母和数字组合的12位密码目前还基本够用。远程桌面竟然不支持CA证书验证登录,这点不如SSH了。SSH设置成2048位RSA证书登录,禁止口令登录,禁止root登录,就相当的安全了。</p>
<p><strong>3、限制登录尝试次数</strong></p>
<p>修改组策略,”计算机配置-&gt;windows设置-&gt;安全设置-&gt;账户策略-&gt;账户锁定策略”,”账户锁定阈值”设置为10,也就是10次无效登录后就封锁对方IP,禁止其在一段时间内继续尝试登录。”账户锁定时间”就是无效登录后多久才可以继续尝试登录。”复位账户锁定计数器”设置多长时间后复位”账户锁定阈值”,必须小于等于”账户锁定时间”。</p>
<p><strong>4、禁止administrator用户远程桌面登录</strong></p>
<p>administrator实在是太扎眼了,可以禁止其远程桌面登录,另设立一个管理员账户来执行远程登录任务,这样用户名和密码的组合就更复杂了,爆破的难度大大加大。<br>双击”计算机配置-&gt;Windows设置-&gt;安全设置-&gt;本地策略-&gt;用户权限分配-&gt;通过终端服务允许登录”,将Administrators账号删除掉,加入另设立的管理员账户即可。</p>
<p><strong>5、加密远程桌面连接</strong></p>
<p>默认情形下,远程桌面的数据链接是不加密的,十分危险有木有,容易被监听有木有。2003以后的windows版本可以使用SSL来加密远程桌面连接。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>windows 8.1 64位系统python3访问mdb数据库</title>
    <url>/2013/11/12/windows-8-1-64bits-python3-access-mdb/</url>
    <content><![CDATA[<p>RT</p>
<a id="more"></a>
<p>有一个小的桌面辅助工具必须要从windows平台运行，因为要转换的数据和使用这个桌面辅助工具的部门使用windows。<br>打算用python3来做这个转换工具，GUI使用python内建支持的事实标准<a href="https://wiki.python.org/moin/TkInter">TkInter</a><br>so,有了这篇post。</p>
<p>翻出windows本，其上的系统为8.1 64 bits。<br>首先需要access database engine,从M$官方下载<a href="http://www.microsoft.com/zh-cn/download/details.aspx?id=13255">Microsoft Access 2010 数据库引擎可再发行程序包</a>,选择下载AccessDatabaseEngine_X64.exe</p>
<p>安装不表。</p>
<p>windows 64 bits平台上mdb驱动的准确名字为:<br>[html]<br>Microsoft Access Driver (*.mdb, *.accdb)<br>[/html]<br>在python3中使用时必须分毫不差。</p>
<p>可以使用<a href="http://www.alexnolan.net/software/mdb_viewer_plus.htm">MDB Viewer Plus</a>查看mdb数据库的结构，这软件不开源，但free。没必要为了简单的查看mdb去买套office suite。</p>
<p>仍然使用pypyodbc和pyodbc做了简单测试。</p>
<p>这次pypyodbc表现不错，正确读取数据库中的中文字段，但是pyodbc则崩溃了</p>
<blockquote>
<blockquote>
<blockquote>
<p>import pyodbc<br>conn=pyodbc.connect(‘Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Record.mdb’)<br>s1=conn.cursor().execute(“SELECT * FROM Build”).fetchone()[0]<br>Traceback (most recent call last):<br> File “”, line 1, in<br> s1=conn.cursor().execute(“SELECT * FROM Build”).fetchone()[0]<br>UnicodeDecodeError: ‘utf-8’ codec can’t decode byte 0xb7 in position 2: invalid start byte<br>还是因为字符编码的问题,windows内码转到到UTF8出现了问题。</p>
</blockquote>
</blockquote>
</blockquote>
<p>pypyodbc则正确的读取转换了中文字段。python3安装到了Program Files目录，安装pypyodbc时需要提供管理员权限。</p>
<p>pypyodbc还为windows平台提供了一些特有的函数，比如连接mdb数据库可以这样写:</p>
<blockquote>
<blockquote>
<blockquote>
<p>import pypyodbc<br>conn=pypyodbc.win_connect_mdb(‘C:\\Record.mdb’)</p>
</blockquote>
</blockquote>
</blockquote>
<p>创建mdb用win_create_mdb函数</p>
<p>注意这些函数是不可移植的。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>windows添加永久静态路由</title>
    <url>/2013/01/21/windows-add-persistent-route/</url>
    <content><![CDATA[<p>windows添加永久静态路由</p>
<a id="more"></a>
<p>route命令有一个 -p 参数,将路由表项永久加入系统注册表,p即persistent</p>
<p>cmd命令行下:</p>
<p>cmd&gt; route -p add 10.100.0.0 mask 255.255.255.0 192.168.5.1 if 3<br>为网络10.100.0.0/24添加路由表项,网关为192.168.5.1,网络设备接口为3,可以从route print输出看到网络设备接口号,还可以指定跃点数metric</p>
<p>cmd&gt; route print<br>Persistent Routes就会显示该条路由表项,重新启动机器亦不受影响。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>windows L2TP/IPSec 预共享密钥VPN客户端连接设置</title>
    <url>/2012/10/20/windows-l2tp-ipsec-vpn-client/</url>
    <content><![CDATA[<p>windows系统自带L2TP/IPSec客户端</p>
<a id="more"></a>
<p><strong>新建VPN连接</strong></p>
<p>开始-程序-附件-通讯-新建连接向导, 选择“连接到我的工作场所的网络”,继续选择“虚拟专用网络连接”,输入连接名称，随便起个名字即可。<br>然后选择“不拨初始连接”,这样VPN拨号前需要先连接到互联网。然后下一步数据VPN服务器的IP地址或域名,完成新建连接向导。</p>
<p>打开新建的连接,点击“属性”,打开“安全”页签,选择“高级”,点”设置”,数据加密选择“可选加密(没有加密也可以连接)”,“允许这些协议”至少要选择”Microsoft CHAP 版本2(MS-CHAP v2)”。<br>回到“安全”页签,点击”IPSec设置”,输入共享密钥。</p>
<p>选择“网络”标签页，VPN类型选择为“L2TP IPSec VPN”。</p>
<p>然后在连接界面输入用户名和密码连接即可。</p>
<p><strong>NAT后面的L2TP/IPSec服务器</strong></p>
<p>windows默认不允许连接到NAT设备后面的L2TP/IPSec服务器,拨号时会出现错误“错误809:无法建立计算机与 VPN 服务器之间的网络连接，因为远程服务器未响应。”<br>如果要访问这样的服务器,需要修改注册表：</p>
<p>HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\IPSec下面新建DWORD项AssumeUDPEncapsulationContextOnSendRule,修改其值为”2”,重新启动计算机。</p>
<p><strong>VPN拨号错误</strong></p>
<p>“错误789:L2TP链接尝试失败,因为安全层在初始化与远程计算的协商时遇到一个错误。”</p>
<p>解决办法：注册表键HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\Rasman\Parameters下新建DWORD项ProhibitIpSec,修改其值为”1”。重新启动计算机。<br>ProhibitIpSec 注册表值设置为 1 时，基于 Windows 2000 的计算机不会创建使用 CA 身份验证的自动筛选器，而是检查本地 IPSec 策略或 Active Directory IPSec 策略。</p>
<p><strong>VPN拨号路由设置</strong></p>
<p>VPN拨号后默认会添加一条默认路由,默认网关指向对端地址,如果对端不转发数据包,则客户端无法访问互联网,就算转发,通过VPN服务器访问互联网效率也比较低下。</p>
<p>可以通过禁止VPN连接添加默认路由,手动修改路由表,以便只有必要的流量通过VPN,其他流量走正常的路径。</p>
<p>打开VPN连接,点击“属性”,选择“网络”页签,选中“Internet协议（TCP/IP）”,点击“属性”,继续点击”高级”,在“常规”页签中,不要选择”在远程网络上使用默认网关”,确定后关闭打开的窗口。</p>
<p>拨号成功后查看本地分配的IP地址,比如为10.100.0.2,然后添加用于VPN网络的静态路由</p>
<p>cmd&gt;route add 10.100.0.0 mask 255.255.255.0 10.100.0.2<br>这样VPN网络和互联网可以互不影响。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>windows平台samba共享无需密码访问设置</title>
    <url>/2013/01/16/windows-samba-nopasswd/</url>
    <content><![CDATA[<p>无需密码访问共享某些环境下还是很方便的。</p>
<a id="more"></a>
<p>设置如下:<br>1、打开guest账户</p>
<p>本地用户和组-&gt;用户-&gt;guest,取消选择”账户已禁用”</p>
<p>2、用户权限分配</p>
<p>本地策略-&gt;用户权限分配-&gt;拒绝从网络访问这台计算机,去掉guest用户</p>
<p>3、共享和安全模式</p>
<p>本地策略-&gt;安全选项-&gt;”网络访问：本地账户的共享和安全模式”设置为“仅来宾-本地 用户以来宾方式认证”。</p>
<p>4、文件夹和共享权限</p>
<p>要共享的文件夹,”属性-&gt;安全”页添加Everyone用户,读写或只读权限,”属性-&gt;共享-&gt;权限”页添加Everyone用户,读写或只读权限</p>
<p>这样其他机器访问此机器共享就可以不用输入用户名和密码,直接访问了。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>windows平台用VIM浏览编辑jar文件</title>
    <url>/2011/03/17/windows-vim-jar/</url>
    <content><![CDATA[<p>windows系统下面用Vim编辑Echofon.jar时，VIM提示错误“**<em>error**</em> (zip#Browse) unzip not available on your system”，</p>
<a id="more"></a>
<p>这是因为没有找到unzip程序导致zip.vim报告的错误，zip.vim是用来支持vim浏览、处理zip格式文件的，而jar正是使用zip格式打包的。</p>
<p>去<a href="http://www.info-zip.org/">info-zip</a>网站下载windows 32位版本的<a href="ftp://ftp.info-zip.org/pub/infozip/win32/unz600xn.exe">unzip</a>,这是自解压文件，解压后将unzip.exe放入$PATH路径中,重新用Vim打开jar文件就没问题了。</p>
<p>但是如果编辑了jar里面的文件后要保存的话，vim又会提示“**<em>error**</em> (zip#Write) sorry,your system doesn’t appear to have the zip pgm”，这是因为zip.vim没有找到zip程序，还是从info-zip下载<a href="ftp://ftp.info-zip.org/pub/infozip/win32/zip300xn.zip">zip</a>,解压缩后将zip.exe放入$PATH路径中，vim保存jar内修改的文件就没问题了。</p>
]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title>windows x64平台部署32位asp程序及连接oracle 10g数据库</title>
    <url>/2011/05/16/windows-x64-32bits-webapp-connect-to-oracle10g/</url>
    <content><![CDATA[<p>32位asp程序在x64平台上的安装以及连接oracle 10g数据库的若干问题记录</p>
<a id="more"></a>
<p>业务系统应用组件仍然是在32位windows平台上运行的,后端数据库oracle 10g已经在64位平台上运行。新的服务器硬件配置很高,再安装32位的windows实在是太浪费资源了。</p>
<p>windows 2003 x64 r2上的iis6支持在32位模式下运行asp程序,只需执行一下指令打开此模式即可</p>
<p>cmd&gt;cscript.exe %SYSTEMDRIVE%\inetpub\adminscripts\adsutil.vbs SET W3SVC/AppPools/Enable32bitAppOnWin64 1</p>
<p>这样就可以像32位平台一样来部署asp应用了,此时32位asp应用程序运行在WOW64模拟环境下。</p>
<p>但是这种模式下32位应用程序访问oracle 10g数据库就要注意了,经过多次实验,总结如下：<br>x64平台下的32位应用程序要访问oracle 10g数据库,只能安装32位版本的oracle 10g或其他版本32位客户端，如果在本机安装服务器端也只能安装32位的oracle 10g服务器。</p>
<p>原因有二：其一，32位应用的程序的注册表被重定向到了Wow6432Node节点下,所以32位应用程序无法访问到64位oracle客户端或者服务器的注册表内容。其次，x64平台上，32位进程不能加载64位Dll，64位进程也不可以加载32位Dll。也就是说，就算能从注册表里能找到64位oracle客户端或服务器的信息，但是仍然无法将其加载，也就无法连接访问。</p>
<p>如果在两台机器之间访问oracle服务则几乎没有任何限制,两边的客户端和服务器端可以跨异构异质平台，因为TCP是天然跨平台的。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>windows x64函数调用约定(function call convention)</title>
    <url>/2009/12/28/windows-x64-function-call-convention/</url>
    <content><![CDATA[<p>　　借PC处理器架构由x86向x64过渡之机，MS清理了windows x64平台上的函数调用约定，由原来的数种包括stdcall,thiscall,fastcall,cdecl,pascal等，统一为一种新的fastcall调用方式。这种调用方式得益于x64平台寄存器数量的增加。<br>　　<br>　　windows x64平台fastcall调用约定的主要特性如下：</p>
<ul>
<li>  前四个整型或指针类型参数由RCX,RDX,R8,R9依次传递，前四个浮点类型参数由XMM0,XMM1,XMM2,XMM3依次传递。</li>
<li>  调用函数为前四个参数在调用栈上保留相应的空间，称作shadow space或spill slot。即使被调用方没有或小于4个参数，调用函数仍然保留那么多的栈空间，这有助于在某些特殊情况下简化调用约定。</li>
<li>  除前四个参数以外的任何其他参数通过栈来传递，从右至左依次入栈。</li>
<li>  由调用函数负责清理调用栈。</li>
<li>  小于等于64位的整型或指针类型返回值由RAX传递。</li>
<li>  浮点返回值由XMM0传递。</li>
<li>  更大的返回值(比如结构体)，由调用方在栈上分配空间，并有RCX持有该空间的指针并传递给被调用函数，因此整型参数使用的寄存器依次右移一格，实际只可以利用3个寄存器，其余参数入栈。函数调用结束后，RAX返回该空间的指针。</li>
<li>  除RCX,RDX,R8,R9以外，RAX、R10、R11、XMM4 和 XMM5也是易变化的(volatile)寄存器。</li>
<li>  RBX, RBP, RDI, RSI, R12, R13, R14, and R15寄存器则必须在使用时进行保护。</li>
<li>  在寄存器中，所有参数都是右对齐的。小于64位的参数并不进行高位零扩展，也就是高位是无法预测的垃圾数据。</li>
</ul>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>wine中文字体链接</title>
    <url>/2018/07/19/wine-fonts-link/</url>
    <content><![CDATA[<a id="more"></a>
<p><strong>字体链接</strong></p>
<p>M$的字体是专有的，有版权的，因此应该使用开源字体。</p>
<p>Windows支持字体链接：当一种字体中不存在某个字时，可以尝试从另一个字体文件中寻找相应的字形。所以只要把当前系统中的中文字体设为”fallback”字体，汉字通常就能正确显示了。方法也很简单，只需创建一个文本文件，如chn_font.reg如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">REGEDIT4</span><br><span class="line"> </span><br><span class="line">\[HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows NT\\CurrentVersion\\FontLink\\SystemLink\]</span><br><span class="line"><span class="string">&quot;Lucida Sans Unicode&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;Microsoft Sans Serif&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;MS Sans Serif&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;Tahoma&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;Tahoma Bold&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;SimSun&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;Arial&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br><span class="line"><span class="string">&quot;Arial Black&quot;</span>=<span class="string">&quot;wqy-microhei.ttc&quot;</span></span><br></pre></td></tr></table></figure>

<p>注意请将wqy-microhei.ttc替换为你系统中的字体文件名，如文泉驿正黑是wqy-zenhei.ttc（请在/usr/share/fonts及其子文件夹中寻找相应字体文件）。<br>MacOSX上可以使用PingFang.ttc。</p>
<p>如果想使用其它字体，也可直接将相应的ttf或ttc文件复制到~/.wine/drive_c/windows/Fonts/，再用其文件名替换上面的wqy-zenhei.ttc即可。</p>
<p>最后，打开注册表wine regedit，导入上面的注册表文件即可。中文应该都能完美显示了（包括Picasa中文显示为方框、软件安装程序汉字无法显示等问题均可被解决）。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wine regedit chn_font.reg</span><br></pre></td></tr></table></figure>

<p>注意上面的注册表键值只能使用字体的文件名，而不能使用字体名，这是由“字体链接”本身的特性决定的。</p>
<p>References:<br>[1]<a href="http://linux-wiki.cn/wiki/%E8%AE%BE%E7%BD%AEwine%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%AD%97%E4%BD%93">Wine的中文显示与字体设置</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>wine QQ</title>
    <url>/2016/01/27/wine-qq/</url>
    <content><![CDATA[<a id="more"></a>
<p>这次又试了一下wine安装QQ,发现wine已今非昔比，已堪大用。</p>
<p><strong>添加i386架构</strong></p>
<p>因为debian早已是mutiarch架构，所以添加intel子架构i386是很简单的:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo dpkg --add-architecture i386</span><br></pre></td></tr></table></figure>

<p><strong>安装wine</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install wine wine64 wine32</span><br></pre></td></tr></table></figure>

<p><strong>安装cabextract</strong></p>
<p>因为下面的安装会下载cab格式文件并解压缩安装，所以需要安装cabextract包</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install cabextract</span><br></pre></td></tr></table></figure>

<p><strong>安装winetricks-zh</strong><br>这是大名顶顶的winetricks的修改版，支持常见的一些中文windows应用。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ cd ~</span><br><span class="line">$ git clone https:<span class="comment">//github.com/hillwoodroc/winetricks-zh.git</span></span><br><span class="line">$ cd winetricks-zh</span><br><span class="line">$ sudo cp winetricks-zh /usr/local/bin</span><br><span class="line">$ cd verb</span><br></pre></td></tr></table></figure>

<p><strong>安装QQ轻聊版(QQLight)</strong></p>
<p>确认位于下载的winetricks-zh的子目录verb中,执行:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ winetricks-zh qqlight</span><br></pre></td></tr></table></figure>
<p>会下载很多东西，耐心等待安装完成</p>
<p><strong>菜单项小问题</strong><br>默认生成的桌面菜单项是~/.local/share/applications/wine/Programs/腾讯软件/QQ轻聊版/QQ轻聊版.desktop，打开此文件可以发现Exec项的可执行文件路径有问题，修正为如下:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Exec=env WINEPREFIX=<span class="regexp">/home/gu</span>oqiang/.local/share/wineprefixes/qqlight wine <span class="string">&quot;C:\\Program Files (x86)\\Tencent\\QQLite\\Bin\\QQScLauncher.exe&quot;</span></span><br></pre></td></tr></table></figure>
<p>可正常执行QQ轻聊版。</p>
<p>经简单试用发现十分稳定。wine进步真的很大。</p>
<p>**注:**如果QQ文本输入框内输入的中文显示为方块，将显示模式从“气泡模式”更改为“文本模式”则可以正常显示中文。</p>
<p>References:<br>[1]<a href="https://github.com/hillwoodroc/winetricks-zh">winetricks-zh</a><br>[2]<a href="http://linux-wiki.cn/wiki/zh-hans/Wine%E7%9A%84%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E4%B8%8E%E5%AD%97%E4%BD%93%E8%AE%BE%E7%BD%AE">Wine的中文显示与字体设置</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>wine set windows PATH environment variables</title>
    <url>/2019/08/01/wine-set-windows-path-environment-variables/</url>
    <content><![CDATA[<a id="more"></a>
<p>wine会将大部分的linux环境变量直接传递给windows程序，但是PATH, SYSTEM和TEMP这几个变量除外，主要还是因为冲突，这些变量需要在windows registry中设置。</p>
<p><code>js$ wine regedit</code></p>
<p>打开注册表编辑器，然后在<code>HKEY_CURRENT_USER/Environment</code>下添加或修改PATH等变量就可以了，比如设置PATH为以下值：</p>
<p><code>jsc:\\windows;c:\\windows\\system32;c:\\Program Files (x86)\\Mozilla Firefox</code></p>
<p>然后运行程序时就无需指定繁琐的全路径了，比如</p>
<p><code>js$ wine firefox</code></p>
<p>就可以运行firefox了。</p>
<p>另外，macosx下每次运行wine都需要打开app，其实只要在.bashrc中添加几个环境变量就可以在terminal下直接使用wine了</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">export</span> PATH=<span class="string">&quot;/Applications/Wine Devel.app/Contents/Resources/wine/bin:$PATH&quot;</span></span><br><span class="line">#<span class="keyword">export</span> PATH=<span class="string">&quot;/Applications/Wine Stable.app/Contents/Resources/wine/bin:$PATH&quot;</span></span><br><span class="line"><span class="keyword">export</span> FREETYPE_PROPERTIES=<span class="string">&quot;truetype:interpreter-version=35&quot;</span></span><br><span class="line"><span class="keyword">export</span> DYLD_FALLBACK_LIBRARY_PATH=<span class="string">&quot;/usr/lib:/opt/X11/lib:$DYLD_FALLBACK_LIBRARY_PATH&quot;</span></span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://wiki.winehq.org/Wine_User%27s_Guide#Setting_Windows.2FDOS_environment_variables">3.6.6 Setting Windows/DOS environment variables</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>终端下无线网络配置</title>
    <url>/2015/10/08/wireless-config/</url>
    <content><![CDATA[<a id="more"></a>
<ul>
<li><p>查看设备名</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># iwconfig</span><br><span class="line"># iw dev</span><br><span class="line"># ip link</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动接口</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ifconfig wlan0 up</span><br><span class="line"># ip link set wlan0 up</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭接口</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ifconfig wlan0 down</span><br><span class="line"># ip link set wlan0 down</span><br></pre></td></tr></table></figure>
</li>
<li><p>扫描热点</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># iwlist wlan0 scan</span><br><span class="line"># iw dev wlan0 scan</span><br></pre></td></tr></table></figure>
</li>
<li><p>连接到WPA/WPA2加密热点</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># wpa_supplicant -i interface -c &lt;(wpa_passphrase your_SSID your_key) -B</span><br><span class="line">-B参数使wpa_supplicant背景运行</span><br></pre></td></tr></table></figure>
</li>
<li><p>动态获取IP地址</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># dhclient wlan0</span><br></pre></td></tr></table></figure>
</li>
<li><p>设置静态ip地址</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ip addr add 192.168.0.2&#x2F;24 dev wlan0</span><br><span class="line"># ip route add default via 192.168.0.1 </span><br></pre></td></tr></table></figure>
</li>
<li><p>查看接口状态</p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># iw dev wlan0 link</span><br><span class="line"># iwconfig wlan0</span><br><span class="line"># ifconfig wlan0</span><br></pre></td></tr></table></figure>


</li>
</ul>
<p>References:</p>
<p>[1]: <a href="https://wiki.archlinux.org/index.php/Wireless_network_configuration_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)">Wireless network configuration</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>wordpress站点更换域名</title>
    <url>/2010/04/02/wordpress-domainname/</url>
    <content><![CDATA[<p>主要是修改wp_options表里面的siteurl和home选项以及wp_posts的post_content和guid字段。</p>
<p>update wp_options set option_value=replace(option_value,’<a href="http://old_domain_name&/#39;,&#39;http://new_domain_name&#39;">http://old_domain_name&#39;,&#39;http://new_domain_name&#39;</a>);</p>
<p>update wp_posts set post_content=replace(post_content,’<a href="http://old_domain_name&/#39;,&#39;http://new_domain_name&#39;">http://old_domain_name&#39;,&#39;http://new_domain_name&#39;</a>);</p>
<p>update wp_posts set guid=replace(guid,’<a href="http://old_domain_name&/#39;,&#39;http://new_domain_name&#39;">http://old_domain_name&#39;,&#39;http://new_domain_name&#39;</a>);</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>wordpress重置密码</title>
    <url>/2013/09/30/wordpress-reset-password/</url>
    <content><![CDATA[<p>wordpress的admin密码忘记了，需要重置。</p>
<a id="more"></a>
<p>首先从站点上使用wordpress提供的重置密码，输入注册时的mail地址，但是服务器上的邮件程序有问题，提示</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">“The e-mail could not be sent.</span><br><span class="line">Possible reason: your host may have disabled the mail() <span class="keyword">function</span>.”</span><br></pre></td></tr></table></figure>
<p>那么直接拿数据库开刀吧</p>
<p>wp_users表为默认的用户信息数据库，其字段user_login为用户名，字段user_pass为密码。<br>user_pass字段为salted MD5 sum,即<a href="http://www.williamlong.info/archives/1978.html">盐化过的MD5散列值</a>，也就是<a href="http://blog.csdn.net/blade2001/article/details/6341078">对原始密码加料</a>后再求MD5散列值，安全性更高。通过散列后的结果查表倒推也拿不到真实的密码。</p>
<p>不过幸好，直接用MD5散列值修改user_pass字段的值wordpress也是允许登录的，不过登录后，这个字段的值立马就会被wordpress更改成salted散列值。<br>所以直接用MD5 sum重置user_pass字段即可。</p>
<p>登录到服务器</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">#mysql -uroot -p</span><br><span class="line"></span><br><span class="line">mysql&gt; USE blogdb;</span><br><span class="line">mysql&gt; UPDATE wp_users SET user_pass=MD5(<span class="string">&#x27;new_password&#x27;</span>) WHERE user_login=<span class="string">&#x27;your_username&#x27;</span>;</span><br></pre></td></tr></table></figure>
<p>然后用new_password登录wordpress就可以了。 </p>
<p>更详细的的信息见<a href="http://codex.wordpress.org.cn/Resetting_Your_Password">wordpress官方重置密码</a>。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>解决WordPress半角转全角的问题</title>
    <url>/2013/10/31/wordpress-texturize/</url>
    <content><![CDATA[<p>WordPress会自动转义一些字符，导致贴上去的代码复制后不再可用。</p>
<a id="more"></a>
<p>因此有必要禁止这个自作主张功能。</p>
<p>主题的funtions.php文件的最后添加如下行即可：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">//取消内容转义 </span></span><br><span class="line">remove_filter(<span class="string">&#x27;the_content&#x27;</span>, <span class="string">&#x27;wptexturize&#x27;</span>);</span><br><span class="line"><span class="comment">//取消摘要转义</span></span><br><span class="line">remove_filter(<span class="string">&#x27;the_excerpt&#x27;</span>, <span class="string">&#x27;wptexturize&#x27;</span>);</span><br><span class="line"><span class="comment">//取消评论转义 </span></span><br><span class="line">remove_filter(<span class="string">&#x27;comment_text&#x27;</span>, <span class="string">&#x27;wptexturize&#x27;</span>);</span><br></pre></td></tr></table></figure>

<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>X11 Forward over SSH</title>
    <url>/2012/01/16/x11-forward-over-ssh/</url>
    <content><![CDATA[<p>X本身就是C/S结构的,支持TCP/IP和unix socket协议。通过设置$DISPLAY变量和适当的授权,就可以远程使用X。</p>
<a id="more"></a>
<p>有键盘,鼠标和显示器,可以显示应用程序界面的是X服务器,而普通的X应用程序则是X客户,一般X服务器就是你物理上正在操作的那台机器。虽然X本身支持远程连接,但通过SSH来远程使用X则更安全,更适合于复杂的网络环境,比如通过internet。SSH的X11 Forwarding用来支持此项特性。</p>
<p>设置十分简单。</p>
<p>X客户端(ssh服务器端)：<br>/etc/ssh/sshd_config文件中设置选项X11Forwarding为yes</p>
<p>X服务器端(ssh客户端)：<br>/etc/ssh/ssh_config文件中为远程host设置选项ForwardX11为yes,也可以全局性的打开此选项。</p>
<p>或者在远程连接时为ssh增加命令行选项-XY,比如<br>$ ssh -XY remotehost</p>
<p>然后在X客户端执行简单的x应用程序,应该可以在X服务器上看到应用程序界面了,比如<br>$xlogo</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
  </entry>
  <entry>
    <title>x64安装oracle 10.2.0.4无法启动em dbconsole问题解决</title>
    <url>/2011/02/22/x64-oracle-10g-emdbconsole-error/</url>
    <content><![CDATA[<p>在一台windows 2003 r2 x64上安装oracle 10g 10.2.0.4，采用默认安装方式，安装进度到85%时出现错误提示窗口</p>
<a id="more"></a>
<p><a href="/images/2011/02/emdc_error.jpg"><img src="/images/2011/02/emdc_error.jpg" title="emdc_error"></a></p>
<p>“由于以下错误，Enterprise Manager配置失败 - 启动Database Control时出错 有关详细资料，请参阅E:\oracle\product\10.2.0\db_1\cfgtoollogs\dbca\orcl\emConfig.log中的日志文件。您可以以后通过手动运行E:\oracle\product\10.2.0\db_1\bin\dmca脚本，重新使用Enterprise Manager配置此数据库。”</p>
<p><strong>日志%ORACLE_HOME%\cfgtoollogs\dbca\orcl\emConfig.log输出：</strong></p>
<p>配置: Waiting for service ‘OracleDBConsoleorcl’ to fully start<br>2011-2-22 10:37:15 oracle.sysman.emcp.util.PlatformInterface serviceCommand<br>配置: Initialization failure for service during start<br>2011-2-22 10:37:15 oracle.sysman.emcp.EMConfig perform<br>严重: 启动 Database Control 时出错<br>有关详细资料, 请参阅 E:\oracle\product\10.2.0\db_1\cfgtoollogs\dbca\orcl\emConfig.log 中的日志文件。<br>2011-2-22 10:37:15 oracle.sysman.emcp.EMConfig perform<br>配置: Stack Trace:<br>oracle.sysman.emcp.exception.EMConfigException: 启动 Database Control 时出错<br>at oracle.sysman.emcp.EMDBPostConfig.performConfiguration(EMDBPostConfig.java:646)<br>at oracle.sysman.emcp.EMDBPostConfig.invoke(EMDBPostConfig.java:224)<br>at oracle.sysman.emcp.EMDBPostConfig.invoke(EMDBPostConfig.java:193)<br>at oracle.sysman.emcp.EMConfig.perform(EMConfig.java:184)<br>at oracle.sysman.assistants.util.em.EMConfiguration.run(EMConfiguration.java:436)<br>at java.lang.Thread.run(Thread.java:595)</p>
<p><strong>trace文件%ORACLE_HOME%\<HOSTNAME>_<SID>\sysman\log\emagent.trc输出：</strong></p>
<p>2011-02-22 10:29:51 Thread-3068 ERROR util.files: ERROR: nmeufis_new: failed in lfiopn on file: E:\oracle\product\10.2.0\db_1\dbserver1_orcl\sysman\emd\agntstmp.txt. error = 0 (No error)<br>2011-02-22 10:29:51 Thread-3068 ERROR ssl: Open wallet failed, ret = 28750<br>2011-02-22 10:29:51 Thread-3068 ERROR ssl: nmehlenv_openWallet failed<br>2011-02-22 10:29:51 Thread-3068 ERROR http: 660: Unable to initialize ssl connection with server, aborting connection attempt<br>2011-02-22 10:29:51 Thread-3068 ERROR pingManager: nmepm_pingReposURL: Cannot connect to <a href="https://dbserver1:1158/em/upload/">https://dbserver1:1158/em/upload/</a>: retStatus=-1</p>
<p>经查询，此问题是由于enterprise manager database control组件的跟CA证书授权过期造成的，其证书到期日为2010年12月31日,2011年安装此版本数据库都会出现这个问题，官方的解决方案是打Patch 8350262</p>
<p><strong>单实例数据库应用此patch的方法如下：</strong></p>
<p>1、安装或者升级数据库到10.2.0.4过程中忽略此错误继续安装，数据库的创建不受影响。<br>2、使用opatch把此补丁应用到oracle安装<br>设置ORACLE_HOME和ORACLE_SID系统环境变量，将%ORACLE_HOME%\opatch加入PATH环境变量,将patch 8350262解压缩，打开cmd窗口，进入解压缩后目录，执行<br>cmd&gt;opatch apply<br>完成后检查%ORACLE_HOME%\cfgtoollogs\opatch\目录下生成的日志文件确认安装patch是否成功。<br>3、应用patch成功后，重新配置em dbconsole<br>cmd&gt;emctl secure dbconsole -reset<br>根据提示输入管理员密码，然后会有两次确认请求，两次都是输入大写的Y<br>4、重新启动dbconsole<br>cmd&gt;emctl start dbconsole</p>
<p>当然，如果不使用enterprise manager database control这个组件的话，那么可以不用理会这个错误，不打这个patch。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>xen vps从Debian Lenny升级到Squeeze</title>
    <url>/2011/04/04/xen-vps-from-lenny-to-squeeze/</url>
    <content><![CDATA[<p>Squeeze发布有一段时间了,连Debian 6.0.1都出来了,vps还是用的lenny,真让人看在眼里,疼在蛋上,升级,必须的!</p>
<a id="more"></a>
<p>咨询了供应商,说vps现在已经可以独立升级系统了,但目前的vps还是运行在HVM(hardware Virtual Machine)模式下,必须重装vps转换到PV(ParaVirtualization)模式下才可以自由升级系统,真蛋疼!</p>
<p>备份,连上xen-shell,shutdown,rebuild后的却可以从/boot下看到内核了,从/boot/grub下也可以看到grub的配置文件了,不过还是lenny,开始升级…</p>
<p> 1 #vim /etc/apt/source.list<br> 2 :%s/lenny/squeeze/g<br> 3 :wq<br> 4<br> 5 #wget <a href="http://ftp-master.debian.org/keys/archive-key-6.0.asc">http://ftp-master.debian.org/keys/archive-key-6.0.asc</a><br> 6 #apt-key add archive-key-6.0.asc<br> 7<br> 8 #apt-get update<br> 9 #apt-get install apt dpkg<br>10 #apt-get dist-upgrade  </p>
<p>先升级一下apt工具,这样才比较稳妥。最后配置grub2时选择不配置,就算选择配置其实也不行的。<br>最后修改一下/etc/grub/menu.lst,将第一个引导项设置为如下:</p>
<p>1 title       Debian GNU/Linux, kernel 2.6.32-5-xen-amd64<br>2 root        (hd0)<br>3 kernel      /boot/vmlinuz-2.6.32-5-xen-amd64 root=/dev/xvda ro<br>4 initrd      /boot/initrd**.img**-2.6.32-5-xen-amd64  </p>
<p>1 #reboot<br>2 #uname -a  </p>
<p>可以看到vps已经使用新的内核了。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>VPS</tag>
      </tags>
  </entry>
  <entry>
    <title>xen vps升级到wheezy</title>
    <url>/2013/05/12/xen-vps-upgrade-to-wheezy/</url>
    <content><![CDATA[<p>wheezy近期发布了，将vps从squeeze升级到wheezy</p>
<a id="more"></a>
<p><strong>修改源</strong></p>
<p>/etc/apt/sources.list文件中全部的squeeze更改为wheezy</p>
<p><strong>更新</strong><br>#apt-get update<br>#apt-get install apt<br>#apt-get update<br>#apt-get upgrade</p>
<p><strong>小麻烦</strong></p>
<p>mysql-server更新时遇到依赖错误，无法更新，按提示apt-get -f install,仍然无法更新，提示与使用的dotdeb相关包有依赖问题</p>
<p>强制卸载两个dotdeb的mysql-client包<br>#dpkg -r mysql-client-5.5 mysql-client-core-5.5</p>
<p>重新<br>#apt-get upgrade</p>
<p>然后<br>#apt-get dist-upgrade</p>
<p><strong>升级内核</strong><br>#apt-get install linux-image-3.2.0-4-amd64</p>
<p>但是xen的grub配置文件不太一样，而且无法更新到grub2,update-grub不起作用，这个没具体研究，手工修改/boot/grub/menu.lst即可</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">default</span>=<span class="number">1</span></span><br><span class="line">timeout=<span class="number">5</span></span><br><span class="line"></span><br><span class="line">title Debian GNU/Linux, kernel <span class="number">2.6</span><span class="number">.32</span>-<span class="number">5</span>-xen-amd64</span><br><span class="line">root (hd0)</span><br><span class="line">kernel /boot/vmlinuz-<span class="number">2.6</span><span class="number">.32</span>-<span class="number">5</span>-xen-amd64 root=<span class="regexp">/dev/</span>xvda ro </span><br><span class="line">initrd /boot/initrd.img-<span class="number">2.6</span><span class="number">.32</span>-<span class="number">5</span>-xen-amd64</span><br><span class="line"></span><br><span class="line">title Debian GNU/Linux, kernel <span class="number">3.2</span><span class="number">.0</span>-<span class="number">4</span>-amd64</span><br><span class="line">root (hd0)</span><br><span class="line">kernel /boot/vmlinuz-<span class="number">3.2</span><span class="number">.0</span>-<span class="number">4</span>-amd64 root=<span class="regexp">/dev/</span>xvda ro </span><br><span class="line">initrd /boot/initrd.img-<span class="number">3.2</span><span class="number">.0</span>-<span class="number">4</span>-amd64</span><br><span class="line"></span><br><span class="line">title Debian GNU/Linux, kernel <span class="number">3.2</span><span class="number">.0</span>-<span class="number">4</span>-amd64 (single-user mode)</span><br><span class="line">root (hd0)</span><br><span class="line">kernel /boot/vmlinuz-<span class="number">3.2</span><span class="number">.0</span>-<span class="number">4</span>-amd64 root=<span class="regexp">/dev/</span>xvda ro single</span><br><span class="line">initrd /boot/initrd.img-<span class="number">3.2</span><span class="number">.0</span>-<span class="number">4</span>-amd64</span><br></pre></td></tr></table></figure>

<p>#uname -a<br>Linux `hostname` 3.2.0-4-amd64 #1 SMP Debian 3.2.41-2 x86_64 GNU/Linux</p>
<p>升级完成</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>XHR2上传下载进度监控</title>
    <url>/2014/09/21/xhr2-upload-download-progress/</url>
    <content><![CDATA[<a id="more"></a>
<p>XMLHttpRequest Level 2 简称XHR2添加了<a href="https://developer.mozilla.org/en-US/docs/Web/API/ProgressEvent">ProgressEven</a>t接口,使得可以不借助第三方插件,使用原生Javascript就可以实现上传下载进度监控。</p>
<p>下载的progess事件由XMLHttpRequest对象自身触发,而上传的progess由XMLHttpRequest.upload对象触发。</p>
<p>使用原生的Javascript可以这样写：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> xhr = <span class="keyword">new</span> XMLHttpRequest();</span><br><span class="line"><span class="comment">// 下载进度监控</span></span><br><span class="line">xhr.addEventListener(<span class="string">&quot;progress&quot;</span>, download_progress_handler, <span class="literal">false</span>);</span><br><span class="line"><span class="comment">// 上传进度监控</span></span><br><span class="line">xhr.upload.addEventListener(<span class="string">&quot;progress&quot;</span>, upload_progress_handler, <span class="literal">false</span>);</span><br></pre></td></tr></table></figure>

<p>如果使用JQuery则需要一些曲折,因为JQuery没有对上传下载进度监控提供直接的支持。但是$.ajax函数提供了xhr和xhrFields配置接口,可以修改JQuery内部使用的XMLHttpRequest对象的属性,甚至可以提供自己的XMLHttpRequest对象供JQuery使用。</p>
<p>所有有了以下两种方式来配置$.ajax实现进度监控:</p>
<p>使用xhr配置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$.ajax(&#123;</span><br><span class="line"> <span class="comment">//.....</span></span><br><span class="line"> xhr: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"> <span class="comment">// 获取JQuery内部使用的XMLHttpRequest对象</span></span><br><span class="line"> <span class="keyword">var</span> xhr = $.ajaxSettings.xhr(); </span><br><span class="line"> <span class="comment">// 下载进度监控</span></span><br><span class="line"> xhr.addEventListener(<span class="string">&#x27;progress&#x27;</span>, download_progress_handler, <span class="literal">false</span>); </span><br><span class="line"> <span class="comment">// 上传进度监控</span></span><br><span class="line"> xhr.upload.addEventListener(<span class="string">&#x27;progress&#x27;</span>, upload_progress_handler, <span class="literal">false</span>);</span><br><span class="line"> <span class="keyword">return</span> xhr;<span class="comment">//一定要返回，不然jQ没有XHR对象用了</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>使用xhrFields配置</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$.ajax(&#123;</span><br><span class="line"> <span class="comment">//......</span></span><br><span class="line"> xhrFields: &#123;</span><br><span class="line"> onsendstart: <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line"> <span class="comment">// this指向JQuery内部使用的XMLHttpRequest对象</span></span><br><span class="line"> <span class="comment">// 下载进度监控</span></span><br><span class="line"> <span class="built_in">this</span>.addEventListener(<span class="string">&#x27;progress&#x27;</span>, download_progress_handler, <span class="literal">false</span>);</span><br><span class="line"> <span class="comment">// 上传进度监控</span></span><br><span class="line"> <span class="built_in">this</span>.upload.addEventListener(<span class="string">&#x27;progress&#x27;</span>, upload_progress_handler, <span class="literal">false</span>);</span><br><span class="line"> &#125;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>进度事件处理函数</p>
<p>此时的事件对象为<a href="https://developer.mozilla.org/en-US/docs/Web/API/ProgressEvent">ProgressEvent</a></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">upload_progress_handler</span> (<span class="params">e</span>) </span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (e.lengthComputable) &#123;</span><br><span class="line"> <span class="keyword">var</span> percentComplete = e.loaded / e.total;</span><br><span class="line"> <span class="comment">// ...</span></span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line"> <span class="comment">// 不能计算进度</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest">Using XMLHttpRequest</a><br>[2]<a href="http://segmentfault.com/blog/epooren/1190000000393302">jQuery+FormData+文件上传+上传进度</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>javascript</category>
      </categories>
      <tags>
        <tag>Javascript</tag>
      </tags>
  </entry>
  <entry>
    <title>xmarks也被\&quot;和谐\&quot;掉</title>
    <url>/2009/10/20/xmarks-banned/</url>
    <content><![CDATA[<p>　　大约从前天开始xmarks开始不正常，无法同步，总以为只是xmarks服务器在维护什么的，很快就能用了，毕竟用了这么久，都习惯了。好几天过去了，还是不能用，google一下，原来大家都无法同步，原来是被“墙”了，真不敢相信，这么个有用的工具，招谁惹谁了。现在连骂都不想骂了，真应了那句话，“天朝有风险，投胎需谨慎”。<br>　　xmarks之后，下一个遭毒手的会是谁呢？</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Firefox</tag>
      </tags>
  </entry>
  <entry>
    <title>xp机器ping出现问号无法上网解决一例</title>
    <url>/2010/03/22/xp-ping-problem/</url>
    <content><![CDATA[<p>一台xp系统机器，无法上网浏览， ping本地私有地址和外部公有地址都通，但是ping命令输出出现问号并伴随一声蜂鸣。输出类似如下：</p>
<p>ping ? 192.168.1.1 with 32 bytes of data:<br>reply from 192.168.1.1: bytes=32 time &lt;10 ttl=64<br>reply from 192.168.1.1: bytes=32 time &lt;10 ttl=64<br>reply from 192.168.1.1: bytes=32 time &lt;10 ttl=64</p>
<p>卸载网卡驱动，重新安装故障依旧。交换机及网线确认无问题，执行如下命令<br>netsh winsock reset<br>重置winsock组件，问题解决，应该是恶意软件或插件所为。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>Xpra入门</title>
    <url>/2020/02/04/xpra-intro/</url>
    <content><![CDATA[<a id="more"></a>
<p>ssh x11 forward太慢了，真的。</p>
<p>Xpra除了很快，还可以后台运行gui应用，被称为screen for X11。还可以远程运行整个桌面。</p>
<p>下面使用macos远程使用debian buster系统上的gui application</p>
<p><strong>安装</strong></p>
<p>debian端:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ wget -q https:<span class="comment">//xpra.org/gpg.asc -O- sudo apt-key add -</span></span><br><span class="line">$ sudo add-apt-repository <span class="string">&quot;deb https://xpra.org/ buster main&quot;</span></span><br><span class="line">$ sudo apt update &amp;&amp; sudo apt install xpra -y</span><br></pre></td></tr></table></figure>

<p>mac端：<br>下载<a href="https://xpra.org/dists/osx/x86_64/Xpra.pkg">Xpra.pkg</a>安装即可。<br>或者</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ brew cask install xpra</span><br></pre></td></tr></table></figure>

<p><strong>运行</strong></p>
<p>通过ssh隧道运行</p>
<p>linux/macos平台:</p>
<p>一次性运行gui应用，结束时自动关闭xpra服务</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra start ssh:<span class="comment">//user@host --start-child=xlogo --exit-with-children=yes --speaker=off --webcam=no</span></span><br></pre></td></tr></table></figure>

<p>启动gui应用,结束时不关闭xpra服务，可以再次附加到gui应用程序</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra start ssh:<span class="comment">//user@host --start-child=xlogo</span></span><br></pre></td></tr></table></figure>

<p>断开后可以重新附加到已经运行的gui应用</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra attach ssh:<span class="comment">//user@host</span></span><br></pre></td></tr></table></figure>

<p>windows平台：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">cmd&gt; xpra_cmd start ssh:<span class="comment">//user@host --ssh=&quot;C:\\\\Program Files\\\\putty\\\\Plink.exe -ssh -noagent -i c:\\\\***.ppk -P 22&quot; --start-child=xlogo --exit-with-children=yes --speaker=off --webcam=no</span></span><br></pre></td></tr></table></figure>

<p><strong>其他命令</strong></p>
<p>列出所有会话</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra list</span><br></pre></td></tr></table></figure>

<p>终止所有会话</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra stop</span><br></pre></td></tr></table></figure>

<p><strong>输入法</strong><br>服务器上安装ibus</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt install ibus-pinyin</span><br></pre></td></tr></table></figure>

<p>配置ibus</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra start ssh:<span class="comment">//user@host --exit-with-children=yes --speaker=off --webcam=no --input-method=IBus --start-child=&quot;ibus-setup&quot;</span></span><br></pre></td></tr></table></figure>
<p>运行firefox，同时启动ibus输入法</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xpra start ssh:<span class="comment">//user@host --start-child=firefox --exit-with-children=yes --speaker=off --webcam=no --input-method=IBus --start-child=&quot;ibus-daemon -x -d -r&quot;</span></span><br></pre></td></tr></table></figure>

<p>其他请参考<code>xpra --help</code></p>
<p>References:<br>[1]<a href="https://xpra.org/trac/browser/xpra/trunk/src/man/xpra.1">manual</a><br>[2]<a href="https://xpra.org/trac/wiki/FAQ">FAQ</a><br>[3]<a href="https://medium.com/@summitkwan/guide-work-remotely-on-a-linux-server-from-local-mac-windows-f05cdc6db0e0">GUIDE: Work remotely on a Linux server from local Mac</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>使用xrandr配置显示 - 内置显示设备和外接显示设备(投影仪等)</title>
    <url>/2015/03/28/xrand-display-configuration/</url>
    <content><![CDATA[<a id="more"></a>
<p>RandR(resize and rotate)是X11和Wayland的扩展协议，用于调整显示分辨率，屏幕旋转和扩展显示等特性。xrandr是官方的命令行配置程序，由freedesktop维护。</p>
<p>不带任何参数时,xrandr输出当前环境支持的显示模式:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr</span><br><span class="line">Screen <span class="number">0</span>: minimum <span class="number">320</span> x <span class="number">200</span>, current <span class="number">1600</span> x <span class="number">900</span>, maximum <span class="number">8192</span> x <span class="number">8192</span></span><br><span class="line">LVDS1 connected primary 1600x900+<span class="number">0</span>+<span class="number">0</span> (normal left inverted right x axis y axis) 294mm x 166mm</span><br><span class="line"> 1600x900 <span class="number">60.07</span>*+</span><br><span class="line"> 1440x900 <span class="number">59.89</span> </span><br><span class="line"> 1360x768 <span class="number">59.80</span> <span class="number">59.96</span> </span><br><span class="line"> 1152x864 <span class="number">60.00</span> </span><br><span class="line"> 1024x768 <span class="number">60.00</span> </span><br><span class="line"> 800x600 <span class="number">60.32</span> <span class="number">56.25</span> </span><br><span class="line"> 640x480 <span class="number">59.94</span> </span><br><span class="line">VGA1 disconnected (normal left inverted right x axis y axis)</span><br><span class="line">HDMI1 disconnected (normal left inverted right x axis y axis)</span><br><span class="line">DP1 disconnected (normal left inverted right x axis y axis)</span><br></pre></td></tr></table></figure>
<p>有+后缀的模式为最优化的模式，有*后缀的模式为当前的模式。</p>
<p>LVDS(Low-Voltage Differential Signaling)为LCD显示器的通用接口(信号传输模式)。<br>LVDS1即第一个LVDS接口的LCD显示设备。<br>VGA1为第一个VGA接口的显示设备(显示器/电视机/投影仪等)。<br>HDMI1为第一个HDMI接口的显示设备(显示器/电视机/投影仪等)。<br>DP1为第一个display port接口的显示设备(显示器/电视机/投影仪等)。</p>
<p>命令示例：</p>
<ul>
<li>  设置分辨率<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr -s 1600x900</span><br></pre></td></tr></table></figure></li>
<li>  打开外接HDMI显示设备，克隆LCD屏幕<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --same-<span class="keyword">as</span> LVDS1 --auto</span><br></pre></td></tr></table></figure></li>
<li>  打开外接HDMI显示设备,克隆LCD屏幕，设置显示模式<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --same-<span class="keyword">as</span> LVDS1 --mode 1600x900</span><br></pre></td></tr></table></figure></li>
<li>  打开外接HDMI接口显示设备，并设置为LCD的右侧扩展屏幕。鼠标会从LCD的右边缘进入HDMI设备的左边缘。<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --right-<span class="keyword">of</span> LVDS1 --auto</span><br></pre></td></tr></table></figure></li>
<li>  打开外接HDMI接口显示设备，并设置为LCD的左侧扩展屏幕。鼠标会从LCD的左边缘进入HDMI设备的右边缘。<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --left-<span class="keyword">of</span> LVDS1 --auto</span><br></pre></td></tr></table></figure></li>
<li>  打开外接HDMI显示设备，同时关闭LCD显示设备<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --auto --output LVDS1 --off</span><br></pre></td></tr></table></figure></li>
<li>  关闭HDMI显示设备，同时打开LCD显示设备<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --off --output LVDS1 --auto</span><br></pre></td></tr></table></figure></li>
<li>  关闭HDMI显示设备<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ xrandr --output HDMI1 --off</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>关于XSD文件</title>
    <url>/2013/10/12/xsd-file/</url>
    <content><![CDATA[<p>XSD(XML Schema Definiton)文件是用来校验XML文件的，使其符合XSD制定的规范。XSD是DTD(Document Type Definition)的继任者。</p>
<a id="more"></a>
<p>比如spring-servlet.xml中的这段<br>[xml]<br><beans xmlns="http://www.springframework.org/schema/beans"
 xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xmlns:p="http://www.springframework.org/schema/p"
 xmlns:context="http://www.springframework.org/schema/context"
 xmlns:mvc="http://www.springframework.org/schema/mvc"
 xsi:schemaLocation="
 http://www.springframework.org/schema/beans
 http://www.springframework.org/schema/beans/spring-beans.xsd
 http://www.springframework.org/schema/context
 http://www.springframework.org/schema/context/spring-context.xsd
 http://www.springframework.org/schema/mvc
 http://www.springframework.org/schema/mvc/spring-mvc.xsd"><br></beans><br>[/xml]</p>
<p>虽然XSD在文件中都是以HTTP URL的方式出现的，但实际上并不会真正直接去互联网上获取这些文档，除非本地找不到这些文件。<br>比如</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">http:<span class="comment">//www.springframework.org/schema/mvc/spring-mvc.xsd</span></span><br></pre></td></tr></table></figure>
<p>在包spring-webmvc-3.2.4.RELEASE.jar里有个文件/META-INF/spring.schemas,其内容如下：<br>[xml]<br>http\://<a href="http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd=org/springframework/web/servlet/config/spring-mvc-3.0.xsd">www.springframework.org/schema/mvc/spring-mvc-3.0.xsd=org/springframework/web/servlet/config/spring-mvc-3.0.xsd</a><br>http\://<a href="http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd=org/springframework/web/servlet/config/spring-mvc-3.1.xsd">www.springframework.org/schema/mvc/spring-mvc-3.1.xsd=org/springframework/web/servlet/config/spring-mvc-3.1.xsd</a><br>http\://<a href="http://www.springframework.org/schema/mvc/spring-mvc-3.2.xsd=org/springframework/web/servlet/config/spring-mvc-3.2.xsd">www.springframework.org/schema/mvc/spring-mvc-3.2.xsd=org/springframework/web/servlet/config/spring-mvc-3.2.xsd</a><br>http\://<a href="http://www.springframework.org/schema/mvc/spring-mvc.xsd=org/springframework/web/servlet/config/spring-mvc-3.2.xsd">www.springframework.org/schema/mvc/spring-mvc.xsd=org/springframework/web/servlet/config/spring-mvc-3.2.xsd</a><br>[/xml]</p>
<p>可以看到其实际上被重定向到spring-webmvc-3.2.4.RELEASE.jar包里面的/org/springframework/web/servlet/config/spring-mvc-3.2.xsd文件上。因此直接从这个jar包读取就可以。</p>
<p>如果本地无法找到XSD文件，则会联网获取该XSD文件。</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>xterm on gnome wayland</title>
    <url>/2019/07/11/xterm-on-gnome-wayland/</url>
    <content><![CDATA[<a id="more"></a>
<p>debian buster gnome桌面默认启用wayland，当前仍然可以切换回Xorg<br>wayland兼容性还是有一些小问题，wayland并不加载profile环境配置文件，<br>也不理会Xsession，导致.xinitrc,.Xresources等无法加载<br>系统及用户的Xresources是由/etc/X11/Xsession.d/30x11-common_xresources脚本加载的，在wayland面前失效了，直接后果就是每次重启机器xterm就会被打回原形，只能手工重新加载~/.Xresources<br>回到gnome on xorg则xterm恢复正常<br>发现一个跨平台GPU加速的terminale emulator <a href="https://github.com/jwilm/alacritty">alacritty</a>看起来很不错，可以试用一番。</p>
<p>References:<br>[1]<a href="https://lwn.net/Articles/709769/">GNOME, Wayland, and environment variables</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>动态设置xterm标题</title>
    <url>/2015/07/28/xterm-dynamic-title-2/</url>
    <content><![CDATA[<a id="more"></a>
<p>xterm终端窗口默认标题都是一样的。经常开很多终端窗口，虽然已经设置了命令行提示符，但如果标题栏也能反应出xterm的当前状态就更好了。</p>
<p><strong>更改标题栏</strong></p>
<p>可以使用xterm的转义序列更改窗口的title</p>
<ul>
<li>  ESC]0;stringBEL — Set icon name and window title to string<br>设置图标化名字(窗口最小化时)和窗口标题</li>
<li>  ESC]1;stringBEL — Set icon name to string<br>设置图标化名字</li>
<li>  ESC]2;stringBEL — Set window title to string<br>设置窗口标题</li>
</ul>
<p>where ESC is the escape character (\033), and BEL is the bell character (\007)<br>此处，ESC是转义字符<code>\033</code>,BEL是bell字符<code>\007</code></p>
<p>因此在.bashrc中添加如下行，让xterm标题栏显示当前的主机名和用户名以及当前路径信息:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">PROMPT_COMMAND=<span class="string">&#x27;echo -ne &quot;\\033\]0;$&#123;USER&#125;@$&#123;HOSTNAME&#125;\[\`basename $&#123;PWD&#125;\`\]\\007&quot;&#x27;</span></span><br></pre></td></tr></table></figure>

<p><strong>ssh登录时更改标题栏</strong></p>
<p>ssh登录时，xterm窗口应该显示当前所在的远程主机和在远程主机上的当前用户以及路径信息，只要在远程主机的bashrc文件中包含同样的行就可以了。</p>
<p><strong>终端vim标题栏</strong></p>
<p>在终端下使用vim时，默认会修改xterm的标题栏，但是没有主机和用户信息，在~/.vimrc中添加如下：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">let</span> &amp;titlestring=$USER.<span class="string">&quot;@&quot;</span>.hostname().<span class="string">&quot;: %t%M(%F)&quot;</span></span><br><span class="line">set title</span><br></pre></td></tr></table></figure>

<p>更多符号的含义请</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">:help titlestring</span><br><span class="line">:help statusline</span><br></pre></td></tr></table></figure>


<p>References:<br>[1]<a href="http://vim.wikia.com/wiki/Automatically_set_screen_title">Automatically set screen title</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>开启xterm终端256色和终端下vim 256色</title>
    <url>/2013/10/10/xterm-vim-256-colors/</url>
    <content><![CDATA[<p>相同的colorschema,vim和gvim的颜色差距还是很大的，因为gvim使用X的颜色，而vim只能使用终端提供的颜色，所以造成了二者的显示差异。</p>
<a id="more"></a>
<p><strong>xterm开启256色</strong></p>
<p>现在的终端模拟器早就支持256色了，不过默认可能还是8色的。</p>
<p>开启xterm终端，查看xterm终端支持的颜色</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tput colors</span><br><span class="line"><span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>xterm终端默认还是8色的</p>
<p>查看终端类型</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ echo $TERM</span><br><span class="line">xterm</span><br></pre></td></tr></table></figure>
<p>只要将终端类型更改为xterm-256color即可，有两种方式可以来修改</p>
<p>1、修改.bashrc文件</p>
<p>~/.bashrc文件添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> \[ <span class="string">&quot;$TERM&quot;</span> == <span class="string">&quot;xterm&quot;</span> \]; then</span><br><span class="line"> <span class="keyword">export</span> TERM=xterm-256color</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>
<p>2、修改.Xresourcesw文件</p>
<p>~/.Xresources文件添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">xterm*termName: xterm-256color</span><br></pre></td></tr></table></figure>
<p>只要其中一种方式修改即可，修改生效后，重新查看</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ tput colors</span><br><span class="line"><span class="number">256</span></span><br><span class="line">$ echo $TERM</span><br><span class="line">xterm-256color</span><br></pre></td></tr></table></figure>
<p>如果系统默认没有xterm-256color类型，可安装ncurses-term包，里面有许多附加的终端类型定义，里面还有一个终端类型xterm+256color,也可以开启256色支持，不知道与xterm-256color有什么区别。</p>
<p><strong>vim开启256色支持</strong></p>
<p>编辑~/.vimrc文件，添加</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">set t_Co=<span class="number">256</span></span><br></pre></td></tr></table></figure>
<p>t_Co即terminal Color之意</p>
<p>开启256颜色之后，colorschema在vim里好看了许多，而且与gvim显示的差别不大。</p>
<p>参考：<br><a href="http://vim.wikia.com/wiki/256_colors_setup_for_console_Vim">256 colors setup for console Vim</a><br><a href="http://push.cx/2008/256-color-xterms-in-ubuntu">256-Color XTerms in Ubuntu</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Xterm</tag>
      </tags>
  </entry>
  <entry>
    <title>Yosemite升级导致的postgresql启动问题</title>
    <url>/2014/10/28/yosemite-postgresql-boot-issue/</url>
    <content><![CDATA[<a id="more"></a>
<p>升级yosemite后，启动postgesql时报以下错误:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">FATAL: could not open directory <span class="string">&quot;pg_twophase&quot;</span>: No such file or directory</span><br><span class="line">Is the server running locally and accepting</span><br><span class="line">connections on Unix domain socket <span class="string">&quot;/tmp/.s.PGSQL.5432&quot;</span>?</span><br></pre></td></tr></table></figure>

<p>据说可能是因为yosemite删除了pg的一些空目录导致的,所以解决方案也十分简单:</p>
<p>如果/usr/local/var/postgres/目录下没有pg_tblspc,pg_twophase和pg_stat_tmp子目录,直接新建这几个目录即可。</p>
<p>然后可以正常启动postgresql</p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>PostgresQL</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix服务端安装配置</title>
    <url>/2015/12/24/zabbix-setup/</url>
    <content><![CDATA[<a id="more"></a>
<p>zabbix是开源的企业级监控平台，可以用来监控服务器、网络设备以及网络服务等的健康状况和运行状态。</p>
<p><strong>安装</strong></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install zabbix-server-pgsql zabbix-frontend-php</span><br></pre></td></tr></table></figure>

<p><strong>创建数据库</strong></p>
<p>创建数据库及角色</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">$ sudo -u postgres createdb zabbix</span><br><span class="line">$ sudo -u postgres createuser -SDRP zabbix # 根据提示输入密码</span><br></pre></td></tr></table></figure>

<p>初始化数据库</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ zcat /usr/share/zabbix-server-pgsql/&#123;schema,images,data&#125;.sql.gz psql -h localhost zabbix zabbix</span><br></pre></td></tr></table></figure>

<p>修改配置文件,添加如下参数:</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">DBPassword=zabbix #　以实际的数据库用户密码为准</span><br></pre></td></tr></table></figure>

<p><strong>启动服务</strong></p>
<p>/etc/default/zabbix文件中，设置START=yes,然后启动服务:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo service zabbix-servere start</span><br></pre></td></tr></table></figure>

<p>有错误提示:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Job <span class="keyword">for</span> zabbix-server.service failed because the control process exited <span class="keyword">with</span> error code. See <span class="string">&quot;systemctl status zabbix-server.service&quot;</span> and <span class="string">&quot;journalctl -xe&quot;</span> <span class="keyword">for</span> details.</span><br></pre></td></tr></table></figure>

<p>执行</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo systemctl status zabbix-server.service</span><br><span class="line">● zabbix-server.service - Zabbix Server (PostgreSQL)</span><br><span class="line"> Loaded: loaded (<span class="regexp">/lib/</span>systemd/system/zabbix-server.service; disabled; vendor preset: enabled)</span><br><span class="line"> Active: failed (Result: exit-code) since Thu <span class="number">2015</span>-<span class="number">12</span>-<span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> EST; 6s ago</span><br><span class="line"> Docs: man:zabbix_server</span><br><span class="line"> Process: <span class="number">1014</span> ExecStart=<span class="regexp">/usr/</span>sbin/zabbix_server (code=exited, status=<span class="number">1</span>/FAILURE)</span><br><span class="line"></span><br><span class="line">Dec <span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> zabbix systemd\[<span class="number">1</span>\]: Starting Zabbix Server (PostgreSQL)...</span><br><span class="line">Dec <span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> zabbix zabbix_server\[<span class="number">1014</span>\]: zabbix_server \[<span class="number">1014</span>\]: <span class="regexp">/etc/</span>zabbix/zabbix_server.conf.d: \[<span class="number">2</span>\] No such file or directory</span><br><span class="line">Dec <span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> zabbix systemd\[<span class="number">1</span>\]: zabbix-server.service: Control process exited, code=exited status=<span class="number">1</span></span><br><span class="line">Dec <span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> zabbix systemd\[<span class="number">1</span>\]: Failed to start Zabbix Server (PostgreSQL).</span><br><span class="line">Dec <span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> zabbix systemd\[<span class="number">1</span>\]: zabbix-server.service: Unit entered failed state.</span><br><span class="line">Dec <span class="number">24</span> <span class="number">03</span>:<span class="number">37</span>:<span class="number">10</span> zabbix systemd\[<span class="number">1</span>\]: zabbix-server.service: Failed <span class="keyword">with</span> result <span class="string">&#x27;exit-code&#x27;</span>.</span><br></pre></td></tr></table></figure>

<p>创建目录,重新启动</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo mkdir /etc/zabbix/zabbix_server.conf.d</span><br><span class="line">$ sudo service zabbix-server start</span><br></pre></td></tr></table></figure>

<p><strong>配置php前端</strong></p>
<p>确认已安装依赖libapache2-mod-php5，如果使用postgresql数据库，还需要安装依赖php5-pgsql</p>
<p>配置apache2虚拟主机:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo ln -s /usr/share/doc/zabbix-frontend-php/examples/apache.conf /etc/apache2/conf-available/zabbix.conf</span><br><span class="line">$ sudo a2enconf zabbix</span><br></pre></td></tr></table></figure>

<p>修改php配置文件:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">post_max_size = 16M </span><br><span class="line">max_execution_time = <span class="number">300</span> </span><br><span class="line">max_input_time = <span class="number">300</span> </span><br><span class="line">always_populate_raw_post_data = -<span class="number">1</span></span><br><span class="line">date.timezone = Asia/Shanghai</span><br></pre></td></tr></table></figure>

<p>重新启动apache2</p>
<p>配置前端运行环境：</p>
<p>浏览器访问<a href="http://zabbix_server_ip/zabbix%E6%A0%B9%E6%8D%AE%E6%8F%90%E7%A4%BA%E5%A1%AB%E5%86%99%E7%9B%B8%E5%85%B3%E4%BF%A1%E6%81%AF%EF%BC%8C%E6%9C%80%E5%90%8E%E7%94%9F%E6%88%90zabbix%E5%89%8D%E7%AB%AF%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6zabbix.conf.php">http://zabbix_server_ip/zabbix根据提示填写相关信息，最后生成zabbix前端配置文件zabbix.conf.php</a><br>如果提示无权限写入配置文件，则将文件下载，拷贝到/etc/zabbix目录下，前端配置完成。</p>
<p>重新访问<a href="http://zabbix_server_ip/zabbix%EF%BC%8C%E7%94%A8%E9%BB%98%E8%AE%A4%E7%AE%A1%E7%90%86%E5%91%98%E8%B4%A6%E6%88%B7Admin/zabbix%E7%99%BB%E5%85%A5%E5%8D%B3%E5%8F%AF%E3%80%82">http://zabbix_server_ip/zabbix，用默认管理员账户Admin/zabbix登入即可。</a></p>
<p><strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ZFS文件系统介绍 - 基础</title>
    <url>/2012/05/14/zfs-basic/</url>
    <content><![CDATA[<p>ZFS是SUN为Solaris开发的文件系统,号称史上最后一个文件系统。</p>
<a id="more"></a>
<p>linux系统上已经有原生ZFS移植<a href="http://zfsonlinux.org/">zfsonlinux</a>,其安装见”<a href="https://openwares.net/linux/debian_amd64_install_zfs.html">Debian Wheezy AMD64编译安装原生ZFS文件系统</a>“</p>
<p>linux虽然有btrfs文件系统可望与ZFS比肩,但btrfs是由oracle主导的,现在oracle已将ZFS纳入囊中,对btrfs会不会有所保留就不得而知了。</p>
<p>ZFS集文件系统、卷管理、RAID功能于一身,能提供超大容量的存储空间,几乎可以视为没有存储空间限制。ZFS分为存储池和文件系统两部分,所有的ZFS文件系统都驻留在存储池之中,zpool命令用于管理存储池,zfs命令用于管理zfs文件系统。</p>
<p>ZFS 是事务性文件系统,这意味着文件系统状态在磁盘上始终是一致的。文件系统绝对不会因意外断电或系统崩溃而被损坏。尽管最近写入的数据片段可能丢失,但是文件系统本身将始终是一致的。ZFS不需要fsck。</p>
<p>ZFS存储池最新版本为33,ZFS文件系统最新版本为5。当前zfsonlinux实现的池版本为28,文件系统版本为5。</p>
<p><strong>存储池</strong></p>
<p>传统的文件系统一般存在于单独的一个物理设备或者由卷管理器如lvm管理的逻辑卷之上。ZFS与之不同,ZFS文件系统建立于虚拟的存储池之上。存储池可以由整块物理磁盘、磁盘分区或者文件组成，而且可以动态增加磁盘。ZFS支持热备组件(hot spare),可以为存储池提供一个或多个备用磁盘，当池内的磁盘出现故障时,ZFS可以使用热备件自动替换出现故障的磁盘。ZFS存储池支持动态扩容,文件不用离线即可更换更大容量的磁盘。还可以为存储池提供高速缓存设备,比如使用SSD磁盘来作为存储池的缓存设备来提高IO性能。ZFS也支持单独的日志设备。</p>
<p>ZFS文件系统可以存取到所有设备组合起来的全部容量。</p>
<p><strong>文件系统</strong></p>
<p>管理ZFS文件系统类似于管理一个普通的目录。</p>
<p>ZFS 文件系统构建于存储池上。文件系统可以动态创建和销毁,而不需要分配或格式化任何底层磁盘空间。</p>
<p><strong>条带与冗余</strong></p>
<p>ZFS支持镜像和RAID-Z配置,RAID-Z又分为三种：raidz(raidz1),raidz2和raidz3。镜像mirror与传统的RAID-1类似,提供最高的冗余性,但存储容量会大打折扣。RAID-Z则在冗余、性能和存储容量之间达到平衡。单奇偶校验RAID-Z (raidz 或 raidz1) 与 RAID-5 类似,双奇偶校验 RAID-Z (raidz2) 与RAID-6类似,三奇偶校验RAID-Z（raidz3)没有传统的RAID对应物。</p>
<p>每个存储池都包含一个或多个虚拟设备(virtual device),简称vdev。虚拟设备是存储池的内部表示形式,用于描述物理存储器的布局以及存储池的故障特征。因此,虚拟设备表示用于创建存储池的磁盘设备或文件。一个池可以在配置的顶层具有任意数目的虚拟设备,称为顶层vdev。ZFS以条带形式将数据动态分布在所有顶层虚拟设备(vdev)上。ZFS的条带类似于传统的RAID-0,但其条带宽度是动态变化的。</p>
<p><strong>快照和克隆</strong></p>
<p>快照是文件系统或卷的只读副本。快照采取写时复制COW技术,在最初创建快照时并不占用额外的存储空间,只是一些指针操作,快照与原始文件系统使用相同的数据块,但当原始的文件系统发生变化时,快照继续引用旧数据块,而原始文件系统会使用新的数据块,因此快照会阻止存储空间的释放,比如原始文件系统删除了一个文件,而该文件存在于快照中,那么此文件占据的空间在快照删除之前不能被重新利用。ZFS文件系统可以回滚到之前创建的快照,具有类似时间机器的效果。</p>
<p>ZFS快照可以发送到远程系统,远程系统可以接收快照流并在本地生成一个新的文件系统,这个特性可以用来做数据备份。</p>
<p>克隆是可读写的文件系统或卷的副本,克隆只能从快照创建。克隆快照时,会在克隆和快照之间建立隐式相关性。即使克隆是在文件系统分层结构中的其他位置创建的,但只要克隆存在,就无法销毁始快照。克隆最初与原始文件系统共享相同的数据块,随着原始文件系统或克隆的变化,会创建新的块,但是未变化的数据块仍然在二者之间共享。</p>
<p><strong>共享ZFS系统</strong></p>
<p>ZFS仍然是单机文件系统,不能直接用于集群环境。如需要在不同系统之间共享数据,可采用NFS或SAMBA共享方式,ZFS内置支持这两种共享方式。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>ZFS文件系统介绍 - 文件系统</title>
    <url>/2012/05/14/zfs-filesystem/</url>
    <content><![CDATA[<p>ZFS 文件系统构建于存储池上。文件系统可以动态创建和销毁,而不需要分配或格式化任何底层磁盘空间。</p>
<a id="more"></a>
<p><strong>创建ZFS文件系统</strong></p>
<p>创建存储池时若没有通过-m选项指定挂装点,则默认会将池子挂载到/poolname这个目录下,比如前文例子中的池子自动挂载到/reservoir,而且ZFS会在开机时自动挂载池子。</p>
<p>在池子中创建新的ZFS文件系统</p>
<h1 id="zfs-create-pool-name-filesystem-name-filesystem-name"><a href="#zfs-create-pool-name-filesystem-name-filesystem-name" class="headerlink" title="zfs create pool-name/[filesystem-name/]filesystem-name"></a>zfs create pool-name/[filesystem-name/]filesystem-name</h1><p>pool-name为新创建ZFS文件系统要驻留其中的池子,路径中最后的filesystem-name为要创建的ZFS文件系统,ZFS文件系统为分层结构,新创建的文件系统可能居于其他文件系统的层次之下,但前提是这里提到的其他文件系统必须是已经存在的，无法一次递归创建多个ZFS文件系统。</p>
<p>比如在池子reservoir上创建文件系统data</p>
<h1 id="zfs-create-reservoir-data"><a href="#zfs-create-reservoir-data" class="headerlink" title="zfs create reservoir/data"></a>zfs create reservoir/data</h1><p>如果文件系统创建成功,ZFS会自动挂载该文件系统。此处新创建的文件系统挂载于/reservoir/data</p>
<p>也可以在创建文件系统时指定挂载点</p>
<h1 id="zfs-create-o-mountpoint-mnt-data-reservoir-data"><a href="#zfs-create-o-mountpoint-mnt-data-reservoir-data" class="headerlink" title="zfs create -o mountpoint=/mnt/data reservoir/data"></a>zfs create -o mountpoint=/mnt/data reservoir/data</h1><h1 id="zfs-list"><a href="#zfs-list" class="headerlink" title="zfs list"></a>zfs list</h1><p> NAME            USED AVAIL  REFER MOUNTPOINT<br>reservoir       146K 1.94G  30K   /reservoir<br>reservoir/data  30K  1.94G  30K   /mnt/data </p>
<p><strong>销毁ZFS文件系统</strong></p>
<p>使用zfs destroy命令来销毁 ZFS 文件系统,销毁的文件系统将自动取消挂载,并取消共享。</p>
<h1 id="zfs-destroy-reservoir-data"><a href="#zfs-destroy-reservoir-data" class="headerlink" title="zfs destroy reservoir/data"></a>zfs destroy reservoir/data</h1><p><strong>重命名ZFS文件系统</strong></p>
<p>使用zfs rename命令不但可以重命名zfs文件系统,而且可以重定位文件系统所在的层级</p>
<p>重命名文件系统</p>
<h1 id="zfs-rename-reservoir-data-reservoir-data-new"><a href="#zfs-rename-reservoir-data-reservoir-data-new" class="headerlink" title="zfs rename reservoir/data reservoir/data_new"></a>zfs rename reservoir/data reservoir/data_new</h1><h1 id="zfs-list-NAME-USED-AVAIL-REFER-MOUNTPOINT"><a href="#zfs-list-NAME-USED-AVAIL-REFER-MOUNTPOINT" class="headerlink" title="zfs list NAME                 USED  AVAIL  REFER  MOUNTPOINT"></a>zfs list NAME                 USED  AVAIL  REFER  MOUNTPOINT</h1><p>reservoir            144K  1.94G    30K  /reservoir<br>reservoir/data_new    30K  1.94G    30K  /mnt/data<br>可以看到虽然文件系统的名字变化了,但其挂载点仍然未变,以下命令改变文件系统的挂载点</p>
<h1 id="zfs-set-mountpoint-mnt-data-new-reservoir-data-new"><a href="#zfs-set-mountpoint-mnt-data-new-reservoir-data-new" class="headerlink" title="zfs set mountpoint=/mnt/data_new reservoir/data_new"></a>zfs set mountpoint=/mnt/data_new reservoir/data_new</h1><h1 id="zfs-list-NAME-USED-AVAIL-REFER-MOUNTPOINT-1"><a href="#zfs-list-NAME-USED-AVAIL-REFER-MOUNTPOINT-1" class="headerlink" title="zfs list NAME                 USED  AVAIL  REFER  MOUNTPOINT"></a>zfs list NAME                 USED  AVAIL  REFER  MOUNTPOINT</h1><p>reservoir            146K  1.94G    30K  /reservoir<br>reservoir/data_new    30K  1.94G    30K  /mnt/data_new </p>
<p>重命名并重定位zfs文件系统层级</p>
<h1 id="zfs-create-reservoir-somefs"><a href="#zfs-create-reservoir-somefs" class="headerlink" title="zfs create reservoir/somefs"></a>zfs create reservoir/somefs</h1><h1 id="zfs-rename-reservoir-data-new-reservoir-somefs-data"><a href="#zfs-rename-reservoir-data-new-reservoir-somefs-data" class="headerlink" title="zfs rename reservoir/data_new reservoir/somefs/data"></a>zfs rename reservoir/data_new reservoir/somefs/data</h1><h1 id="zfs-list-NAME-USED-AVAIL-REFER-MOUNTPOINT-2"><a href="#zfs-list-NAME-USED-AVAIL-REFER-MOUNTPOINT-2" class="headerlink" title="zfs list NAME                  USED AVAIL REFER MOUNTPOINT"></a>zfs list NAME                  USED AVAIL REFER MOUNTPOINT</h1><p>reservoir             184K 1.94G   31K /reservoir<br>reservoir/somefs      60K 1.94G   30K /reservoir/somefs<br>reservoir/somefs/data 30K 1.94G   30K /mnt/data_new </p>
<p><strong>共享ZFS文件系统</strong></p>
<p>ZFS支持两种共享方式发布ZFS文件系统,NFS和SAMBA</p>
<p><strong>NFS方式发布ZFS文件系统</strong><br>首先ZFS所在的主机要安装nfs服务器,debian系统可以安装包nfs-kernel-server</p>
<p>设置ZFS文件系统NFS共享</p>
<h1 id="zfs-set-sharenfs-on-reservoir-somefs-data"><a href="#zfs-set-sharenfs-on-reservoir-somefs-data" class="headerlink" title="zfs set sharenfs=on reservoir/somefs/data"></a>zfs set sharenfs=on reservoir/somefs/data</h1><h1 id="zfs-get-sharenfs-reservoir-somefs-data-NAME-PROPERTY-VALUE-SOURCE"><a href="#zfs-get-sharenfs-reservoir-somefs-data-NAME-PROPERTY-VALUE-SOURCE" class="headerlink" title="zfs get sharenfs reservoir/somefs/data NAME                  PROPERTY VALUE SOURCE"></a>zfs get sharenfs reservoir/somefs/data NAME                  PROPERTY VALUE SOURCE</h1><p>reservoir/somefs/data sharenfs on    local </p>
<p>对外共享的目录即该文件系统挂载的目录/mnt/data_new</p>
<p>从其他主机访问该文件系统</p>
<h1 id="mount-t-nfs4-ip-mnt-data-new-mnt-data-new"><a href="#mount-t-nfs4-ip-mnt-data-new-mnt-data-new" class="headerlink" title="mount -t nfs4 ip:/mnt/data_new /mnt/data_new"></a>mount -t nfs4 ip:/mnt/data_new /mnt/data_new</h1><p>取消NFS共享</p>
<h1 id="zfs-set-sharenfs-off-reservoir-somefs-data"><a href="#zfs-set-sharenfs-off-reservoir-somefs-data" class="headerlink" title="zfs set sharenfs=off reservoir/somefs/data"></a>zfs set sharenfs=off reservoir/somefs/data</h1><p><strong>SAMBA方式发布ZFS文件系统</strong></p>
<p>zfsonlinux有sharesmb属性,但当前实现尚不支持直接以samba方式发布ZFS文件系统,但仍然可以以传统的方式对ZFS文件系统设置smaba共享。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>ZFS文件系统介绍 - 存储池(1):创建存储池</title>
    <url>/2012/05/14/zfs-pool-create/</url>
    <content><![CDATA[<p>ZFS使用存储池来管理物理存储,文件系统不再受限于单个物理设备。</p>
<a id="more"></a>
<p>不再需要预先考虑并确定文件系统的大小,因为文件系统会在分配给存储池的磁盘空间内自动增长。添加新的物理存储设备后,无需执行其他操作,池中的所有文件系统即可立即使用所增加的磁盘空间。所以有了ZFS,就不再需要传统的卷管理器，甚至也不再需要传统的RAID设备了。</p>
<p>下文及后续文章涉及到的命令皆基于如下KVM虚拟系统环境：</p>
<p>debian amd64 testing + zfsonlinux 0.6.0-rc8</p>
<p><strong>创建存储池</strong></p>
<p>可以使用整块磁盘,磁盘上面的分区或者文件来创建ZFS存储池,但是推荐使用整块磁盘来创建存储池，并且最好不要用硬件RAID提供的虚拟卷。</p>
<p>下面只演示使用整块物理磁盘的情形。这里创建了6个1G的磁盘设备,从KVM客户机里看到的“物理设备”名称为/dev/vdb,/dev/vdc,/dev/vdd,/dev/vde,/dev/vdf,/dev/vdg。所有6个磁盘没有进行分区,处于原始状态。</p>
<p><strong>1、创建基本存储池</strong></p>
<p>先查看下物理磁盘状态</p>
<h1 id="fdisk-dev-vdb"><a href="#fdisk-dev-vdb" class="headerlink" title="fdisk /dev/vdb"></a>fdisk /dev/vdb</h1><p>Disk /dev/vdb: 1073 MB, 1073741824 bytes<br>16 heads, 63 sectors/track, 2080 cylinders, total 2097152 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 512 bytes<br>I/O size (minimum/optimal): 512 bytes / 512 bytes<br>Disk identifier: 0x00000000</p>
<p>Disk /dev/vdb doesn’t contain a valid partition table</p>
<p>创建池</p>
<h1 id="zpool-create-reservoir-dev-vdb-dev-vdc-dev-vdd"><a href="#zpool-create-reservoir-dev-vdb-dev-vdc-dev-vdd" class="headerlink" title="zpool create reservoir /dev/vdb /dev/vdc /dev/vdd"></a>zpool create reservoir /dev/vdb /dev/vdc /dev/vdd</h1><p>会有提示：<br>invalid vdev specification<br>use ‘-f’ to override the following errors:<br>/dev/vdb does not contain an EFI label but it may contain partition<br>information in the MBR</p>
<p>这是ZFS检测到磁盘不是GPT格式的,而且有可能存在分区,所以进行了提示,加上-f选项继续执行会成功创建存储池。</p>
<h1 id="zpool-create-f-reservoir-dev-vdb-dev-vdc-dev-vdd"><a href="#zpool-create-f-reservoir-dev-vdb-dev-vdc-dev-vdd" class="headerlink" title="zpool create -f reservoir /dev/vdb /dev/vdc /dev/vdd"></a>zpool create -f reservoir /dev/vdb /dev/vdc /dev/vdd</h1><p>reservoir是存储池的名字,solaris提供的zfs手册里举例喜欢用tank做池子的名字,tank与reservoir都有蓄水池的意思。这个存储池基于/dev/vdb,/dev/vdc和/dev/vdd这三个物理磁盘设备创建。从ZFS的角度看,这三个物理磁盘设备同时还是顶层的vdev设备。</p>
<p>查看存储池基本信息</p>
<h1 id="zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT"><a href="#zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT" class="headerlink" title="zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT"></a>zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT</h1><p>reservoir 2.95G 112K  2.95G 0%  1.00x ONLINE - </p>
<p>ZFS在这三个设备上执行动态条带,但没有任何数据冗余,任何一个磁盘出现故障都将导致存储池不可用,而且无法动态更换磁盘。其容量为3块物理磁盘之和。</p>
<p>这种类型的池子对物理磁盘数量没有限制</p>
<p>查看下存储池reservoir的状态和布局</p>
<h1 id="zpool-status-reservoir-pool-reservoir"><a href="#zpool-status-reservoir-pool-reservoir" class="headerlink" title="zpool status reservoir pool: reservoir"></a>zpool status reservoir pool: reservoir</h1><p> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>          vdc1      ONLINE       0     0     0<br>          vdd1      ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>可以看到池子并没有如预期使用整个磁盘,而是在磁盘上自动创建了一个覆盖全部存储空间的GPT分区来做为存储池的底层物理设备,可以再看下物理磁盘的分区状态</p>
<h1 id="fidsk-dev-vdb"><a href="#fidsk-dev-vdb" class="headerlink" title="fidsk /dev/vdb"></a>fidsk /dev/vdb</h1><p>Disk /dev/vdb: 1073 MB, 1073741824 bytes<br>256 heads, 63 sectors/track, 130 cylinders, total 2097152 sectors<br>Units = sectors of 1 * 512 = 512 bytes<br>Sector size (logical/physical): 512 bytes / 512 bytes<br>I/O size (minimum/optimal): 512 bytes / 512 bytes<br>Disk identifier: 0x00000000</p>
<p> Device Boot Start End Blocks Id System<br>/dev/vdb1 1 2097151 1048575+ ee GPT</p>
<p>可以清楚的看到ZFS为物理磁盘自动创建了一个GPT分区,为什么会这样呢？可以看此处<a href="https://github.com/zfsonlinux/zfs/issues/94">对这个问题的讨论</a>,Brian Behlendorf对此的解释是为了对齐，而且ZFS的行为尽量与solaris一致云云。<br>总之目前在zfsonlinux上面,你给了它整个物理磁盘,它自动为你分区,然后使用整个分区,这也不是什么大问题。</p>
<p><strong>2、创建镜像池</strong></p>
<p>没有任何冗余的池子你敢用吗？这也体现不出ZFS的优势。使用mirror命令来创建镜像池,至少需要两块物理磁盘。</p>
<h1 id="zpool-create-reservoir-mirror-dev-vdb-dev-vdc"><a href="#zpool-create-reservoir-mirror-dev-vdb-dev-vdc" class="headerlink" title="zpool create reservoir mirror /dev/vdb /dev/vdc"></a>zpool create reservoir mirror /dev/vdb /dev/vdc</h1><p>查看池子的基本信息</p>
<h1 id="zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT-1"><a href="#zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT-1" class="headerlink" title="zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT"></a>zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT</h1><p>reservoir 1008M 109K  1008M 0%  1.00x ONLINE - 可以看到其容量为一块磁盘的容量,与RAID1基本类似。</p>
<p>查看存储池状态和布局</p>
<h1 id="zpool-status-reservoir-pool-reservoir-1"><a href="#zpool-status-reservoir-pool-reservoir-1" class="headerlink" title="zpool status reservoir pool: reservoir"></a>zpool status reservoir pool: reservoir</h1><p> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          mirror-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>此镜像池reservoir的顶层虚拟设备vdev为mirror-0,而不是那两块物理磁盘。<br>这个池子是双向镜像池,还可以创建三向或更多向镜像池,其冗余度越来越高。</p>
<p>三向镜像池</p>
<h1 id="zpool-create-reservoir-mirror-dev-vdb-dev-vdc-dev-vdd"><a href="#zpool-create-reservoir-mirror-dev-vdb-dev-vdc-dev-vdd" class="headerlink" title="zpool create reservoir mirror /dev/vdb /dev/vdc /dev/vdd"></a>zpool create reservoir mirror /dev/vdb /dev/vdc /dev/vdd</h1><p>这个新池子只是多了一份冗余,其容量仍然是一块物理磁盘的容量。</p>
<p>ZFS存储池支持层次结构,比如可以创建一个池子，动态条带化两个顶层镜像虚拟设备,如下</p>
<h1 id="zpool-create-reservoir-mirror-dev-vdb-dev-vdc-mirror-dev-vdd-dev-vde"><a href="#zpool-create-reservoir-mirror-dev-vdb-dev-vdc-mirror-dev-vdd-dev-vde" class="headerlink" title="zpool create reservoir mirror /dev/vdb /dev/vdc mirror /dev/vdd /dev/vde"></a>zpool create reservoir mirror /dev/vdb /dev/vdc mirror /dev/vdd /dev/vde</h1><p>查看池子的基本信息</p>
<h1 id="zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT-2"><a href="#zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT-2" class="headerlink" title="zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT"></a>zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT</h1><p>reservoir 1.97G 91.5K 1.97G 0%  1.00x ONLINE -<br>其容量为两个镜像虚拟设备的容量之和</p>
<p>查看池子的状态和布局</p>
<h1 id="zpool-status-reservoir-pool-reservoir-2"><a href="#zpool-status-reservoir-pool-reservoir-2" class="headerlink" title="zpool status reservoir pool: reservoir"></a>zpool status reservoir pool: reservoir</h1><p> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          mirror-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>          mirror-1  ONLINE       0     0     0<br>            vdd1    ONLINE       0     0     0<br>            vde1    ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>可以看到这个池子有两个顶层vdev,mirror-0和mirror-1,ZFS在这两个vdev之间执行动态条带化,而每个vdev又对其数据进行镜像。</p>
<p><strong>3、创建raidz池</strong></p>
<p>RAID-Z有3种,分别为单奇偶校验的raidz或叫raidz1,双奇偶校验的raidz2和三奇偶校验的raidz3。一个RAID-Z配置包含 N 个大小为 X 的磁盘,其中有 P 个奇偶校验磁盘,该配置可以存放大约 (N-P)*X 字节的数据,并且只有在 P 个设备出现故障时才会危及数据完整性。单奇偶校验 RAID-Z 配置至少需要两个磁盘,双奇偶校验 RAID-Z 配置至少需要三个磁盘,三奇偶校验 RAID-Z 配置至少需要四个磁盘。单奇偶校验至多只能掉一块磁盘,双奇偶校验至多只能掉2块盘,三奇偶校验至多只能掉3块盘。</p>
<p>创建raidz2池</p>
<h1 id="zpool-create-reservoir-raidz2-dev-vdb-dev-vdc-dev-vdd"><a href="#zpool-create-reservoir-raidz2-dev-vdb-dev-vdc-dev-vdd" class="headerlink" title="zpool create reservoir raidz2 /dev/vdb /dev/vdc /dev/vdd"></a>zpool create reservoir raidz2 /dev/vdb /dev/vdc /dev/vdd</h1><p>查看池子基本信息</p>
<h1 id="zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT-3"><a href="#zpool-list-reservoir-NAME-SIZE-ALLOC-FREE-CAP-DEDUP-HEALTH-ALTROOT-3" class="headerlink" title="zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT"></a>zpool list reservoir NAME      SIZE  ALLOC FREE  CAP DEDUP HEALTH ALTROOT</h1><p>reservoir 2.95G 279K  2.95G 0%  1.00x ONLINE - </p>
<p>查看池子的状态和布局</p>
<h1 id="zpool-status-reservoir-pool-reservoir-3"><a href="#zpool-status-reservoir-pool-reservoir-3" class="headerlink" title="zpool status reservoir pool: reservoir"></a>zpool status reservoir pool: reservoir</h1><p> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          raidz2-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>            vdd1    ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>可以看到池子的顶层vdev设备为raidz2-0</p>
<p><strong>4、创建使用日志设备的存储池</strong></p>
<p>默认情况下,ZFS的日志从主池中分配,通过提供单独的日志设备，可以提高ZFS的性能和安全性,也可以使用镜像日志设备,但日志设备不支持RAID-Z,也就是日志设备不可以作成RAID-Z方式,但是RAID-Z池可以使用日志设备。<br>创建使用镜像日志设备的raidz池</p>
<h1 id="zpool-create-reservoir-raidz-dev-vdb-dev-vdc-log-mirror-dev-vdd-dev-vde"><a href="#zpool-create-reservoir-raidz-dev-vdb-dev-vdc-log-mirror-dev-vdd-dev-vde" class="headerlink" title="zpool create reservoir raidz /dev/vdb /dev/vdc log mirror /dev/vdd /dev/vde"></a>zpool create reservoir raidz /dev/vdb /dev/vdc log mirror /dev/vdd /dev/vde</h1><p>查看池子的状态和布局<br>#zpool status reservoir pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          raidz1-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>        logs<br>          mirror-1  ONLINE       0     0     0<br>            vdd1    ONLINE       0     0     0<br>            vde1    ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p><strong>5、创建使用高速缓存设备的存储池</strong><br>为池子指定高速缓存设备可以有效提高ZFS的性能,比如使用SSD作为高速缓存设备</p>
<h1 id="zpool-create-reservoir-raidz-dev-vdb-dev-vdc-cache-dev-vdd-dev-vde"><a href="#zpool-create-reservoir-raidz-dev-vdb-dev-vdc-cache-dev-vdd-dev-vde" class="headerlink" title="zpool create reservoir raidz /dev/vdb /dev/vdc cache /dev/vdd /dev/vde"></a>zpool create reservoir raidz /dev/vdb /dev/vdc cache /dev/vdd /dev/vde</h1><p>查看池子的状态和布局<br>#zpool status reservoir pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          raidz1-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>        cache<br>          vdd1      ONLINE       0     0     0<br>          vde1      ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p><strong>6、创建使用热备件的存储池</strong><br>ZFS支持hot spare,通过指定热备件,当池中的活动设备发生严重故障时必须更换时,ZFS可以自动使用热备件来替换故障设备</p>
<h1 id="zpool-create-reservoir-raidz-dev-vdb-dev-vdc-spare-dev-vdd-dev-vde"><a href="#zpool-create-reservoir-raidz-dev-vdb-dev-vdc-spare-dev-vdd-dev-vde" class="headerlink" title="zpool create reservoir raidz /dev/vdb /dev/vdc spare /dev/vdd /dev/vde"></a>zpool create reservoir raidz /dev/vdb /dev/vdc spare /dev/vdd /dev/vde</h1><p>查看池子的状态和布局</p>
<h1 id="zpool-status-reservoir-pool-reservoir-4"><a href="#zpool-status-reservoir-pool-reservoir-4" class="headerlink" title="zpool status reservoir pool: reservoir"></a>zpool status reservoir pool: reservoir</h1><p> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          raidz1-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>        spares<br>          vdd1      AVAIL   <br>          vde1      AVAIL     </p>
<p>errors: No known data errors</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>zfs pool 空间扩展</title>
    <url>/2019/10/13/zfs-pool-expand/</url>
    <content><![CDATA[<a id="more"></a>
<p>这里以lxd使用的zfs存储后端为例来扩展zpool</p>
<p>先看一下lxd默认存储池default的信息:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc storage show <span class="keyword">default</span></span><br><span class="line">config:</span><br><span class="line"> size: 10GB</span><br><span class="line"> source: <span class="regexp">/var/</span>snap/lxd/common/lxd/disks/<span class="keyword">default</span>.img</span><br><span class="line"> zfs.pool_name: <span class="keyword">default</span></span><br><span class="line">description: <span class="string">&quot;&quot;</span></span><br><span class="line">name: <span class="keyword">default</span></span><br><span class="line">driver: zfs</span><br><span class="line">used_by:</span><br><span class="line">- <span class="regexp">/1.0/</span>profiles/<span class="keyword">default</span></span><br><span class="line">status: Created</span><br><span class="line">locations:</span><br><span class="line">- none</span><br></pre></td></tr></table></figure>
<p>从zfs端看default zpool</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ zpool list <span class="keyword">default</span></span><br><span class="line">NAME SIZE ALLOC FREE CKPOINT EXPANDSZ FRAG CAP DEDUP HEALTH ALTROOT</span><br><span class="line"><span class="keyword">default</span> 9G 372K <span class="number">9.</span>00G - - <span class="number">0</span>% <span class="number">0</span>% <span class="number">1.</span>00x ONLINE -</span><br></pre></td></tr></table></figure>
<p>只有10G大小，现在扩展到100G</p>
<p>停止所有正在运行的容器，使用truncate将存储文件尺寸增大90G：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo truncate -c -s +90G /<span class="keyword">var</span>/snap/lxd/common/lxd/disks/<span class="keyword">default</span>.img</span><br></pre></td></tr></table></figure>

<p>查看zpool的自动扩展属性：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ zpool get autoexpand <span class="keyword">default</span></span><br><span class="line">NAME PROPERTY VALUE SOURCE</span><br><span class="line"><span class="keyword">default</span> autoexpand off <span class="keyword">default</span></span><br></pre></td></tr></table></figure>
<p>是关闭的，将其打开</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo zpool set autoexpand=on <span class="keyword">default</span></span><br></pre></td></tr></table></figure>

<p>查看default存储池的设备名称</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ zpool status -vg <span class="keyword">default</span></span><br><span class="line">pool: <span class="keyword">default</span></span><br><span class="line"> state: ONLINE</span><br><span class="line"> scan: none requested</span><br><span class="line">config:</span><br><span class="line"></span><br><span class="line">NAME STATE READ WRITE CKSUM</span><br><span class="line"><span class="keyword">default</span> ONLINE <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"> <span class="number">15286821055422665849</span> ONLINE <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">errors: No known data errors</span><br></pre></td></tr></table></figure>

<p>扩展default池到最大可用容量</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo zpool online -e <span class="keyword">default</span> <span class="number">15286821055422665849</span></span><br></pre></td></tr></table></figure>
<p>查看default池</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ zpool list <span class="keyword">default</span></span><br><span class="line">NAME SIZE ALLOC FREE CKPOINT EXPANDSZ FRAG CAP DEDUP HEALTH ALTROOT</span><br><span class="line"><span class="keyword">default</span> 99G 399K <span class="number">99.</span>0G - - <span class="number">0</span>% <span class="number">0</span>% <span class="number">1.</span>00x ONLINE -</span><br></pre></td></tr></table></figure>
<p>可以看到容量已经扩展到了100G</p>
<p>关闭zpool的自动扩展</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo zpool set autoexpand=off <span class="keyword">default</span></span><br></pre></td></tr></table></figure>

<p>lxd端查看：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ lxc storage info <span class="keyword">default</span></span><br><span class="line">info:</span><br><span class="line"> description: <span class="string">&quot;&quot;</span></span><br><span class="line"> driver: zfs</span><br><span class="line"> name: <span class="keyword">default</span></span><br><span class="line"> space used: <span class="number">340.</span>99kB</span><br><span class="line"> total space: <span class="number">102.</span>98GB</span><br><span class="line">used by:</span><br><span class="line"> profiles:</span><br><span class="line"> - <span class="keyword">default</span></span><br></pre></td></tr></table></figure>

<p>lxd官方文档给的方案，参见[3]：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">sudo truncate -s +5G /<span class="keyword">var</span>/lib/lxd/disks/&lt;POOL&gt;.img</span><br><span class="line">sudo zpool set autoexpand=on lxd</span><br><span class="line">sudo zpool online -e lxd /<span class="keyword">var</span>/lib/lxd/disks/&lt;POOL&gt;.img</span><br><span class="line">sudo zpool set autoexpand=off lxd</span><br></pre></td></tr></table></figure>

<p>References:<br>[1]<a href="https://discuss.linuxcontainers.org/t/how-to-resize-zfs-used-in-lxd/1333">How to resize ZFS used in LXD</a><br>[2]<a href="https://tomasz.korwel.net/2014/01/03/growing-zfs-pool/">GROWING ZFS POOL</a><br>[3]<a href="https://lxd.readthedocs.io/en/latest/storage/">Storage configuration</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>ZFS文件系统介绍 - 存储池(2):管理和销毁存储池</title>
    <url>/2012/05/14/zfs-pool-manager-destroy/</url>
    <content><![CDATA[<p>管理和销毁存储池</p>
<a id="more"></a>
<p><strong>管理存储池中的设备</strong></p>
<p><strong>1、添加删除设备</strong></p>
<p>通过添加新的顶层虚拟设备vdev,可以向存储池中动态添加、删除磁盘。此磁盘空间立即可供池中的所有数据集使用。使用zpool add命令向池中添加新虚拟设备,使用zpool remove命令从池中删除虚拟设备。zpool remove命令仅支持删除热备件、日志设备和高速缓存设备,非冗余设备和RAID-Z设备无法从池中删除,也就是在没有足够的冗余,无法保证池中数据完整的情况下,无法从池中删除设备。</p>
<p>新添加的普通顶层虚拟设备,即非日志设备,非高速缓存设备,非热备设备,与池中现有顶层虚拟设备进行动态条带。</p>
<p>普通条带池 # zpool create reservoir /dev/vdb /dev/vdc  </p>
<h1 id="zpool-status-reservoir"><a href="#zpool-status-reservoir" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>          vdc1      ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-add-reservoir-dev-vdd"><a href="#zpool-add-reservoir-dev-vdd" class="headerlink" title="zpool add reservoir /dev/vdd"></a>zpool add reservoir /dev/vdd</h1><h1 id="zpool-status-reservoir-1"><a href="#zpool-status-reservoir-1" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>          vdc1      ONLINE       0     0     0<br>          vdd1      ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-remove-reservoir-dev-vdd"><a href="#zpool-remove-reservoir-dev-vdd" class="headerlink" title="zpool remove reservoir /dev/vdd"></a>zpool remove reservoir /dev/vdd</h1><p>cannot remove /dev/vdd: only inactive hot spares, cache, top-level, or log devices can be removed </p>
<p>一个更复杂的例子,当然没人会用这样的池子 # zpool create reservoir /dev/vdb  </p>
<h1 id="zpool-add-reservoir-mirror-dev-vdc-dev-vdd"><a href="#zpool-add-reservoir-mirror-dev-vdc-dev-vdd" class="headerlink" title="zpool add reservoir mirror /dev/vdc /dev/vdd"></a>zpool add reservoir mirror /dev/vdc /dev/vdd</h1><p>invalid vdev specification<br>use ‘-f’ to override the following errors:<br>mismatched replication level: pool uses disk and new vdev is mirror  </p>
<h1 id="zpool-add-f-reservoir-mirror-dev-vdc-dev-vdd"><a href="#zpool-add-f-reservoir-mirror-dev-vdc-dev-vdd" class="headerlink" title="zpool add -f reservoir mirror /dev/vdc /dev/vdd"></a>zpool add -f reservoir mirror /dev/vdc /dev/vdd</h1><h1 id="zpool-add-reservoir-raidz-dev-vde-dev-vdf"><a href="#zpool-add-reservoir-raidz-dev-vde-dev-vdf" class="headerlink" title="zpool add reservoir raidz /dev/vde /dev/vdf"></a>zpool add reservoir raidz /dev/vde /dev/vdf</h1><h1 id="zpool-status-reservoir-2"><a href="#zpool-status-reservoir-2" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>          mirror-1  ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>            vdd1    ONLINE       0     0     0<br>          raidz1-2  ONLINE       0     0     0<br>            vde1    ONLINE       0     0     0<br>            vdf1    ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>添加删除日志设备 # zpool add reservoir log /dev/vdc  </p>
<h1 id="zpool-status"><a href="#zpool-status" class="headerlink" title="zpool status"></a>zpool status</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>        logs<br>          vdc1      ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-remove-reservoir-dev-vdc"><a href="#zpool-remove-reservoir-dev-vdc" class="headerlink" title="zpool remove reservoir /dev/vdc"></a>zpool remove reservoir /dev/vdc</h1><h1 id="zpool-status-1"><a href="#zpool-status-1" class="headerlink" title="zpool status"></a>zpool status</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>添加删除高速缓存设备 # zpool add reservoir cache /dev/vdc  </p>
<h1 id="zpool-status-reservoir-3"><a href="#zpool-status-reservoir-3" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>        cache<br>          vdc1      ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-remove-reservoir-dev-vdc-1"><a href="#zpool-remove-reservoir-dev-vdc-1" class="headerlink" title="zpool remove reservoir /dev/vdc"></a>zpool remove reservoir /dev/vdc</h1><h1 id="zpool-status-reservoir-4"><a href="#zpool-status-reservoir-4" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>添加删除热备件 # zpool add reservoir spare /dev/vdc  </p>
<h1 id="zpool-status-reservoir-5"><a href="#zpool-status-reservoir-5" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0<br>        spares<br>          vdc1      AVAIL     </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-remove-reservoir-dev-vdc-2"><a href="#zpool-remove-reservoir-dev-vdc-2" class="headerlink" title="zpool remove reservoir /dev/vdc"></a>zpool remove reservoir /dev/vdc</h1><h1 id="zpool-status-reservoir-6"><a href="#zpool-status-reservoir-6" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p><strong>2、附加分离设备</strong></p>
<p>附加分离设备与添加删除设备的根本区别在于,附加分离设备是在虚拟设备内附加或分离磁盘,一般是在顶层虚拟设备内,而添加和删除设备是在池子中添加或删除顶层虚拟设备。</p>
<p>可以通过附加磁盘使普通池成为冗余镜像池 # zpool status reservoir<br>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-attach-reservoir-dev-vdb-dev-vdc"><a href="#zpool-attach-reservoir-dev-vdb-dev-vdc" class="headerlink" title="zpool attach reservoir /dev/vdb /dev/vdc"></a>zpool attach reservoir /dev/vdb /dev/vdc</h1><h1 id="zpool-status-reservoir-7"><a href="#zpool-status-reservoir-7" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: resilvered 84K in 0h0m with 0 errors on Wed May 16 10:30:48 2012<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          mirror-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-detach-reservoir-dev-vdc"><a href="#zpool-detach-reservoir-dev-vdc" class="headerlink" title="zpool detach reservoir /dev/vdc"></a>zpool detach reservoir /dev/vdc</h1><h1 id="zpool-status-reservoir-8"><a href="#zpool-status-reservoir-8" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: resilvered 84K in 0h0m with 0 errors on Wed May 16 10:30:48 2012<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          vdb1      ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p>附加磁盘时通过指定其前导磁盘来确定新附加磁盘的位置。此例的实质就是在唯一的顶层虚拟设备内,在原有磁盘设备/dev/vdb之后附加了另外一个磁盘/dev/vdc,二者位于同一个顶层设备内,成为镜像关系。</p>
<p>还可以通过附加磁盘使双路镜像成为多路镜像,或者相反,但不能向现有raidz(1,2,3)配置中附加磁盘。 # zpool status<br>  pool: reservoir<br> state: ONLINE<br> scan: none requested<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          mirror-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-attach-reservoir-dev-vdb-dev-vdd"><a href="#zpool-attach-reservoir-dev-vdb-dev-vdd" class="headerlink" title="zpool attach reservoir /dev/vdb /dev/vdd"></a>zpool attach reservoir /dev/vdb /dev/vdd</h1><h1 id="zpool-status-reservoir-9"><a href="#zpool-status-reservoir-9" class="headerlink" title="zpool status reservoir"></a>zpool status reservoir</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: resilvered 84K in 0h0m with 0 errors on Wed May 16 10:43:31 2012<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          mirror-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0<br>            vdd1    ONLINE       0     0     0  </p>
<p>errors: No known data errors  </p>
<h1 id="zpool-detach-reservoir-dev-vdd"><a href="#zpool-detach-reservoir-dev-vdd" class="headerlink" title="zpool detach reservoir /dev/vdd"></a>zpool detach reservoir /dev/vdd</h1><h1 id="zpool-status-2"><a href="#zpool-status-2" class="headerlink" title="zpool status"></a>zpool status</h1><p>  pool: reservoir<br> state: ONLINE<br> scan: resilvered 84K in 0h0m with 0 errors on Wed May 16 10:43:31 2012<br>config:  </p>
<p>        NAME        STATE     READ WRITE CKSUM<br>        reservoir   ONLINE       0     0     0<br>          mirror-0  ONLINE       0     0     0<br>            vdb1    ONLINE       0     0     0<br>            vdc1    ONLINE       0     0     0  </p>
<p>errors: No known data errors </p>
<p><strong>3、替换设备</strong></p>
<p>如果冗余池中的设备出现故障,或者对所有池来说只是用更大容量的磁盘替换池中原有的小容量磁盘,可以使用zpool replace命令。<br>如果替换涉及到的新旧设备位于同一个物理位置,则只需标识出这个位置的物理设备即可,如果新旧磁盘设备位于不同的物理位置则需要分别标识出旧设备和新设备的物理位置。用大容量的磁盘替换非冗余池中的小容量磁盘设备,则新旧设备必须同时在线,同步完成后才可以移除旧设备。</p>
<p><strong>替换镜像池中的故障设备</strong></p>
<p>如果冗余池中的故障磁盘并未离线，先用以下命令使其离线</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># zpool offline reservoir /dev/vdc</span><br></pre></td></tr></table></figure>
<p>然后将故障磁盘抽出,将新的磁盘插入，然后</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># zpool replace reservoir /dev/vdc</span><br></pre></td></tr></table></figure>
<p>最后使新磁盘在线</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># zpool online reservoir /dev/vdc</span><br></pre></td></tr></table></figure>
<p><strong>用大容量磁盘替换小容量磁盘来扩展镜像冗余池</strong></p>
<p>假设镜像池reservoir由/dev/vdb和/dev/vdc组成,现由更大容量的/dev/vdd和/dev/vde来替换池中的磁盘</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># zpool replace reservoir /dev/vdb /dev/vdd</span><br><span class="line"># zpool replace reservoir /dev/vdd /dev/vde</span><br></pre></td></tr></table></figure>
<p>最后需要设置autoexpand属性为on池子的容量才可以扩展到新设备的容量</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># zpool set autoexpand=on reservoir</span><br></pre></td></tr></table></figure>
<p>但当前zfsonlinux的实现好像还是有点儿问题,设置了此属性,容量仍然无法扩展,虽然设备已经替换过了。<br>注：需要执行zpool onlie命令来扩展空间，每个设备上都要执行：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ sudo zpool online -e reservoir &lt;设备id&gt;</span><br></pre></td></tr></table></figure>
<p>设备id获取:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ zpool status -vg reservoir</span><br></pre></td></tr></table></figure>

<p><strong>销毁存储池</strong></p>
<p>销毁存储池很简单,但一定要三思。</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line"># zpool destroy reservoir</span><br></pre></td></tr></table></figure>
<p>此命令会销毁池,即使池中包含挂载的数据集也是如此。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>ZFS文件系统介绍 - 快照和克隆</title>
    <url>/2012/05/16/zfs-snapshot-clone/</url>
    <content><![CDATA[<p>快照是文件系统或卷的只读副本,而克隆是可读写的卷或文件系统,克隆只能从快照创建。</p>
<a id="more"></a>
<p><strong>ZFS快照</strong></p>
<p>创建快照几乎没有任何成本,可以即时创建完成,而且快照创建的最初几乎不占用额外的存储池空间，ZFS采用COW策略,快照会与原始文件系统共享快照创建后一直没有变化的存储块。无法直接访问卷的快照,但是可以对它们执行克隆、备份、回滚等操作</p>
<p><strong>创建ZFS快照</strong></p>
<p>使用zfs snapshot filesystem@snapname,快照名称由两部分组成,@前面为文件系统名称,@后面为快照标识,二者组成完成的快照名</p>
<h1 id="zfs-snapshot-reservoir-data-thursday"><a href="#zfs-snapshot-reservoir-data-thursday" class="headerlink" title="zfs snapshot reservoir/data@thursday"></a>zfs snapshot reservoir/data@thursday</h1><p>查看ZFS快照</p>
<h1 id="zfs-list-t-snapshot-NAME-USED-AVAIL-REFER-MOUNTPOINT"><a href="#zfs-list-t-snapshot-NAME-USED-AVAIL-REFER-MOUNTPOINT" class="headerlink" title="zfs list -t snapshot NAME                      USED  AVAIL  REFER  MOUNTPOINT"></a>zfs list -t snapshot NAME                      USED  AVAIL  REFER  MOUNTPOINT</h1><p>reservoir/data@thursday      0      -    30K  - </p>
<p>使用-r选项为所有后代文件系统递归创建快照</p>
<h1 id="zfs-snapshot-r-reservoir-data-thursday"><a href="#zfs-snapshot-r-reservoir-data-thursday" class="headerlink" title="zfs snapshot -r reservoir/data@thursday"></a>zfs snapshot -r reservoir/data@thursday</h1><p><strong>销毁ZFS快照</strong></p>
<p>使用zfs destroy filesystem@snapname销毁ZFS快照</p>
<h1 id="zfs-destroy-reservoir-data-thursday"><a href="#zfs-destroy-reservoir-data-thursday" class="headerlink" title="zfs destroy reservoir/data@thursday"></a>zfs destroy reservoir/data@thursday</h1><p>如果数据集(dataset)存在快照,则不能销毁该数据集。也可指定-r选项一起销毁快照和数据集。</p>
<p><strong>重命名ZFS快照</strong></p>
<p>可以重命名快照,但是不能跨越池和数据集对它们进行重命名。</p>
<h1 id="zfs-rename-reservoir-data-thursday-reservoir-data-thursday1"><a href="#zfs-rename-reservoir-data-thursday-reservoir-data-thursday1" class="headerlink" title="zfs rename reservoir/data@thursday reservoir/data@thursday1"></a>zfs rename reservoir/data@thursday reservoir/data@thursday1</h1><p>可以使用更快捷的方式重命名快照</p>
<h1 id="zfs-rename-reservoir-data-thursday-thursday1"><a href="#zfs-rename-reservoir-data-thursday-thursday1" class="headerlink" title="zfs rename reservoir/data@thursday thursday1"></a>zfs rename reservoir/data@thursday thursday1</h1><p><strong>回滚ZFS快照</strong></p>
<p>可以使用 zfs rollback 命令放弃自特定快照创建以来对文件系统所做的全部更改。文件系统恢复到创建快照时的状态。缺省情况下,该命令无法回滚到除最新快照以外的快照。<br>要回滚到早期快照,必须销毁所有的中间快照。可以通过指定 -r 选项销毁早期的快照。如果存在任何中间快照的克隆,则还必须指定 -R 选项以销毁克隆。</p>
<h1 id="zfs-rollback-reservoir-data-thursday"><a href="#zfs-rollback-reservoir-data-thursday" class="headerlink" title="zfs rollback reservoir/data@thursday"></a>zfs rollback reservoir/data@thursday</h1><p>则自此快照之后文件系统的任何改变都会被丢弃。</p>
<p><strong>ZFS快照差异比较</strong></p>
<p>可以使用 zfs diff 命令来比较两个ZFS快照之间的差异。</p>
<p>比如下面的例子</p>
<h1 id="cd-reservoir-data"><a href="#cd-reservoir-data" class="headerlink" title="cd /reservoir/data/"></a>cd /reservoir/data/</h1><h1 id="touch-file1"><a href="#touch-file1" class="headerlink" title="touch file1"></a>touch file1</h1><h1 id="zfs-snapshot-reservoir-data-snap1"><a href="#zfs-snapshot-reservoir-data-snap1" class="headerlink" title="zfs snapshot reservoir/data@snap1"></a>zfs snapshot reservoir/data@snap1</h1><h1 id="touch-file2"><a href="#touch-file2" class="headerlink" title="touch file2"></a>touch file2</h1><h1 id="zfs-snapshot-reservoir-data-snap2"><a href="#zfs-snapshot-reservoir-data-snap2" class="headerlink" title="zfs snapshot reservoir/data@snap2"></a>zfs snapshot reservoir/data@snap2</h1><h1 id="zfs-diff-reservoir-data-snap1-reservoir-data-snap2"><a href="#zfs-diff-reservoir-data-snap1-reservoir-data-snap2" class="headerlink" title="zfs diff reservoir/data@snap1 reservoir/data@snap2"></a>zfs diff reservoir/data@snap1 reservoir/data@snap2</h1><p>M /reservoir/data/</p>
<ul>
<li>/reservoir/data/file2</li>
</ul>
<p>M表示目录被修改过了,+表示文件/reservoir/data/file2存在与更新的快照中<br>zfs diff 命令输出符号的含义见下表<br> 文件或目录更改                                          标识符<br>————————————————–      ——<br>文件或目录已被修改,或文件或目录链接已更改               M<br>文件或目录出现在较旧的快照中,但未出现在较新的快照中     -<br>文件或目录出现在较新的快照中,但未出现在较旧的快照中     +<br>文件或目录已重命名                                      R </p>
<p><strong>ZFS克隆</strong></p>
<p>克隆是可写入的卷或文件系统,其初始内容与从中创建它的数据集的内容相同。与快照一样,创建克隆几乎是即时的,而且最初不占用其他磁盘空间。此外,还可以创建克隆的快照。克隆只能从快照创建。克隆快照时,会在克隆和快照之间建立隐式相关性。即使克隆是在文件系统分层结构中的其他位置创建的,但只要克隆存在,就无法销毁原始快照。</p>
<p><strong>创建ZFS克隆</strong></p>
<p>使用 zfs clone 命令创建克隆,指定从中创建克隆的快照以及新文件系统或卷的名称。新文件系统或卷可以位于ZFS文件系统分层结构中的任意位置。新数据集与从其中创建克隆的快照属同一类型(例如文件系统或卷)。不能在原始文件系统快照所在池以外的池中创建该文件系统的克隆,亦即克隆是不能跨越存储池的。</p>
<h1 id="zfs-clone-reservoir-data-snap2-reservoir-clone-snap2"><a href="#zfs-clone-reservoir-data-snap2-reservoir-clone-snap2" class="headerlink" title="zfs clone reservoir/data@snap2 reservoir/clone_snap2"></a>zfs clone reservoir/data@snap2 reservoir/clone_snap2</h1><p><strong>销毁ZFS克隆</strong></p>
<h1 id="zfs-destroy-reservoir-clone-snap2"><a href="#zfs-destroy-reservoir-clone-snap2" class="headerlink" title="zfs destroy reservoir/clone_snap2"></a>zfs destroy reservoir/clone_snap2</h1><p>必须先销毁克隆,才能销毁父快照。</p>
<p><strong>发送和接收ZFS快照流</strong></p>
<p>通过使用zfs send命令,可以将 ZFS 文件系统或卷的快照转换为快照流。然后可以通过zfs receive命令使用快照流重新创建 ZFS 文件系统或卷。<br>可以生成两种快照流：<br>完整流 - 包含从创建数据集时开始到指定的快照为止的所有数据集内容。zfs send 命令生成的缺省流是完整流。它包含一个文件系统或卷,直到并包括指定的快照。流不会包含在命令行上指定的快照之外的快照。</p>
<p>增量流 - 包含一个快照与另一个快照之间的差异。</p>
<p>使用 zfs send 命令来发送快照流,并在同一系统的另一个池中或用于存储备份数据的不同系统上的另一个池中接收快照流。</p>
<p>例如</p>
<h1 id="zfs-send-reservoir-data-snap1-zfs-receive-reservoir-data-received"><a href="#zfs-send-reservoir-data-snap1-zfs-receive-reservoir-data-received" class="headerlink" title="zfs send reservoir/data@snap1 zfs receive reservoir/data_received"></a>zfs send reservoir/data@snap1 zfs receive reservoir/data_received</h1><p>这样通过send和receive发送和接收快照流生成一个新的ZFS文件系统reservoir/data_snap_stream</p>
<p>使用 zfs send -i 选项可以发送增量数据。</p>
<p>例如:</p>
<h1 id="zfs-send-i-reservoir-data-snap1-reservoir-data-snap2-zfs-receive-reservoir-data-received"><a href="#zfs-send-i-reservoir-data-snap1-reservoir-data-snap2-zfs-receive-reservoir-data-received" class="headerlink" title="zfs send -i reservoir/data@snap1 reservoir/data@snap2 zfs receive reservoir/data_received"></a>zfs send -i reservoir/data@snap1 reservoir/data@snap2 zfs receive reservoir/data_received</h1><p>这里snap1是较早的快照,snap2是较晚的快照,而且reservoir/data_received必须已经存在而且已经接收了snap1快照流,增量接收才能成功。</p>
<p>可以通过SSH将快照流发送到远程系统</p>
<h1 id="zfs-send-reservoir-data-snap1-ssh-remote-system-zfs-receive-reservoir-data-received"><a href="#zfs-send-reservoir-data-snap1-ssh-remote-system-zfs-receive-reservoir-data-received" class="headerlink" title="zfs send reservoir/data@snap1 ssh remote_system zfs receive reservoir/data_received"></a>zfs send reservoir/data@snap1 ssh remote_system zfs receive reservoir/data_received</h1><p>还可以将快照流压缩归档保存</p>
<h1 id="zfs-send-reservoir-data-snap1-gzip-gt-data-gz"><a href="#zfs-send-reservoir-data-snap1-gzip-gt-data-gz" class="headerlink" title="zfs send reservoir/data@snap1 gzip &gt; data.gz"></a>zfs send reservoir/data@snap1 gzip &gt; data.gz</h1><p>然后可以接收压缩归档的快照流</p>
<h1 id="zfs-gunzip-c-data-gz-zfs-receive-reservoir-data-recv"><a href="#zfs-gunzip-c-data-gz-zfs-receive-reservoir-data-recv" class="headerlink" title="zfs gunzip -c data.gz zfs receive reservoir/data_recv"></a>zfs gunzip -c data.gz zfs receive reservoir/data_recv</h1><p>可以将发送接收ZFS快照流以及其增量机制作为备份ZFS文件系统的一种策略,但这种备份方式不能逐个恢复文件,必须恢复整个文件系统。</p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
        <tag>ZFS</tag>
      </tags>
  </entry>
  <entry>
    <title>开源可视化web编辑器BlueGriffon</title>
    <url>/2013/12/04/%E5%BC%80%E6%BA%90%E5%8F%AF%E8%A7%86%E5%8C%96web%E7%BC%96%E8%BE%91%E5%99%A8bluegriffon/</url>
    <content><![CDATA[<p>The next-generation Web Editor based on the rendering engine of Firefox.</p>
<a id="more"></a>
<p>支持HTML5和CSS3可视化编辑,前身为Nvu。</p>
<p>项目活跃，跨平台，开源，最新版本1.7.2。</p>
<p>从官方下载<a href="http://bluegriffon.org/freshmeat/1.7.2/bluegriffon-1.7.2.Ubuntu13.04.x86_64.tar.bz2">64位版本</a>,解压缩到/opt/目录，执行/opt/bluegriffon即可启动BlueGriffon。</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>手机发布test</title>
    <url>/2013/10/31/%E6%89%8B%E6%9C%BA%E5%8F%91%E5%B8%83test/</url>
    <content><![CDATA[<p>这是用wordpress手机客户端Wordpress for Android发表的第一篇post</p>
]]></content>
      <categories>
        <category>Misc</category>
      </categories>
  </entry>
  <entry>
    <title>显式label与隐式label</title>
    <url>/2014/05/22/%E6%98%BE%E7%A4%BAlabel%E4%B8%8E%E9%9A%90%E5%BC%8Flabel/</url>
    <content><![CDATA[<a id="more"></a>
<p>label元素平淡无奇，就是为表单输入元素贴上标签，方便辨识。label有个很重要的属性是for,可以将label与其标识的输入元素绑定在一起，提供更好的操作体验。</p>
<p><strong>显式label</strong></p>
<p>[html]<br><label for="foo"></label><input type="text" id="foo"><br>[/html]</p>
<p>重置和提交按钮,图片按钮以及button元素按钮不用使用显式label，因为它们已经有了隐式标签，如value 和 alt 属性值，button元素的内容。</p>
<p>显式的label对Accessibility是最友好的。</p>
<p><strong>隐式label</strong><br>将输入元素直接包裹在label标签之内,for属性也可以省略了,甚至输入元素的id也可以省略了。<br>[html]<br><label>sometext<input type="text"></label><br>[/html]<br>IE6不支持隐式label</p>
<p><strong>混合式label</strong><br>即使用label的for特性,又将输入元素包裹在label之内<br>[html]<br><label for="foo"><input type="text" id="foo"></label><br>[/html]</p>
<p>References:<br>[1]<a href="http://www.topcss.org/?p=349">表单显式LABEL和隐式LABEL对屏幕阅读器用户的影响–更新</a><br>[2]<a href="http://www.w3school.com.cn/tags/att_label_for.asp">HTML 标签的 for 属性</a></p>
<p> <strong>===<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title>烽火HG2201U改桥接</title>
    <url>/2019/07/24/%E7%83%BD%E7%81%ABhg2201u%E6%94%B9%E6%A1%A5%E6%8E%A5/</url>
    <content><![CDATA[<a id="more"></a>
<p>拿到配置文件就可以破译管理员密码了，只是base64编码了一下下，秒解码。<br>有两种方法可以拿到配置文件</p>
<p><strong>telnet方法</strong></p>
<p>用光猫后面提供的user密码登录，然后访问<a href="http://192.168.1.1/servmngr.html%EF%BC%8C%E7%95%8C%E9%9D%A2%E5%87%A0%E4%B9%8E%E6%98%AF%E5%85%A8%E7%99%BD%E7%9A%84%EF%BC%8C%E9%80%89%E6%8B%A9%E4%B8%80%E4%B8%8B%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E5%A4%A7%E9%83%A8%E5%88%86%E5%86%85%E5%AE%B9%E4%BA%86%EF%BC%8C%E5%90%AF%E7%94%A8telnet%E5%B9%B6%E8%AE%BE%E7%BD%AE%E4%B8%BA%E5%9C%A8LAN%E7%BD%91%E7%BB%9C%E7%9B%91%E5%90%AC%EF%BC%8C%E9%BB%98%E8%AE%A4%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81%E6%98%AFadmin/admin%EF%BC%8C%E5%8F%AF%E4%BB%A5%E4%BF%AE%E6%94%B9%EF%BC%8C%E7%84%B6%E5%90%8E">http://192.168.1.1/servmngr.html，界面几乎是全白的，选择一下就可以看到大部分内容了，启用telnet并设置为在LAN网络监听，默认账号密码是admin/admin，可以修改，然后</a></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">$ telnet <span class="number">192.168</span><span class="number">.1</span><span class="number">.1</span></span><br><span class="line">&gt; help</span><br><span class="line">&gt; dumpcfg</span><br></pre></td></tr></table></figure>
<p>找到</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;Web&gt;</span><br><span class="line"> &lt;UserPassword&gt;NXB1c2RmbTQA&lt;/UserPassword&gt;</span><br><span class="line"> &lt;AdminPassword&gt;Y3VhZG1pbxxxxxxNTgwAA==&lt;/AdminPassword&gt;</span><br><span class="line">&lt;/Web&gt;</span><br></pre></td></tr></table></figure>
<p>这一段，UserPassword就是光猫后面印刷的user账户的密码，AdminPassword就是管理员的密码了，都是base64编码的，随便找个在线服务解码一下好了。</p>
<p>telnet模式还可以执行sh获的shell，可以慢慢研究一下，跑的就是个linux系统</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&gt; sh</span><br><span class="line">BusyBox v1<span class="number">.17</span><span class="number">.2</span> (<span class="number">2018</span>-<span class="number">09</span>-<span class="number">04</span> <span class="number">20</span>:<span class="number">22</span>:<span class="number">42</span> CST) built-<span class="keyword">in</span> shell (ash)</span><br><span class="line">Enter <span class="string">&#x27;help&#x27;</span> <span class="keyword">for</span> a list <span class="keyword">of</span> built-<span class="keyword">in</span> commands.</span><br><span class="line"></span><br><span class="line"># uname -a</span><br><span class="line">Linux (none) 3.4.11-rt19 #1 SMP PREEMPT Tue Sep 4 18:24:42 CST 2018 mips GNU/Linux</span><br></pre></td></tr></table></figure>
<p>获得是特权shell，切记不要乱删东西。</p>
<p><strong>工程账号方法</strong></p>
<p>访问<a href="http://192.168.1.1/logoffaccount.html%EF%BC%8C%E9%9A%90%E8%97%8F%E8%B4%A6%E6%88%B7%E9%80%89%E6%8B%A9%E2%80%9C%E5%90%AF%E7%94%A8%E2%80%9D%EF%BC%8C&quot;%E4%BF%9D%E5%AD%98/%E5%BA%94%E7%94%A8&quot;%E4%B9%8B%E5%90%8E%EF%BC%8C%E8%B7%B3%E8%BD%AC%E5%88%B0http://192.168.1.1/logoffaccount.cmd?enableFactoryAccount=1%EF%BC%8C%E5%9C%A8%E6%AD%A4%E7%95%8C%E9%9D%A2%E4%B8%8B%E8%BE%93%E5%85%A5%E5%B7%A5%E5%8E%82%E8%B4%A6%E5%8F%B7%E7%9A%84%E5%AF%86%E7%A0%81%E2%80%9Chg2x0%E2%80%9D%E8%BF%9B%E5%85%A5%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F">http://192.168.1.1/logoffaccount.html，隐藏账户选择“启用”，&quot;保存/应用&quot;之后，跳转到http://192.168.1.1/logoffaccount.cmd?enableFactoryAccount=1，在此界面下输入工厂账号的密码“hg2x0”进入工厂模式</a></p>
<p>然后访问<a href="http://192.168.1.1/backupsettings.html%E9%A1%B5%E9%9D%A2,%E7%82%B9%E5%87%BB%E2%80%9C%E4%BF%9D%E5%AD%98/%E5%BA%94%E7%94%A8%E2%80%9D%E4%B8%8B%E8%BD%BD%E5%BD%93%E5%89%8D%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%E7%94%B5%E8%84%91%EF%BC%8C%E5%90%8E%E9%9D%A2%E5%B0%B1%E5%92%8C%E7%AC%AC%E4%B8%80%E4%B8%AA%E6%96%B9%E6%B3%95%E4%B8%80%E6%A0%B7%E4%BA%86%E3%80%82">http://192.168.1.1/backupsettings.html页面,点击“保存/应用”下载当前配置文件到本地电脑，后面就和第一个方法一样了。</a></p>
<p><strong>桥接模式</strong></p>
<p>访问<a href="http://192.168.1.1/cu.html%E9%A1%B5%E9%9D%A2%EF%BC%8C%E4%BD%BF%E7%94%A8%E7%AE%A1%E7%90%86%E5%91%98%E8%B4%A6%E6%88%B7%E7%99%BB%E5%BD%95%E5%85%89%E7%8C%AB%EF%BC%8C&quot;%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE&quot;-&gt;&quot;%E5%AE%BD%E5%B8%A6%E9%85%8D%E7%BD%AE&quot;%E7%95%8C%E9%9D%A2%E9%80%89%E6%8B%A9%E2%80%9C*_INTERNET_R_VID_*%E2%80%9D%E8%BF%99%E4%B8%AA%E8%BF%9E%E6%8E%A5%E5%90%8D%E7%A7%B0%EF%BC%8C%E6%94%B9%E4%B8%BA%E6%A1%A5%E6%8E%A5%E5%B0%B1%E5%A5%BD%E4%BA%86%EF%BC%8C%E6%AF%94%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E7%9A%84%E6%96%B9%E5%BC%8F%E7%AE%80%E5%8D%95%E4%B8%8D%E6%98%93%E5%87%BA%E9%94%99%E3%80%82">http://192.168.1.1/cu.html页面，使用管理员账户登录光猫，&quot;基本配置&quot;-&gt;&quot;宽带配置&quot;界面选择“*_INTERNET_R_VID_*”这个连接名称，改为桥接就好了，比修改配置文件上传的方式简单不易出错。</a></p>
<p>据说user用户登录后，直接访问<a href="http://192.168.1.1/fbctwanconfig.html%E4%B9%9F%E5%8F%AF%E4%BB%A5%E4%BF%AE%E6%94%B9%E6%A1%A5%E6%8E%A5%E6%A8%A1%E5%BC%8F%EF%BC%8C%E8%83%BD%E7%9C%8B%E5%88%B0%E9%85%8D%E7%BD%AE%E7%95%8C%E9%9D%A2%EF%BC%8C%E6%B2%A1%E6%9C%89%E5%B0%9D%E8%AF%95%E3%80%82">http://192.168.1.1/fbctwanconfig.html也可以修改桥接模式，能看到配置界面，没有尝试。</a></p>
<p>References:<br>[1]<a href="https://flyfish.im/liferecords/1698.html">上海联通光猫烽火HG2201U改桥接，路由拨号上网并做解析</a><br>[2]<a href="https://blog.acesheep.com/index.php/archives/608/">烽火HG2201U 5.0/5.01 版本 光猫改桥接 设置IPV6 超级管理员获取</a></p>
]]></content>
      <categories>
        <category>GNU/Linux</category>
      </categories>
      <tags>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>Dataguard配置中phsycia standby备库网络超时故障一例</title>
    <url>/2015/07/17/dataguar-standby-network-timeout/</url>
    <content><![CDATA[<a id="more"></a>
<p>本来DG已经配置为最大可用模式(maximize availability)了，也就是说如果物理备库无法访问，不应该影响主库的运行才对。<br>但是有一条光纤物理链路出现故障严重丢包，导致主库向其传输归档日志时出现超时错误，无法归档，导致主库运行十分缓慢，直至无法正常访问。</p>
<p>alert_orcl.log文件中有如下错误记录:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32</span> <span class="number">2015</span></span><br><span class="line">ORA-<span class="number">16198</span>: LGWR received timedout error <span class="keyword">from</span> KSR</span><br><span class="line">LGWR: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (<span class="number">16198</span>)</span><br><span class="line">LGWR: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span><br><span class="line">ORA-<span class="number">16198</span>: Timeout incurred on internal channel during remote archival</span><br><span class="line"></span><br><span class="line">LGWR: Network asynch I/O wait error <span class="number">16198</span> log <span class="number">1</span> service <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32</span> <span class="number">2015</span></span><br><span class="line">Destination LOG_ARCHIVE_DEST_3 is UNSYNCHRONIZED</span><br><span class="line">LGWR: Failed to archive log <span class="number">1</span> thread <span class="number">1</span> sequence <span class="number">4526</span> (<span class="number">16198</span>)</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span><br><span class="line">ORA-<span class="number">16198</span>: Timeout incurred on internal channel during remote archival</span><br><span class="line"></span><br><span class="line">LGWR: <span class="built_in">Error</span> <span class="number">16198</span> closing archivelog file <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">LGWR: <span class="built_in">Error</span> <span class="number">16198</span> disconnecting <span class="keyword">from</span> destination LOG_ARCHIVE_DEST_3 standby host <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">42</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4527</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4527</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">43</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4527</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 2 seq# 4527 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">18</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4528</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4528</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">18</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4528</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 3 seq# 4528 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO03.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">00</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4529</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4529</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">00</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4529</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 1 seq# 4529 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO01.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">05</span> <span class="number">2015</span></span><br><span class="line">ARC1: LGWR is actively archiving destination LOG_ARCHIVE_DEST_3</span><br><span class="line">ARC1: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4528</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_3</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">06</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> cannot allocate <span class="keyword">new</span> log, sequence <span class="number">4530</span></span><br><span class="line">Checkpoint not complete</span><br><span class="line"> Current log# 1 seq# 4529 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO01.LOG</span><br><span class="line">LNSc started <span class="keyword">with</span> pid=<span class="number">88</span>, OS id=<span class="number">3680</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">16</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4530</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4530</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_3</span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4530</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4530</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">21</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4530</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 2 seq# 4530 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">21</span> <span class="number">2015</span></span><br><span class="line">ARC0: LGWR is actively archiving destination LOG_ARCHIVE_DEST_3</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">44</span> <span class="number">2015</span></span><br><span class="line">ARC0: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4529</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_3</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">48</span>:<span class="number">36</span> <span class="number">2015</span></span><br><span class="line">ORA-<span class="number">16198</span>: LGWR received timedout error <span class="keyword">from</span> KSR</span><br><span class="line">LGWR: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (<span class="number">16198</span>)</span><br><span class="line">LGWR: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">48</span>:<span class="number">36</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span><br><span class="line">ORA-<span class="number">16198</span>: Timeout incurred on internal channel during remote archival</span><br><span class="line"></span><br><span class="line">LGWR: Network asynch I/O wait error <span class="number">16198</span> log <span class="number">2</span> service <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">50</span>:<span class="number">58</span> <span class="number">2015</span></span><br><span class="line">LGWR: Failed to archive log <span class="number">2</span> thread <span class="number">1</span> sequence <span class="number">4530</span> (<span class="number">16198</span>)</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">50</span>:<span class="number">58</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span><br><span class="line">ORA-<span class="number">16198</span>: Timeout incurred on internal channel during remote archival</span><br><span class="line"></span><br><span class="line">LGWR: <span class="built_in">Error</span> <span class="number">16198</span> closing archivelog file <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4531</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4531</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">51</span>:<span class="number">07</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4531</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 1 seq# 4531 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO01.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">54</span>:<span class="number">12</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> cannot allocate <span class="keyword">new</span> log, sequence <span class="number">4532</span></span><br><span class="line">All online logs needed archiving</span><br><span class="line"> Current log# 1 seq# 4531 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO01.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">56</span>:<span class="number">10</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4532</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4532</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">56</span>:<span class="number">10</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4532</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 2 seq# 4532 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">56</span>:<span class="number">10</span> <span class="number">2015</span></span><br><span class="line">ARC0: LGWR is actively archiving destination LOG_ARCHIVE_DEST_3</span><br><span class="line">ARC0: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4531</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_3</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">58</span>:<span class="number">53</span> <span class="number">2015</span></span><br><span class="line">ARC1: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (<span class="number">12571</span>)</span><br><span class="line">ARC1: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">58</span>:<span class="number">53</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span><br><span class="line">ORA-<span class="number">12571</span>: TNS:packet writer failure</span><br><span class="line"></span><br><span class="line">ARC1: I/O error <span class="number">12571</span> archiving log <span class="number">3</span> to <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">00</span>:<span class="number">58</span>:<span class="number">54</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span><br><span class="line">ORA-<span class="number">01041</span>: internal error. hostdef extension doesn<span class="string">&#x27;t exist</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ARC1: Error 1041 Closing archive log file &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">LNSc started with pid=46, OS id=3000</span></span><br><span class="line"><span class="string">Fri Jul 17 00:59:30 2015</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected to archive thread 1 sequence 4533</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected for thread 1 sequence 4533 for destination LOG_ARCHIVE_DEST_3</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected to archive thread 1 sequence 4533</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected for thread 1 sequence 4533 for destination LOG_ARCHIVE_DEST_2</span></span><br><span class="line"><span class="string">Fri Jul 17 00:59:35 2015</span></span><br><span class="line"><span class="string">Thread 1 advanced to log sequence 4533 (LGWR switch)</span></span><br><span class="line"><span class="string"> Current log# 3 seq# 4533 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO03.LOG</span></span><br><span class="line"><span class="string">Fri Jul 17 01:05:13 2015</span></span><br><span class="line"><span class="string">ORA-16198: LGWR received timedout error from KSR</span></span><br><span class="line"><span class="string">LGWR: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (16198)</span></span><br><span class="line"><span class="string">LGWR: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span></span><br><span class="line"><span class="string">Fri Jul 17 01:05:13 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span></span><br><span class="line"><span class="string">ORA-16198: Timeout incurred on internal channel during remote archival</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">LGWR: Network asynch I/O wait error 16198 log 3 service &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Fri Jul 17 01:07:52 2015</span></span><br><span class="line"><span class="string">Thread 1 cannot allocate new log, sequence 4534</span></span><br><span class="line"><span class="string">All online logs needed archiving</span></span><br><span class="line"><span class="string"> Current log# 3 seq# 4533 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO03.LOG</span></span><br><span class="line"><span class="string">Fri Jul 17 01:23:03 2015</span></span><br><span class="line"><span class="string">ARC1: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (12571)</span></span><br><span class="line"><span class="string">ARC1: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span></span><br><span class="line"><span class="string">Fri Jul 17 01:23:03 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span></span><br><span class="line"><span class="string">ORA-12571: TNS:packet writer failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">FAL\[server, ARC1\]: FAL archive failed, see trace file.</span></span><br><span class="line"><span class="string">Fri Jul 17 01:23:03 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span></span><br><span class="line"><span class="string">ORA-16055: FAL request rejected</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ARCH: FAL archive failed. Archiver continuing</span></span><br><span class="line"><span class="string">Fri Jul 17 02:01:41 2015</span></span><br><span class="line"><span class="string">&gt;&gt;&gt; WAITED TOO LONG FOR A ROW CACHE ENQUEUE LOCK! pid=128</span></span><br><span class="line"><span class="string">System State dumped to trace file e:\\oracle\\product\\10.2.0\\admin\\orcl\\udump\\orcl_ora_2960.trc</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:22 2015</span></span><br><span class="line"><span class="string">ARC1: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (12571)</span></span><br><span class="line"><span class="string">ARC1: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:22 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span></span><br><span class="line"><span class="string">ORA-12571: TNS:packet writer failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">FAL\[server, ARC1\]: FAL archive failed, see trace file.</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:22 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span></span><br><span class="line"><span class="string">ORA-16055: FAL request rejected</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ARCH: FAL archive failed. Archiver continuing</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:25 2015</span></span><br><span class="line"><span class="string">LGWR: Failed to archive log 3 thread 1 sequence 4533 (16198)</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:25 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span></span><br><span class="line"><span class="string">ORA-16198: Timeout incurred on internal channel during remote archival</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">LGWR: Error 16198 closing archivelog file &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">LGWR: Error 16198 disconnecting from destination LOG_ARCHIVE_DEST_3 standby host &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:36 2015</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected to archive thread 1 sequence 4534</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected for thread 1 sequence 4534 for destination LOG_ARCHIVE_DEST_2</span></span><br><span class="line"><span class="string">Fri Jul 17 02:05:36 2015</span></span><br><span class="line"><span class="string">Thread 1 advanced to log sequence 4534 (LGWR switch)</span></span><br><span class="line"><span class="string"> Current log# 2 seq# 4534 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span></span><br><span class="line"><span class="string">Fri Jul 17 02:07:39 2015</span></span><br><span class="line"><span class="string">Thread 1 cannot allocate new log, sequence 4535</span></span><br><span class="line"><span class="string">All online logs needed archiving</span></span><br><span class="line"><span class="string"> Current log# 2 seq# 4534 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span></span><br><span class="line"><span class="string">LNSc started with pid=44, OS id=3356</span></span><br><span class="line"><span class="string">Fri Jul 17 02:11:42 2015</span></span><br><span class="line"><span class="string">Error 12637 received logging on to the standby</span></span><br><span class="line"><span class="string">Fri Jul 17 02:11:42 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span></span><br><span class="line"><span class="string">ORA-12637: Packet receive failed</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PING\[ARC1\]: Heartbeat failed to connect to standby &#x27;</span>db_feich<span class="string">&#x27;. Error is 12637.</span></span><br><span class="line"><span class="string">Fri Jul 17 02:12:02 2015</span></span><br><span class="line"><span class="string">Error 28547 received logging on to the standby</span></span><br><span class="line"><span class="string">Fri Jul 17 02:12:06 2015</span></span><br><span class="line"><span class="string">LGWR: Error 28547 creating archivelog file &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Fri Jul 17 02:12:06 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span></span><br><span class="line"><span class="string">ORA-28547: connection to server failed, probable Oracle Net admin error</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected to archive thread 1 sequence 4535</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected for thread 1 sequence 4535 for destination LOG_ARCHIVE_DEST_2</span></span><br><span class="line"><span class="string">Fri Jul 17 02:12:11 2015</span></span><br><span class="line"><span class="string">Thread 1 advanced to log sequence 4535 (LGWR switch)</span></span><br><span class="line"><span class="string"> Current log# 3 seq# 4535 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO03.LOG</span></span><br><span class="line"><span class="string">Fri Jul 17 02:14:11 2015</span></span><br><span class="line"><span class="string">Thread 1 cannot allocate new log, sequence 4536</span></span><br><span class="line"><span class="string">All online logs needed archiving</span></span><br><span class="line"><span class="string"> Current log# 3 seq# 4535 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO03.LOG</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:20 2015</span></span><br><span class="line"><span class="string">LGWR: Failed to archive log 3 thread 1 sequence 4535 (28547)</span></span><br><span class="line"><span class="string">LNSc started with pid=46, OS id=4036</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:33 2015</span></span><br><span class="line"><span class="string">Error 12170 received logging on to the standby</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:33 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc1_2584.trc:</span></span><br><span class="line"><span class="string">ORA-12170: TNS:Connect timeout occurred</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PING\[ARC1\]: Heartbeat failed to connect to standby &#x27;</span>db_feich<span class="string">&#x27;. Error is 12170.</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:44 2015</span></span><br><span class="line"><span class="string">Error 12170 received logging on to the standby</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:48 2015</span></span><br><span class="line"><span class="string">LGWR: Error 12170 creating archivelog file &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:48 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_lgwr_1568.trc:</span></span><br><span class="line"><span class="string">ORA-12170: TNS:Connect timeout occurred</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:53 2015</span></span><br><span class="line"><span class="string">ARC0: Attempting destination LOG_ARCHIVE_DEST_3 network reconnect (12571)</span></span><br><span class="line"><span class="string">ARC0: Destination LOG_ARCHIVE_DEST_3 network reconnect abandoned</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:53 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc0_2784.trc:</span></span><br><span class="line"><span class="string">ORA-12571: TNS:packet writer failure</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ARC0: I/O error 12571 archiving log 1 to &#x27;</span>db_feich<span class="string">&#x27;</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:53 2015</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected to archive thread 1 sequence 4536</span></span><br><span class="line"><span class="string">LGWR: Standby redo logfile selected for thread 1 sequence 4536 for destination LOG_ARCHIVE_DEST_2</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:53 2015</span></span><br><span class="line"><span class="string">Thread 1 advanced to log sequence 4536 (LGWR switch)</span></span><br><span class="line"><span class="string"> Current log# 2 seq# 4536 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span></span><br><span class="line"><span class="string">Fri Jul 17 02:17:57 2015</span></span><br><span class="line"><span class="string">Errors in file e:\\oracle\\product\\10.2.0\\admin\\orcl\\bdump\\orcl_arc0_2784.trc:</span></span><br><span class="line"><span class="string">ORA-01041: internal error. hostdef extension doesn&#x27;</span>t exist</span><br><span class="line"></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">17</span>:<span class="number">57</span> <span class="number">2015</span></span><br><span class="line">ARC0: <span class="built_in">Error</span> <span class="number">1041</span> Closing archive log file <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">19</span>:<span class="number">45</span> <span class="number">2015</span></span><br><span class="line">LGWR: Failed to archive log <span class="number">2</span> thread <span class="number">1</span> sequence <span class="number">4536</span> (<span class="number">12170</span>)</span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4537</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4537</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">19</span>:<span class="number">51</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4537</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 1 seq# 4537 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO01.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">21</span>:<span class="number">23</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4538</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4538</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">21</span>:<span class="number">23</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4538</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 3 seq# 4538 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO03.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">22</span>:<span class="number">55</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4539</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4539</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">22</span>:<span class="number">55</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4539</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 2 seq# 4539 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO02.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">22</span>:<span class="number">55</span> <span class="number">2015</span></span><br><span class="line">ARC0: LGWR is actively archiving destination LOG_ARCHIVE_DEST_3</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">23</span>:<span class="number">16</span> <span class="number">2015</span></span><br><span class="line"><span class="built_in">Error</span> <span class="number">12170</span> received logging on to the standby</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">02</span>:<span class="number">23</span>:<span class="number">16</span> <span class="number">2015</span></span><br><span class="line">Errors <span class="keyword">in</span> file e:\\oracle\\product\\<span class="number">10.2</span><span class="number">.0</span>\\admin\\orcl\\bdump\\orcl_arc0_2784.trc:</span><br><span class="line">ORA-<span class="number">12170</span>: TNS:Connect timeout occurred</span><br><span class="line"></span><br><span class="line">ARC0: <span class="built_in">Error</span> <span class="number">12170</span> Creating archive log file to <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">05</span>:<span class="number">22</span>:<span class="number">08</span> <span class="number">2015</span></span><br><span class="line">LGWR: Standby redo logfile selected to archive thread <span class="number">1</span> sequence <span class="number">4540</span></span><br><span class="line">LGWR: Standby redo logfile selected <span class="keyword">for</span> thread <span class="number">1</span> sequence <span class="number">4540</span> <span class="keyword">for</span> destination LOG_ARCHIVE_DEST_2</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">05</span>:<span class="number">22</span>:<span class="number">08</span> <span class="number">2015</span></span><br><span class="line">Thread <span class="number">1</span> advanced to log sequence <span class="number">4540</span> (LGWR <span class="keyword">switch</span>)</span><br><span class="line"> Current log# 1 seq# 4540 mem# 0: E:\\ORACLE\\PRODUCT\\10.2.0\\ORADATA\\ORCL\\REDO01.LOG</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">05</span>:<span class="number">23</span>:<span class="number">19</span> <span class="number">2015</span></span><br><span class="line">Suppressing further error logging <span class="keyword">of</span> LOG_ARCHIVE_DEST_3.</span><br><span class="line">Fri Jul <span class="number">17</span> <span class="number">05</span>:<span class="number">23</span>:<span class="number">40</span> <span class="number">2015</span></span><br><span class="line"><span class="built_in">Error</span> <span class="number">12170</span> received logging on to the standby</span><br><span class="line">Suppressing further error logging <span class="keyword">of</span> LOG_ARCHIVE_DEST_3.</span><br></pre></td></tr></table></figure>

<p>这错误从早上０点多就出现了。<br>trace文件中有如下错误：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32.348</span> <span class="number">57480</span> kcrr.c</span><br><span class="line">Making upinblc request to LNSc (ocis <span class="number">0x000000001677E828</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">2832</span></span><br><span class="line">LGWR had received a timeout previously. <span class="keyword">return</span> timeout again</span><br><span class="line">LGWR had received a timeout previously. <span class="keyword">return</span> timeout again</span><br><span class="line"><span class="built_in">Error</span> <span class="number">16198</span> closing standby archive log file at host <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">ORA-<span class="number">16198</span>: Timeout incurred on internal channel during remote archival</span><br><span class="line">Archive destination LOG_ARCHIVE_DEST_3 made inactive: File close error</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32.351</span> <span class="number">62692</span> kcrr.c</span><br><span class="line">LGWR: <span class="built_in">Error</span> <span class="number">16198</span> closing archivelog file <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">LGWR had received a timeout previously. <span class="keyword">return</span> timeout again</span><br><span class="line"><span class="built_in">Error</span> <span class="number">16198</span> detaching RFS <span class="keyword">from</span> standby instance at host <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32.392</span> <span class="number">57269</span> kcrr.c</span><br><span class="line">Making upidhs request to LNSc (ocis <span class="number">0x000000001677E828</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">32</span>&gt; and NET_TIMEOUT &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">2832</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">36.392</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">36.392</span> <span class="number">57391</span> kcrr.c</span><br><span class="line">Cleaninup up LNS12 \[pid <span class="number">2832</span>\] after network detach</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">36.397</span> <span class="number">54392</span> kcrr.c</span><br><span class="line">LNSc \[pid <span class="number">2832</span>\] receiving termination signal..</span><br><span class="line"> .... killed successfully</span><br><span class="line"> .. pmon posted <span class="keyword">for</span> <span class="keyword">async</span> lns cleanup</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">37.597</span> <span class="number">62692</span> kcrr.c</span><br><span class="line">LGWR: <span class="built_in">Error</span> <span class="number">16198</span> disconnecting <span class="keyword">from</span> destination LOG_ARCHIVE_DEST_3 standby host <span class="string">&#x27;db_feich&#x27;</span></span><br><span class="line">Ignoring krslcmp() detach error <span class="number">16198</span></span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">42.863</span> <span class="number">57625</span> kcrr.c</span><br><span class="line">Making upinbls request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">34</span>:<span class="number">37</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">13.051</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">13.051</span> <span class="number">57480</span> kcrr.c</span><br><span class="line">Making upinblc request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">13</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">18.509</span> <span class="number">57625</span> kcrr.c</span><br><span class="line">Making upinbls request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">37</span>:<span class="number">13</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">39</span>:<span class="number">54.545</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">39</span>:<span class="number">54.545</span> <span class="number">57480</span> kcrr.c</span><br><span class="line">Making upinblc request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">39</span>:<span class="number">54</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">00</span><span class="number">.802</span> <span class="number">57625</span> kcrr.c</span><br><span class="line">Making upinbls request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">39</span>:<span class="number">54</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">12.967</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">12.967</span> <span class="number">57480</span> kcrr.c</span><br><span class="line">Making upinblc request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">12</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">13.066</span> <span class="number">55452</span> kcrr.c</span><br><span class="line">Initializing NetServer\[LNSc\] <span class="keyword">for</span> dest=db_feich mode SYNC</span><br><span class="line">LNSc is not running anymore. </span><br><span class="line">New SYNC LNSc needs to be started</span><br><span class="line">Waiting <span class="keyword">for</span> subscriber count on LGWR-LNSc channel to go to zero</span><br><span class="line">Subscriber count went to zero - time now is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">13</span>&gt;</span><br><span class="line">Starting LNSc ...</span><br><span class="line">Waiting <span class="keyword">for</span> LNSc to initialize itself</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">16.083</span> <span class="number">55743</span> kcrr.c</span><br><span class="line">Netserver LNSc \[pid <span class="number">3680</span>\] <span class="keyword">for</span> mode SYNC has been initialized</span><br><span class="line">Performing a channel reset to ignore previous responses</span><br><span class="line">Successfully started LNSc \[pid <span class="number">3680</span>\] <span class="keyword">for</span> dest db_feich mode SYNC ocis=<span class="number">0x000000001677E828</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">16.083</span> <span class="number">56246</span> kcrr.c</span><br><span class="line">Making upiahm request to LNSc \[pid <span class="number">3680</span>\]: Begin Time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">13</span>&gt;. NET_TIMEOUT = &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">Waiting <span class="keyword">for</span> LNSc to respond to upiahm</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">16.156</span> <span class="number">56410</span> kcrr.c</span><br><span class="line"> upiahm connect done status is <span class="number">0</span></span><br><span class="line">Receiving message <span class="keyword">from</span> LNSc</span><br><span class="line">Receiving message <span class="keyword">from</span> LNSc</span><br><span class="line">Receiving message <span class="keyword">from</span> LNSc</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">16.508</span> <span class="number">57625</span> kcrr.c</span><br><span class="line">Making upinbls request to LNSc (ocis <span class="number">0x000000001677E828</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">13</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3680</span></span><br><span class="line">Receiving message <span class="keyword">from</span> LNSb</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">21.818</span> <span class="number">57625</span> kcrr.c</span><br><span class="line">Making upinbls request to LNSb (ocis <span class="number">0x000000001677E580</span>). Begin time is &lt;<span class="number">07</span>/<span class="number">17</span>/<span class="number">2015</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">16</span>&gt; and NET_TIMEOUT is &lt;<span class="number">180</span>&gt; seconds</span><br><span class="line">NetServer pid:<span class="number">3584</span></span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">42.129</span></span><br><span class="line">LGWR found LNSc alive.. waiting <span class="keyword">for</span> msg</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">40</span>:<span class="number">52.140</span></span><br><span class="line">LGWR found LNSc alive.. waiting <span class="keyword">for</span> msg</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">41</span>:<span class="number">03</span><span class="number">.356</span></span><br><span class="line">LGWR found LNSc alive.. waiting <span class="keyword">for</span> msg</span><br><span class="line">*** <span class="number">2015</span>-<span class="number">07</span>-<span class="number">17</span> <span class="number">00</span>:<span class="number">41</span>:<span class="number">18.972</span></span><br></pre></td></tr></table></figure>

<p>按官方文档讲，DG最大可用模式下备库不可用是可以自动降级到最大性能模式的，但这次没有，主库的运行受到了影响。<br>因为物理链路修复没有时间表，因此当务之急时先略过或禁用出故障的备库。</p>
<p>首先尝试将DG降级到最大性能模式：<br>[sql]<br>SQL&gt;alter database set standby database to maximize performance;<br>[/sql]</p>
<p>无果</p>
<p>禁用出故障的备库：<br>[sql]<br>SQL&gt;alter system set log_archive_dest_state_3 = defer;<br>SQL&gt;shutdown immediate<br>SQL&gt;startup<br>[/sql]<br>故障解除。而且需要重新启动数据库。</p>
<p>LOG_ARCHIVE_DEST_STATE_n参数，可以取值alternate reset defer enable，其含义如下：</p>
<ul>
<li><p>  alternate<br>备用。只有当其他归档目标失效时才尝试使用本归档目标。</p>
</li>
<li><p>  defer<br>保留配置信息，但从归档目标中删除，直到重新启用。</p>
</li>
<li><p>  enable<br>启用。这是默认值。</p>
</li>
<li><p>*UPDATE(06/05/2016):**</p>
</li>
</ul>
<p>在未禁用有网络故障的standby备库的情况下，如果重新启动数据库，有可能startup过程会一直卡在Database mounted.处</p>
<p>从alert.log看，主库正在向有网络故障的备库同步归档日志文件，因为网络不通畅就卡住了，此时将备库禁用后，重新启动数据库就可以了。</p>
<p><strong>====<br>[erq]</strong></p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Oracle</tag>
      </tags>
  </entry>
  <entry>
    <title>GUI之窗口过程thunk</title>
    <url>/2009/06/04/gui-wndproc-thunk/</url>
    <content><![CDATA[<p>thunk是什么？查字典只能让人一头雾水。thunk是一段插入程序中实现特定功能的二进制代码，这个定义是我下的，对不对各位看官请自己斟酌，呵呵。</p>
<p>我这里要讲的是窗口回调专用thunk，thunk的核心是调用栈动态修改技术。地球人都知道，windows的窗口回调函数是一个全局函数，类成员函数 是不可以作为窗口回调函数的，因为它有this指针，这给我们用C++来包装窗口带来不小的麻烦。你说什么？用一个全局函数或类的静态成员函数来做窗口回 调函数？这肯定没问题。但是这样带来的麻烦也许比你想象的要多，想想我们的GUI Framework不会只有一个类，而是一个类层级结构，会有许许多许多、形形色色的widget，每个都是一个窗口。对象与窗口之间的映射可能就是个不 小的问题，像MFC那样搞？太落伍了吧！用thunk就要简单的多。WTL用了thunk，但是不够彻底。<br>废话少说，先贴出thunk核心代码。</p>
<a id="more"></a>
<p> 20 /*<br> 21  *  thunk with DEP support<br> 22  *<br> 23  *  author:proguru<br> 24  *  July 9,2008<br> 25 <em>/<br> 26 /</em><br> 27  *  modify x64 thunk code according to the feedback from Loaden<br> 28  *  “<a href="http://topic.csdn.net/u/20090322/08/b6bf82ca-8ba2-452b-92f8-bb2adb05a1ef.html">http://topic.csdn.net/u/20090322/08/b6bf82ca-8ba2-452b-92f8-bb2adb05a1ef.html</a>“<br> 29  *  maybe also “<a href="http://www.qpsoft.com/blog/x64-thunk-callback-conversion/">http://www.qpsoft.com/blog/x64-thunk-callback-conversion/</a>“<br> 30 *<br> 31  *  proguru<br> 32  *  June 04,2009<br> 33 <em>/<br> 34<br> 35 #ifndef <strong>KTHUNK_H__<br> 36 #define __KTHUNK_H</strong><br> 37 #include “windows.h”<br> 38  <br> 39 <strong>namespace</strong> kwinui{<br> 40<br> 41 //#define USE_THISCALL_CONVENTION   //turn it off for c++ builder compatibility<br> 42<br> 43 #ifdef USE_THISCALL_CONVENTION<br> 44 #define WNDPROC_THUNK_LENGTH 29 //For __thiscall calling convention ONLY,assign m_hWnd by thunk<br> 45 #define GENERAL_THUNK_LENGTH 10<br> 46 #define KCALLBACK //__thiscall is default<br> 47 #else<br> 48 #define WNDPROC_THUNK_LENGTH 22 //__stdcall calling convention ONLY,assign m_hWnd by thunk<br> 49 #define GENERAL_THUNK_LENGTH 16<br> 50     #define KCALLBACK __stdcall<br> 51 #endif<br> 52<br> 53 #define WNDPROC_THUNK_LENGTH_X64 28<br> 54 #define GENERAL_THUNK_LENGTH_X64 34<br> 55<br> 56 <strong>static</strong> HANDLE g_hHeapExecutable;<br> 57<br> 58 <strong>class</strong> KThunkBase{<br> 59 <strong>public</strong>:<br> 60     KThunkBase(SIZE_T size){<br> 61         <strong>if</strong>(!g_hHeapExecutable){       //first thunk,create the executable heap<br> 62             g_hHeapExecutable=::HeapCreate(HEAP_CREATE_ENABLE_EXECUTE,0,0);<br> 63             //if (!g_hHeapExecutable) abort<br> 64         }<br> 65         m_szMachineCode=(<strong>unsigned</strong> <strong>char</strong></em>)::HeapAlloc(g_hHeapExecutable,HEAP_ZERO_MEMORY,size);<br> 66     }<br> 67     ~KThunkBase(){<br> 68         <strong>if</strong>(g_hHeapExecutable)<br> 69             ::HeapFree(g_hHeapExecutable,0,(<strong>void*<strong>)m_szMachineCode);<br> 70     }<br> 71     **inline</strong> *<em>void</em></strong> GetThunkedCodePtr(){<strong>return</strong> &amp;m_szMachineCode[0];}<br> 72 <strong>protected</strong>:<br> 73     <strong>unsigned</strong> *<em>char**</em> m_szMachineCode;<br> 74 };<br> 75<br> 76 <strong>class</strong> KWndProcThunk : <strong>public</strong> KThunkBase{<br> 77 <strong>public</strong>:<br> 78 #ifndef _WIN64<br> 79     KWndProcThunk():KThunkBase(WNDPROC_THUNK_LENGTH){}<br> 80 #else   //_WIN64<br> 81     KWndProcThunk():KThunkBase(WNDPROC_THUNK_LENGTH_X64){}<br> 82 #endif<br> 83<br> 84     <strong>void</strong> Init(INT_PTR pThis, INT_PTR ProcPtr){<br> 85 #ifndef _WIN64<br> 86 #pragma warning(disable: 4311)<br> 87         DWORD dwDistance =(DWORD)(ProcPtr) - (DWORD)(&amp;m_szMachineCode[0]) - WNDPROC_THUNK_LENGTH;<br> 88         #pragma warning(<strong>default</strong>: 4311)<br> 89<br> 90     #ifdef USE_THISCALL_CONVENTION<br> 91         /*<br> 92         For __thiscall, the default calling convention used by Microsoft VC++, The thing needed is<br> 93         just set ECX with the value of ‘this pointer’<br> 94<br> 95         machine code                    assembly instruction        comment<br> 96         —————————     ————————-   ———-<br> 97         B9 ?? ?? ?? ??                  mov ecx, pThis              ;Load ecx with this pointer<br> 98 50                              PUSH EAX<br> 99         8B 44 24 08                     MOV EAX, DWORD PTR[ESP+8]   ;EAX=hWnd<br>100         89 01                           MOV DWORD PTR [ECX], EAX    ;[pThis]=[ECX]=hWnd<br>101         8B 44 24 04                     mov eax,DWORD PTR [ESP+04H] ;eax=(return address)<br>102         89 44 24 08                     mov DWORD PTR [ESP+08h],eax ;hWnd=(return address)<br>103 58                              POP EAX<br>104 83 C4 04                        add ESP,04h<br>105<br>106         E9 ?? ?? ?? ??                  jmp ProcPtr                 ;Jump to target message handler<br>107 <em>/<br>108         m_szMachineCode[0]                = 0xB9;<br>109         <em>((DWORD</em>)&amp;m_szMachineCode[1] ) =(DWORD)pThis;<br>110         <em>((DWORD</em>)&amp;m_szMachineCode[5] )   =0x24448B50;  <br>111         <em>((DWORD</em>)&amp;m_szMachineCode[9] )   =0x8B018908;<br>112         <em>((DWORD</em>)&amp;m_szMachineCode[13])   =0x89042444;<br>113         <em>((DWORD</em>)&amp;m_szMachineCode[17])   =0x58082444;<br>114         <em>((DWORD</em>)&amp;m_szMachineCode[21])   =0xE904C483;<br>115         <em>((DWORD</em>)&amp;m_szMachineCode[25]) =dwDistance;  <br>116     #else  <br>117         /</em><br>118          * 01/26/2008 modify<br>119         For __stdcall calling convention, replace ‘HWND’ with ‘this pointer’<br>120<br>121         Stack frame before inserting            Stack frame after inserting<br>122<br>123         :      …      :                       :       …      :<br>124         —————                       —————-<br>125 lParam                                lParam<br>126         —————                       —————-<br>127 wParam                                wParam<br>128         —————                       —————-<br>129 uMsg                                  uMsg<br>130         —————                       —————-<br>131              hWnd                             <this pointer><br>132         —————                       —————-<br>133          (Return Addr) &lt;- ESP                 (Return Addr)   &lt;-ESP<br>134         —————                       —————-<br>135 :      …      :                       :       …<br>136<br>137         machine code        assembly instruction            comment<br>138         ——————- —————————-    ————–<br>139         51                  push ecx<br>140         B8 ?? ?? ?? ??      mov  eax,pThis                  ;eax=this;<br>141         8B 4C 24 08         mov  ecx,dword ptr [esp+08H]    ;ecx=hWnd;<br>142 89 08               mov  dword ptr [eax],ecx        ;[this]=hWnd,if has vftbl shound [this+4]=hWnd<br>143         89 44 24 08         mov  dword ptr [esp+08H], eax   ;Overwite the ‘hWnd’ with ‘this pointer’<br>144         59                  pop  ecx<br>145         E9 ?? ?? ?? ??      jmp  ProcPtr                    ; Jump to target message handler<br>146 <em>/<br>147<br>148         *((WORD  *) &amp;m_szMachineCode[ 0]) = 0xB851;<br>149         *((DWORD *) &amp;m_szMachineCode[ 2]) = (DWORD)pThis;<br>150         *((DWORD *) &amp;m_szMachineCode[ 6]) = 0x08244C8B;<br>151         *((DWORD *) &amp;m_szMachineCode[10]) = 0x44890889;<br>152         *((DWORD *) &amp;m_szMachineCode[14]) = 0xE9590824;<br>153         *((DWORD *) &amp;m_szMachineCode[18]) = (DWORD)dwDistance;<br>154     #endif //USE_THISCALL_CONVENTION<br>155 #else   //_WIN64<br>156         /</em><br>157         For x64 calling convention, RCX hold the ‘HWND’,copy the ‘HWND’ to Window object,<br>158 then insert ‘this pointer’ into RCX,so perfectly!!!<br>159<br>160         Stack frame before modify               Stack frame after modify<br>161<br>162         :      …      :                       :       …      :<br>163         —————                       —————-<br>164                        &lt;-R9(lParam)                           &lt;-R9(lParam)<br>165         —————                       —————-<br>166                        &lt;-R8(wParam)                           &lt;-R8(wParam)<br>167         —————                       —————-<br>168                        &lt;-RDX(msg)                             &lt;-RDX(msg)<br>169         —————                       —————-<br>170                        &lt;-RCX(hWnd)                            &lt;-RCX(this)<br>171         —————                       —————-<br>172          (Return Addr) &lt;-RSP                 (Return Addr)   &lt;-RSP<br>173         —————                       —————-<br>174         :      …      :                       :   …  :<br>175<br>176         machine code            assembly instruction    comment<br>177         ——————-     ———————– —-<br>178         48B8 ????????????????   mov RAX,pThis<br>179         #4808                   mov qword ptr [RAX],RCX ;m_hWnd=[this]=RCX<br>180         488908                  mov qword ptr [RAX],RCX ;m_hWnd=[this]=RCX //feedback from Loaden<br>181         4889C1                  mov RCX,RAX             ;RCX=pThis (488BC8 ?)<br>182         48B8 ????????????????   mov RAX,ProcPtr<br>183 FFE0                    jmp RAX<br>184 <em>/<br>185         <em>((WORD   *)&amp;m_szMachineCode[0] ) =0xB848;<br>186         *((INT_PTR</em>)&amp;m_szMachineCode[2] ) =pThis;<br>187         //</em>((DWORD  <em>)&amp;m_szMachineCode[10])   =0x89480848;<br>188         *((DWORD  *)&amp;m_szMachineCode[10]) =0x48088948;<br>189         //</em>((DWORD  <em>)&amp;m_szMachineCode[14])   =0x00B848C1;<br>190         *((DWORD  *)&amp;m_szMachineCode[14]) =0xB848C189;<br>191         //</em>((INT_PTR*)&amp;m_szMachineCode[17])   =ProcPtr;<br>192         <em>((INT_PTR</em>)&amp;m_szMachineCode[18]) =ProcPtr;<br>193         //*((WORD   *)&amp;m_szMachineCode[25])   =0xE0FF;<br>194         *((WORD   *)&amp;m_szMachineCode[26]) =0xE0FF;<br>195 #endif<br>196     }<br>197 };  </p>
<p>是不是有些头晕？且待我慢慢分解。<br>类成员函数有两种调用约定，MS VC++默认采用thiscall调用约定，而Borland C++默认采用stdcall调用约定。thiscall采用ECX寄存器来传递this指针，而stdcall则通过栈来传递this指针，this指 针是成员函数隐藏的第一个参数。而到了x64平台，则问题有了新的变化。为了充分利用寄存器，提高效率，函数的前四个参数默认用寄存器传递，分别是 RCX,RDX,R8和R9。对于成员函数，其this指针通过RCX传递。x64 thunk代码我并未测试过，因为一直未使用x64平台，不过应该不会有太大问题。</p>
<p>在这里，我只分析x86平台上使用stdcall调用习惯的thunk代码。因为这段代码将窗口回调函数调用栈上的HWND直接修改this指针，所以有两个问题需要提前了解一下。<br>第一、我将回调函数的signature修改为如下形式：<br>LRESULT KCALLBACK KWndProc(UINT uMsg, WPARAM wParam, LPARAM lParam) ;<br>请注意这是个成员函数，而且没有HWND hWnd这个参数。<br>第二、窗口类的第一个数据成员必须是窗口句柄变量，我的是HWND m_hWnd.至于为什么要这样，后面会有提及。<br>现在请看代码第85行开始的图形，前一个是修改前windows调用我们提供的回调函数的栈结构，后一个则是为了适应我们的需求修改过后的调用栈。首先， 我们的回调函数需要一个this指针，而且要放到栈上第一个参数的位置上，这是通过第46行的thunk初始化函数Init传递进来的。其次我们的窗口对象必须要得到自己所对应的窗口句柄，不然一切都是空谈。</p>
<p>那么我们可以用thunk来修改调用栈。首先用初始栈上的第一个参数，也就是实际的窗口句柄，传递给窗口对象。如何传递呢？因为m_hWnd成员是对象的 第一个数据成员，那么很简单，如果没有虚函数的存在，那么这个m_hWnd就静静地待在对象的最开始处，就是this指针所指向的位置。如果有虚函数的存 在，那么事情也不是太复杂，对象的起始处现在是VPTR,m_hWnd紧随其后，代码略作调整即可。其次用this指针覆盖栈上的第一个参数，也就是窗口 句柄HWND。下面是逐条注释的汇编格式指令：<br>1 push ecx                        ;保护ecx，后面会用到<br>2 mov  eax,pThis                  ;传送this指针到eax. eax=this;<br>3 mov  ecx,dword ptr [esp+08H]    ;把调用栈上的第一个参数送ecx. ecx=hWnd<br>4 mov  dword ptr [eax],ecx        ;把窗口句柄赋予窗口对象数据成员m_hWnd.<br>5                                 ;[this]=hWnd,if has vftbl shound [this+4]=hWnd<br>6 mov  dword ptr [esp+08H], eax   ;用this指针覆盖调用栈上的第一个参数即窗口句柄<br>7                                 ;Overwite the ‘hWnd’ with ‘this pointer’<br>8 pop  ecx                        ;弹出先前ecx<br>9 jmp  ProcPtr                    ;跳转到消息处理函数.Jump to target message handler  </p>
<p>这样就把窗口(句柄)和窗口对象完美的绑定到一起，不需要一个对应查找表，不使用任何全局或静态的数据，满足thread safe。</p>
<p>至于汇编格式指令翻译到机器码的问题，下载intel的指令手册，查查表就可以了。<br>下面的代码展示了thunk的使用(删除了不相干的代码)：<br> 1 <strong>template</strong> &lt;**typename** T,**typename** TBase=KWindow&gt;<br> 2 <strong>class</strong> KWindowRoot : <strong>public</strong> TBase{<br> 3 <strong>public</strong>:<br> 4     KWindowRoot():TBase(){<br> 5         T* pT=<strong>static_cast</strong>&lt;T*&gt;(<strong>this</strong>);<br> 6         m_thunk.Init((INT_PTR)pT, pT-&gt;GetMessageProcPtr());<br> 7     }<br> 8  <br> 9     INT_PTR GetMessageProcPtr(){<br>10         <strong>typedef</strong> LRESULT (KCALLBACK T::<em>KWndProc_t)(UINT,WPARAM,LPARAM);<br>11         <br>12         <strong>union</strong>{<br>13             KWndProc_t     wndproc;<br>14             INT_PTR        dwProcAddr;<br>15         }u;<br>16         u.wndproc=&amp;T::KWndProc;<br>17         <strong>return</strong> u.dwProcAddr;<br>18     }<br>19  <br>20     LRESULT KCALLBACK KWndProc(UINT uMsg, WPARAM wParam, LPARAM lParam){<br>21         T</em> pT=<strong>static_cast</strong>&lt;T*&gt;(<strong>this</strong>);<br>22         <strong>return</strong> pT-&gt;ProcessWindowMessage(uMsg,wParam,lParam);<br>23     }<br>24  <br>25 <strong>protected</strong>:<br>26     KWndProcThunk   m_thunk;<br>27     <strong>inline</strong> INT_PTR GetThunkedProcPtr(){<strong>return</strong> (INT_PTR)m_thunk.GetThunkedCodePtr();}<br>28 };  </p>
<p>在基类KWindow中HWND m_hWnd是其第一个数据成员。因为使用了模板的静态多态特性，故对象没有VPTR指针。<br>到了这里事情还没有结束。既然使用thunk就不得不面对DEP。DEP会阻止没有执行权限的内存执行代码。如果我们的thunk分配在栈上或new出来的堆上，则会被DEP阻止，程序执行失败。因此可以申请一个具有执行权限的堆来解决这个问题：<br>1 KThunkBase(SIZE_T size){<br>2     <strong>if</strong>(!g_hHeapExecutable){        //first thunk,create the executable heap<br>3         g_hHeapExecutable=::HeapCreate(HEAP_CREATE_ENABLE_EXECUTE,0,0);<br>4         //if (!g_hHeapExecutable) abort<br>5     }<br>6     m_szMachineCode=(<strong>unsigned</strong> *<em>char**</em>)::HeapAlloc(g_hHeapExecutable,HEAP_ZERO_MEMORY,size);<br>7 }  </p>
<p>总的来讲thunk的空间和时间开销都是足够小的，甚至可以忽略不计。但是却带来了极大的便利。<br>thunk只是开了一个头。</p>
<p>PS:<a href="http://www.cppblog.com/proguru/archive/2008/08/24/59831.html">原文</a>早先发表于cppblog。根据 Loaden的反馈做了关于x64的修订。</p>
]]></content>
      <categories>
        <category>KWinUI</category>
      </categories>
      <tags>
        <tag>KWinUI</tag>
      </tags>
  </entry>
</search>
